user_input,retrieved_contexts,response,reference,context_precision,faithfulness,answer_relevancy
What is the primary motivation for integrating security during the requirements analysis phase?,"['CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr', 'CONTEXT: This chunk discusses the challenges of identifying implicit security requirements in software requirements engineering (SRE), emphasizing the limitations of existing datasets and the need for AI-driven NLP methods, while highlighting the role of the OWASP ASVS framework in addressing these gaps through standardized security practices.\n\nCONTENT: Implicit Security Requirements Classification 3\n“The system will allow the user to print documents,” carries numerous implicit\nsecurity needs, including verifying user authorization, maintaining a valid ses-\nsion, and recording the action for accountability. These concerns correspond\nto common security control areas, such as access control, session management,\nand logging. This complexity requires substantial guidance. Manually iden-\ntifying and validating this network of implicit security dependencies across\nthousands of requirements is error prone, inconsistent, and not scalable (Ye\net al., 2025).\nGiven the limitations of manual SRA, automation through Artificial In-\ntelligence (AI) based Natural Language Processing (NLP) methods, offers a\npromising path forward. Although AI based approaches for RE have received\ngrowing attention (Abbasi et al., 2025; Zadenoori et al., 2025), recent evidence\nshows a gap between experimental advances and validated industrial solutions.\nFor example, an analysis of 74 primary studies found that most AI based tools\nare evaluated in controlled settings, with limited industrial adoption and weak\nintegration into real workflows (Bolanos et al., 2024). Similarly, another study\nreports a clear mismatch between expectations and practical outcomes in SRE\nin real world use (Karhu et al., 2025).\nThe main problem is the lack of suitable data, not the availability of ef-\nfective modeling approaches. The development and validation of data driven\napproaches is constrained by the scarcity and limited quality of domain spe-\ncific datasets (Wang et al., 2024; Zadenoori et al., 2025). This concern ex-\ntends beyond SRE, as leading NLP venues highlight dataset limitations that\nmake reliable evaluation difficult (Muresan et al., 2022; Goldberg et al., 2022;\nChristodoulopoulos et al., 2025).\nThis challenge is especially evident in SRE. Identifying implicit security\nrequirements relies on large collections of functional requirements annotated\nby security experts to reflect underlying security concerns. Current datasets do\nnot meet this need. For instance, PROMISE exp (Lima et al., 2019) includes\nonly a single, high-level security category; DOSSPRE (Kadebu et al., 2023)\nis based on student projects and lacks industry realism; and the Healthcare\ndataset (Riaz et al., 2014) is limited to a narrow domain and uses coarse-\ngrained labels. As a result, existing resources offer limited support for devel-\noping and evaluating methods aimed at uncovering implicit security require-\nments.\nThe OWASP Application Security Verification Standard (ASVS)1 offers a\nstandardized, systematic, and verifiable framework for defining and evaluating\napplication security controls. ASVS emphasizes the principle of “security by\ndesign” by facilitating the integration of security considerations early in the\nsoftware development lifecycle. Its comprehensive set of requirements can be\ndirectly mapped to verifiable test cases and secure coding practices, ensuring\ntraceability throughout the development process. This approach enables the\nearly identification and remediation of vulnerabilities, which is both more effi-\n1 https://owasp.org/www-project-application-security-verification-standard/', 'CONTEXT: **Comparison of Fine-Tuned Models and LLMs for Security Requirements Classification**: This chunk discusses the performance comparison between fine-tuned transformer models (e.g., BERT) and few-shot prompting with LLMs (e.g., Gemini 2.0) for classifying implicit security requirements in SRS documents, emphasizing the practicality of LLMs as a resource-efficient alternative while highlighting challenges in Security Requirements Engineering (SRE).\n\nCONTENT: 2 Yusuf G¨ ur et al.\ntional fine-tuned transformer models and contemporary Large Language Mod-\nels (LLMs) employing few-shot and zero-shot prompt engineering strategies.\nThe results show that a few-shot prompting with Gemini 2.0 achieves a macro-\naverage F1 score of 0.941, directly comparable to the fine-tuned BERT model’s\n0.942. This study culminates in two primary findings: first, the validation and\npublication of the ASRD, a high-granularity, multi-label dataset for implicit\nsecurity requirements based on OWASP ASVS V2-V13; and second, the di-\nrect comparison demonstrating that few-shot Large Language Models (LLMs)\nachieve competitive multi-label classification performance (Macro-F1 0.941)\nnearly equal to resource-intensive fine-tuned transformer models (Macro-F1\n0.942). This confirms that LLMs represent a highly practical and resource-\nsaving strategy for automating the identification of embedded (implicit) secu-\nrity requirements for software security in industrial SRS documents\nKeywordsCybersecurity requirement elicitation·OWASP based security\nrequirement classification·OWASP ASVS-based Requirement Labeling·\nLLM based classification\n1 Introduction\nRequirements Engineering (RE) concerns the identification, documentation,\nand management of software requirements (Sommerville and Sawyer, 1997).\nThe increasing interconnectivity of information systems forces organizations\nto provide secure services in cyberspace. Integrating security during initial\nrequirements analysis is essential to proactively mitigate risks, reduce vulner-\nabilities, and reduce the high costs associated with downstream remediation\n(Villamizar et al., 2018). This proactive approach is central to the ”Shift-\nLeft” security paradigm, which advocates for the identification and mitigation\nof vulnerabilities as early as possible in the Software Development Life Cycle\n(SDLC).\nAlthough Security Requirements Engineering (SRE) has matured as a dis-\ncipline, its effective application in practice remains challenging. The issue is\nnot the absence of security considerations, but the difficulty of ensuring that\nsecurity requirements are properly validated and verified. An empirical investi-\ngation that combines a systematic literature review with a survey of 58 indus-\ntry professionals highlights this gap (Alam et al., 2025). While practitioners\nreported a moderate understanding of SRE practices, Security Requirements\nAssurance (SRA) was found to be poorly understood and rarely applied in\nindustrial contexts. The study concludes that validating and ensuring security\nrequirements remains a major and unresolved challenge in practice.\nThis assurance gap persists due to the documented lack of specialized se-\ncurity training for developers in early-phase RE (Andrade et al., 2023). The\ntask relies heavily on scarce specialized expertise and time-intensive manual\nanalysis. The main challenge is that critical security requirements are often not\nexplicitly stated. Instead, they are implicitly embedded within standard func-\ntional descriptions. For example, a seemingly simple functional requirement,', 'CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the', 'CONTEXT: **Advancements in LLM-Assisted Security and Related Frameworks**: This chunk discusses the application of transformer-based models and LLMs in security requirements engineering (SRE), highlighting their capabilities, challenges, and the importance of high-quality datasets and evaluation frameworks. It also reviews the role of security frameworks in systematically identifying and classifying security requirements in automated settings.\n\nCONTENT: 6 Yusuf G¨ ur et al.\nBeyond requirements classification, security research has also turned to\ntask-specific models for narrowly defined problems. For instance, deep learning\napproaches such as BiLSTMs have been used to detect re-entrancy vulnerabil-\nities in smart contracts, where generic models are insufficient (Maturi et al.,\n2025). This work highlights the importance of explainability, as security de-\ncisions must be understandable to support assurance and auditing. Although\nthis line of research addresses a different problem, it reflects a shift toward\ndomain-aware and interpretable models.\nTransformer-based models have enabled new capabilities in automated text\nunderstanding(Zhou et al., 2025). They possess emergent abilities like in-\ncontext learning, instruction following, and step-by-step reasoning (Zhu et al.,\n2025), which allow them to perform complex tasks, including requirements\nclassification, with minimal or no labeled data (Liu et al., 2023b; Zhu et al.,\n2025). Recent trends show a growing interest in applying LLMs to RE tasks,\nincluding requirements classification, prioritization, and traceability (Rajbhoj\net al., 2024; White et al., 2024). LLMs can perform zero-shot and few-shot\nlearning, reducing the need for large annotated datasets and facilitating adap-\ntation to specialized domains like SRE (Labrak et al., 2023). Techniques such\nas prompt engineering and integration with external knowledge bases (e.g.,\nRetrieval-Augmented Generation) further improve their performance and con-\ntextual relevance (Masoudifard et al., 2024).\nLLM-assisted security solutions typically follow a three-step process: pre-\nprocessing (extracting context like documentation or target units), prompt\ngeneration (using instructions and unfilled slots for the model to complete\nwith artifacts like fuzz drivers or patches), and post-processing (validating\noutputs, e.g., checking if generated code successfully compiles) (Zhu et al.,\n2025).\nWhile these models provide powerful automation, they can also introduce\nnew risks and errors if applied without careful oversight. This underscores the\nneed for realistic, high-quality datasets and standardized evaluation frame-\nworks to reliably assess automated security requirement classification, ensuring\nboth effectiveness and safety in practice.\nThe use of automated models in security highlights both their potential and\nthe risks they can introduce. Ensuring accurate and reliable classification of\nsecurity requirements requires evaluation against high-quality, domain-specific\nbenchmarks (Jeong, 2024). This underscores the need for realistic datasets and\nstandardized evaluation frameworks tailored to SRE.\n2.2 Related Work on Security Frameworks\nAn appropriate security framework is necessary to ensure systematic and con-\nsistent identification and classification of security requirements, particularly in\nautomated settings. This section reviews widely adopted security frameworks\nand evaluates their suitability for requirement analysis.', 'CONTEXT: **Comparison of Security Frameworks and Related Datasets**: This chunk contrasts various security frameworks, highlighting the suitability of OWASP ASVS for fine-grained security requirement classification, and reviews existing security-related requirement datasets, emphasizing their limitations and relevance to automated classification research.\n\nCONTENT: Implicit Security Requirements Classification 7\nSeveral established frameworks, while influential, are not designed for this\npurpose. MITRE ATT&ACK 2 framework is a threat-based model of adver-\nsary behaviors, not a taxonomy of software requirements. Microsoft’s STRIDE\noperates at a high level of abstraction (e.g., “Spoofing”, “Tampering”) which\nis useful for threat modeling but lacks the granularity needed for require-\nment classification (Khan et al., 2017). Similarly, the NIST Secure Software\nDevelopment Framework (SSDF) defines high-level secure process practices\nrather than atomic requirement categories (Souppaya et al., 2022), and the\nCommon Criteria (CC) 3 is a template-based framework designed for formal\ncertification, making it impractical for fine-grained, natural-language analysis\n(Infrastructure and Profile, 2002).\nIn contrast, the Open Web Application Security Project (OWASP)4 Appli-\ncation Security Verification Standard (ASVS)5 is well suited to the objectives\nof this study. ASVS provides a detailed, verifiable, and developer-oriented\ntaxonomy explicitly intended for requirement-level security analysis. Its orga-\nnization into distinct, actionable security categories supports direct mapping\nto functional and non-functional security controls. Previous studies have suc-\ncessfully applied ASVS in requirements and design contexts ( Lukasiewicz and\nCyga´ nska, 2019; Tan et al., 2021; Wen and Katt, 2023). Its consistency with\nstandards such as NIST 800-63B supports its use in both academic research\nand industrial settings.\n2.3 Related Work on Security Related Requirement Datasets\nHigh-quality benchmark datasets are essential for developing automated clas-\nsification models, ensuring research reproducibility, and assessing model gen-\neralizability. In response to this need, the research community has developed\na limited number of foundational datasets for security requirements analysis,\neach offering distinct advantages and limitations. The three most represen-\ntative datasets are briefly described below, and their key characteristics are\nsummarized in Table 1.\n2.3.1 PROMISEExp\nIntroduced by Lima et al. (Lima et al., 2019), to expand the well-established\ntera-PROMISE repository, this dataset resulted from a systematic curation\nof publicly available SRS documents. The curation process relied on man-\nual extraction and expert consensus to ensure high-quality annotations. Al-\nthough it offers significant project diversity compared to its predecessor, its\nprimary challenge for modern research is its “High Dimension, Low Sample\nSize” (HDLSS) nature. The high feature-to-instance ratio and inherent class\n2 https://attack.mitre.org/\n3 https://www.commoncriteriaportal.org/cc/\n4 https://owasp.org/\n5 https://owasp.org/www-project-application-security-verification-standard/', 'CONTEXT: This chunk provides background on NLP-based techniques for software requirements classification, highlighting the evolution from traditional supervised learning methods to transformer-based models like BERT and SecureBERT, and emphasizing the challenges of classifying implicit security requirements due to ambiguity and the lack of high-quality, domain-specific datasets.\n\nCONTENT: Implicit Security Requirements Classification 5\nthreats to validity, and Section 8 concludes with a summary of contributions\nand directions for future work.\n2 Background\nThis section reviews prior work on NLP-based techniques for requirements\nclassification, followed by an overview of relevant security frameworks. It con-\ncludes with a discussion of existing datasets used in security requirements\nresearch.\n2.1 Related Work on Requirements Classification using NLP Techniques\nSoftware requirements (SR) classification supports effective project manage-\nment by enabling prioritization and risk assessment (Batool et al., 2025). The\ntask typically involves distinguishing functional requirements (FRs) from non-\nfunctional requirements (NFRs) and further categorizing NFRs into classes\nsuch as security, usability, and performance. Security requirements may ap-\npear as explicit system behaviors or as quality attributes addressing confiden-\ntiality, integrity, and availability—the security triad—which are often abstract\nand difficult to specify precisely in practice (Anwar Mohammad et al., 2019).\nThis inherent ambiguity complicates the development of clear guidelines for\nseparating security-related requirements from non-security ones.\nEarly studies applied supervised learning techniques, including Bayesian\nclassifiers(Knauss et al., 2011), decision trees (Jindal et al., 2016), and Sup-\nport Vector Machines (SVMs) (Dalpiaz et al., 2019), but these approaches\ndepended heavily on manual feature engineering and rigid linguistic patterns.\nTo address these limitations, later work adopted neural models such as convo-\nlutional neural networks (CNN) combined with Word2Vec embeddings (Dekht-\nyar and Fong, 2017). The adoption of transformer-based models such as BERT\nenabled improved classification accuracy through transfer learning and fine-\ntuning, eliminating the need for handcrafted features (Devlin et al., 2019; Sub-\nahi, 2023). More recent work explores domain-adapted transformer models,\nsuch as NoRBERT (Hey et al., 2020) and SecureBERT (Aghaei et al., 2022),\nto better capture domain-specific semantics and mitigate overfitting. These\nmodels have shown improved capability in identifying implicit non-functional\nrequirements, a particularly challenging task in security-critical settings (Nec-\nula et al., 2024). However, further progress in SRE is limited by the availability\nof large, high-quality, and domain-specific annotated datasets.\nThe subjective nature of defining security requirements further complicates\nreliable classification (Riaz and Williams, 2012). Security Requirement Elic-\nitation highly depends on domain-relevant expertise which includes various\ncostly manual steps such as creating security requirement templates, deter-\nmining security classification levels according to natural language artifacts,\nand mapping the class labels to related requirement templates by identifying\nentities.', 'CONTEXT: This chunk focuses on the introduction of the **Agency Security Requirements Dataset (ASRD)**, detailing its real-world data sources, expert annotation process, and alignment with OWASP ASVS categories, as well as outlining the research questions and comparative evaluation of fine-tuned transformer models versus prompt-based approaches for security requirements classification.\n\nCONTENT: 4 Yusuf G¨ ur et al.\ncient and cost-effective compared to addressing security issues at later stages\nof development ((Khan et al., 2024).\nThis paper proposes a machine learning-based system to automatically an-\nalyze SRS documents and classify security requirements according to OWASP\nASVS. Its main contribution is the Agency Security Requirements Dataset\n(ASRD), a publicly available corpus created to support research in automated\nSRA. The ASRD comprises:\n–Real-World Data: 2,652 Software Requirements Specification (SRS) sen-\ntences extracted from six diverse, real-world industry projects,\n–Expert Annotation: Meticulously annotated by three cybersecurity experts,\neach with over 15 years of industry experience,\n–Rigorous Methodology: Developed using the iterative MATTER cycle an-\nnotation framework (Pustejovsky and Stubbs, 2012),\n–High Granularity and Multi-label Structure: Mapped to 11 distinct, action-\nable security categories from the industry-standard OWASP Application\nSecurity Verification Standard (ASVS,V2–V13), allowing each require-\nment to be associated with multiple categories.\nThe ASRD is intended as a shared research resource and benchmark. Using\nthis dataset, the study conducts an empirical analysis of automated classifica-\ntion approaches and addresses the following research questions:\n1. To what extent can fine-tuned transformer models accurately perform\nmulti-label classification of implicit security requirements into OWASP\nASVS categories using the ASRD?\n2. How does the performance of prompt-based approaches (zero-shot and few-\nshot) using modern LLMs compare to fine-tuned BERT-based models and\nnaive baselines for this task?\nThe results show that few-shot prompting with a modern language model\n(Gemini 2.0) achieves a macro-average F1 score of 0.941, closely matching the\nbest fine-tuned BERT-based model (0.942). This demonstrates that example-\nguided inference can reach performance comparable to supervised fine-tuning\nwhile requiring substantially less annotated data and model retraining. The\nevaluation compares fine-tuned transformer models (e.g., SecureBERT) with\nprompt-based methods in zero-shot and few-shot settings across multiple con-\ntemporary models, demonstrating that prompt-based approaches provide a\npractical and resource-efficient alternative for identifying implicit security re-\nquirements in industrial SRS documents.\nThe remainder of this paper is organized as follows. Section 2 reviews re-\nlated work on NLP-based requirements classification, security frameworks, and\nexisting security datasets. Section 3 describes the curation and expert anno-\ntation of the ASRD and summarizes its key characteristics. Section 4 outlines\nthe experimental setup and classification methods, including fine-tuned BERT\nmodels and prompt-based approaches. Section 5 reports the experimental re-\nsults. Section 6 discusses the findings and their implications, with a com-\nparative analysis of fine-tuning and prompting strategies. Section 7 examines']","The primary motivation for integrating security during the requirements analysis phase is to proactively mitigate risks, reduce vulnerabilities, and minimize the high costs associated with addressing security issues at later stages of the Software Development Life Cycle (SDLC). This approach aligns with the ""Shift-Left"" security paradigm, which emphasizes identifying and addressing vulnerabilities as early as possible in the development process. Early integration of security ensures effective resource allocation, risk management, and systematic identification of implicit security requirements, which are often embedded within functional descriptions and difficult to identify manually. Automating this process using frameworks like OWASP ASVS and AI-driven methodologies further enhances efficiency and accuracy.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","Integrating security during initial requirements analysis is essential to proactively mitigate risks, reduce vulnerabilities, and reduce the high costs associated with downstream remediation. This aligns with the 'Shift-Left' security paradigm[cite: 32, 33].",,,
Why is the manual identification of security requirements described as challenging?,"['CONTEXT: This chunk discusses the challenges of identifying implicit security requirements in software requirements engineering (SRE), emphasizing the limitations of existing datasets and the need for AI-driven NLP methods, while highlighting the role of the OWASP ASVS framework in addressing these gaps through standardized security practices.\n\nCONTENT: Implicit Security Requirements Classification 3\n“The system will allow the user to print documents,” carries numerous implicit\nsecurity needs, including verifying user authorization, maintaining a valid ses-\nsion, and recording the action for accountability. These concerns correspond\nto common security control areas, such as access control, session management,\nand logging. This complexity requires substantial guidance. Manually iden-\ntifying and validating this network of implicit security dependencies across\nthousands of requirements is error prone, inconsistent, and not scalable (Ye\net al., 2025).\nGiven the limitations of manual SRA, automation through Artificial In-\ntelligence (AI) based Natural Language Processing (NLP) methods, offers a\npromising path forward. Although AI based approaches for RE have received\ngrowing attention (Abbasi et al., 2025; Zadenoori et al., 2025), recent evidence\nshows a gap between experimental advances and validated industrial solutions.\nFor example, an analysis of 74 primary studies found that most AI based tools\nare evaluated in controlled settings, with limited industrial adoption and weak\nintegration into real workflows (Bolanos et al., 2024). Similarly, another study\nreports a clear mismatch between expectations and practical outcomes in SRE\nin real world use (Karhu et al., 2025).\nThe main problem is the lack of suitable data, not the availability of ef-\nfective modeling approaches. The development and validation of data driven\napproaches is constrained by the scarcity and limited quality of domain spe-\ncific datasets (Wang et al., 2024; Zadenoori et al., 2025). This concern ex-\ntends beyond SRE, as leading NLP venues highlight dataset limitations that\nmake reliable evaluation difficult (Muresan et al., 2022; Goldberg et al., 2022;\nChristodoulopoulos et al., 2025).\nThis challenge is especially evident in SRE. Identifying implicit security\nrequirements relies on large collections of functional requirements annotated\nby security experts to reflect underlying security concerns. Current datasets do\nnot meet this need. For instance, PROMISE exp (Lima et al., 2019) includes\nonly a single, high-level security category; DOSSPRE (Kadebu et al., 2023)\nis based on student projects and lacks industry realism; and the Healthcare\ndataset (Riaz et al., 2014) is limited to a narrow domain and uses coarse-\ngrained labels. As a result, existing resources offer limited support for devel-\noping and evaluating methods aimed at uncovering implicit security require-\nments.\nThe OWASP Application Security Verification Standard (ASVS)1 offers a\nstandardized, systematic, and verifiable framework for defining and evaluating\napplication security controls. ASVS emphasizes the principle of “security by\ndesign” by facilitating the integration of security considerations early in the\nsoftware development lifecycle. Its comprehensive set of requirements can be\ndirectly mapped to verifiable test cases and secure coding practices, ensuring\ntraceability throughout the development process. This approach enables the\nearly identification and remediation of vulnerabilities, which is both more effi-\n1 https://owasp.org/www-project-application-security-verification-standard/', 'CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr', 'CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: This chunk provides background on NLP-based techniques for software requirements classification, highlighting the evolution from traditional supervised learning methods to transformer-based models like BERT and SecureBERT, and emphasizing the challenges of classifying implicit security requirements due to ambiguity and the lack of high-quality, domain-specific datasets.\n\nCONTENT: Implicit Security Requirements Classification 5\nthreats to validity, and Section 8 concludes with a summary of contributions\nand directions for future work.\n2 Background\nThis section reviews prior work on NLP-based techniques for requirements\nclassification, followed by an overview of relevant security frameworks. It con-\ncludes with a discussion of existing datasets used in security requirements\nresearch.\n2.1 Related Work on Requirements Classification using NLP Techniques\nSoftware requirements (SR) classification supports effective project manage-\nment by enabling prioritization and risk assessment (Batool et al., 2025). The\ntask typically involves distinguishing functional requirements (FRs) from non-\nfunctional requirements (NFRs) and further categorizing NFRs into classes\nsuch as security, usability, and performance. Security requirements may ap-\npear as explicit system behaviors or as quality attributes addressing confiden-\ntiality, integrity, and availability—the security triad—which are often abstract\nand difficult to specify precisely in practice (Anwar Mohammad et al., 2019).\nThis inherent ambiguity complicates the development of clear guidelines for\nseparating security-related requirements from non-security ones.\nEarly studies applied supervised learning techniques, including Bayesian\nclassifiers(Knauss et al., 2011), decision trees (Jindal et al., 2016), and Sup-\nport Vector Machines (SVMs) (Dalpiaz et al., 2019), but these approaches\ndepended heavily on manual feature engineering and rigid linguistic patterns.\nTo address these limitations, later work adopted neural models such as convo-\nlutional neural networks (CNN) combined with Word2Vec embeddings (Dekht-\nyar and Fong, 2017). The adoption of transformer-based models such as BERT\nenabled improved classification accuracy through transfer learning and fine-\ntuning, eliminating the need for handcrafted features (Devlin et al., 2019; Sub-\nahi, 2023). More recent work explores domain-adapted transformer models,\nsuch as NoRBERT (Hey et al., 2020) and SecureBERT (Aghaei et al., 2022),\nto better capture domain-specific semantics and mitigate overfitting. These\nmodels have shown improved capability in identifying implicit non-functional\nrequirements, a particularly challenging task in security-critical settings (Nec-\nula et al., 2024). However, further progress in SRE is limited by the availability\nof large, high-quality, and domain-specific annotated datasets.\nThe subjective nature of defining security requirements further complicates\nreliable classification (Riaz and Williams, 2012). Security Requirement Elic-\nitation highly depends on domain-relevant expertise which includes various\ncostly manual steps such as creating security requirement templates, deter-\nmining security classification levels according to natural language artifacts,\nand mapping the class labels to related requirement templates by identifying\nentities.', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference', 'CONTEXT: **Advancements in LLM-Assisted Security and Related Frameworks**: This chunk discusses the application of transformer-based models and LLMs in security requirements engineering (SRE), highlighting their capabilities, challenges, and the importance of high-quality datasets and evaluation frameworks. It also reviews the role of security frameworks in systematically identifying and classifying security requirements in automated settings.\n\nCONTENT: 6 Yusuf G¨ ur et al.\nBeyond requirements classification, security research has also turned to\ntask-specific models for narrowly defined problems. For instance, deep learning\napproaches such as BiLSTMs have been used to detect re-entrancy vulnerabil-\nities in smart contracts, where generic models are insufficient (Maturi et al.,\n2025). This work highlights the importance of explainability, as security de-\ncisions must be understandable to support assurance and auditing. Although\nthis line of research addresses a different problem, it reflects a shift toward\ndomain-aware and interpretable models.\nTransformer-based models have enabled new capabilities in automated text\nunderstanding(Zhou et al., 2025). They possess emergent abilities like in-\ncontext learning, instruction following, and step-by-step reasoning (Zhu et al.,\n2025), which allow them to perform complex tasks, including requirements\nclassification, with minimal or no labeled data (Liu et al., 2023b; Zhu et al.,\n2025). Recent trends show a growing interest in applying LLMs to RE tasks,\nincluding requirements classification, prioritization, and traceability (Rajbhoj\net al., 2024; White et al., 2024). LLMs can perform zero-shot and few-shot\nlearning, reducing the need for large annotated datasets and facilitating adap-\ntation to specialized domains like SRE (Labrak et al., 2023). Techniques such\nas prompt engineering and integration with external knowledge bases (e.g.,\nRetrieval-Augmented Generation) further improve their performance and con-\ntextual relevance (Masoudifard et al., 2024).\nLLM-assisted security solutions typically follow a three-step process: pre-\nprocessing (extracting context like documentation or target units), prompt\ngeneration (using instructions and unfilled slots for the model to complete\nwith artifacts like fuzz drivers or patches), and post-processing (validating\noutputs, e.g., checking if generated code successfully compiles) (Zhu et al.,\n2025).\nWhile these models provide powerful automation, they can also introduce\nnew risks and errors if applied without careful oversight. This underscores the\nneed for realistic, high-quality datasets and standardized evaluation frame-\nworks to reliably assess automated security requirement classification, ensuring\nboth effectiveness and safety in practice.\nThe use of automated models in security highlights both their potential and\nthe risks they can introduce. Ensuring accurate and reliable classification of\nsecurity requirements requires evaluation against high-quality, domain-specific\nbenchmarks (Jeong, 2024). This underscores the need for realistic datasets and\nstandardized evaluation frameworks tailored to SRE.\n2.2 Related Work on Security Frameworks\nAn appropriate security framework is necessary to ensure systematic and con-\nsistent identification and classification of security requirements, particularly in\nautomated settings. This section reviews widely adopted security frameworks\nand evaluates their suitability for requirement analysis.', 'CONTEXT: **Comparison of Fine-Tuned Models and LLMs for Security Requirements Classification**: This chunk discusses the performance comparison between fine-tuned transformer models (e.g., BERT) and few-shot prompting with LLMs (e.g., Gemini 2.0) for classifying implicit security requirements in SRS documents, emphasizing the practicality of LLMs as a resource-efficient alternative while highlighting challenges in Security Requirements Engineering (SRE).\n\nCONTENT: 2 Yusuf G¨ ur et al.\ntional fine-tuned transformer models and contemporary Large Language Mod-\nels (LLMs) employing few-shot and zero-shot prompt engineering strategies.\nThe results show that a few-shot prompting with Gemini 2.0 achieves a macro-\naverage F1 score of 0.941, directly comparable to the fine-tuned BERT model’s\n0.942. This study culminates in two primary findings: first, the validation and\npublication of the ASRD, a high-granularity, multi-label dataset for implicit\nsecurity requirements based on OWASP ASVS V2-V13; and second, the di-\nrect comparison demonstrating that few-shot Large Language Models (LLMs)\nachieve competitive multi-label classification performance (Macro-F1 0.941)\nnearly equal to resource-intensive fine-tuned transformer models (Macro-F1\n0.942). This confirms that LLMs represent a highly practical and resource-\nsaving strategy for automating the identification of embedded (implicit) secu-\nrity requirements for software security in industrial SRS documents\nKeywordsCybersecurity requirement elicitation·OWASP based security\nrequirement classification·OWASP ASVS-based Requirement Labeling·\nLLM based classification\n1 Introduction\nRequirements Engineering (RE) concerns the identification, documentation,\nand management of software requirements (Sommerville and Sawyer, 1997).\nThe increasing interconnectivity of information systems forces organizations\nto provide secure services in cyberspace. Integrating security during initial\nrequirements analysis is essential to proactively mitigate risks, reduce vulner-\nabilities, and reduce the high costs associated with downstream remediation\n(Villamizar et al., 2018). This proactive approach is central to the ”Shift-\nLeft” security paradigm, which advocates for the identification and mitigation\nof vulnerabilities as early as possible in the Software Development Life Cycle\n(SDLC).\nAlthough Security Requirements Engineering (SRE) has matured as a dis-\ncipline, its effective application in practice remains challenging. The issue is\nnot the absence of security considerations, but the difficulty of ensuring that\nsecurity requirements are properly validated and verified. An empirical investi-\ngation that combines a systematic literature review with a survey of 58 indus-\ntry professionals highlights this gap (Alam et al., 2025). While practitioners\nreported a moderate understanding of SRE practices, Security Requirements\nAssurance (SRA) was found to be poorly understood and rarely applied in\nindustrial contexts. The study concludes that validating and ensuring security\nrequirements remains a major and unresolved challenge in practice.\nThis assurance gap persists due to the documented lack of specialized se-\ncurity training for developers in early-phase RE (Andrade et al., 2023). The\ntask relies heavily on scarce specialized expertise and time-intensive manual\nanalysis. The main challenge is that critical security requirements are often not\nexplicitly stated. Instead, they are implicitly embedded within standard func-\ntional descriptions. For example, a seemingly simple functional requirement,']","The manual identification of security requirements is described as challenging due to several factors:

1. **Implicit Nature of Security Requirements**: Security requirements are often embedded within functional requirements rather than explicitly stated. For example, a requirement like ""The system will allow the user to print documents"" implicitly includes security needs such as verifying user authorization, maintaining session validity, and logging actions for accountability. Identifying these implicit dependencies requires substantial expertise and effort.

2. **Error-Prone and Inconsistent Process**: Manually identifying and validating implicit security requirements across thousands of requirements is prone to errors, inconsistencies, and lacks scalability. This process heavily relies on specialized expertise, which is often scarce.

3. **Ambiguity and Subjectivity**: Security requirements are inherently abstract and difficult to specify precisely. This ambiguity complicates the development of clear guidelines for distinguishing security-related requirements from non-security ones.

4. **Dataset Limitations**: The lack of high-quality, domain-specific datasets further exacerbates the challenge. Existing datasets often lack granularity, realism, or sufficient annotations, making it difficult to develop and evaluate methods for uncovering implicit security requirements.

5. **Resource-Intensive Nature**: Manual annotation and validation require significant time and effort. For example, the creation of the ASRD dataset involved 267 person-hours of expert labor to annotate 2,652 requirements.

6. **Class Imbalance**: Security requirements often follow a ""long-tail"" distribution, where critical security concerns (e.g., cryptographic storage) are underrepresented compared to more common ones (e.g., authentication). This imbalance makes manual identification even more challenging.

These challenges highlight the need for automated solutions, such as AI-driven NLP methods, to improve scalability, accuracy, and efficiency in identifying security requirements.

**Source**: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf","Manual identification is described as time-consuming, error-prone, and reliant on specialized expertise because security requirements are often implicitly embedded within standard functional descriptions rather than being explicitly stated[cite: 8, 40, 41, 42].",,,
What is the specific name of the dataset introduced in this paper?,"['CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr', 'CONTEXT: This chunk focuses on the introduction of the **Agency Security Requirements Dataset (ASRD)**, detailing its real-world data sources, expert annotation process, and alignment with OWASP ASVS categories, as well as outlining the research questions and comparative evaluation of fine-tuned transformer models versus prompt-based approaches for security requirements classification.\n\nCONTENT: 4 Yusuf G¨ ur et al.\ncient and cost-effective compared to addressing security issues at later stages\nof development ((Khan et al., 2024).\nThis paper proposes a machine learning-based system to automatically an-\nalyze SRS documents and classify security requirements according to OWASP\nASVS. Its main contribution is the Agency Security Requirements Dataset\n(ASRD), a publicly available corpus created to support research in automated\nSRA. The ASRD comprises:\n–Real-World Data: 2,652 Software Requirements Specification (SRS) sen-\ntences extracted from six diverse, real-world industry projects,\n–Expert Annotation: Meticulously annotated by three cybersecurity experts,\neach with over 15 years of industry experience,\n–Rigorous Methodology: Developed using the iterative MATTER cycle an-\nnotation framework (Pustejovsky and Stubbs, 2012),\n–High Granularity and Multi-label Structure: Mapped to 11 distinct, action-\nable security categories from the industry-standard OWASP Application\nSecurity Verification Standard (ASVS,V2–V13), allowing each require-\nment to be associated with multiple categories.\nThe ASRD is intended as a shared research resource and benchmark. Using\nthis dataset, the study conducts an empirical analysis of automated classifica-\ntion approaches and addresses the following research questions:\n1. To what extent can fine-tuned transformer models accurately perform\nmulti-label classification of implicit security requirements into OWASP\nASVS categories using the ASRD?\n2. How does the performance of prompt-based approaches (zero-shot and few-\nshot) using modern LLMs compare to fine-tuned BERT-based models and\nnaive baselines for this task?\nThe results show that few-shot prompting with a modern language model\n(Gemini 2.0) achieves a macro-average F1 score of 0.941, closely matching the\nbest fine-tuned BERT-based model (0.942). This demonstrates that example-\nguided inference can reach performance comparable to supervised fine-tuning\nwhile requiring substantially less annotated data and model retraining. The\nevaluation compares fine-tuned transformer models (e.g., SecureBERT) with\nprompt-based methods in zero-shot and few-shot settings across multiple con-\ntemporary models, demonstrating that prompt-based approaches provide a\npractical and resource-efficient alternative for identifying implicit security re-\nquirements in industrial SRS documents.\nThe remainder of this paper is organized as follows. Section 2 reviews re-\nlated work on NLP-based requirements classification, security frameworks, and\nexisting security datasets. Section 3 describes the curation and expert anno-\ntation of the ASRD and summarizes its key characteristics. Section 4 outlines\nthe experimental setup and classification methods, including fine-tuned BERT\nmodels and prompt-based approaches. Section 5 reports the experimental re-\nsults. Section 6 discusses the findings and their implications, with a com-\nparative analysis of fine-tuning and prompting strategies. Section 7 examines', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: This chunk discusses the curation and preprocessing of the ASRD dataset, detailing the data collection process from real-world Software Requirements Specification (SRS) documents, the multi-stage preprocessing pipeline for sentence extraction and anonymization, and how the dataset addresses gaps in prior work by incorporating industrial complexity and linguistic diversity.\n\nCONTENT: Implicit Security Requirements Classification 9\n2.3.3 Electronic Health Domain Dataset\nThis corpus focuses on the electronic healthcare industry, a sector defined\nby stringent regulatory and high-assurance demands (Riaz et al., 2014). The\ndataset’s strength lies in its rigorous multi-stage annotation methodology,\nwhich utilized independent researchers and a mediator to ensure high inter-\nannotator agreement. While it provides a large-scale, authentic resource for\nhealthcare-specific tasks, its narrow focus may limit the generalizability of\nmodels to other industries, and its high-level security objectives may be too\ncoarse for detailed technical analysis.\n2.3.4 Summary of Datasets\nAs summarized in Table 1, these datasets vary significantly in their suitability\nfor tasks ranging from general non-functional requirement (NFR) classifica-\ntion to detailed security analysis. Our proposed Agency Security Require-\nments Dataset (ASRD) addresses gaps in prior work by adopting the OWASP\nASVS taxonomy for multi-label annotation. Furthermore, by utilizing real-\nworld projects originally written in Turkish, ASRD introduces both industrial\ncomplexity and linguistic diversity to the field.\n3 Dataset Curation, Annotation, and Evaluation\n3.1 Data Collection and Preprocessing\nThe dataset compilation began with the collection of six Software Require-\nments Specification (SRS) documents from an Agency’s Security Department.\nThese documents were selected from an initial pool of 19 projects executed\nbetween 2019 and 2023, specifically chosen for their domain diversity and\namenability to effective anonymization. The original documents were provided\nin standard document formats (e.g., PDF, DOCX) where requirements were\norganized in itemized lists. To transform these documents into a machine-\nreadable dataset, we employed a multi-stage preprocessing pipeline:\n1. Sentence Segmentation and Extraction: As the source SRS documents uti-\nlized standard itemization for requirements, we employed a rule-based ex-\ntraction method. We utilized pattern matching to identify requirement\nblocks based on hierarchical numbering schemes and line breaks. Each iden-\ntified requirement was extracted and treated as a single processing unit,\npreserving the structural integrity of the original specification.\n2. Anonymization: To protect sensitive data, a semi-automated anonymiza-\ntion process was implemented. Custom scripts replaced entities such as\nproject names, specific URLs, and IP addresses with generic placeholders.\nThis was followed by a manual review by domain experts to ensure that\nthe removal of personally identifiable information (PII) did not compromise\nthe semantic meaning or contextual integrity of the requirements.', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb', 'CONTEXT: **Comparison of Security Frameworks and Related Datasets**: This chunk contrasts various security frameworks, highlighting the suitability of OWASP ASVS for fine-grained security requirement classification, and reviews existing security-related requirement datasets, emphasizing their limitations and relevance to automated classification research.\n\nCONTENT: Implicit Security Requirements Classification 7\nSeveral established frameworks, while influential, are not designed for this\npurpose. MITRE ATT&ACK 2 framework is a threat-based model of adver-\nsary behaviors, not a taxonomy of software requirements. Microsoft’s STRIDE\noperates at a high level of abstraction (e.g., “Spoofing”, “Tampering”) which\nis useful for threat modeling but lacks the granularity needed for require-\nment classification (Khan et al., 2017). Similarly, the NIST Secure Software\nDevelopment Framework (SSDF) defines high-level secure process practices\nrather than atomic requirement categories (Souppaya et al., 2022), and the\nCommon Criteria (CC) 3 is a template-based framework designed for formal\ncertification, making it impractical for fine-grained, natural-language analysis\n(Infrastructure and Profile, 2002).\nIn contrast, the Open Web Application Security Project (OWASP)4 Appli-\ncation Security Verification Standard (ASVS)5 is well suited to the objectives\nof this study. ASVS provides a detailed, verifiable, and developer-oriented\ntaxonomy explicitly intended for requirement-level security analysis. Its orga-\nnization into distinct, actionable security categories supports direct mapping\nto functional and non-functional security controls. Previous studies have suc-\ncessfully applied ASVS in requirements and design contexts ( Lukasiewicz and\nCyga´ nska, 2019; Tan et al., 2021; Wen and Katt, 2023). Its consistency with\nstandards such as NIST 800-63B supports its use in both academic research\nand industrial settings.\n2.3 Related Work on Security Related Requirement Datasets\nHigh-quality benchmark datasets are essential for developing automated clas-\nsification models, ensuring research reproducibility, and assessing model gen-\neralizability. In response to this need, the research community has developed\na limited number of foundational datasets for security requirements analysis,\neach offering distinct advantages and limitations. The three most represen-\ntative datasets are briefly described below, and their key characteristics are\nsummarized in Table 1.\n2.3.1 PROMISEExp\nIntroduced by Lima et al. (Lima et al., 2019), to expand the well-established\ntera-PROMISE repository, this dataset resulted from a systematic curation\nof publicly available SRS documents. The curation process relied on man-\nual extraction and expert consensus to ensure high-quality annotations. Al-\nthough it offers significant project diversity compared to its predecessor, its\nprimary challenge for modern research is its “High Dimension, Low Sample\nSize” (HDLSS) nature. The high feature-to-instance ratio and inherent class\n2 https://attack.mitre.org/\n3 https://www.commoncriteriaportal.org/cc/\n4 https://owasp.org/\n5 https://owasp.org/www-project-application-security-verification-standard/', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', ""CONTEXT: **Comparative Analysis of Security Requirement Datasets**: This chunk provides a detailed comparison of the ASRD dataset with other prominent security requirement datasets, highlighting differences in size, domain coverage, annotation methodologies, and granularity, while emphasizing ASRD's strengths in industrial complexity, multi-domain applicability, and alignment with OWASP ASVS standards.\n\nCONTENT: 8 Yusuf G¨ ur et al.\nTable 1: Comparative Analysis of Security Requirement Datasets\nCharacteristic PROMISE\nexp\nDOSSPRE Healthcare\nDataset\nASRD (Ours)\nTotal Require-\nments\n969 1,317 10,963 2,652\nData Source Public SRS\ndocuments\n(expanded to\n49 projects)\n105 Student\nproject docu-\nments\n6 Official Cana-\ndian and U.S.\nSRS documents\n6 Real-world\nSRS docs from\na gov’t agency\nDomain General /\nCross-domain\nGeneral / Aca-\ndemic\nElectronic\nHealthcare\nMulti-domain:\nLegal, Const.,\nEdu., etc.\nPrimary Task FR vs. NFR,\nMulti-class\nNFR\nSR vs. NSR,\nMulti-class SR\nMulti-label\nSecurity Objec-\ntives\nMulti-label Im-\nplicit Security\nClass.\nSecurity Granu-\nlarity\nSingle SE\nclass\n10 security\nclasses\n6 security objec-\ntives\n11 OWASP\nASVS classes\nLanguage English English English Turkish\nAnnotation\nMethodology\nExpert Con-\nsensus: Man-\nual extraction\nand valida-\ntion\nAuthor Com-\npilation: Cat-\negorized by\nauthors only,\nlimited rigorous\nvalidation\nMulti-Stage\nConsensus: 2\nresearchers +\nmediator, high\nagreement\nMATTER Cy-\ncle: 3 SMEs\nwith adjudica-\ntion, iterative\nrefinement and\nabjudication\nKey Strength Established\nbenchmark\nand project\ndiversity\nFine-grained\nsecurity-specific\ntaxonomy\nLarge scale and\ndomain authen-\nticity\nIndustrial\ncomplexity +\nOWASP ASVS\nKey Limitation Small size\nand class\nimbalance\nPotential lack of\nprofessional re-\nalism\nDomain-\nspecific; coarse-\ngrained labels\nReal-world class\nimbalance in\nspecific cate-\ngories\nimbalance often restrict its suitability for training complex deep learning ar-\nchitectures.\n2.3.2 DOSSPRE\nThe Dataset of Students’ Software Projects Requirements (DOSSPRE) was\ncompiled by Kadebu et al. from documentation within academic curricula\n(Kadebu et al., 2023), likely from the Harare Institute of Technology. It pro-\nvides a fine-grained classification through a detailed taxonomy for both se-\ncurity and non-security requirements. However, as the requirements were au-\nthored by students, they may not fully reflect the realism and complexity of\nindustry-grade requirements.""]","The specific name of the dataset introduced in this paper is the **Agency Security Requirements Dataset (ASRD)**. 

This dataset is a novel multi-label corpus derived from 2,652 real-world requirement statements from six diverse documents. It is meticulously annotated by three cybersecurity experts using a high-granularity taxonomy based on the OWASP Application Security Verification Standard (ASVS) V2-V13 and the MATTER cycle annotation framework. The ASRD is designed to support research in automated Security Requirements Analysis (SRA) and serves as a benchmark for classifying implicit security requirements in Software Requirements Specification (SRS) documents.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","The dataset is named the Agency Security Requirements Dataset (ASRD)[cite: 12, 69].",,,
How many requirements does the ASRD contain and where did they come from?,"['CONTEXT: **ASRD Dataset Filtering and Composition**: This chunk details the rigorous filtering, randomization, and composition process used to create the ASRD dataset, highlighting its focus on functional requirements across six business domains and its alignment with OWASP ASVS security classes for security requirements classification.\n\nCONTENT: 10 Yusuf G¨ ur et al.\n3. Filtering: The initial extraction yielded 3,264 items. To ensure the qual-\nity of the dataset, domain experts conducted a rigorous manual filtering\npass to remove 612 items. This exclusion process went beyond simple for-\nmatting artifacts (such as headers or tables of contents). We specifically\nremoved non-functional administrative clauses that addressed the vendor\nrather than the system (e.g., “The contractor must provide training man-\nuals”), project management constraints (e.g., “The project must be deliv-\nered by Q3”), and requirements with ambiguous scope that lacked clear\nverification criteria.\n4. Randomization: The remaining requirements were randomized and masked\nto mitigate potential annotation bias related to the document source or the\nsequence of requirements.\nThe resulting ASRD comprises 2,652 well-formed functional requirements\nacross six distinct business areas: Construction (1,202), Legal (177), Education\n(312), Software (199), Meeting (126), and Accommodation (636). A sample of\nthese requirements is provided in Table 2. The requirements included in this\nsample were selected based on three specific criteria to ensure a representative\noverview:\n–Samples were chosen to reflect the varied terminology and phrasing styles\nused across the six different business domains.\n–We prioritized requirements that demonstrate how standard functional de-\nscriptions conceal underlying security dependencies.\n–We ensured that the sample includes representative examples for all 11\nOWASP ASVS security classes used in the study to demonstrate the full\nscope of the classification task.\nIt is important to note that the ASRD is a Turkish-language corpus; all experi-\nments detailed in this study, including BERT fine-tuning and LLM prompting,\nwere conducted exclusively on the original text. English translations are pro-\nvided only for readability.\nTable 2: Sample Requirements from ASRD\nNo Original Requirements Translated Requirements\n1 Sistem, yetkili kullanıcının hukuk\ndosyası t¨ ur¨ u kayıt etmesini\nsa˘ glayacaktır.\nThe system shall allow authorized\nusers to record the legal file type.\n2 Sistem, kullanıcının kullanılmamı¸ s\nhukuk dosyası t¨ ur¨ un¨ u g¨ uncellemesini\nsa˘ glayacaktır.\nThe system shall allow the user to up-\ndate an unused legal file type.\n3 Sistem, kullanıcının kullanılmamı¸ s\nolan hukuk dosyası t¨ ur¨ un¨ u silmesini\nsa˘ glayacaktır.\nThe system shall allow the user to\ndelete an unused legal file type.\n4 Sistem, kullanıcının hukuk dosyası\nt¨ urlerini sorgulamasını ve listelemesini\nsa˘ glayacaktır.\nThe system shall allow the user to\nquery and list legal file types.', 'CONTEXT: This chunk provides examples of security requirements translated from Turkish to English, illustrating the type of statements included in the ASRD dataset, and discusses the adoption of the OWASP ASVS framework as a standardized taxonomy for security requirement verification in alignment with international standards like NIST SP 800-63b.\n\nCONTENT: 12 Yusuf G¨ ur et al.\nTable 2 – continued from previous page\nNu Original Requirements Translated Requirements\n21 Sistem, tarayıcı ¨ uzerinde g¨ osterilen fil-\nigranı, kullanıcı adı ve IP bilgisi gibi\nalanları ¸ sifrelemesi ile olu¸ sturacaktır.\nThe system shall generate\nbrowser-displayed watermarks by\nencrypting information such as\nusername and IP address.\n22 Sistem, y¨ oneticinin, g¨ orevli personel\ni¸ cin kullanıcı hesabı olu¸ sturabilmesini\nsa˘ glayacaktır.\nThe system shall allow the administra-\ntor to create user accounts for assigned\npersonnel.\n23 Sistem, y¨ oneticinin, kullanıcının aktif\ndizinde ¨ uye olabilece˘ gi g¨ uvenlik gru-\nplarını se¸ cebilmesini sa˘ glayacaktır.\nThe system shall allow the administra-\ntor to select security groups for users in\nthe Active Directory.\n24 Sistem, g¨ u¸ cl¨ u ¸ sifrelerin kullanılmasını\nzorunlu kılacaktır.\nThe system shall enforce the use of\nstrong passwords.\n25 Sistem, kullanıcıların ¸ sifrelerini\ny¨ onetebilmesine olanak sa˘ glayacaktır.\nThe system shall allow users to manage\ntheir passwords.\n26 Sistem, kullanıcının 10 dk boyunca\ni¸ slem yapmaması durumunda oturu-\nmunu sonlandıracaktır.\nThe system shall terminate a user ses-\nsion if no transaction is performed\nwithin 10 minutes.\n27 Sistem, kullanıcıların ilk oturum\ng¨ uvenlik ayarlarının uygulanmasını\nzorunlu kılacaktır.\nThe system shall enforce the configu-\nration of security settings during the\nuser’s first login.\n28 Sistem, y¨ oneticilerin alan ve yetki\nprensibine g¨ ore i¸ slem yapabilmesini\nsa˘ glayacaktır.\nThe system shall allow administrators\nto act according to domain and autho-\nrization principles.\n29 Sistem, kullanıcıların kayıtlarını tuta-\ncaktır.\nThe system shall maintain logs of user\nactivities.\n30 Sistem, kullanıcıların etkile¸ simleri\ng¨ uvenlik do˘ grulaması yapılacaktır.\nThe system shall perform authentica-\ntion for all users accessing the system.\n3.2 Framework and OWASP Classes Selection\nIncreasing web application complexity and threat sophistication necessitate\nstandardized, requirement-level security verification. Accordingly, this study\nadopts the OWASP Application Security Verification Standard (ASVS) as its\nfoundational ontology, as it provides a granular, developer-centric taxonomy\nof verifiable security requirements, in contrast to high-level threat models such\nas STRIDE or certification-oriented standards like the Common Criteria (ISO\n15408), and is supported by industry adoption (ADA 6 , CREST7 ).\nAn important validation for using ASVS 4.0.3 in academic research is its\nexplicit alignment with the National Institute of Standards and Technology\n(NIST) Special Publication 800-63b, Digital Identity Guidelines. This synchro-\nnization ensures that the requirements derived from ASVS are compatible with\nfederal and international regulatory frameworks. A seminal study by Tan (Tan\net al., 2021) serves as a primary example of ASVS adoption in the financial sec-\ntor. The researchers utilized OWASP ASVS to map security controls directly\nto the Monetary Authority of Singapore (MAS) Technology Risk Management\n6 https://appdefensealliance.dev/\n7 https://www.crest-approved.org/membership/crest-ovs-programme/', 'CONTEXT: **Contextual Header:** This chunk provides examples of implicit security requirements from the ASRD dataset, showcasing original Turkish requirements alongside their English translations, which highlight diverse functional and security-related specifications for software systems.\n\nCONTENT: Implicit Security Requirements Classification 11\nTable 2 – continued from previous page\nNu Original Requirements Translated Requirements\n5 Sistem, kullanıcının var olan bir hukuk\ndosyası t¨ ur¨ une hukuk dosyası alt t¨ ur¨ u\ntanımlamasını sa˘ glayacaktır.\nThe system shall allow the user to de-\nfine subtypes for an existing legal file\ntype.\n6 Sistem, kullanıcının hukuk dosyası\nalt t¨ ur¨ un¨ u aktif/pasife ¸ cekmesini\nsa˘ glayacaktır.\nThe system shall allow the user to ac-\ntivate or deactivate legal file subtypes.\n7 Sistem, kullanıcının dava dosyasına bir\nveya birden fazla davacı tanımlamasını\nsa˘ glayacaktır.\nThe system shall allow the user to de-\nfine one or more plaintiffs for a legal\nfile.\n8 Sistem, davaların konu kodunun\nzorunlu olmasını sa˘ glayacaktır.\nThe system shall enforce the manda-\ntory entry of a subject code for cases.\n9 Sistem, kullanıcının hukuk dosyasında\ng¨ or¨ unt¨ ulendi˘ gi evrakın ¸ cıktısını al-\nmasını sa˘ glayacaktır.\nThe system shall allow the user to print\ndocuments displayed in the legal file.\n10 Sistem, sistem soru ¨ onerilerine\notomatik numara vermesini\nsa˘ glayacaktır.\nThe system shall automatically assign\nnumbers to system question proposals.\n11 Sistem, kullanıcının dava dosyası evrak\nlistesinden se¸ cti˘ gi bir evrakı UYAP en-\ntegrasyonu ile ¸ cekmesini sa˘ glayacaktır.\nThe system shall allow the user to re-\ntrieve a document selected from the\ncase file list via UYAP integration.\n12 Sistem, toplantı salonunun tahsis\nedilmi¸ s oldu˘ gu tarih saat ile ¸ cakı¸ san\ntoplantı salonu tahsis taleplerinin\nolu¸ sturulmasını engelleyecektir.\nThe system shall prevent the creation\nof meeting room allocation requests\nthat overlap with already allocated\ndate and time slots.\n13 Sistem, kullanıcının, sayısalla¸ stırılmı¸ s\ngenel ke¸ sif incelemeleri dok¨ umanını sis-\nteme y¨ uklemesini sa˘ glayacaktır.\nThe system shall allow users to upload\ndigitized general inspection report doc-\numents to the system.\n14 Sistem, kullanıcının katılımcı listesin-\nden katılımcı se¸ cerek, o katılımcıya\nait detay bilgilerini g¨ ormesini\nsa˘ glayacaktır.\nThe system shall allow the user to se-\nlect a participant from the list and\nview their detailed information.\n15 Sistem, kullanıcının e˘ gitici ¨ odeme,\nileti¸ sim ve ula¸ sım bilgilerini kay-\ndetmesini sa˘ glayacaktır.\nThe system shall allow the user to save\npayment, communication, and contact\ninformation for the trainer.\n16 Sistem, intranet ve internet a˘ gındaki\nkullanıcıların e˘ gitim plan duyurusunu\nindirmesini sa˘ glayacaktır.\nThe system shall allow users on the in-\ntranet and internet network to down-\nload training announcements.\n17 Sistem, uygulama yazılımında dı¸ s\nortamlar i¸ cin geli¸ stirilecek web\nservislerine HTTP ve/veya HTTPS\nprotokol¨ u ¨ uzerinden eri¸ silebilmesi\ndeste˘ gini sa˘ glayacaktır.\nThe system shall provide access sup-\nport for web services to be de-\nveloped for application software in\ndistributed environments via HTTP\nand/or HTTPS protocols.\n18 Sistem, uygulama yazılımının\nmod¨ uler ve da˘ gıtık bir yapıda\ngeli¸ stirilebilmesini sa˘ glayacaktır.\nThe system shall support the develop-\nment of the application software in a\nmodular and distributed architecture.\n19 Sistem, uygulama yazılımının,\nSpring framework ile MVC (Model-\nView-Controller) mimari tasarım\n¸ sablonuna uygun geli¸ stirilebilmesini\nsa˘ glayacaktır.\nThe system shall enable the devel-\nopment of the application software\nin compliance with the Spring frame-\nwork and the MVC (Model-View-\nController) architectural design pat-\ntern.\n20 Sistem, kullanıcının veri giri¸ si\nsırasında, otomatik olarak maskeleme\ndeste˘ gi sa˘ glayacaktır.\nThe system shall provide automatic\nmasking support during user data en-\ntry.', 'CONTEXT: This chunk focuses on the introduction of the **Agency Security Requirements Dataset (ASRD)**, detailing its real-world data sources, expert annotation process, and alignment with OWASP ASVS categories, as well as outlining the research questions and comparative evaluation of fine-tuned transformer models versus prompt-based approaches for security requirements classification.\n\nCONTENT: 4 Yusuf G¨ ur et al.\ncient and cost-effective compared to addressing security issues at later stages\nof development ((Khan et al., 2024).\nThis paper proposes a machine learning-based system to automatically an-\nalyze SRS documents and classify security requirements according to OWASP\nASVS. Its main contribution is the Agency Security Requirements Dataset\n(ASRD), a publicly available corpus created to support research in automated\nSRA. The ASRD comprises:\n–Real-World Data: 2,652 Software Requirements Specification (SRS) sen-\ntences extracted from six diverse, real-world industry projects,\n–Expert Annotation: Meticulously annotated by three cybersecurity experts,\neach with over 15 years of industry experience,\n–Rigorous Methodology: Developed using the iterative MATTER cycle an-\nnotation framework (Pustejovsky and Stubbs, 2012),\n–High Granularity and Multi-label Structure: Mapped to 11 distinct, action-\nable security categories from the industry-standard OWASP Application\nSecurity Verification Standard (ASVS,V2–V13), allowing each require-\nment to be associated with multiple categories.\nThe ASRD is intended as a shared research resource and benchmark. Using\nthis dataset, the study conducts an empirical analysis of automated classifica-\ntion approaches and addresses the following research questions:\n1. To what extent can fine-tuned transformer models accurately perform\nmulti-label classification of implicit security requirements into OWASP\nASVS categories using the ASRD?\n2. How does the performance of prompt-based approaches (zero-shot and few-\nshot) using modern LLMs compare to fine-tuned BERT-based models and\nnaive baselines for this task?\nThe results show that few-shot prompting with a modern language model\n(Gemini 2.0) achieves a macro-average F1 score of 0.941, closely matching the\nbest fine-tuned BERT-based model (0.942). This demonstrates that example-\nguided inference can reach performance comparable to supervised fine-tuning\nwhile requiring substantially less annotated data and model retraining. The\nevaluation compares fine-tuned transformer models (e.g., SecureBERT) with\nprompt-based methods in zero-shot and few-shot settings across multiple con-\ntemporary models, demonstrating that prompt-based approaches provide a\npractical and resource-efficient alternative for identifying implicit security re-\nquirements in industrial SRS documents.\nThe remainder of this paper is organized as follows. Section 2 reviews re-\nlated work on NLP-based requirements classification, security frameworks, and\nexisting security datasets. Section 3 describes the curation and expert anno-\ntation of the ASRD and summarizes its key characteristics. Section 4 outlines\nthe experimental setup and classification methods, including fine-tuned BERT\nmodels and prompt-based approaches. Section 5 reports the experimental re-\nsults. Section 6 discusses the findings and their implications, with a com-\nparative analysis of fine-tuning and prompting strategies. Section 7 examines', 'CONTEXT: This chunk discusses the curation and preprocessing of the ASRD dataset, detailing the data collection process from real-world Software Requirements Specification (SRS) documents, the multi-stage preprocessing pipeline for sentence extraction and anonymization, and how the dataset addresses gaps in prior work by incorporating industrial complexity and linguistic diversity.\n\nCONTENT: Implicit Security Requirements Classification 9\n2.3.3 Electronic Health Domain Dataset\nThis corpus focuses on the electronic healthcare industry, a sector defined\nby stringent regulatory and high-assurance demands (Riaz et al., 2014). The\ndataset’s strength lies in its rigorous multi-stage annotation methodology,\nwhich utilized independent researchers and a mediator to ensure high inter-\nannotator agreement. While it provides a large-scale, authentic resource for\nhealthcare-specific tasks, its narrow focus may limit the generalizability of\nmodels to other industries, and its high-level security objectives may be too\ncoarse for detailed technical analysis.\n2.3.4 Summary of Datasets\nAs summarized in Table 1, these datasets vary significantly in their suitability\nfor tasks ranging from general non-functional requirement (NFR) classifica-\ntion to detailed security analysis. Our proposed Agency Security Require-\nments Dataset (ASRD) addresses gaps in prior work by adopting the OWASP\nASVS taxonomy for multi-label annotation. Furthermore, by utilizing real-\nworld projects originally written in Turkish, ASRD introduces both industrial\ncomplexity and linguistic diversity to the field.\n3 Dataset Curation, Annotation, and Evaluation\n3.1 Data Collection and Preprocessing\nThe dataset compilation began with the collection of six Software Require-\nments Specification (SRS) documents from an Agency’s Security Department.\nThese documents were selected from an initial pool of 19 projects executed\nbetween 2019 and 2023, specifically chosen for their domain diversity and\namenability to effective anonymization. The original documents were provided\nin standard document formats (e.g., PDF, DOCX) where requirements were\norganized in itemized lists. To transform these documents into a machine-\nreadable dataset, we employed a multi-stage preprocessing pipeline:\n1. Sentence Segmentation and Extraction: As the source SRS documents uti-\nlized standard itemization for requirements, we employed a rule-based ex-\ntraction method. We utilized pattern matching to identify requirement\nblocks based on hierarchical numbering schemes and line breaks. Each iden-\ntified requirement was extracted and treated as a single processing unit,\npreserving the structural integrity of the original specification.\n2. Anonymization: To protect sensitive data, a semi-automated anonymiza-\ntion process was implemented. Custom scripts replaced entities such as\nproject names, specific URLs, and IP addresses with generic placeholders.\nThis was followed by a manual review by domain experts to ensure that\nthe removal of personally identifiable information (PII) did not compromise\nthe semantic meaning or contextual integrity of the requirements.', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb', ""CONTEXT: **Sample Security Requirement Classifications and Dataset Insights**: This chunk provides examples of security requirement classifications from the ASRD dataset, showcasing Turkish-language requirements, their English translations, and corresponding OWASP ASVS category mappings, highlighting the dataset's structure and annotation methodology.\n\nCONTENT: 18 Yusuf G¨ ur et al.\nFig. 1: Distribution of Classes\n\nImplicit Security Requirements Classification 19\nTable 4: Sample Requirement Classifications\nNo Original Requirements in Turkish Translated Requirements\nV2, Authentication\nV3, Session Mngmt.\nV4, Access Control\nV5, Validation\nV6, Cryptography\nV7, Error Handling\nV8, Data Protection\nV9, Communication\nV10, Malicious Code\nV12, File/Resources\nV13, API/Web Service\n1 Sistem, otel devir i¸ slemi ger¸ cekle¸ stirecektir. The system shall carry out the hotel room handover\nprocess.\n1 0 1 1 0 0 1 1 1 0 1\n2 Sistem, demirba¸ s devir i¸ slemi ger¸ cekle¸ stirecektir. The system shall carry out the fixed asset handover\nprocess.\n1 1 1 1 1 0 1 1 1 1 1\n3 Sistem, i¸ sletme stokları devri ger¸ cekle¸ stirecektir. The system shall carry out the business stock han-\ndover.\n1 1 1 1 1 1 1 1 1 1 1\n4 Sistem, kullanıcının Demirba¸ s Devir ¸ cizelgesi ra-\nporunu almasını sa˘ glayacaktır.\nThe system shall allow the user to generate the\nfixed asset handover schedule report.\n1 1 1 1 1 1 1 1 1 0 1\n5 Sistem, kullanıcının El Senedi Eki raporu almasını\nsa˘ glayacaktır.\nThe system shall allow the user to generate the\nPromissory Note Attachment report.\n1 1 1 1 1 0 1 1 1 0 1\n6 Sistem, uygulama yazılımına, mevcutta bulunan\ndil deste˘ gine ilave olarak di˘ ger dillerin property\ndosyaları olarak eklenebilmesini sa˘ glayacaktır.\nThe system shall enable additional languages to be\nadded to the application software via property files,\nin addition to the existing language support.\n0 0 1 0 0 0 0 1 1 0 1\n7 Sistem, raporun ekranda g¨ or¨ unt¨ ulenerek ¨ on izlen-\nmesini, yazıcıdan alabilmesini ve dosyaya ak-\ntarılabilmesini sa˘ glayacaktır.\nThe system shall allow reports to be previewed on\nscreen, printed, and exported to files.\n1 1 1 0 0 1 1 1 1 0 1\n8 Sistem, uygulama yazılımı i¸ slevleri arası dahili\nileti¸ sim i¸ cin geli¸ stirilecek web servislerinin REST\nstandartlarını desteklemesini sa˘ glayacaktır.\nThe system shall ensure that web services devel-\noped for internal communication between applica-\ntion functions comply with REST standards.\n1 0 1 1 0 0 1 0 0 0 1\n9 Sistem, kullanıcının uygulama yazılımı ekranları ve\nsayfaları ¨ uzerinde i¸ slem yapabilece˘ gi alanlar T¨ urk¸ ce\nF ve Q klavye ile uyumlu olacaktır.\nThe system shall ensure that user input areas on\napplication screens and pages are compatible with\nTurkish F and Q keyboards.\n0 0 0 1 0 0 0 0 0 1 0\n10 Sistem, uygulamada olu¸ san hatalara ili¸ skin\nbildirimlerin T¨ urk¸ ce olmasını, hatayı a¸ cıklayacak\nteknik detay ya da hata kodunu i¸ cermesini\nsa˘ glayacaktır.\nThe system shall ensure that notifications regard-\ning errors occurring in the application are in Turk-\nish and include technical details or error codes ex-\nplaining the error.\n0 0 0 0 0 1 0 0 0 0 0\n11 Sistem, uygulama yazılımı ekranlarının, ana say-\nfaya d¨ on¨ u¸ s sa˘ glayan bir ba˘ glantı i¸ cermesini\nsa˘ glayacaktır.\nThe system shall ensure that the application soft-\nware screens contain a link that allows returning to\nthe homepage.\n0 0 1 0 0 0 0 1 0 0 0\n12 Sistem, kullanıcının, uygulamada birbiriyle ili¸ skili\nekranlar arasında bir ¨ ust sayfaya ge¸ ci¸ s yapa-\nbilmesini sa˘ glayacaktır.\nThe system shall allow users to navigate to a par-\nent (higher-level) page among related application\nscreens.\n1 1 1 1 0 0 0 1 0 0 0\n13 Sistem, uygulama ekranları i¸ cin, en az bir tane\nyardım ekranı sa˘ glayacaktır.\nThe system shall provide at least one help screen\nfor application screens.\n0 0 0 0 0 0 0 0 0 0 0\n14 Sistem, uygulamanın tasarım a¸ samasında\nbelirlenecek ekranları i¸ cin yardım videoları\nsa˘ glayacaktır.\nThe system shall provide help videos for screens\nidentified during the application design phase.\n0 0 0 0 0 0 0 0 0 0 0"", 'CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr']","The ASRD contains **2,652 requirements**. These requirements were derived from six real-world Software Requirements Specification (SRS) documents across diverse business domains, including Construction, Legal, Education, Software, Meeting, and Accommodation. The dataset was meticulously curated through a multi-stage process involving sentence extraction, anonymization, and expert annotation. The requirements were aligned with the OWASP Application Security Verification Standard (ASVS) for security classification. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","The ASRD comprises 2,652 real-world requirement statements derived from six diverse Software Requirements Specification (SRS) documents from a government agency[cite: 12, 71].",,,
Which security standard was used to annotate the dataset?,"['CONTEXT: **Annotation Process and Dataset Composition**: This chunk details the multi-stage annotation methodology used to create the ASRD dataset, addressing class distribution, challenges with imbalanced categories (e.g., V6 Cryptography, V12 Files/Resources), and the inclusion of true negatives to ensure realistic and high-quality security requirement classification.\n\nCONTENT: Implicit Security Requirements Classification 17\n0.71 to 0.79, further confirmed substantial agreement between individual\nannotator pairs.\n–Adjudication: Disagreements were resolved through structured expert dis-\ncussions led by the senior SME. When the two annotators disagreed on a\nrequirement, it was resolved through a structured process:\n–Both annotators presented their choice and their reasons.\n–The senior expert reviewed both positions against the guideline.\n–If the guideline clearly supported one choice, that one was used. If not,\nthe senior expert led a discussion to decide.\n–Final decision and the reason was written down.\nThe goal was to reach unanimous agreement for each disputed requirement.\nThis process produced final Gold Standard annotations for 135 contested\nitems, ensuring consistency and validation of the dataset.\nThis multi-stage annotation methodology produced a reliable dataset which\ncomprises 2,652 annotated security-relevant requirements. The category dis-\ntributions of the requirements can be seen in Figure 1. The class distribution\namong the classes are largely balanced (90%) except the V6(Stored Cryptog-\nraphy) and V12 (Files & Resources) as 6% each. This imbalance is considered\na reflection of the source projects, where requirements for these two categories\nare inherently less frequent than pervasive controls like access control or input\nvalidation. Stored cryptography requirements are typically captured as holis-\ntic, architectural decisions rather than numerous, distinct functional require-\nments. Similarly, explicit security controls for file handling are less ubiquitous,\nappearing only in projects with specific file processing features, which explains\ntheir low frequency in our corpus. Sample annotated requirements can be seen\nin Table 4.\nThis imbalance mirrors real-world security requirement frequency - most\nsoftware functions involve access and data; few involve file uploads or encryp-\ntion configuration - and introduces a challenge for machine learning. Partic-\nularly, the sparsity in V6 and V12 categories may hinder generalization and\ncalls for class imbalance handling techniques. Despite this, the dataset presents\na realistic and high-quality foundation for developing and evaluating security-\naware NLP and classification models.\nTwenty-six requirements (0.98% of the data) labeled as “UNASSIGNED”\nwere requirements unanimously determined by the experts to be purely func-\ntional requirements with no discernible implicit security component (e.g., “The\nsystem will enable application software to be developed with an object-oriented\nprogramming approach”,). These items were intentionally retained in the dataset\nas true negatives to ensure a realistic distribution and test the models’ ability\nto correctly reject non-security items.\n\n18 Yusuf G¨ ur et al.\nFig. 1: Distribution of Classes', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: This chunk focuses on the introduction of the **Agency Security Requirements Dataset (ASRD)**, detailing its real-world data sources, expert annotation process, and alignment with OWASP ASVS categories, as well as outlining the research questions and comparative evaluation of fine-tuned transformer models versus prompt-based approaches for security requirements classification.\n\nCONTENT: 4 Yusuf G¨ ur et al.\ncient and cost-effective compared to addressing security issues at later stages\nof development ((Khan et al., 2024).\nThis paper proposes a machine learning-based system to automatically an-\nalyze SRS documents and classify security requirements according to OWASP\nASVS. Its main contribution is the Agency Security Requirements Dataset\n(ASRD), a publicly available corpus created to support research in automated\nSRA. The ASRD comprises:\n–Real-World Data: 2,652 Software Requirements Specification (SRS) sen-\ntences extracted from six diverse, real-world industry projects,\n–Expert Annotation: Meticulously annotated by three cybersecurity experts,\neach with over 15 years of industry experience,\n–Rigorous Methodology: Developed using the iterative MATTER cycle an-\nnotation framework (Pustejovsky and Stubbs, 2012),\n–High Granularity and Multi-label Structure: Mapped to 11 distinct, action-\nable security categories from the industry-standard OWASP Application\nSecurity Verification Standard (ASVS,V2–V13), allowing each require-\nment to be associated with multiple categories.\nThe ASRD is intended as a shared research resource and benchmark. Using\nthis dataset, the study conducts an empirical analysis of automated classifica-\ntion approaches and addresses the following research questions:\n1. To what extent can fine-tuned transformer models accurately perform\nmulti-label classification of implicit security requirements into OWASP\nASVS categories using the ASRD?\n2. How does the performance of prompt-based approaches (zero-shot and few-\nshot) using modern LLMs compare to fine-tuned BERT-based models and\nnaive baselines for this task?\nThe results show that few-shot prompting with a modern language model\n(Gemini 2.0) achieves a macro-average F1 score of 0.941, closely matching the\nbest fine-tuned BERT-based model (0.942). This demonstrates that example-\nguided inference can reach performance comparable to supervised fine-tuning\nwhile requiring substantially less annotated data and model retraining. The\nevaluation compares fine-tuned transformer models (e.g., SecureBERT) with\nprompt-based methods in zero-shot and few-shot settings across multiple con-\ntemporary models, demonstrating that prompt-based approaches provide a\npractical and resource-efficient alternative for identifying implicit security re-\nquirements in industrial SRS documents.\nThe remainder of this paper is organized as follows. Section 2 reviews re-\nlated work on NLP-based requirements classification, security frameworks, and\nexisting security datasets. Section 3 describes the curation and expert anno-\ntation of the ASRD and summarizes its key characteristics. Section 4 outlines\nthe experimental setup and classification methods, including fine-tuned BERT\nmodels and prompt-based approaches. Section 5 reports the experimental re-\nsults. Section 6 discusses the findings and their implications, with a com-\nparative analysis of fine-tuning and prompting strategies. Section 7 examines', 'CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr', 'CONTEXT: This chunk details the **annotation methodology** and **dataset curation process** for the ASRD, following the MATTER cycle framework. It describes annotator selection, corpus preparation, and the iterative development of annotation guidelines aligned with OWASP ASVS categories to ensure high-quality, domain-specific annotations.\n\nCONTENT: Implicit Security Requirements Classification 15\n3.3 Annotation Methodology (MATTER Cycle) & Dataset Curation\nThe annotation process followed the MATTER development cycle, an estab-\nlished iterative framework for corpus annotation (Pustejovsky and Stubbs,\n2012). Crucially, the annotation task was defined as a multi-label text classifi-\ncation problem. It consists of the phases Model, Annotate, Train, Test, Eval-\nuate, and Revise. The annotation guidelines were developed and iteratively\nrefined to ensure consistency and clarity.\nThe Model–Annotate cycle involved writing guidelines, selecting annota-\ntors, conducting trial annotations, and refining the process. Once stabilized,\nthis cycle was expanded to the full dataset to generate a Gold Standard corpus.\nThe annotation workflow included the following processes:\n–Annotator Selection: Following Bayerl and Paul’s recommendation to use\ndomain-aligned annotators (Bayerl and Paul, 2011), three cybersecurity\nsubject matter experts (SME) from the agency, each with over 15 years\nof experience in designing security architectures, analyzing threat models,\nand identifying security requirements, performed the annotations. Their\ndeep practical experience ensured accurate and context-aware interpreta-\ntion which aligned with the requirement “experts must demonstrate signif-\nicant skills, knowledge, and experience” emphasized by Hopkins (Hopkins\nand Unger, 2017). The senior manager among them also provided over-\nsight and led the adjudication process. The senior SME acted as both an\nannotator and the final adjudicator for resolving disagreements. They also\nprovided feedback to improve the quality and clarity of the annotation\nguideline.\n–Corpus Selection and Preparation: Cohen (Cohen et al., 2005) recommends\nthat during corpus design, balance and representativeness of the corpus\nis important. In line with his recommendation, of the 19 initial project\ndocuments, six were chosen for their domain diversity and potential for\neffective anonymization by the SMEs. These documents underwent a semi-\nautomated anonymization process to remove all project-specific and per-\nsonally identifiable information (PII). The process targeted entities such\nas names of individuals and organizations, project codenames, and specific\ntechnical identifiers. This was done using custom scripts with placeholder\nreplacement, followed by manual review to ensure that anonymization did\nnot alter the meaning, structure, or intent of the original requirements. The\nextracted requirements were then randomized and masked to prevent po-\ntential bias related to document origin or sequence during the annotation\nphase. Total corpus has 2,652 requirements (30 pilot + 2,622 independent\nannotations).\n–Annotation Guideline Development: The Annotation Guidelines’ develop-\nment involved an initial iterative process, refining the guidelines three times\nto resolve ambiguities before the formal assessment phase. Annotation rules\nwere based on OWASP ASVS categories V2–V13 and refined iteratively\nusing example annotations. Following best practices suggested by Cohen\n(Cohen et al., 2005), the guidelines and annotation documents ensured:', 'CONTEXT: This chunk discusses the curation and preprocessing of the ASRD dataset, detailing the data collection process from real-world Software Requirements Specification (SRS) documents, the multi-stage preprocessing pipeline for sentence extraction and anonymization, and how the dataset addresses gaps in prior work by incorporating industrial complexity and linguistic diversity.\n\nCONTENT: Implicit Security Requirements Classification 9\n2.3.3 Electronic Health Domain Dataset\nThis corpus focuses on the electronic healthcare industry, a sector defined\nby stringent regulatory and high-assurance demands (Riaz et al., 2014). The\ndataset’s strength lies in its rigorous multi-stage annotation methodology,\nwhich utilized independent researchers and a mediator to ensure high inter-\nannotator agreement. While it provides a large-scale, authentic resource for\nhealthcare-specific tasks, its narrow focus may limit the generalizability of\nmodels to other industries, and its high-level security objectives may be too\ncoarse for detailed technical analysis.\n2.3.4 Summary of Datasets\nAs summarized in Table 1, these datasets vary significantly in their suitability\nfor tasks ranging from general non-functional requirement (NFR) classifica-\ntion to detailed security analysis. Our proposed Agency Security Require-\nments Dataset (ASRD) addresses gaps in prior work by adopting the OWASP\nASVS taxonomy for multi-label annotation. Furthermore, by utilizing real-\nworld projects originally written in Turkish, ASRD introduces both industrial\ncomplexity and linguistic diversity to the field.\n3 Dataset Curation, Annotation, and Evaluation\n3.1 Data Collection and Preprocessing\nThe dataset compilation began with the collection of six Software Require-\nments Specification (SRS) documents from an Agency’s Security Department.\nThese documents were selected from an initial pool of 19 projects executed\nbetween 2019 and 2023, specifically chosen for their domain diversity and\namenability to effective anonymization. The original documents were provided\nin standard document formats (e.g., PDF, DOCX) where requirements were\norganized in itemized lists. To transform these documents into a machine-\nreadable dataset, we employed a multi-stage preprocessing pipeline:\n1. Sentence Segmentation and Extraction: As the source SRS documents uti-\nlized standard itemization for requirements, we employed a rule-based ex-\ntraction method. We utilized pattern matching to identify requirement\nblocks based on hierarchical numbering schemes and line breaks. Each iden-\ntified requirement was extracted and treated as a single processing unit,\npreserving the structural integrity of the original specification.\n2. Anonymization: To protect sensitive data, a semi-automated anonymiza-\ntion process was implemented. Custom scripts replaced entities such as\nproject names, specific URLs, and IP addresses with generic placeholders.\nThis was followed by a manual review by domain experts to ensure that\nthe removal of personally identifiable information (PII) did not compromise\nthe semantic meaning or contextual integrity of the requirements.', ""CONTEXT: **Comparative Analysis of Security Requirement Datasets**: This chunk provides a detailed comparison of the ASRD dataset with other prominent security requirement datasets, highlighting differences in size, domain coverage, annotation methodologies, and granularity, while emphasizing ASRD's strengths in industrial complexity, multi-domain applicability, and alignment with OWASP ASVS standards.\n\nCONTENT: 8 Yusuf G¨ ur et al.\nTable 1: Comparative Analysis of Security Requirement Datasets\nCharacteristic PROMISE\nexp\nDOSSPRE Healthcare\nDataset\nASRD (Ours)\nTotal Require-\nments\n969 1,317 10,963 2,652\nData Source Public SRS\ndocuments\n(expanded to\n49 projects)\n105 Student\nproject docu-\nments\n6 Official Cana-\ndian and U.S.\nSRS documents\n6 Real-world\nSRS docs from\na gov’t agency\nDomain General /\nCross-domain\nGeneral / Aca-\ndemic\nElectronic\nHealthcare\nMulti-domain:\nLegal, Const.,\nEdu., etc.\nPrimary Task FR vs. NFR,\nMulti-class\nNFR\nSR vs. NSR,\nMulti-class SR\nMulti-label\nSecurity Objec-\ntives\nMulti-label Im-\nplicit Security\nClass.\nSecurity Granu-\nlarity\nSingle SE\nclass\n10 security\nclasses\n6 security objec-\ntives\n11 OWASP\nASVS classes\nLanguage English English English Turkish\nAnnotation\nMethodology\nExpert Con-\nsensus: Man-\nual extraction\nand valida-\ntion\nAuthor Com-\npilation: Cat-\negorized by\nauthors only,\nlimited rigorous\nvalidation\nMulti-Stage\nConsensus: 2\nresearchers +\nmediator, high\nagreement\nMATTER Cy-\ncle: 3 SMEs\nwith adjudica-\ntion, iterative\nrefinement and\nabjudication\nKey Strength Established\nbenchmark\nand project\ndiversity\nFine-grained\nsecurity-specific\ntaxonomy\nLarge scale and\ndomain authen-\nticity\nIndustrial\ncomplexity +\nOWASP ASVS\nKey Limitation Small size\nand class\nimbalance\nPotential lack of\nprofessional re-\nalism\nDomain-\nspecific; coarse-\ngrained labels\nReal-world class\nimbalance in\nspecific cate-\ngories\nimbalance often restrict its suitability for training complex deep learning ar-\nchitectures.\n2.3.2 DOSSPRE\nThe Dataset of Students’ Software Projects Requirements (DOSSPRE) was\ncompiled by Kadebu et al. from documentation within academic curricula\n(Kadebu et al., 2023), likely from the Harare Institute of Technology. It pro-\nvides a fine-grained classification through a detailed taxonomy for both se-\ncurity and non-security requirements. However, as the requirements were au-\nthored by students, they may not fully reflect the realism and complexity of\nindustry-grade requirements."", ""CONTEXT: **Sample Security Requirement Classifications and Dataset Insights**: This chunk provides examples of security requirement classifications from the ASRD dataset, showcasing Turkish-language requirements, their English translations, and corresponding OWASP ASVS category mappings, highlighting the dataset's structure and annotation methodology.\n\nCONTENT: 18 Yusuf G¨ ur et al.\nFig. 1: Distribution of Classes\n\nImplicit Security Requirements Classification 19\nTable 4: Sample Requirement Classifications\nNo Original Requirements in Turkish Translated Requirements\nV2, Authentication\nV3, Session Mngmt.\nV4, Access Control\nV5, Validation\nV6, Cryptography\nV7, Error Handling\nV8, Data Protection\nV9, Communication\nV10, Malicious Code\nV12, File/Resources\nV13, API/Web Service\n1 Sistem, otel devir i¸ slemi ger¸ cekle¸ stirecektir. The system shall carry out the hotel room handover\nprocess.\n1 0 1 1 0 0 1 1 1 0 1\n2 Sistem, demirba¸ s devir i¸ slemi ger¸ cekle¸ stirecektir. The system shall carry out the fixed asset handover\nprocess.\n1 1 1 1 1 0 1 1 1 1 1\n3 Sistem, i¸ sletme stokları devri ger¸ cekle¸ stirecektir. The system shall carry out the business stock han-\ndover.\n1 1 1 1 1 1 1 1 1 1 1\n4 Sistem, kullanıcının Demirba¸ s Devir ¸ cizelgesi ra-\nporunu almasını sa˘ glayacaktır.\nThe system shall allow the user to generate the\nfixed asset handover schedule report.\n1 1 1 1 1 1 1 1 1 0 1\n5 Sistem, kullanıcının El Senedi Eki raporu almasını\nsa˘ glayacaktır.\nThe system shall allow the user to generate the\nPromissory Note Attachment report.\n1 1 1 1 1 0 1 1 1 0 1\n6 Sistem, uygulama yazılımına, mevcutta bulunan\ndil deste˘ gine ilave olarak di˘ ger dillerin property\ndosyaları olarak eklenebilmesini sa˘ glayacaktır.\nThe system shall enable additional languages to be\nadded to the application software via property files,\nin addition to the existing language support.\n0 0 1 0 0 0 0 1 1 0 1\n7 Sistem, raporun ekranda g¨ or¨ unt¨ ulenerek ¨ on izlen-\nmesini, yazıcıdan alabilmesini ve dosyaya ak-\ntarılabilmesini sa˘ glayacaktır.\nThe system shall allow reports to be previewed on\nscreen, printed, and exported to files.\n1 1 1 0 0 1 1 1 1 0 1\n8 Sistem, uygulama yazılımı i¸ slevleri arası dahili\nileti¸ sim i¸ cin geli¸ stirilecek web servislerinin REST\nstandartlarını desteklemesini sa˘ glayacaktır.\nThe system shall ensure that web services devel-\noped for internal communication between applica-\ntion functions comply with REST standards.\n1 0 1 1 0 0 1 0 0 0 1\n9 Sistem, kullanıcının uygulama yazılımı ekranları ve\nsayfaları ¨ uzerinde i¸ slem yapabilece˘ gi alanlar T¨ urk¸ ce\nF ve Q klavye ile uyumlu olacaktır.\nThe system shall ensure that user input areas on\napplication screens and pages are compatible with\nTurkish F and Q keyboards.\n0 0 0 1 0 0 0 0 0 1 0\n10 Sistem, uygulamada olu¸ san hatalara ili¸ skin\nbildirimlerin T¨ urk¸ ce olmasını, hatayı a¸ cıklayacak\nteknik detay ya da hata kodunu i¸ cermesini\nsa˘ glayacaktır.\nThe system shall ensure that notifications regard-\ning errors occurring in the application are in Turk-\nish and include technical details or error codes ex-\nplaining the error.\n0 0 0 0 0 1 0 0 0 0 0\n11 Sistem, uygulama yazılımı ekranlarının, ana say-\nfaya d¨ on¨ u¸ s sa˘ glayan bir ba˘ glantı i¸ cermesini\nsa˘ glayacaktır.\nThe system shall ensure that the application soft-\nware screens contain a link that allows returning to\nthe homepage.\n0 0 1 0 0 0 0 1 0 0 0\n12 Sistem, kullanıcının, uygulamada birbiriyle ili¸ skili\nekranlar arasında bir ¨ ust sayfaya ge¸ ci¸ s yapa-\nbilmesini sa˘ glayacaktır.\nThe system shall allow users to navigate to a par-\nent (higher-level) page among related application\nscreens.\n1 1 1 1 0 0 0 1 0 0 0\n13 Sistem, uygulama ekranları i¸ cin, en az bir tane\nyardım ekranı sa˘ glayacaktır.\nThe system shall provide at least one help screen\nfor application screens.\n0 0 0 0 0 0 0 0 0 0 0\n14 Sistem, uygulamanın tasarım a¸ samasında\nbelirlenecek ekranları i¸ cin yardım videoları\nsa˘ glayacaktır.\nThe system shall provide help videos for screens\nidentified during the application design phase.\n0 0 0 0 0 0 0 0 0 0 0""]","The security standard used to annotate the dataset is the **OWASP Application Security Verification Standard (ASVS)**. The dataset, ASRD, was annotated using a high-granularity taxonomy based on OWASP ASVS categories (V2–V13). This standard was employed to ensure multi-label classification of security requirements, aligning with industry standards for actionable security categories.

**Source:** temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf","The dataset was annotated using a high-granularity taxonomy based on the OWASP Application Security Verification Standard (ASVS) V2-V13[cite: 12, 73].",,,
What specific annotation framework was employed to ensure dataset quality?,"['CONTEXT: This chunk details the **annotation methodology** and **dataset curation process** for the ASRD, following the MATTER cycle framework. It describes annotator selection, corpus preparation, and the iterative development of annotation guidelines aligned with OWASP ASVS categories to ensure high-quality, domain-specific annotations.\n\nCONTENT: Implicit Security Requirements Classification 15\n3.3 Annotation Methodology (MATTER Cycle) & Dataset Curation\nThe annotation process followed the MATTER development cycle, an estab-\nlished iterative framework for corpus annotation (Pustejovsky and Stubbs,\n2012). Crucially, the annotation task was defined as a multi-label text classifi-\ncation problem. It consists of the phases Model, Annotate, Train, Test, Eval-\nuate, and Revise. The annotation guidelines were developed and iteratively\nrefined to ensure consistency and clarity.\nThe Model–Annotate cycle involved writing guidelines, selecting annota-\ntors, conducting trial annotations, and refining the process. Once stabilized,\nthis cycle was expanded to the full dataset to generate a Gold Standard corpus.\nThe annotation workflow included the following processes:\n–Annotator Selection: Following Bayerl and Paul’s recommendation to use\ndomain-aligned annotators (Bayerl and Paul, 2011), three cybersecurity\nsubject matter experts (SME) from the agency, each with over 15 years\nof experience in designing security architectures, analyzing threat models,\nand identifying security requirements, performed the annotations. Their\ndeep practical experience ensured accurate and context-aware interpreta-\ntion which aligned with the requirement “experts must demonstrate signif-\nicant skills, knowledge, and experience” emphasized by Hopkins (Hopkins\nand Unger, 2017). The senior manager among them also provided over-\nsight and led the adjudication process. The senior SME acted as both an\nannotator and the final adjudicator for resolving disagreements. They also\nprovided feedback to improve the quality and clarity of the annotation\nguideline.\n–Corpus Selection and Preparation: Cohen (Cohen et al., 2005) recommends\nthat during corpus design, balance and representativeness of the corpus\nis important. In line with his recommendation, of the 19 initial project\ndocuments, six were chosen for their domain diversity and potential for\neffective anonymization by the SMEs. These documents underwent a semi-\nautomated anonymization process to remove all project-specific and per-\nsonally identifiable information (PII). The process targeted entities such\nas names of individuals and organizations, project codenames, and specific\ntechnical identifiers. This was done using custom scripts with placeholder\nreplacement, followed by manual review to ensure that anonymization did\nnot alter the meaning, structure, or intent of the original requirements. The\nextracted requirements were then randomized and masked to prevent po-\ntential bias related to document origin or sequence during the annotation\nphase. Total corpus has 2,652 requirements (30 pilot + 2,622 independent\nannotations).\n–Annotation Guideline Development: The Annotation Guidelines’ develop-\nment involved an initial iterative process, refining the guidelines three times\nto resolve ambiguities before the formal assessment phase. Annotation rules\nwere based on OWASP ASVS categories V2–V13 and refined iteratively\nusing example annotations. Following best practices suggested by Cohen\n(Cohen et al., 2005), the guidelines and annotation documents ensured:', 'CONTEXT: **Annotation Process and Quality Assurance in ASRD Development**: This chunk details the iterative annotation process for the ASRD dataset, including pilot and independent annotation phases, adjudication meetings, and the use of agreement metrics (e.g., Fleiss’s Kappa) to ensure high annotation quality and consistency among cybersecurity experts.\n\nCONTENT: 16 Yusuf G¨ ur et al.\n(1) original text and annotations were recoverable, (2) clear documenta-\ntion was maintained, (3) annotation quality was consistently high. The\nannotation template included fields for the software requirement text, se-\nlected OWASP labels, and annotator comments or questions. All versions\nof the guideline and annotation documents were preserved to track revi-\nsions based on annotator feedback. For the annotation process, a sample\ncorpus from the requirement set has been selected by inter agreement of\nSMEs. The first version of the Annotation Guideline based on OWASP\nASVS security classes has been developed, where each annotator has in-\ndividually classified the sample corpus by annotating it with one or more\nlabels following the instructions provided in the first Annotation Guide-\nline. After the initial annotation, the SMEs met under the guidance of the\nsenior SME, who is also the branch manager, to review and discuss the\nannotation decisions. Each of the 30 software requirements was examined\nindividually, and in cases where there were differing opinions among the\nannotators, efforts were made to persuade and convince others by provid-\ning explanations and reasons for their choices. After three iterations of\ndiscussions and deliberations, a full agreement was reached for 30 software\nrequirements.\n–Pilot Annotation: An initial batch of 30 software requirements was anno-\ntated early in the study, prompting multiple discussion rounds and three\nupdates to the guidelines. Adjudication meetings enabled the resolution\nof non-consensus requirements through SME-led discussions, during which\nthe rationale for classification was articulated. Discrepancies arising from\nquality issues, such as guideline violations, were addressed by implement-\ning corrections to ensure conformity with established criteria. Each SME\nprovided justifications for their decisions, which facilitated informed dis-\ncussions and enhanced understanding during adjudication. This iterative\nprocess resolved discrepancies across 98 requirements throughout the entire\ncorpus and was important in establishing the finalized annotation frame-\nwork.\n–Independent Annotation: Each SME classified all remaining 2622 require-\nments independently, using the finalized guideline. Annotators were re-\nquired to justify each decision. This practice proved important for facili-\ntating informed discussions and understanding annotator reasoning during\nthe subsequent adjudication phase. The process took 284 days and 267\nperson-hours of expert time.\n–Agreement Metrics: Inter-Annotator Agreement (IAA) was calculated us-\ning Fleiss’s Kappa and pairwise Cohen’s Kappa to assess consistency. IAA\nscores were instrumental in identifying instances of disagreement among\nannotators, thereby highlighting areas where the guidelines might require\nfurther clarification or where ambiguous requirement phrasings contributed\nto annotation discrepancies. Fleiss’s Kappa coefficient of 0.82 was obtained\nacross the three annotators, indicating strong agreement that significantly\nexceeded random chance. Pairwise Cohen’s Kappa values, ranging from', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: **Annotation Process and Dataset Composition**: This chunk details the multi-stage annotation methodology used to create the ASRD dataset, addressing class distribution, challenges with imbalanced categories (e.g., V6 Cryptography, V12 Files/Resources), and the inclusion of true negatives to ensure realistic and high-quality security requirement classification.\n\nCONTENT: Implicit Security Requirements Classification 17\n0.71 to 0.79, further confirmed substantial agreement between individual\nannotator pairs.\n–Adjudication: Disagreements were resolved through structured expert dis-\ncussions led by the senior SME. When the two annotators disagreed on a\nrequirement, it was resolved through a structured process:\n–Both annotators presented their choice and their reasons.\n–The senior expert reviewed both positions against the guideline.\n–If the guideline clearly supported one choice, that one was used. If not,\nthe senior expert led a discussion to decide.\n–Final decision and the reason was written down.\nThe goal was to reach unanimous agreement for each disputed requirement.\nThis process produced final Gold Standard annotations for 135 contested\nitems, ensuring consistency and validation of the dataset.\nThis multi-stage annotation methodology produced a reliable dataset which\ncomprises 2,652 annotated security-relevant requirements. The category dis-\ntributions of the requirements can be seen in Figure 1. The class distribution\namong the classes are largely balanced (90%) except the V6(Stored Cryptog-\nraphy) and V12 (Files & Resources) as 6% each. This imbalance is considered\na reflection of the source projects, where requirements for these two categories\nare inherently less frequent than pervasive controls like access control or input\nvalidation. Stored cryptography requirements are typically captured as holis-\ntic, architectural decisions rather than numerous, distinct functional require-\nments. Similarly, explicit security controls for file handling are less ubiquitous,\nappearing only in projects with specific file processing features, which explains\ntheir low frequency in our corpus. Sample annotated requirements can be seen\nin Table 4.\nThis imbalance mirrors real-world security requirement frequency - most\nsoftware functions involve access and data; few involve file uploads or encryp-\ntion configuration - and introduces a challenge for machine learning. Partic-\nularly, the sparsity in V6 and V12 categories may hinder generalization and\ncalls for class imbalance handling techniques. Despite this, the dataset presents\na realistic and high-quality foundation for developing and evaluating security-\naware NLP and classification models.\nTwenty-six requirements (0.98% of the data) labeled as “UNASSIGNED”\nwere requirements unanimously determined by the experts to be purely func-\ntional requirements with no discernible implicit security component (e.g., “The\nsystem will enable application software to be developed with an object-oriented\nprogramming approach”,). These items were intentionally retained in the dataset\nas true negatives to ensure a realistic distribution and test the models’ ability\nto correctly reject non-security items.\n\n18 Yusuf G¨ ur et al.\nFig. 1: Distribution of Classes', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb', 'CONTEXT: **Advancements in LLM-Assisted Security and Related Frameworks**: This chunk discusses the application of transformer-based models and LLMs in security requirements engineering (SRE), highlighting their capabilities, challenges, and the importance of high-quality datasets and evaluation frameworks. It also reviews the role of security frameworks in systematically identifying and classifying security requirements in automated settings.\n\nCONTENT: 6 Yusuf G¨ ur et al.\nBeyond requirements classification, security research has also turned to\ntask-specific models for narrowly defined problems. For instance, deep learning\napproaches such as BiLSTMs have been used to detect re-entrancy vulnerabil-\nities in smart contracts, where generic models are insufficient (Maturi et al.,\n2025). This work highlights the importance of explainability, as security de-\ncisions must be understandable to support assurance and auditing. Although\nthis line of research addresses a different problem, it reflects a shift toward\ndomain-aware and interpretable models.\nTransformer-based models have enabled new capabilities in automated text\nunderstanding(Zhou et al., 2025). They possess emergent abilities like in-\ncontext learning, instruction following, and step-by-step reasoning (Zhu et al.,\n2025), which allow them to perform complex tasks, including requirements\nclassification, with minimal or no labeled data (Liu et al., 2023b; Zhu et al.,\n2025). Recent trends show a growing interest in applying LLMs to RE tasks,\nincluding requirements classification, prioritization, and traceability (Rajbhoj\net al., 2024; White et al., 2024). LLMs can perform zero-shot and few-shot\nlearning, reducing the need for large annotated datasets and facilitating adap-\ntation to specialized domains like SRE (Labrak et al., 2023). Techniques such\nas prompt engineering and integration with external knowledge bases (e.g.,\nRetrieval-Augmented Generation) further improve their performance and con-\ntextual relevance (Masoudifard et al., 2024).\nLLM-assisted security solutions typically follow a three-step process: pre-\nprocessing (extracting context like documentation or target units), prompt\ngeneration (using instructions and unfilled slots for the model to complete\nwith artifacts like fuzz drivers or patches), and post-processing (validating\noutputs, e.g., checking if generated code successfully compiles) (Zhu et al.,\n2025).\nWhile these models provide powerful automation, they can also introduce\nnew risks and errors if applied without careful oversight. This underscores the\nneed for realistic, high-quality datasets and standardized evaluation frame-\nworks to reliably assess automated security requirement classification, ensuring\nboth effectiveness and safety in practice.\nThe use of automated models in security highlights both their potential and\nthe risks they can introduce. Ensuring accurate and reliable classification of\nsecurity requirements requires evaluation against high-quality, domain-specific\nbenchmarks (Jeong, 2024). This underscores the need for realistic datasets and\nstandardized evaluation frameworks tailored to SRE.\n2.2 Related Work on Security Frameworks\nAn appropriate security framework is necessary to ensure systematic and con-\nsistent identification and classification of security requirements, particularly in\nautomated settings. This section reviews widely adopted security frameworks\nand evaluates their suitability for requirement analysis.', 'CONTEXT: This chunk discusses the curation and preprocessing of the ASRD dataset, detailing the data collection process from real-world Software Requirements Specification (SRS) documents, the multi-stage preprocessing pipeline for sentence extraction and anonymization, and how the dataset addresses gaps in prior work by incorporating industrial complexity and linguistic diversity.\n\nCONTENT: Implicit Security Requirements Classification 9\n2.3.3 Electronic Health Domain Dataset\nThis corpus focuses on the electronic healthcare industry, a sector defined\nby stringent regulatory and high-assurance demands (Riaz et al., 2014). The\ndataset’s strength lies in its rigorous multi-stage annotation methodology,\nwhich utilized independent researchers and a mediator to ensure high inter-\nannotator agreement. While it provides a large-scale, authentic resource for\nhealthcare-specific tasks, its narrow focus may limit the generalizability of\nmodels to other industries, and its high-level security objectives may be too\ncoarse for detailed technical analysis.\n2.3.4 Summary of Datasets\nAs summarized in Table 1, these datasets vary significantly in their suitability\nfor tasks ranging from general non-functional requirement (NFR) classifica-\ntion to detailed security analysis. Our proposed Agency Security Require-\nments Dataset (ASRD) addresses gaps in prior work by adopting the OWASP\nASVS taxonomy for multi-label annotation. Furthermore, by utilizing real-\nworld projects originally written in Turkish, ASRD introduces both industrial\ncomplexity and linguistic diversity to the field.\n3 Dataset Curation, Annotation, and Evaluation\n3.1 Data Collection and Preprocessing\nThe dataset compilation began with the collection of six Software Require-\nments Specification (SRS) documents from an Agency’s Security Department.\nThese documents were selected from an initial pool of 19 projects executed\nbetween 2019 and 2023, specifically chosen for their domain diversity and\namenability to effective anonymization. The original documents were provided\nin standard document formats (e.g., PDF, DOCX) where requirements were\norganized in itemized lists. To transform these documents into a machine-\nreadable dataset, we employed a multi-stage preprocessing pipeline:\n1. Sentence Segmentation and Extraction: As the source SRS documents uti-\nlized standard itemization for requirements, we employed a rule-based ex-\ntraction method. We utilized pattern matching to identify requirement\nblocks based on hierarchical numbering schemes and line breaks. Each iden-\ntified requirement was extracted and treated as a single processing unit,\npreserving the structural integrity of the original specification.\n2. Anonymization: To protect sensitive data, a semi-automated anonymiza-\ntion process was implemented. Custom scripts replaced entities such as\nproject names, specific URLs, and IP addresses with generic placeholders.\nThis was followed by a manual review by domain experts to ensure that\nthe removal of personally identifiable information (PII) did not compromise\nthe semantic meaning or contextual integrity of the requirements.', 'CONTEXT: **Analysis of Minority Class Performance and Annotation Challenges in SRE**: This chunk discusses the performance gap between majority and minority security classes in SRE, the expert-driven annotation process using the MATTER cycle, and the measures taken to mitigate subjectivity and ensure realistic, industry-relevant model evaluation.\n\nCONTENT: 32 Yusuf G¨ ur et al.\nFig. 4:Minority vs. Majority Class Performance Gap.A comparative\nanalysis revealing that while advanced LLMs and fine-tuned models achieve\nnear-parity on Majority Classes (Blue), a significant performance gap remains\non Minority Classes (Red), underscoring the “Long Tail” challenge in SRE.\nAnnotation was performed by three experienced cybersecurity experts.\nWhile their domain knowledge ensured quality, the small annotator pool may\nintroduce subjective bias and limit the range of interpretations. This was mit-\nigated through the iterative MATTER cycle which includes training, iterative\nguideline refinement, and consensus-based adjudication.\nA key threat to internal validity is subjectivity as classifications rely heavily\non the latent domain knowledge and industry experience, rather than explicit\nindicators within the requirement text itself. This expert-driven approach pro-\nvides a “gold standard” for realistic industrial needs but it may introduce in-\nconsistencies if replicated by annotators with different backgrounds or if the\nbroader system context is not explicitly documented.\nThe test set was manually selected to balance computational efficiency and\ngeneralizability assessment. While cross-validation could improve test calibra-\ntion, it was avoided due to its high computational cost.\nTo minimize researcher bias and ensure the results reflect real-world in-\ndustry needs, domain experts used for the selection of both the test set and\nthe LLM suite. Rather than selecting data or models arbitrarily, these experts\ncurated a test set containing the most complex, “implicit” security scenarios\nto challenge the models beyond simple pattern matching. For the model suite,\nthey prioritized architectures with advanced reasoning capabilities, hypothe-\nsizing that these specific technical features are essential for the multi-step de-\nduction required in security requirements engineering. Although the experts']","The specific annotation framework employed to ensure dataset quality was the **MATTER cycle framework**. This iterative framework includes phases such as Model, Annotate, Train, Test, Evaluate, and Revise. It was used to define the annotation task as a multi-label text classification problem. The process involved annotator selection, corpus preparation, iterative development of annotation guidelines, and adjudication meetings to resolve disagreements. The guidelines were aligned with OWASP ASVS categories (V2–V13) and refined iteratively to ensure high-quality, domain-specific annotations. Agreement metrics like Fleiss’s Kappa and pairwise Cohen’s Kappa were calculated to assess consistency, achieving strong inter-annotator agreement.

**Source:** temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf","The MATTER cycle annotation framework (Model, Annotate, Train, Test, Evaluate, Revise) was used[cite: 12, 72, 235].",,,
Who performed the annotations for the ASRD?,"['CONTEXT: This chunk details the **annotation methodology** and **dataset curation process** for the ASRD, following the MATTER cycle framework. It describes annotator selection, corpus preparation, and the iterative development of annotation guidelines aligned with OWASP ASVS categories to ensure high-quality, domain-specific annotations.\n\nCONTENT: Implicit Security Requirements Classification 15\n3.3 Annotation Methodology (MATTER Cycle) & Dataset Curation\nThe annotation process followed the MATTER development cycle, an estab-\nlished iterative framework for corpus annotation (Pustejovsky and Stubbs,\n2012). Crucially, the annotation task was defined as a multi-label text classifi-\ncation problem. It consists of the phases Model, Annotate, Train, Test, Eval-\nuate, and Revise. The annotation guidelines were developed and iteratively\nrefined to ensure consistency and clarity.\nThe Model–Annotate cycle involved writing guidelines, selecting annota-\ntors, conducting trial annotations, and refining the process. Once stabilized,\nthis cycle was expanded to the full dataset to generate a Gold Standard corpus.\nThe annotation workflow included the following processes:\n–Annotator Selection: Following Bayerl and Paul’s recommendation to use\ndomain-aligned annotators (Bayerl and Paul, 2011), three cybersecurity\nsubject matter experts (SME) from the agency, each with over 15 years\nof experience in designing security architectures, analyzing threat models,\nand identifying security requirements, performed the annotations. Their\ndeep practical experience ensured accurate and context-aware interpreta-\ntion which aligned with the requirement “experts must demonstrate signif-\nicant skills, knowledge, and experience” emphasized by Hopkins (Hopkins\nand Unger, 2017). The senior manager among them also provided over-\nsight and led the adjudication process. The senior SME acted as both an\nannotator and the final adjudicator for resolving disagreements. They also\nprovided feedback to improve the quality and clarity of the annotation\nguideline.\n–Corpus Selection and Preparation: Cohen (Cohen et al., 2005) recommends\nthat during corpus design, balance and representativeness of the corpus\nis important. In line with his recommendation, of the 19 initial project\ndocuments, six were chosen for their domain diversity and potential for\neffective anonymization by the SMEs. These documents underwent a semi-\nautomated anonymization process to remove all project-specific and per-\nsonally identifiable information (PII). The process targeted entities such\nas names of individuals and organizations, project codenames, and specific\ntechnical identifiers. This was done using custom scripts with placeholder\nreplacement, followed by manual review to ensure that anonymization did\nnot alter the meaning, structure, or intent of the original requirements. The\nextracted requirements were then randomized and masked to prevent po-\ntential bias related to document origin or sequence during the annotation\nphase. Total corpus has 2,652 requirements (30 pilot + 2,622 independent\nannotations).\n–Annotation Guideline Development: The Annotation Guidelines’ develop-\nment involved an initial iterative process, refining the guidelines three times\nto resolve ambiguities before the formal assessment phase. Annotation rules\nwere based on OWASP ASVS categories V2–V13 and refined iteratively\nusing example annotations. Following best practices suggested by Cohen\n(Cohen et al., 2005), the guidelines and annotation documents ensured:', 'CONTEXT: **Annotation Process and Quality Assurance in ASRD Development**: This chunk details the iterative annotation process for the ASRD dataset, including pilot and independent annotation phases, adjudication meetings, and the use of agreement metrics (e.g., Fleiss’s Kappa) to ensure high annotation quality and consistency among cybersecurity experts.\n\nCONTENT: 16 Yusuf G¨ ur et al.\n(1) original text and annotations were recoverable, (2) clear documenta-\ntion was maintained, (3) annotation quality was consistently high. The\nannotation template included fields for the software requirement text, se-\nlected OWASP labels, and annotator comments or questions. All versions\nof the guideline and annotation documents were preserved to track revi-\nsions based on annotator feedback. For the annotation process, a sample\ncorpus from the requirement set has been selected by inter agreement of\nSMEs. The first version of the Annotation Guideline based on OWASP\nASVS security classes has been developed, where each annotator has in-\ndividually classified the sample corpus by annotating it with one or more\nlabels following the instructions provided in the first Annotation Guide-\nline. After the initial annotation, the SMEs met under the guidance of the\nsenior SME, who is also the branch manager, to review and discuss the\nannotation decisions. Each of the 30 software requirements was examined\nindividually, and in cases where there were differing opinions among the\nannotators, efforts were made to persuade and convince others by provid-\ning explanations and reasons for their choices. After three iterations of\ndiscussions and deliberations, a full agreement was reached for 30 software\nrequirements.\n–Pilot Annotation: An initial batch of 30 software requirements was anno-\ntated early in the study, prompting multiple discussion rounds and three\nupdates to the guidelines. Adjudication meetings enabled the resolution\nof non-consensus requirements through SME-led discussions, during which\nthe rationale for classification was articulated. Discrepancies arising from\nquality issues, such as guideline violations, were addressed by implement-\ning corrections to ensure conformity with established criteria. Each SME\nprovided justifications for their decisions, which facilitated informed dis-\ncussions and enhanced understanding during adjudication. This iterative\nprocess resolved discrepancies across 98 requirements throughout the entire\ncorpus and was important in establishing the finalized annotation frame-\nwork.\n–Independent Annotation: Each SME classified all remaining 2622 require-\nments independently, using the finalized guideline. Annotators were re-\nquired to justify each decision. This practice proved important for facili-\ntating informed discussions and understanding annotator reasoning during\nthe subsequent adjudication phase. The process took 284 days and 267\nperson-hours of expert time.\n–Agreement Metrics: Inter-Annotator Agreement (IAA) was calculated us-\ning Fleiss’s Kappa and pairwise Cohen’s Kappa to assess consistency. IAA\nscores were instrumental in identifying instances of disagreement among\nannotators, thereby highlighting areas where the guidelines might require\nfurther clarification or where ambiguous requirement phrasings contributed\nto annotation discrepancies. Fleiss’s Kappa coefficient of 0.82 was obtained\nacross the three annotators, indicating strong agreement that significantly\nexceeded random chance. Pairwise Cohen’s Kappa values, ranging from', 'CONTEXT: **Comparison of Effort vs. Performance and Validation of ASRD**: This chunk compares the effort and performance of different approaches (BERT fine-tuning, few-shot, and zero-shot LLMs) for security requirement classification, highlights the advantages of the ASRD dataset over existing benchmarks, and emphasizes the challenges of eliciting implicit security requirements in real-world industrial contexts.\n\nCONTENT: 34 Yusuf G¨ ur et al.\nTable 9: Comparison of Effort vs. Performance across Approaches\nApproach Data Requirement Est. Setup Effort Best Macro-F1\nBERT Fine-Tuning High (∼2,600 ex) High (267 hours)0.942\nLLM Few-Shot Low (∼30 ex) Low (<10 hours)0.941\nLLM Zero-Shot None Minimal (<2 hours) 0.890\nLLM Few-Shot approach (using Gemini 2.0) achieved a similar performance\n(Macro-F1 0.941) while requiring only the selection of a small number of in-\ncontext examples (approx. 30 examples per prompt).\nThis comparison points to diminishing returns from large-scale annotation\nwhen capable LLMs are available. Although extensive annotation was required\nhere to establish a reliable ground truth and validate the test set, the results\nindicate that, in industrial settings, a few-shot LLM approach can offer a more\nfavorable balance between effort and accuracy. Comparable performance can\nbe reached with substantially less data preparation, reducing the need for\nprolonged expert annotation.\nThe main contribution of this work is the introduction and validation of\nthe ASRD. The consistent performance of both fine-tuned BERT models and\nLLM-based approaches on ASRD supports its reliability and practical value.\nThe dataset addresses a persistent limitation in SRE research which is the\nlack of large, well-curated, professionally sourced benchmarks for security re-\nquirement classification. Compared with existing datasets, ASRD offers sev-\neral advantages. Unlike DOSSPRE (Kadebu et al., 2023), which is derived\nfrom student projects, ASRD includes 2,652 requirements from six commer-\ncial software systems, reflecting real industrial language and complexity. Its\nOWASP ASVS–based taxonomy spans 11 security classes, providing finer de-\ntail than PROMISE exp (Lima et al., 2019), where security is treated as a\nsingle category. Although the healthcare dataset by Riaz et al. (Riaz et al.,\n2014) is larger, it focuses on six broad objectives within a single domain, lim-\niting its scope. By contrast, ASRD supports cross-domain analysis and aligns\nwith a framework widely used in practice.\nThe dataset also benefits from a rigorous annotation process. Three cy-\nbersecurity specialists, each with over 15 years of experience, labeled the data\nusing an iterative MATTER-based procedure. This resulted in strong agree-\nment (Fleiss’ Kappa = 0.82) and helps mitigate the subjectivity that often\naffects security-related requirement datasets.\nBeyond the dataset construction, this study highlights the complexity of\nimplicit security requirement elicitation. A significant portion of security vul-\nnerabilities stems not from missing explicit security constraints (e.g., “The\nsystem shall encrypt passwords”), but from functional requirements that im-\nplicitly demand robust security controls. Our analysis of the ASRD reveals\nthat functional descriptions of business logic often conceal a dense network of\nsecurity dependencies. A representative example from our results is Require-\nment No. 2 (“The system will carry out the asset handover process”). While', 'CONTEXT: This chunk focuses on the introduction of the **Agency Security Requirements Dataset (ASRD)**, detailing its real-world data sources, expert annotation process, and alignment with OWASP ASVS categories, as well as outlining the research questions and comparative evaluation of fine-tuned transformer models versus prompt-based approaches for security requirements classification.\n\nCONTENT: 4 Yusuf G¨ ur et al.\ncient and cost-effective compared to addressing security issues at later stages\nof development ((Khan et al., 2024).\nThis paper proposes a machine learning-based system to automatically an-\nalyze SRS documents and classify security requirements according to OWASP\nASVS. Its main contribution is the Agency Security Requirements Dataset\n(ASRD), a publicly available corpus created to support research in automated\nSRA. The ASRD comprises:\n–Real-World Data: 2,652 Software Requirements Specification (SRS) sen-\ntences extracted from six diverse, real-world industry projects,\n–Expert Annotation: Meticulously annotated by three cybersecurity experts,\neach with over 15 years of industry experience,\n–Rigorous Methodology: Developed using the iterative MATTER cycle an-\nnotation framework (Pustejovsky and Stubbs, 2012),\n–High Granularity and Multi-label Structure: Mapped to 11 distinct, action-\nable security categories from the industry-standard OWASP Application\nSecurity Verification Standard (ASVS,V2–V13), allowing each require-\nment to be associated with multiple categories.\nThe ASRD is intended as a shared research resource and benchmark. Using\nthis dataset, the study conducts an empirical analysis of automated classifica-\ntion approaches and addresses the following research questions:\n1. To what extent can fine-tuned transformer models accurately perform\nmulti-label classification of implicit security requirements into OWASP\nASVS categories using the ASRD?\n2. How does the performance of prompt-based approaches (zero-shot and few-\nshot) using modern LLMs compare to fine-tuned BERT-based models and\nnaive baselines for this task?\nThe results show that few-shot prompting with a modern language model\n(Gemini 2.0) achieves a macro-average F1 score of 0.941, closely matching the\nbest fine-tuned BERT-based model (0.942). This demonstrates that example-\nguided inference can reach performance comparable to supervised fine-tuning\nwhile requiring substantially less annotated data and model retraining. The\nevaluation compares fine-tuned transformer models (e.g., SecureBERT) with\nprompt-based methods in zero-shot and few-shot settings across multiple con-\ntemporary models, demonstrating that prompt-based approaches provide a\npractical and resource-efficient alternative for identifying implicit security re-\nquirements in industrial SRS documents.\nThe remainder of this paper is organized as follows. Section 2 reviews re-\nlated work on NLP-based requirements classification, security frameworks, and\nexisting security datasets. Section 3 describes the curation and expert anno-\ntation of the ASRD and summarizes its key characteristics. Section 4 outlines\nthe experimental setup and classification methods, including fine-tuned BERT\nmodels and prompt-based approaches. Section 5 reports the experimental re-\nsults. Section 6 discusses the findings and their implications, with a com-\nparative analysis of fine-tuning and prompting strategies. Section 7 examines', 'CONTEXT: **Analysis of Minority Class Performance and Annotation Challenges in SRE**: This chunk discusses the performance gap between majority and minority security classes in SRE, the expert-driven annotation process using the MATTER cycle, and the measures taken to mitigate subjectivity and ensure realistic, industry-relevant model evaluation.\n\nCONTENT: 32 Yusuf G¨ ur et al.\nFig. 4:Minority vs. Majority Class Performance Gap.A comparative\nanalysis revealing that while advanced LLMs and fine-tuned models achieve\nnear-parity on Majority Classes (Blue), a significant performance gap remains\non Minority Classes (Red), underscoring the “Long Tail” challenge in SRE.\nAnnotation was performed by three experienced cybersecurity experts.\nWhile their domain knowledge ensured quality, the small annotator pool may\nintroduce subjective bias and limit the range of interpretations. This was mit-\nigated through the iterative MATTER cycle which includes training, iterative\nguideline refinement, and consensus-based adjudication.\nA key threat to internal validity is subjectivity as classifications rely heavily\non the latent domain knowledge and industry experience, rather than explicit\nindicators within the requirement text itself. This expert-driven approach pro-\nvides a “gold standard” for realistic industrial needs but it may introduce in-\nconsistencies if replicated by annotators with different backgrounds or if the\nbroader system context is not explicitly documented.\nThe test set was manually selected to balance computational efficiency and\ngeneralizability assessment. While cross-validation could improve test calibra-\ntion, it was avoided due to its high computational cost.\nTo minimize researcher bias and ensure the results reflect real-world in-\ndustry needs, domain experts used for the selection of both the test set and\nthe LLM suite. Rather than selecting data or models arbitrarily, these experts\ncurated a test set containing the most complex, “implicit” security scenarios\nto challenge the models beyond simple pattern matching. For the model suite,\nthey prioritized architectures with advanced reasoning capabilities, hypothe-\nsizing that these specific technical features are essential for the multi-step de-\nduction required in security requirements engineering. Although the experts', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: **Annotation Process and Dataset Composition**: This chunk details the multi-stage annotation methodology used to create the ASRD dataset, addressing class distribution, challenges with imbalanced categories (e.g., V6 Cryptography, V12 Files/Resources), and the inclusion of true negatives to ensure realistic and high-quality security requirement classification.\n\nCONTENT: Implicit Security Requirements Classification 17\n0.71 to 0.79, further confirmed substantial agreement between individual\nannotator pairs.\n–Adjudication: Disagreements were resolved through structured expert dis-\ncussions led by the senior SME. When the two annotators disagreed on a\nrequirement, it was resolved through a structured process:\n–Both annotators presented their choice and their reasons.\n–The senior expert reviewed both positions against the guideline.\n–If the guideline clearly supported one choice, that one was used. If not,\nthe senior expert led a discussion to decide.\n–Final decision and the reason was written down.\nThe goal was to reach unanimous agreement for each disputed requirement.\nThis process produced final Gold Standard annotations for 135 contested\nitems, ensuring consistency and validation of the dataset.\nThis multi-stage annotation methodology produced a reliable dataset which\ncomprises 2,652 annotated security-relevant requirements. The category dis-\ntributions of the requirements can be seen in Figure 1. The class distribution\namong the classes are largely balanced (90%) except the V6(Stored Cryptog-\nraphy) and V12 (Files & Resources) as 6% each. This imbalance is considered\na reflection of the source projects, where requirements for these two categories\nare inherently less frequent than pervasive controls like access control or input\nvalidation. Stored cryptography requirements are typically captured as holis-\ntic, architectural decisions rather than numerous, distinct functional require-\nments. Similarly, explicit security controls for file handling are less ubiquitous,\nappearing only in projects with specific file processing features, which explains\ntheir low frequency in our corpus. Sample annotated requirements can be seen\nin Table 4.\nThis imbalance mirrors real-world security requirement frequency - most\nsoftware functions involve access and data; few involve file uploads or encryp-\ntion configuration - and introduces a challenge for machine learning. Partic-\nularly, the sparsity in V6 and V12 categories may hinder generalization and\ncalls for class imbalance handling techniques. Despite this, the dataset presents\na realistic and high-quality foundation for developing and evaluating security-\naware NLP and classification models.\nTwenty-six requirements (0.98% of the data) labeled as “UNASSIGNED”\nwere requirements unanimously determined by the experts to be purely func-\ntional requirements with no discernible implicit security component (e.g., “The\nsystem will enable application software to be developed with an object-oriented\nprogramming approach”,). These items were intentionally retained in the dataset\nas true negatives to ensure a realistic distribution and test the models’ ability\nto correctly reject non-security items.\n\n18 Yusuf G¨ ur et al.\nFig. 1: Distribution of Classes', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb']","The annotations for the ASRD were performed by three cybersecurity subject matter experts (SMEs) from the agency, each with over 15 years of experience in designing security architectures, analyzing threat models, and identifying security requirements. The senior SME also acted as the final adjudicator for resolving disagreements and provided oversight to improve the quality and clarity of the annotation guidelines. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","Three cybersecurity subject matter experts (SME) from the agency, each with over 15 years of industry experience, performed the annotations[cite: 71, 241].",,,
What was the Inter-Annotator Agreement (IAA) score for the dataset?,"['CONTEXT: **Annotation Process and Dataset Composition**: This chunk details the multi-stage annotation methodology used to create the ASRD dataset, addressing class distribution, challenges with imbalanced categories (e.g., V6 Cryptography, V12 Files/Resources), and the inclusion of true negatives to ensure realistic and high-quality security requirement classification.\n\nCONTENT: Implicit Security Requirements Classification 17\n0.71 to 0.79, further confirmed substantial agreement between individual\nannotator pairs.\n–Adjudication: Disagreements were resolved through structured expert dis-\ncussions led by the senior SME. When the two annotators disagreed on a\nrequirement, it was resolved through a structured process:\n–Both annotators presented their choice and their reasons.\n–The senior expert reviewed both positions against the guideline.\n–If the guideline clearly supported one choice, that one was used. If not,\nthe senior expert led a discussion to decide.\n–Final decision and the reason was written down.\nThe goal was to reach unanimous agreement for each disputed requirement.\nThis process produced final Gold Standard annotations for 135 contested\nitems, ensuring consistency and validation of the dataset.\nThis multi-stage annotation methodology produced a reliable dataset which\ncomprises 2,652 annotated security-relevant requirements. The category dis-\ntributions of the requirements can be seen in Figure 1. The class distribution\namong the classes are largely balanced (90%) except the V6(Stored Cryptog-\nraphy) and V12 (Files & Resources) as 6% each. This imbalance is considered\na reflection of the source projects, where requirements for these two categories\nare inherently less frequent than pervasive controls like access control or input\nvalidation. Stored cryptography requirements are typically captured as holis-\ntic, architectural decisions rather than numerous, distinct functional require-\nments. Similarly, explicit security controls for file handling are less ubiquitous,\nappearing only in projects with specific file processing features, which explains\ntheir low frequency in our corpus. Sample annotated requirements can be seen\nin Table 4.\nThis imbalance mirrors real-world security requirement frequency - most\nsoftware functions involve access and data; few involve file uploads or encryp-\ntion configuration - and introduces a challenge for machine learning. Partic-\nularly, the sparsity in V6 and V12 categories may hinder generalization and\ncalls for class imbalance handling techniques. Despite this, the dataset presents\na realistic and high-quality foundation for developing and evaluating security-\naware NLP and classification models.\nTwenty-six requirements (0.98% of the data) labeled as “UNASSIGNED”\nwere requirements unanimously determined by the experts to be purely func-\ntional requirements with no discernible implicit security component (e.g., “The\nsystem will enable application software to be developed with an object-oriented\nprogramming approach”,). These items were intentionally retained in the dataset\nas true negatives to ensure a realistic distribution and test the models’ ability\nto correctly reject non-security items.\n\n18 Yusuf G¨ ur et al.\nFig. 1: Distribution of Classes', 'CONTEXT: **Annotation Process and Quality Assurance in ASRD Development**: This chunk details the iterative annotation process for the ASRD dataset, including pilot and independent annotation phases, adjudication meetings, and the use of agreement metrics (e.g., Fleiss’s Kappa) to ensure high annotation quality and consistency among cybersecurity experts.\n\nCONTENT: 16 Yusuf G¨ ur et al.\n(1) original text and annotations were recoverable, (2) clear documenta-\ntion was maintained, (3) annotation quality was consistently high. The\nannotation template included fields for the software requirement text, se-\nlected OWASP labels, and annotator comments or questions. All versions\nof the guideline and annotation documents were preserved to track revi-\nsions based on annotator feedback. For the annotation process, a sample\ncorpus from the requirement set has been selected by inter agreement of\nSMEs. The first version of the Annotation Guideline based on OWASP\nASVS security classes has been developed, where each annotator has in-\ndividually classified the sample corpus by annotating it with one or more\nlabels following the instructions provided in the first Annotation Guide-\nline. After the initial annotation, the SMEs met under the guidance of the\nsenior SME, who is also the branch manager, to review and discuss the\nannotation decisions. Each of the 30 software requirements was examined\nindividually, and in cases where there were differing opinions among the\nannotators, efforts were made to persuade and convince others by provid-\ning explanations and reasons for their choices. After three iterations of\ndiscussions and deliberations, a full agreement was reached for 30 software\nrequirements.\n–Pilot Annotation: An initial batch of 30 software requirements was anno-\ntated early in the study, prompting multiple discussion rounds and three\nupdates to the guidelines. Adjudication meetings enabled the resolution\nof non-consensus requirements through SME-led discussions, during which\nthe rationale for classification was articulated. Discrepancies arising from\nquality issues, such as guideline violations, were addressed by implement-\ning corrections to ensure conformity with established criteria. Each SME\nprovided justifications for their decisions, which facilitated informed dis-\ncussions and enhanced understanding during adjudication. This iterative\nprocess resolved discrepancies across 98 requirements throughout the entire\ncorpus and was important in establishing the finalized annotation frame-\nwork.\n–Independent Annotation: Each SME classified all remaining 2622 require-\nments independently, using the finalized guideline. Annotators were re-\nquired to justify each decision. This practice proved important for facili-\ntating informed discussions and understanding annotator reasoning during\nthe subsequent adjudication phase. The process took 284 days and 267\nperson-hours of expert time.\n–Agreement Metrics: Inter-Annotator Agreement (IAA) was calculated us-\ning Fleiss’s Kappa and pairwise Cohen’s Kappa to assess consistency. IAA\nscores were instrumental in identifying instances of disagreement among\nannotators, thereby highlighting areas where the guidelines might require\nfurther clarification or where ambiguous requirement phrasings contributed\nto annotation discrepancies. Fleiss’s Kappa coefficient of 0.82 was obtained\nacross the three annotators, indicating strong agreement that significantly\nexceeded random chance. Pairwise Cohen’s Kappa values, ranging from', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: This chunk details the **annotation methodology** and **dataset curation process** for the ASRD, following the MATTER cycle framework. It describes annotator selection, corpus preparation, and the iterative development of annotation guidelines aligned with OWASP ASVS categories to ensure high-quality, domain-specific annotations.\n\nCONTENT: Implicit Security Requirements Classification 15\n3.3 Annotation Methodology (MATTER Cycle) & Dataset Curation\nThe annotation process followed the MATTER development cycle, an estab-\nlished iterative framework for corpus annotation (Pustejovsky and Stubbs,\n2012). Crucially, the annotation task was defined as a multi-label text classifi-\ncation problem. It consists of the phases Model, Annotate, Train, Test, Eval-\nuate, and Revise. The annotation guidelines were developed and iteratively\nrefined to ensure consistency and clarity.\nThe Model–Annotate cycle involved writing guidelines, selecting annota-\ntors, conducting trial annotations, and refining the process. Once stabilized,\nthis cycle was expanded to the full dataset to generate a Gold Standard corpus.\nThe annotation workflow included the following processes:\n–Annotator Selection: Following Bayerl and Paul’s recommendation to use\ndomain-aligned annotators (Bayerl and Paul, 2011), three cybersecurity\nsubject matter experts (SME) from the agency, each with over 15 years\nof experience in designing security architectures, analyzing threat models,\nand identifying security requirements, performed the annotations. Their\ndeep practical experience ensured accurate and context-aware interpreta-\ntion which aligned with the requirement “experts must demonstrate signif-\nicant skills, knowledge, and experience” emphasized by Hopkins (Hopkins\nand Unger, 2017). The senior manager among them also provided over-\nsight and led the adjudication process. The senior SME acted as both an\nannotator and the final adjudicator for resolving disagreements. They also\nprovided feedback to improve the quality and clarity of the annotation\nguideline.\n–Corpus Selection and Preparation: Cohen (Cohen et al., 2005) recommends\nthat during corpus design, balance and representativeness of the corpus\nis important. In line with his recommendation, of the 19 initial project\ndocuments, six were chosen for their domain diversity and potential for\neffective anonymization by the SMEs. These documents underwent a semi-\nautomated anonymization process to remove all project-specific and per-\nsonally identifiable information (PII). The process targeted entities such\nas names of individuals and organizations, project codenames, and specific\ntechnical identifiers. This was done using custom scripts with placeholder\nreplacement, followed by manual review to ensure that anonymization did\nnot alter the meaning, structure, or intent of the original requirements. The\nextracted requirements were then randomized and masked to prevent po-\ntential bias related to document origin or sequence during the annotation\nphase. Total corpus has 2,652 requirements (30 pilot + 2,622 independent\nannotations).\n–Annotation Guideline Development: The Annotation Guidelines’ develop-\nment involved an initial iterative process, refining the guidelines three times\nto resolve ambiguities before the formal assessment phase. Annotation rules\nwere based on OWASP ASVS categories V2–V13 and refined iteratively\nusing example annotations. Following best practices suggested by Cohen\n(Cohen et al., 2005), the guidelines and annotation documents ensured:', 'CONTEXT: This chunk discusses the curation and preprocessing of the ASRD dataset, detailing the data collection process from real-world Software Requirements Specification (SRS) documents, the multi-stage preprocessing pipeline for sentence extraction and anonymization, and how the dataset addresses gaps in prior work by incorporating industrial complexity and linguistic diversity.\n\nCONTENT: Implicit Security Requirements Classification 9\n2.3.3 Electronic Health Domain Dataset\nThis corpus focuses on the electronic healthcare industry, a sector defined\nby stringent regulatory and high-assurance demands (Riaz et al., 2014). The\ndataset’s strength lies in its rigorous multi-stage annotation methodology,\nwhich utilized independent researchers and a mediator to ensure high inter-\nannotator agreement. While it provides a large-scale, authentic resource for\nhealthcare-specific tasks, its narrow focus may limit the generalizability of\nmodels to other industries, and its high-level security objectives may be too\ncoarse for detailed technical analysis.\n2.3.4 Summary of Datasets\nAs summarized in Table 1, these datasets vary significantly in their suitability\nfor tasks ranging from general non-functional requirement (NFR) classifica-\ntion to detailed security analysis. Our proposed Agency Security Require-\nments Dataset (ASRD) addresses gaps in prior work by adopting the OWASP\nASVS taxonomy for multi-label annotation. Furthermore, by utilizing real-\nworld projects originally written in Turkish, ASRD introduces both industrial\ncomplexity and linguistic diversity to the field.\n3 Dataset Curation, Annotation, and Evaluation\n3.1 Data Collection and Preprocessing\nThe dataset compilation began with the collection of six Software Require-\nments Specification (SRS) documents from an Agency’s Security Department.\nThese documents were selected from an initial pool of 19 projects executed\nbetween 2019 and 2023, specifically chosen for their domain diversity and\namenability to effective anonymization. The original documents were provided\nin standard document formats (e.g., PDF, DOCX) where requirements were\norganized in itemized lists. To transform these documents into a machine-\nreadable dataset, we employed a multi-stage preprocessing pipeline:\n1. Sentence Segmentation and Extraction: As the source SRS documents uti-\nlized standard itemization for requirements, we employed a rule-based ex-\ntraction method. We utilized pattern matching to identify requirement\nblocks based on hierarchical numbering schemes and line breaks. Each iden-\ntified requirement was extracted and treated as a single processing unit,\npreserving the structural integrity of the original specification.\n2. Anonymization: To protect sensitive data, a semi-automated anonymiza-\ntion process was implemented. Custom scripts replaced entities such as\nproject names, specific URLs, and IP addresses with generic placeholders.\nThis was followed by a manual review by domain experts to ensure that\nthe removal of personally identifiable information (PII) did not compromise\nthe semantic meaning or contextual integrity of the requirements.', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb', 'CONTEXT: **Comparison of Effort vs. Performance and Validation of ASRD**: This chunk compares the effort and performance of different approaches (BERT fine-tuning, few-shot, and zero-shot LLMs) for security requirement classification, highlights the advantages of the ASRD dataset over existing benchmarks, and emphasizes the challenges of eliciting implicit security requirements in real-world industrial contexts.\n\nCONTENT: 34 Yusuf G¨ ur et al.\nTable 9: Comparison of Effort vs. Performance across Approaches\nApproach Data Requirement Est. Setup Effort Best Macro-F1\nBERT Fine-Tuning High (∼2,600 ex) High (267 hours)0.942\nLLM Few-Shot Low (∼30 ex) Low (<10 hours)0.941\nLLM Zero-Shot None Minimal (<2 hours) 0.890\nLLM Few-Shot approach (using Gemini 2.0) achieved a similar performance\n(Macro-F1 0.941) while requiring only the selection of a small number of in-\ncontext examples (approx. 30 examples per prompt).\nThis comparison points to diminishing returns from large-scale annotation\nwhen capable LLMs are available. Although extensive annotation was required\nhere to establish a reliable ground truth and validate the test set, the results\nindicate that, in industrial settings, a few-shot LLM approach can offer a more\nfavorable balance between effort and accuracy. Comparable performance can\nbe reached with substantially less data preparation, reducing the need for\nprolonged expert annotation.\nThe main contribution of this work is the introduction and validation of\nthe ASRD. The consistent performance of both fine-tuned BERT models and\nLLM-based approaches on ASRD supports its reliability and practical value.\nThe dataset addresses a persistent limitation in SRE research which is the\nlack of large, well-curated, professionally sourced benchmarks for security re-\nquirement classification. Compared with existing datasets, ASRD offers sev-\neral advantages. Unlike DOSSPRE (Kadebu et al., 2023), which is derived\nfrom student projects, ASRD includes 2,652 requirements from six commer-\ncial software systems, reflecting real industrial language and complexity. Its\nOWASP ASVS–based taxonomy spans 11 security classes, providing finer de-\ntail than PROMISE exp (Lima et al., 2019), where security is treated as a\nsingle category. Although the healthcare dataset by Riaz et al. (Riaz et al.,\n2014) is larger, it focuses on six broad objectives within a single domain, lim-\niting its scope. By contrast, ASRD supports cross-domain analysis and aligns\nwith a framework widely used in practice.\nThe dataset also benefits from a rigorous annotation process. Three cy-\nbersecurity specialists, each with over 15 years of experience, labeled the data\nusing an iterative MATTER-based procedure. This resulted in strong agree-\nment (Fleiss’ Kappa = 0.82) and helps mitigate the subjectivity that often\naffects security-related requirement datasets.\nBeyond the dataset construction, this study highlights the complexity of\nimplicit security requirement elicitation. A significant portion of security vul-\nnerabilities stems not from missing explicit security constraints (e.g., “The\nsystem shall encrypt passwords”), but from functional requirements that im-\nplicitly demand robust security controls. Our analysis of the ASRD reveals\nthat functional descriptions of business logic often conceal a dense network of\nsecurity dependencies. A representative example from our results is Require-\nment No. 2 (“The system will carry out the asset handover process”). While', 'CONTEXT: **Analysis of Minority Class Performance and Annotation Challenges in SRE**: This chunk discusses the performance gap between majority and minority security classes in SRE, the expert-driven annotation process using the MATTER cycle, and the measures taken to mitigate subjectivity and ensure realistic, industry-relevant model evaluation.\n\nCONTENT: 32 Yusuf G¨ ur et al.\nFig. 4:Minority vs. Majority Class Performance Gap.A comparative\nanalysis revealing that while advanced LLMs and fine-tuned models achieve\nnear-parity on Majority Classes (Blue), a significant performance gap remains\non Minority Classes (Red), underscoring the “Long Tail” challenge in SRE.\nAnnotation was performed by three experienced cybersecurity experts.\nWhile their domain knowledge ensured quality, the small annotator pool may\nintroduce subjective bias and limit the range of interpretations. This was mit-\nigated through the iterative MATTER cycle which includes training, iterative\nguideline refinement, and consensus-based adjudication.\nA key threat to internal validity is subjectivity as classifications rely heavily\non the latent domain knowledge and industry experience, rather than explicit\nindicators within the requirement text itself. This expert-driven approach pro-\nvides a “gold standard” for realistic industrial needs but it may introduce in-\nconsistencies if replicated by annotators with different backgrounds or if the\nbroader system context is not explicitly documented.\nThe test set was manually selected to balance computational efficiency and\ngeneralizability assessment. While cross-validation could improve test calibra-\ntion, it was avoided due to its high computational cost.\nTo minimize researcher bias and ensure the results reflect real-world in-\ndustry needs, domain experts used for the selection of both the test set and\nthe LLM suite. Rather than selecting data or models arbitrarily, these experts\ncurated a test set containing the most complex, “implicit” security scenarios\nto challenge the models beyond simple pattern matching. For the model suite,\nthey prioritized architectures with advanced reasoning capabilities, hypothe-\nsizing that these specific technical features are essential for the multi-step de-\nduction required in security requirements engineering. Although the experts']","The Inter-Annotator Agreement (IAA) score for the dataset was calculated using Fleiss’s Kappa, which yielded a coefficient of **0.82**, indicating strong agreement among the annotators. Pairwise Cohen’s Kappa values ranged from **0.71 to 0.79**, further confirming substantial agreement between individual annotator pairs. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","The Fleiss' Kappa coefficient was 0.82 across the three annotators, indicating strong agreement[cite: 276].",,,
Which specific OWASP ASVS classes were excluded from the study and why?,"['CONTEXT: **Overview of ASVS 4.0.3 Adoption and Security Classes**: This chunk discusses the widespread adoption of OWASP ASVS 4.0.3 as an industry-standard framework for application security verification, its use in various sectors, and the specific security classes included in the standard, highlighting the focus of the study on 11 of these classes.\n\nCONTENT: Implicit Security Requirements Classification 13\n(TRM) Guidelines. In the healthcare domain, Schmeelk and Tao (Schmeelk\nand Tao, 2022) conducted a case study on mobile health applications.\nAs of 2024–2025, commercial security platforms and verification tools con-\ntinue to offer native support for ASVS 4.0.3 compliance templates and map-\npings (Reqview, 2016; JIT.io, 2024), with requirement managers, compliance\ntracking systems, and automated security testing platforms (SAST/DAST) ex-\nplicitly designed around the 4.0.3 control structure. Multiple government and\nregulatory bodies, including the Moroccan government’s Directorate General\nfor Information Systems Security (DGSSI), have formally adopted ASVS 4.0.3\nas the basis for their national application security verification frameworks as\nof October 2024 (DGSSI, 2024).\nAt the time this study was designed and conducted (2023–2025), ASVS\n4.0.3 was the latest stable, officially released version of the standard. Version\n4.0.3, released in October 2021, had achieved widespread adoption and had\nbeen serving as the industry-standard reference for application security verifi-\ncation across finance, healthcare, technology, and government sectors for mul-\ntiple years. The ASVS 5.0 major revision was only released on 30 May 2025,\nafter the empirical work for this research had been substantially completed.\nTherefore, this research’s use of ASVS 4.0.3 represents both a temporally ap-\npropriate choice at the time of study design and a durable contribution to the\nliterature that will remain relevant and comparable with prior ASVS-based\nwork for years to come.\nThe standard includes 14 main security classes given in Table 3. For this\nstudy, only 11 classes (V2–V10, V12-V13) were used. V1, V11, and V14 were\nexcluded as they are not inferable from functional or non-functional require-\nments. Each requirement can be mapped to more than one classes.\nTable 3: OWASP ASVS 4.0.3 Classes\nClass Id Class Name Definition\nV1 Architecture, Design and\nThreat Modeling\nThis class focuses on the security of the\napplication’s architecture, component\ndesign, and the process of identifying\nand mitigating threats throughout the\ndevelopment lifecycle.\nV2 Authentication This class deals with verifying the\nidentity of users, services, or applica-\ntions, ensuring that only authorized\nentities can access specific functionali-\nties or data.\nV3 Session Management This class covers the secure manage-\nment of user sessions, from creation\nto termination, including protection of\nsession identifiers and prevention of\nsession-related attacks.\nV4 Access Control This class ensures that users can only\naccess the data and functions for which\nthey are explicitly authorized, enforc-\ning the principle of least privilege.', 'CONTEXT: This chunk provides detailed definitions of OWASP ASVS security requirement classes (V5–V14), which are critical for categorizing and addressing specific security concerns in software applications, as discussed in the broader context of automating security requirements classification using AI and the ASRD dataset.\n\nCONTENT: 14 Yusuf G¨ ur et al.\nTable 3 – continued from previous page\nClass Id Class Name Definition\nV5 Malicious Input Handling This class focuses on requirements\nfor validating and sanitizing all input\ndata to prevent injection attacks, such\nas SQL injection, Cross-Site Scripting\n(XSS), and others.\nV6 Stored Cryptography This class addresses the secure stor-\nage of cryptographic keys and sensi-\ntive data at rest, ensuring they are pro-\ntected from unauthorized disclosure or\nmodification.\nV7 Error Handling and Logging This class ensures that applications\nhandle errors gracefully without leak-\ning sensitive information and that\nsecurity-relevant events are logged for\nmonitoring and analysis.\nV8 Data Protection This class covers the requirements for\nprotecting sensitive data during tran-\nsit and in storage, focusing on confi-\ndentiality, integrity, and classification.\nV9 Communications Security This class focuses on securing commu-\nnication channels between system com-\nponents, such as between the client and\nserver, to prevent eavesdropping, tam-\npering, or spoofing.\nV10 Malicious Code This class deals with ensuring the ap-\nplication code is free from malicious\ncode, backdoors, or other unintended\nsecurity vulnerabilities introduced in-\ntentionally or unintentionally.\nV11 Business Logic This class addresses security con-\ncerns within the application’s business\nlogic, preventing attackers from abus-\ning workflows or functionalities for un-\nintended purposes.\nV12 File and Resources This class covers the secure handling of\nfiles and other resources, including up-\nload, download, and management, to\nprevent path traversal and other re-\nlated attacks.\nV13 API and Web Service This class provides security require-\nments specifically for APIs and web\nservices, covering aspects like authen-\ntication, authorization, and protection\nagainst common API attacks.\nV14 Configuration This class focuses on securing the con-\nfiguration of all application compo-\nnents, including the application server,\nplatform, and third-party libraries, to\nprevent security misconfigurations.', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to', 'CONTEXT: **Performance Metrics for OWASP ASVS Verification Categories**: This chunk presents precision, recall, F1 scores, and support metrics for various OWASP ASVS verification categories, highlighting model performance across security requirements, with particular challenges in underrepresented classes like V6 (Cryptography) and V12 (Files/Resources).\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.943 0.922 0.967 0.905 0.214 0.903 0.918 0.906 0.876 0.250 0.880RECALL 0.950 0.932 0.974 0.943 0.231 0.907 0.927 0.914 0.920 0.250 0.899F1 0.947 0.927 0.970 0.924 0.222 0.905 0.922 0.910 0.898 0.250 0.890SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398', 'CONTEXT: **Performance Metrics for OWASP ASVS Verification Categories**: This chunk presents precision, recall, F1 scores, and support metrics for various OWASP ASVS verification categories, highlighting model performance across security requirements, with a focus on challenges in underrepresented classes like V6 Cryptography and V12 File/Resources.\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.975 0.972 0.975 0.970 0.917 0.985 0.975 0.975 0.930 0.869 0.962RECALL 0.974 0.972 0.974 0.963 0.175 0.985 0.974 0.974 0.911 0.350 0.955F1 0.992 0.992 0.990 0.987 0.179 0.997 0.995 0.995 0.960 1.000 0.994SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398', 'CONTEXT: **Performance Visualization and Analysis of Classifiers**: This chunk focuses on the comparative performance analysis of 20 classifiers across OWASP ASVS classes, using critical difference diagrams, heatmaps, and gap analysis to highlight strengths and weaknesses, particularly in handling rare security classes like V6 (Stored Cryptography) and V12 (Files and Resources). It also discusses dataset diversity, threats to validity, and the generalizability of findings.\n\nCONTENT: 30 Yusuf G¨ ur et al.\nFig. 2: Critical Difference (CD) diagram visualizing the statistical comparison\nof classifiers. The horizontal axis represents the average rank of each model\nacross all 11 OWASP ASVS classes (lower ranks indicate better performance).\nThe Critical Difference (CD = 10.46) represents the minimum difference in\naverage rank required for two models to be considered statistically significantly\ndifferent atp <0.05.\n5.6 Comparative Visualization Analysis\nTo complement the statistical rankings, we visualized the performance land-\nscape across all 20 model configurations.\nHeatmap Analysis: Figure 3 shows F1-scores by class. Requirements related\nto V2 (Authentication), V3 (Session Management), and V4 (Access Control)\nare handled well by nearly all models, with scores typically above 0.95. These\ncategories are common and appear consistently across training sources. In\ncontrast, V6 (Stored Cryptography) and V12 (Files and Resources) show low\nscores across the board, including for GPT-4o and Gemini 2.0 Pro. This pat-\ntern points to a systematic difficulty with sparse categories rather than a\nweakness of a particular model.\nGap Analysis: Figure 4 contrasts average performance on frequent and in-\nfrequent classes. Fine-tuned models such as SecureBERT and BERT-Multilingual\nperform better on rare classes, with F1-scores around 0.70–0.80. Zero-shot\nLLMs perform poorly in these cases, often below 0.30. Few-shot prompting\nimproves results for some models, such as Gemini 2.0, but the gap remains\nsubstantial.\n6 Threats to Validity\nOur dataset consists of 2,652 requirements derived from six Software Require-\nments Specification (SRS) documents. While the number of source documents\n\nImplicit Security Requirements Classification 31\nFig. 3:Comprehensive Performance Heatmap.F1-scores for all 20 eval-\nuated models across 11 OWASP ASVS classes. The visualization highlights\nthe “zone of failure” (red) for classes V6 and V12 across models, contrasting\nwith the high performance (green) on ubiquitous classes like V2 and V4.\nis limited, potential bias was mitigated by strategically selecting projects from\nsix distinct business domains: Construction, Legal, Education, Software, Meet-\ning Management, and Accommodation. This semantic diversity ensures that\nthe models are evaluated on a broad vocabulary and varied functional contexts\nrather than a single industry vertical. A specific consideration regarding the\nexternal validity of this study is that the ASRD is a Turkish-language corpus\nwhich allows for the evaluation of automated tools in linguistically diverse\nindustrial contexts.\nFurthermore, because security requirements (e.g., Authentication, Log-\nging) represent cross-cutting concerns that apply universally across software\nsystems, we believe the fundamental patterns captured in the ASRD are trans-\nferable to other industries. Our current evaluation used a stratified split across\nthe entire dataset, meaning requirements from all six source projects are\npresent in the training, validation, and test sets. However, we acknowledge\nthat this approach does not fully measure the models’ ability to generalize to\nentirely new projects with different authors or linguistic styles, as the test set\nis not completely “unseen” in terms of project context.', 'CONTEXT: **Evaluation of Model Challenges and Prompt Engineering Strategies**: This chunk discusses the challenges faced by models, particularly with underrepresented OWASP ASVS categories (e.g., V6 Cryptography, V12 Files/Resources), and outlines the experimental setup for prompt engineering in LLMs, including zero-shot and few-shot configurations, persona-based prompting, and strategies to ensure consistency and adherence to security standards.\n\nCONTENT: 26 Yusuf G¨ ur et al.\nshowed both low Recall (0.658) and low Precision (0.781), indicating it was\nboth missing true cases and incorrectly labeling other requirements as V6.\nModels struggle significantly with underrepresented categories, particularly\nV12 (File and Resources) and V6 (Stored Cryptography). This is evident in\nthe high number of false negatives, where the models fail to identify true\ninstances of these classes. For example, the baseline BERT model incorrectly\nclassified over half of the V12 requirements as negative (14 false negatives vs.\n13 true positives). Conversely, the matrices show that models often misclassify\nrequirements by incorrectly assigning them to other categories. The BERT\nBase model, for example, incorrectly labeled 92 different requirements as V10\n(Malicious Code) and 78 requirements as V5 (Malicious Input Handling).\n5.2 Experimental Setup for LLM Prompt Engineering\nWe adapted prompt engineering strategies from Ronanki (Ronanki et al.,\n2024), originally used for multi-class requirement classification. Two configu-\nrations were evaluated: zero-shot prompting (Appendix A), which relied solely\non task instructions and the input requirement, and few-shot prompting (Ap-\npendix B), which additionally incorporated labeled examples. The few-shot\nsetup used 30 training instances that were chosen to (i) capture multi-label\ncases where a single requirement spans multiple security categories, (ii) cover\nall 11 OWASP ASVS categories, and (iii) reflect requirements from different\nbusiness domains to preserve linguistic variation.\nPersona-based prompting was applied in both configurations by instruct-\ning the model to act as an experienced cybersecurity specialist. This alignment\nhelped reduce output variance by grounding responses in professional domain\nexpertise rather than general conversational patterns. The final prompt was\nobtained after five iterations. These iterations focused on three primary ar-\neas: (1) instruction clarity to prevent the model from defaulting to binary\nsecurity labels; (2) contextual grounding, by iteratively refining the OWASP\nASVS category definitions to ensure the model adhered to provided standards;\n(3) constraint formatting, to stabilize the PSV output structure for machine-\nreadability and ensure the inclusion of mandatory explanation fields. All ex-\nperiments were conducted with fixed parameters (Temperature = 0, Top-p =\n0.95) and repeated three times. The reported results are averaged to reduce\nthe impact of any minor, non-deterministic fluctuations in the models’ token\nselection during individual inferences.\nPrompt-based methods can be sensitive to phrasing, structure, and exam-\nple selection. To manage prompt sensitivity and contextual bias, we adopted a\nunified Persona–Context–Constraint strategy. A single prompt structure was\nused across all models, without model-specific tuning or iterative optimization\naimed at maximizing scores. The few-shot examples were chosen for representa-\ntiveness with respect to the OWASP ASVS taxonomy rather than performance\ngains.', 'CONTEXT: This chunk discusses the challenges of identifying implicit security requirements in software requirements engineering (SRE), emphasizing the limitations of existing datasets and the need for AI-driven NLP methods, while highlighting the role of the OWASP ASVS framework in addressing these gaps through standardized security practices.\n\nCONTENT: Implicit Security Requirements Classification 3\n“The system will allow the user to print documents,” carries numerous implicit\nsecurity needs, including verifying user authorization, maintaining a valid ses-\nsion, and recording the action for accountability. These concerns correspond\nto common security control areas, such as access control, session management,\nand logging. This complexity requires substantial guidance. Manually iden-\ntifying and validating this network of implicit security dependencies across\nthousands of requirements is error prone, inconsistent, and not scalable (Ye\net al., 2025).\nGiven the limitations of manual SRA, automation through Artificial In-\ntelligence (AI) based Natural Language Processing (NLP) methods, offers a\npromising path forward. Although AI based approaches for RE have received\ngrowing attention (Abbasi et al., 2025; Zadenoori et al., 2025), recent evidence\nshows a gap between experimental advances and validated industrial solutions.\nFor example, an analysis of 74 primary studies found that most AI based tools\nare evaluated in controlled settings, with limited industrial adoption and weak\nintegration into real workflows (Bolanos et al., 2024). Similarly, another study\nreports a clear mismatch between expectations and practical outcomes in SRE\nin real world use (Karhu et al., 2025).\nThe main problem is the lack of suitable data, not the availability of ef-\nfective modeling approaches. The development and validation of data driven\napproaches is constrained by the scarcity and limited quality of domain spe-\ncific datasets (Wang et al., 2024; Zadenoori et al., 2025). This concern ex-\ntends beyond SRE, as leading NLP venues highlight dataset limitations that\nmake reliable evaluation difficult (Muresan et al., 2022; Goldberg et al., 2022;\nChristodoulopoulos et al., 2025).\nThis challenge is especially evident in SRE. Identifying implicit security\nrequirements relies on large collections of functional requirements annotated\nby security experts to reflect underlying security concerns. Current datasets do\nnot meet this need. For instance, PROMISE exp (Lima et al., 2019) includes\nonly a single, high-level security category; DOSSPRE (Kadebu et al., 2023)\nis based on student projects and lacks industry realism; and the Healthcare\ndataset (Riaz et al., 2014) is limited to a narrow domain and uses coarse-\ngrained labels. As a result, existing resources offer limited support for devel-\noping and evaluating methods aimed at uncovering implicit security require-\nments.\nThe OWASP Application Security Verification Standard (ASVS)1 offers a\nstandardized, systematic, and verifiable framework for defining and evaluating\napplication security controls. ASVS emphasizes the principle of “security by\ndesign” by facilitating the integration of security considerations early in the\nsoftware development lifecycle. Its comprehensive set of requirements can be\ndirectly mapped to verifiable test cases and secure coding practices, ensuring\ntraceability throughout the development process. This approach enables the\nearly identification and remediation of vulnerabilities, which is both more effi-\n1 https://owasp.org/www-project-application-security-verification-standard/']","The study excluded three specific OWASP ASVS 4.0.3 classes: **V1 (Architecture, Design, and Threat Modeling)**, **V11 (Business Logic)**, and **V14 (Configuration)**. These classes were excluded because they are **not inferable from functional or non-functional requirements**, making them unsuitable for the study's focus on mapping security requirements to actionable controls.

**Source:** temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf","Classes V1 (Architecture), V11 (Business Logic), and V14 (Configuration) were excluded because they are generally not inferable from functional or non-functional requirements statements[cite: 223, 224].",,,
What are the limitations of the PROMISE_exp dataset mentioned in the background?,"[""CONTEXT: **Comparative Analysis of Security Requirement Datasets**: This chunk provides a detailed comparison of the ASRD dataset with other prominent security requirement datasets, highlighting differences in size, domain coverage, annotation methodologies, and granularity, while emphasizing ASRD's strengths in industrial complexity, multi-domain applicability, and alignment with OWASP ASVS standards.\n\nCONTENT: 8 Yusuf G¨ ur et al.\nTable 1: Comparative Analysis of Security Requirement Datasets\nCharacteristic PROMISE\nexp\nDOSSPRE Healthcare\nDataset\nASRD (Ours)\nTotal Require-\nments\n969 1,317 10,963 2,652\nData Source Public SRS\ndocuments\n(expanded to\n49 projects)\n105 Student\nproject docu-\nments\n6 Official Cana-\ndian and U.S.\nSRS documents\n6 Real-world\nSRS docs from\na gov’t agency\nDomain General /\nCross-domain\nGeneral / Aca-\ndemic\nElectronic\nHealthcare\nMulti-domain:\nLegal, Const.,\nEdu., etc.\nPrimary Task FR vs. NFR,\nMulti-class\nNFR\nSR vs. NSR,\nMulti-class SR\nMulti-label\nSecurity Objec-\ntives\nMulti-label Im-\nplicit Security\nClass.\nSecurity Granu-\nlarity\nSingle SE\nclass\n10 security\nclasses\n6 security objec-\ntives\n11 OWASP\nASVS classes\nLanguage English English English Turkish\nAnnotation\nMethodology\nExpert Con-\nsensus: Man-\nual extraction\nand valida-\ntion\nAuthor Com-\npilation: Cat-\negorized by\nauthors only,\nlimited rigorous\nvalidation\nMulti-Stage\nConsensus: 2\nresearchers +\nmediator, high\nagreement\nMATTER Cy-\ncle: 3 SMEs\nwith adjudica-\ntion, iterative\nrefinement and\nabjudication\nKey Strength Established\nbenchmark\nand project\ndiversity\nFine-grained\nsecurity-specific\ntaxonomy\nLarge scale and\ndomain authen-\nticity\nIndustrial\ncomplexity +\nOWASP ASVS\nKey Limitation Small size\nand class\nimbalance\nPotential lack of\nprofessional re-\nalism\nDomain-\nspecific; coarse-\ngrained labels\nReal-world class\nimbalance in\nspecific cate-\ngories\nimbalance often restrict its suitability for training complex deep learning ar-\nchitectures.\n2.3.2 DOSSPRE\nThe Dataset of Students’ Software Projects Requirements (DOSSPRE) was\ncompiled by Kadebu et al. from documentation within academic curricula\n(Kadebu et al., 2023), likely from the Harare Institute of Technology. It pro-\nvides a fine-grained classification through a detailed taxonomy for both se-\ncurity and non-security requirements. However, as the requirements were au-\nthored by students, they may not fully reflect the realism and complexity of\nindustry-grade requirements."", 'CONTEXT: **Comparison of Effort vs. Performance and Validation of ASRD**: This chunk compares the effort and performance of different approaches (BERT fine-tuning, few-shot, and zero-shot LLMs) for security requirement classification, highlights the advantages of the ASRD dataset over existing benchmarks, and emphasizes the challenges of eliciting implicit security requirements in real-world industrial contexts.\n\nCONTENT: 34 Yusuf G¨ ur et al.\nTable 9: Comparison of Effort vs. Performance across Approaches\nApproach Data Requirement Est. Setup Effort Best Macro-F1\nBERT Fine-Tuning High (∼2,600 ex) High (267 hours)0.942\nLLM Few-Shot Low (∼30 ex) Low (<10 hours)0.941\nLLM Zero-Shot None Minimal (<2 hours) 0.890\nLLM Few-Shot approach (using Gemini 2.0) achieved a similar performance\n(Macro-F1 0.941) while requiring only the selection of a small number of in-\ncontext examples (approx. 30 examples per prompt).\nThis comparison points to diminishing returns from large-scale annotation\nwhen capable LLMs are available. Although extensive annotation was required\nhere to establish a reliable ground truth and validate the test set, the results\nindicate that, in industrial settings, a few-shot LLM approach can offer a more\nfavorable balance between effort and accuracy. Comparable performance can\nbe reached with substantially less data preparation, reducing the need for\nprolonged expert annotation.\nThe main contribution of this work is the introduction and validation of\nthe ASRD. The consistent performance of both fine-tuned BERT models and\nLLM-based approaches on ASRD supports its reliability and practical value.\nThe dataset addresses a persistent limitation in SRE research which is the\nlack of large, well-curated, professionally sourced benchmarks for security re-\nquirement classification. Compared with existing datasets, ASRD offers sev-\neral advantages. Unlike DOSSPRE (Kadebu et al., 2023), which is derived\nfrom student projects, ASRD includes 2,652 requirements from six commer-\ncial software systems, reflecting real industrial language and complexity. Its\nOWASP ASVS–based taxonomy spans 11 security classes, providing finer de-\ntail than PROMISE exp (Lima et al., 2019), where security is treated as a\nsingle category. Although the healthcare dataset by Riaz et al. (Riaz et al.,\n2014) is larger, it focuses on six broad objectives within a single domain, lim-\niting its scope. By contrast, ASRD supports cross-domain analysis and aligns\nwith a framework widely used in practice.\nThe dataset also benefits from a rigorous annotation process. Three cy-\nbersecurity specialists, each with over 15 years of experience, labeled the data\nusing an iterative MATTER-based procedure. This resulted in strong agree-\nment (Fleiss’ Kappa = 0.82) and helps mitigate the subjectivity that often\naffects security-related requirement datasets.\nBeyond the dataset construction, this study highlights the complexity of\nimplicit security requirement elicitation. A significant portion of security vul-\nnerabilities stems not from missing explicit security constraints (e.g., “The\nsystem shall encrypt passwords”), but from functional requirements that im-\nplicitly demand robust security controls. Our analysis of the ASRD reveals\nthat functional descriptions of business logic often conceal a dense network of\nsecurity dependencies. A representative example from our results is Require-\nment No. 2 (“The system will carry out the asset handover process”). While', 'CONTEXT: This chunk provides background on NLP-based techniques for software requirements classification, highlighting the evolution from traditional supervised learning methods to transformer-based models like BERT and SecureBERT, and emphasizing the challenges of classifying implicit security requirements due to ambiguity and the lack of high-quality, domain-specific datasets.\n\nCONTENT: Implicit Security Requirements Classification 5\nthreats to validity, and Section 8 concludes with a summary of contributions\nand directions for future work.\n2 Background\nThis section reviews prior work on NLP-based techniques for requirements\nclassification, followed by an overview of relevant security frameworks. It con-\ncludes with a discussion of existing datasets used in security requirements\nresearch.\n2.1 Related Work on Requirements Classification using NLP Techniques\nSoftware requirements (SR) classification supports effective project manage-\nment by enabling prioritization and risk assessment (Batool et al., 2025). The\ntask typically involves distinguishing functional requirements (FRs) from non-\nfunctional requirements (NFRs) and further categorizing NFRs into classes\nsuch as security, usability, and performance. Security requirements may ap-\npear as explicit system behaviors or as quality attributes addressing confiden-\ntiality, integrity, and availability—the security triad—which are often abstract\nand difficult to specify precisely in practice (Anwar Mohammad et al., 2019).\nThis inherent ambiguity complicates the development of clear guidelines for\nseparating security-related requirements from non-security ones.\nEarly studies applied supervised learning techniques, including Bayesian\nclassifiers(Knauss et al., 2011), decision trees (Jindal et al., 2016), and Sup-\nport Vector Machines (SVMs) (Dalpiaz et al., 2019), but these approaches\ndepended heavily on manual feature engineering and rigid linguistic patterns.\nTo address these limitations, later work adopted neural models such as convo-\nlutional neural networks (CNN) combined with Word2Vec embeddings (Dekht-\nyar and Fong, 2017). The adoption of transformer-based models such as BERT\nenabled improved classification accuracy through transfer learning and fine-\ntuning, eliminating the need for handcrafted features (Devlin et al., 2019; Sub-\nahi, 2023). More recent work explores domain-adapted transformer models,\nsuch as NoRBERT (Hey et al., 2020) and SecureBERT (Aghaei et al., 2022),\nto better capture domain-specific semantics and mitigate overfitting. These\nmodels have shown improved capability in identifying implicit non-functional\nrequirements, a particularly challenging task in security-critical settings (Nec-\nula et al., 2024). However, further progress in SRE is limited by the availability\nof large, high-quality, and domain-specific annotated datasets.\nThe subjective nature of defining security requirements further complicates\nreliable classification (Riaz and Williams, 2012). Security Requirement Elic-\nitation highly depends on domain-relevant expertise which includes various\ncostly manual steps such as creating security requirement templates, deter-\nmining security classification levels according to natural language artifacts,\nand mapping the class labels to related requirement templates by identifying\nentities.', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to', 'CONTEXT: **Comparison of Security Frameworks and Related Datasets**: This chunk contrasts various security frameworks, highlighting the suitability of OWASP ASVS for fine-grained security requirement classification, and reviews existing security-related requirement datasets, emphasizing their limitations and relevance to automated classification research.\n\nCONTENT: Implicit Security Requirements Classification 7\nSeveral established frameworks, while influential, are not designed for this\npurpose. MITRE ATT&ACK 2 framework is a threat-based model of adver-\nsary behaviors, not a taxonomy of software requirements. Microsoft’s STRIDE\noperates at a high level of abstraction (e.g., “Spoofing”, “Tampering”) which\nis useful for threat modeling but lacks the granularity needed for require-\nment classification (Khan et al., 2017). Similarly, the NIST Secure Software\nDevelopment Framework (SSDF) defines high-level secure process practices\nrather than atomic requirement categories (Souppaya et al., 2022), and the\nCommon Criteria (CC) 3 is a template-based framework designed for formal\ncertification, making it impractical for fine-grained, natural-language analysis\n(Infrastructure and Profile, 2002).\nIn contrast, the Open Web Application Security Project (OWASP)4 Appli-\ncation Security Verification Standard (ASVS)5 is well suited to the objectives\nof this study. ASVS provides a detailed, verifiable, and developer-oriented\ntaxonomy explicitly intended for requirement-level security analysis. Its orga-\nnization into distinct, actionable security categories supports direct mapping\nto functional and non-functional security controls. Previous studies have suc-\ncessfully applied ASVS in requirements and design contexts ( Lukasiewicz and\nCyga´ nska, 2019; Tan et al., 2021; Wen and Katt, 2023). Its consistency with\nstandards such as NIST 800-63B supports its use in both academic research\nand industrial settings.\n2.3 Related Work on Security Related Requirement Datasets\nHigh-quality benchmark datasets are essential for developing automated clas-\nsification models, ensuring research reproducibility, and assessing model gen-\neralizability. In response to this need, the research community has developed\na limited number of foundational datasets for security requirements analysis,\neach offering distinct advantages and limitations. The three most represen-\ntative datasets are briefly described below, and their key characteristics are\nsummarized in Table 1.\n2.3.1 PROMISEExp\nIntroduced by Lima et al. (Lima et al., 2019), to expand the well-established\ntera-PROMISE repository, this dataset resulted from a systematic curation\nof publicly available SRS documents. The curation process relied on man-\nual extraction and expert consensus to ensure high-quality annotations. Al-\nthough it offers significant project diversity compared to its predecessor, its\nprimary challenge for modern research is its “High Dimension, Low Sample\nSize” (HDLSS) nature. The high feature-to-instance ratio and inherent class\n2 https://attack.mitre.org/\n3 https://www.commoncriteriaportal.org/cc/\n4 https://owasp.org/\n5 https://owasp.org/www-project-application-security-verification-standard/', 'CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr', 'CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the']","The limitations of the PROMISE_exp dataset mentioned in the background are:

1. **Small Size**: The dataset is relatively small, with only 969 requirements, which limits its utility for training complex machine learning models.
2. **Class Imbalance**: There is an inherent imbalance in the distribution of classes, which restricts its suitability for tasks requiring balanced data representation.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","PROMISE_exp has a 'High Dimension, Low Sample Size' (HDLSS) nature, high feature-to-instance ratio, and includes only a single, high-level security category rather than fine-grained classes[cite: 56, 143, 144].",,,
What is the primary limitation of the DOSSPRE dataset?,"[""CONTEXT: **Comparative Analysis of Security Requirement Datasets**: This chunk provides a detailed comparison of the ASRD dataset with other prominent security requirement datasets, highlighting differences in size, domain coverage, annotation methodologies, and granularity, while emphasizing ASRD's strengths in industrial complexity, multi-domain applicability, and alignment with OWASP ASVS standards.\n\nCONTENT: 8 Yusuf G¨ ur et al.\nTable 1: Comparative Analysis of Security Requirement Datasets\nCharacteristic PROMISE\nexp\nDOSSPRE Healthcare\nDataset\nASRD (Ours)\nTotal Require-\nments\n969 1,317 10,963 2,652\nData Source Public SRS\ndocuments\n(expanded to\n49 projects)\n105 Student\nproject docu-\nments\n6 Official Cana-\ndian and U.S.\nSRS documents\n6 Real-world\nSRS docs from\na gov’t agency\nDomain General /\nCross-domain\nGeneral / Aca-\ndemic\nElectronic\nHealthcare\nMulti-domain:\nLegal, Const.,\nEdu., etc.\nPrimary Task FR vs. NFR,\nMulti-class\nNFR\nSR vs. NSR,\nMulti-class SR\nMulti-label\nSecurity Objec-\ntives\nMulti-label Im-\nplicit Security\nClass.\nSecurity Granu-\nlarity\nSingle SE\nclass\n10 security\nclasses\n6 security objec-\ntives\n11 OWASP\nASVS classes\nLanguage English English English Turkish\nAnnotation\nMethodology\nExpert Con-\nsensus: Man-\nual extraction\nand valida-\ntion\nAuthor Com-\npilation: Cat-\negorized by\nauthors only,\nlimited rigorous\nvalidation\nMulti-Stage\nConsensus: 2\nresearchers +\nmediator, high\nagreement\nMATTER Cy-\ncle: 3 SMEs\nwith adjudica-\ntion, iterative\nrefinement and\nabjudication\nKey Strength Established\nbenchmark\nand project\ndiversity\nFine-grained\nsecurity-specific\ntaxonomy\nLarge scale and\ndomain authen-\nticity\nIndustrial\ncomplexity +\nOWASP ASVS\nKey Limitation Small size\nand class\nimbalance\nPotential lack of\nprofessional re-\nalism\nDomain-\nspecific; coarse-\ngrained labels\nReal-world class\nimbalance in\nspecific cate-\ngories\nimbalance often restrict its suitability for training complex deep learning ar-\nchitectures.\n2.3.2 DOSSPRE\nThe Dataset of Students’ Software Projects Requirements (DOSSPRE) was\ncompiled by Kadebu et al. from documentation within academic curricula\n(Kadebu et al., 2023), likely from the Harare Institute of Technology. It pro-\nvides a fine-grained classification through a detailed taxonomy for both se-\ncurity and non-security requirements. However, as the requirements were au-\nthored by students, they may not fully reflect the realism and complexity of\nindustry-grade requirements."", 'CONTEXT: **Comparison of Effort vs. Performance and Validation of ASRD**: This chunk compares the effort and performance of different approaches (BERT fine-tuning, few-shot, and zero-shot LLMs) for security requirement classification, highlights the advantages of the ASRD dataset over existing benchmarks, and emphasizes the challenges of eliciting implicit security requirements in real-world industrial contexts.\n\nCONTENT: 34 Yusuf G¨ ur et al.\nTable 9: Comparison of Effort vs. Performance across Approaches\nApproach Data Requirement Est. Setup Effort Best Macro-F1\nBERT Fine-Tuning High (∼2,600 ex) High (267 hours)0.942\nLLM Few-Shot Low (∼30 ex) Low (<10 hours)0.941\nLLM Zero-Shot None Minimal (<2 hours) 0.890\nLLM Few-Shot approach (using Gemini 2.0) achieved a similar performance\n(Macro-F1 0.941) while requiring only the selection of a small number of in-\ncontext examples (approx. 30 examples per prompt).\nThis comparison points to diminishing returns from large-scale annotation\nwhen capable LLMs are available. Although extensive annotation was required\nhere to establish a reliable ground truth and validate the test set, the results\nindicate that, in industrial settings, a few-shot LLM approach can offer a more\nfavorable balance between effort and accuracy. Comparable performance can\nbe reached with substantially less data preparation, reducing the need for\nprolonged expert annotation.\nThe main contribution of this work is the introduction and validation of\nthe ASRD. The consistent performance of both fine-tuned BERT models and\nLLM-based approaches on ASRD supports its reliability and practical value.\nThe dataset addresses a persistent limitation in SRE research which is the\nlack of large, well-curated, professionally sourced benchmarks for security re-\nquirement classification. Compared with existing datasets, ASRD offers sev-\neral advantages. Unlike DOSSPRE (Kadebu et al., 2023), which is derived\nfrom student projects, ASRD includes 2,652 requirements from six commer-\ncial software systems, reflecting real industrial language and complexity. Its\nOWASP ASVS–based taxonomy spans 11 security classes, providing finer de-\ntail than PROMISE exp (Lima et al., 2019), where security is treated as a\nsingle category. Although the healthcare dataset by Riaz et al. (Riaz et al.,\n2014) is larger, it focuses on six broad objectives within a single domain, lim-\niting its scope. By contrast, ASRD supports cross-domain analysis and aligns\nwith a framework widely used in practice.\nThe dataset also benefits from a rigorous annotation process. Three cy-\nbersecurity specialists, each with over 15 years of experience, labeled the data\nusing an iterative MATTER-based procedure. This resulted in strong agree-\nment (Fleiss’ Kappa = 0.82) and helps mitigate the subjectivity that often\naffects security-related requirement datasets.\nBeyond the dataset construction, this study highlights the complexity of\nimplicit security requirement elicitation. A significant portion of security vul-\nnerabilities stems not from missing explicit security constraints (e.g., “The\nsystem shall encrypt passwords”), but from functional requirements that im-\nplicitly demand robust security controls. Our analysis of the ASRD reveals\nthat functional descriptions of business logic often conceal a dense network of\nsecurity dependencies. A representative example from our results is Require-\nment No. 2 (“The system will carry out the asset handover process”). While', 'CONTEXT: **Comparison of Security Frameworks and Related Datasets**: This chunk contrasts various security frameworks, highlighting the suitability of OWASP ASVS for fine-grained security requirement classification, and reviews existing security-related requirement datasets, emphasizing their limitations and relevance to automated classification research.\n\nCONTENT: Implicit Security Requirements Classification 7\nSeveral established frameworks, while influential, are not designed for this\npurpose. MITRE ATT&ACK 2 framework is a threat-based model of adver-\nsary behaviors, not a taxonomy of software requirements. Microsoft’s STRIDE\noperates at a high level of abstraction (e.g., “Spoofing”, “Tampering”) which\nis useful for threat modeling but lacks the granularity needed for require-\nment classification (Khan et al., 2017). Similarly, the NIST Secure Software\nDevelopment Framework (SSDF) defines high-level secure process practices\nrather than atomic requirement categories (Souppaya et al., 2022), and the\nCommon Criteria (CC) 3 is a template-based framework designed for formal\ncertification, making it impractical for fine-grained, natural-language analysis\n(Infrastructure and Profile, 2002).\nIn contrast, the Open Web Application Security Project (OWASP)4 Appli-\ncation Security Verification Standard (ASVS)5 is well suited to the objectives\nof this study. ASVS provides a detailed, verifiable, and developer-oriented\ntaxonomy explicitly intended for requirement-level security analysis. Its orga-\nnization into distinct, actionable security categories supports direct mapping\nto functional and non-functional security controls. Previous studies have suc-\ncessfully applied ASVS in requirements and design contexts ( Lukasiewicz and\nCyga´ nska, 2019; Tan et al., 2021; Wen and Katt, 2023). Its consistency with\nstandards such as NIST 800-63B supports its use in both academic research\nand industrial settings.\n2.3 Related Work on Security Related Requirement Datasets\nHigh-quality benchmark datasets are essential for developing automated clas-\nsification models, ensuring research reproducibility, and assessing model gen-\neralizability. In response to this need, the research community has developed\na limited number of foundational datasets for security requirements analysis,\neach offering distinct advantages and limitations. The three most represen-\ntative datasets are briefly described below, and their key characteristics are\nsummarized in Table 1.\n2.3.1 PROMISEExp\nIntroduced by Lima et al. (Lima et al., 2019), to expand the well-established\ntera-PROMISE repository, this dataset resulted from a systematic curation\nof publicly available SRS documents. The curation process relied on man-\nual extraction and expert consensus to ensure high-quality annotations. Al-\nthough it offers significant project diversity compared to its predecessor, its\nprimary challenge for modern research is its “High Dimension, Low Sample\nSize” (HDLSS) nature. The high feature-to-instance ratio and inherent class\n2 https://attack.mitre.org/\n3 https://www.commoncriteriaportal.org/cc/\n4 https://owasp.org/\n5 https://owasp.org/www-project-application-security-verification-standard/', 'CONTEXT: This chunk discusses the challenges of identifying implicit security requirements in software requirements engineering (SRE), emphasizing the limitations of existing datasets and the need for AI-driven NLP methods, while highlighting the role of the OWASP ASVS framework in addressing these gaps through standardized security practices.\n\nCONTENT: Implicit Security Requirements Classification 3\n“The system will allow the user to print documents,” carries numerous implicit\nsecurity needs, including verifying user authorization, maintaining a valid ses-\nsion, and recording the action for accountability. These concerns correspond\nto common security control areas, such as access control, session management,\nand logging. This complexity requires substantial guidance. Manually iden-\ntifying and validating this network of implicit security dependencies across\nthousands of requirements is error prone, inconsistent, and not scalable (Ye\net al., 2025).\nGiven the limitations of manual SRA, automation through Artificial In-\ntelligence (AI) based Natural Language Processing (NLP) methods, offers a\npromising path forward. Although AI based approaches for RE have received\ngrowing attention (Abbasi et al., 2025; Zadenoori et al., 2025), recent evidence\nshows a gap between experimental advances and validated industrial solutions.\nFor example, an analysis of 74 primary studies found that most AI based tools\nare evaluated in controlled settings, with limited industrial adoption and weak\nintegration into real workflows (Bolanos et al., 2024). Similarly, another study\nreports a clear mismatch between expectations and practical outcomes in SRE\nin real world use (Karhu et al., 2025).\nThe main problem is the lack of suitable data, not the availability of ef-\nfective modeling approaches. The development and validation of data driven\napproaches is constrained by the scarcity and limited quality of domain spe-\ncific datasets (Wang et al., 2024; Zadenoori et al., 2025). This concern ex-\ntends beyond SRE, as leading NLP venues highlight dataset limitations that\nmake reliable evaluation difficult (Muresan et al., 2022; Goldberg et al., 2022;\nChristodoulopoulos et al., 2025).\nThis challenge is especially evident in SRE. Identifying implicit security\nrequirements relies on large collections of functional requirements annotated\nby security experts to reflect underlying security concerns. Current datasets do\nnot meet this need. For instance, PROMISE exp (Lima et al., 2019) includes\nonly a single, high-level security category; DOSSPRE (Kadebu et al., 2023)\nis based on student projects and lacks industry realism; and the Healthcare\ndataset (Riaz et al., 2014) is limited to a narrow domain and uses coarse-\ngrained labels. As a result, existing resources offer limited support for devel-\noping and evaluating methods aimed at uncovering implicit security require-\nments.\nThe OWASP Application Security Verification Standard (ASVS)1 offers a\nstandardized, systematic, and verifiable framework for defining and evaluating\napplication security controls. ASVS emphasizes the principle of “security by\ndesign” by facilitating the integration of security considerations early in the\nsoftware development lifecycle. Its comprehensive set of requirements can be\ndirectly mapped to verifiable test cases and secure coding practices, ensuring\ntraceability throughout the development process. This approach enables the\nearly identification and remediation of vulnerabilities, which is both more effi-\n1 https://owasp.org/www-project-application-security-verification-standard/', 'CONTEXT: **Performance Evaluation of GPT-4o Models in Security Requirement Classification**: This chunk presents the precision, recall, F1 scores, and support metrics for GPT-4o models (Few-Shot and Zero-Shot) across OWASP ASVS security categories, highlighting their effectiveness and limitations in classifying security requirements, particularly for underrepresented classes.\n\nCONTENT: Test Results of the LLMs used in the study\nGpt_4o_Few_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.969 0.956 0.969 0.946 0.205 0.974 0.961 0.951 0.928 0.357 0.938RECALL 0.982 0.971 0.977 0.949 0.205 0.982 0.974 0.961 0.943 0.357 0.953F1 0.975 0.964 0.973 0.948 0.205 0.978 0.968 0.956 0.936 0.357 0.945SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nGpt_4o_mini_Zero_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.953 0.865 0.928 0.829 0.254 0.824 0.671 0.779 0.659 0.093 0.720RECALL 0.963 0.877 0.938 0.863 0.385 0.828 0.680 0.785 0.690 0.250 0.736F1 0.958 0.871 0.933 0.846 0.306 0.826 0.675 0.782 0.674 0.136 0.728SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nGpt_4o_mini_Few_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.969 0.956 0.964 0.821 0.128 0.959 0.871 0.862 0.768 0.179 0.813RECALL 0.976 0.966 0.969 0.829 0.128 0.964 0.878 0.866 0.773 0.179 0.821F1 0.973 0.961 0.966 0.825 0.128 0.962 0.874 0.864 0.771 0.179 0.817SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398', 'CONTEXT: **ASRD Dataset Filtering and Composition**: This chunk details the rigorous filtering, randomization, and composition process used to create the ASRD dataset, highlighting its focus on functional requirements across six business domains and its alignment with OWASP ASVS security classes for security requirements classification.\n\nCONTENT: 10 Yusuf G¨ ur et al.\n3. Filtering: The initial extraction yielded 3,264 items. To ensure the qual-\nity of the dataset, domain experts conducted a rigorous manual filtering\npass to remove 612 items. This exclusion process went beyond simple for-\nmatting artifacts (such as headers or tables of contents). We specifically\nremoved non-functional administrative clauses that addressed the vendor\nrather than the system (e.g., “The contractor must provide training man-\nuals”), project management constraints (e.g., “The project must be deliv-\nered by Q3”), and requirements with ambiguous scope that lacked clear\nverification criteria.\n4. Randomization: The remaining requirements were randomized and masked\nto mitigate potential annotation bias related to the document source or the\nsequence of requirements.\nThe resulting ASRD comprises 2,652 well-formed functional requirements\nacross six distinct business areas: Construction (1,202), Legal (177), Education\n(312), Software (199), Meeting (126), and Accommodation (636). A sample of\nthese requirements is provided in Table 2. The requirements included in this\nsample were selected based on three specific criteria to ensure a representative\noverview:\n–Samples were chosen to reflect the varied terminology and phrasing styles\nused across the six different business domains.\n–We prioritized requirements that demonstrate how standard functional de-\nscriptions conceal underlying security dependencies.\n–We ensured that the sample includes representative examples for all 11\nOWASP ASVS security classes used in the study to demonstrate the full\nscope of the classification task.\nIt is important to note that the ASRD is a Turkish-language corpus; all experi-\nments detailed in this study, including BERT fine-tuning and LLM prompting,\nwere conducted exclusively on the original text. English translations are pro-\nvided only for readability.\nTable 2: Sample Requirements from ASRD\nNo Original Requirements Translated Requirements\n1 Sistem, yetkili kullanıcının hukuk\ndosyası t¨ ur¨ u kayıt etmesini\nsa˘ glayacaktır.\nThe system shall allow authorized\nusers to record the legal file type.\n2 Sistem, kullanıcının kullanılmamı¸ s\nhukuk dosyası t¨ ur¨ un¨ u g¨ uncellemesini\nsa˘ glayacaktır.\nThe system shall allow the user to up-\ndate an unused legal file type.\n3 Sistem, kullanıcının kullanılmamı¸ s\nolan hukuk dosyası t¨ ur¨ un¨ u silmesini\nsa˘ glayacaktır.\nThe system shall allow the user to\ndelete an unused legal file type.\n4 Sistem, kullanıcının hukuk dosyası\nt¨ urlerini sorgulamasını ve listelemesini\nsa˘ glayacaktır.\nThe system shall allow the user to\nquery and list legal file types.', 'CONTEXT: **Annotation Process and Dataset Composition**: This chunk details the multi-stage annotation methodology used to create the ASRD dataset, addressing class distribution, challenges with imbalanced categories (e.g., V6 Cryptography, V12 Files/Resources), and the inclusion of true negatives to ensure realistic and high-quality security requirement classification.\n\nCONTENT: Implicit Security Requirements Classification 17\n0.71 to 0.79, further confirmed substantial agreement between individual\nannotator pairs.\n–Adjudication: Disagreements were resolved through structured expert dis-\ncussions led by the senior SME. When the two annotators disagreed on a\nrequirement, it was resolved through a structured process:\n–Both annotators presented their choice and their reasons.\n–The senior expert reviewed both positions against the guideline.\n–If the guideline clearly supported one choice, that one was used. If not,\nthe senior expert led a discussion to decide.\n–Final decision and the reason was written down.\nThe goal was to reach unanimous agreement for each disputed requirement.\nThis process produced final Gold Standard annotations for 135 contested\nitems, ensuring consistency and validation of the dataset.\nThis multi-stage annotation methodology produced a reliable dataset which\ncomprises 2,652 annotated security-relevant requirements. The category dis-\ntributions of the requirements can be seen in Figure 1. The class distribution\namong the classes are largely balanced (90%) except the V6(Stored Cryptog-\nraphy) and V12 (Files & Resources) as 6% each. This imbalance is considered\na reflection of the source projects, where requirements for these two categories\nare inherently less frequent than pervasive controls like access control or input\nvalidation. Stored cryptography requirements are typically captured as holis-\ntic, architectural decisions rather than numerous, distinct functional require-\nments. Similarly, explicit security controls for file handling are less ubiquitous,\nappearing only in projects with specific file processing features, which explains\ntheir low frequency in our corpus. Sample annotated requirements can be seen\nin Table 4.\nThis imbalance mirrors real-world security requirement frequency - most\nsoftware functions involve access and data; few involve file uploads or encryp-\ntion configuration - and introduces a challenge for machine learning. Partic-\nularly, the sparsity in V6 and V12 categories may hinder generalization and\ncalls for class imbalance handling techniques. Despite this, the dataset presents\na realistic and high-quality foundation for developing and evaluating security-\naware NLP and classification models.\nTwenty-six requirements (0.98% of the data) labeled as “UNASSIGNED”\nwere requirements unanimously determined by the experts to be purely func-\ntional requirements with no discernible implicit security component (e.g., “The\nsystem will enable application software to be developed with an object-oriented\nprogramming approach”,). These items were intentionally retained in the dataset\nas true negatives to ensure a realistic distribution and test the models’ ability\nto correctly reject non-security items.\n\n18 Yusuf G¨ ur et al.\nFig. 1: Distribution of Classes', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb']","The primary limitation of the DOSSPRE dataset is its lack of professional realism. Since the dataset is derived from student-authored project documents, it may not fully reflect the complexity and authenticity of industry-grade requirements. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","DOSSPRE is based on student projects, which may lack the realism and complexity of industry-grade requirements[cite: 57, 158].",,,
Why is the Electronic Health Domain Dataset considered limited for this study's purpose?,"['CONTEXT: This chunk discusses the curation and preprocessing of the ASRD dataset, detailing the data collection process from real-world Software Requirements Specification (SRS) documents, the multi-stage preprocessing pipeline for sentence extraction and anonymization, and how the dataset addresses gaps in prior work by incorporating industrial complexity and linguistic diversity.\n\nCONTENT: Implicit Security Requirements Classification 9\n2.3.3 Electronic Health Domain Dataset\nThis corpus focuses on the electronic healthcare industry, a sector defined\nby stringent regulatory and high-assurance demands (Riaz et al., 2014). The\ndataset’s strength lies in its rigorous multi-stage annotation methodology,\nwhich utilized independent researchers and a mediator to ensure high inter-\nannotator agreement. While it provides a large-scale, authentic resource for\nhealthcare-specific tasks, its narrow focus may limit the generalizability of\nmodels to other industries, and its high-level security objectives may be too\ncoarse for detailed technical analysis.\n2.3.4 Summary of Datasets\nAs summarized in Table 1, these datasets vary significantly in their suitability\nfor tasks ranging from general non-functional requirement (NFR) classifica-\ntion to detailed security analysis. Our proposed Agency Security Require-\nments Dataset (ASRD) addresses gaps in prior work by adopting the OWASP\nASVS taxonomy for multi-label annotation. Furthermore, by utilizing real-\nworld projects originally written in Turkish, ASRD introduces both industrial\ncomplexity and linguistic diversity to the field.\n3 Dataset Curation, Annotation, and Evaluation\n3.1 Data Collection and Preprocessing\nThe dataset compilation began with the collection of six Software Require-\nments Specification (SRS) documents from an Agency’s Security Department.\nThese documents were selected from an initial pool of 19 projects executed\nbetween 2019 and 2023, specifically chosen for their domain diversity and\namenability to effective anonymization. The original documents were provided\nin standard document formats (e.g., PDF, DOCX) where requirements were\norganized in itemized lists. To transform these documents into a machine-\nreadable dataset, we employed a multi-stage preprocessing pipeline:\n1. Sentence Segmentation and Extraction: As the source SRS documents uti-\nlized standard itemization for requirements, we employed a rule-based ex-\ntraction method. We utilized pattern matching to identify requirement\nblocks based on hierarchical numbering schemes and line breaks. Each iden-\ntified requirement was extracted and treated as a single processing unit,\npreserving the structural integrity of the original specification.\n2. Anonymization: To protect sensitive data, a semi-automated anonymiza-\ntion process was implemented. Custom scripts replaced entities such as\nproject names, specific URLs, and IP addresses with generic placeholders.\nThis was followed by a manual review by domain experts to ensure that\nthe removal of personally identifiable information (PII) did not compromise\nthe semantic meaning or contextual integrity of the requirements.', ""CONTEXT: **Comparative Analysis of Security Requirement Datasets**: This chunk provides a detailed comparison of the ASRD dataset with other prominent security requirement datasets, highlighting differences in size, domain coverage, annotation methodologies, and granularity, while emphasizing ASRD's strengths in industrial complexity, multi-domain applicability, and alignment with OWASP ASVS standards.\n\nCONTENT: 8 Yusuf G¨ ur et al.\nTable 1: Comparative Analysis of Security Requirement Datasets\nCharacteristic PROMISE\nexp\nDOSSPRE Healthcare\nDataset\nASRD (Ours)\nTotal Require-\nments\n969 1,317 10,963 2,652\nData Source Public SRS\ndocuments\n(expanded to\n49 projects)\n105 Student\nproject docu-\nments\n6 Official Cana-\ndian and U.S.\nSRS documents\n6 Real-world\nSRS docs from\na gov’t agency\nDomain General /\nCross-domain\nGeneral / Aca-\ndemic\nElectronic\nHealthcare\nMulti-domain:\nLegal, Const.,\nEdu., etc.\nPrimary Task FR vs. NFR,\nMulti-class\nNFR\nSR vs. NSR,\nMulti-class SR\nMulti-label\nSecurity Objec-\ntives\nMulti-label Im-\nplicit Security\nClass.\nSecurity Granu-\nlarity\nSingle SE\nclass\n10 security\nclasses\n6 security objec-\ntives\n11 OWASP\nASVS classes\nLanguage English English English Turkish\nAnnotation\nMethodology\nExpert Con-\nsensus: Man-\nual extraction\nand valida-\ntion\nAuthor Com-\npilation: Cat-\negorized by\nauthors only,\nlimited rigorous\nvalidation\nMulti-Stage\nConsensus: 2\nresearchers +\nmediator, high\nagreement\nMATTER Cy-\ncle: 3 SMEs\nwith adjudica-\ntion, iterative\nrefinement and\nabjudication\nKey Strength Established\nbenchmark\nand project\ndiversity\nFine-grained\nsecurity-specific\ntaxonomy\nLarge scale and\ndomain authen-\nticity\nIndustrial\ncomplexity +\nOWASP ASVS\nKey Limitation Small size\nand class\nimbalance\nPotential lack of\nprofessional re-\nalism\nDomain-\nspecific; coarse-\ngrained labels\nReal-world class\nimbalance in\nspecific cate-\ngories\nimbalance often restrict its suitability for training complex deep learning ar-\nchitectures.\n2.3.2 DOSSPRE\nThe Dataset of Students’ Software Projects Requirements (DOSSPRE) was\ncompiled by Kadebu et al. from documentation within academic curricula\n(Kadebu et al., 2023), likely from the Harare Institute of Technology. It pro-\nvides a fine-grained classification through a detailed taxonomy for both se-\ncurity and non-security requirements. However, as the requirements were au-\nthored by students, they may not fully reflect the realism and complexity of\nindustry-grade requirements."", 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: This chunk provides background on NLP-based techniques for software requirements classification, highlighting the evolution from traditional supervised learning methods to transformer-based models like BERT and SecureBERT, and emphasizing the challenges of classifying implicit security requirements due to ambiguity and the lack of high-quality, domain-specific datasets.\n\nCONTENT: Implicit Security Requirements Classification 5\nthreats to validity, and Section 8 concludes with a summary of contributions\nand directions for future work.\n2 Background\nThis section reviews prior work on NLP-based techniques for requirements\nclassification, followed by an overview of relevant security frameworks. It con-\ncludes with a discussion of existing datasets used in security requirements\nresearch.\n2.1 Related Work on Requirements Classification using NLP Techniques\nSoftware requirements (SR) classification supports effective project manage-\nment by enabling prioritization and risk assessment (Batool et al., 2025). The\ntask typically involves distinguishing functional requirements (FRs) from non-\nfunctional requirements (NFRs) and further categorizing NFRs into classes\nsuch as security, usability, and performance. Security requirements may ap-\npear as explicit system behaviors or as quality attributes addressing confiden-\ntiality, integrity, and availability—the security triad—which are often abstract\nand difficult to specify precisely in practice (Anwar Mohammad et al., 2019).\nThis inherent ambiguity complicates the development of clear guidelines for\nseparating security-related requirements from non-security ones.\nEarly studies applied supervised learning techniques, including Bayesian\nclassifiers(Knauss et al., 2011), decision trees (Jindal et al., 2016), and Sup-\nport Vector Machines (SVMs) (Dalpiaz et al., 2019), but these approaches\ndepended heavily on manual feature engineering and rigid linguistic patterns.\nTo address these limitations, later work adopted neural models such as convo-\nlutional neural networks (CNN) combined with Word2Vec embeddings (Dekht-\nyar and Fong, 2017). The adoption of transformer-based models such as BERT\nenabled improved classification accuracy through transfer learning and fine-\ntuning, eliminating the need for handcrafted features (Devlin et al., 2019; Sub-\nahi, 2023). More recent work explores domain-adapted transformer models,\nsuch as NoRBERT (Hey et al., 2020) and SecureBERT (Aghaei et al., 2022),\nto better capture domain-specific semantics and mitigate overfitting. These\nmodels have shown improved capability in identifying implicit non-functional\nrequirements, a particularly challenging task in security-critical settings (Nec-\nula et al., 2024). However, further progress in SRE is limited by the availability\nof large, high-quality, and domain-specific annotated datasets.\nThe subjective nature of defining security requirements further complicates\nreliable classification (Riaz and Williams, 2012). Security Requirement Elic-\nitation highly depends on domain-relevant expertise which includes various\ncostly manual steps such as creating security requirement templates, deter-\nmining security classification levels according to natural language artifacts,\nand mapping the class labels to related requirement templates by identifying\nentities.', 'CONTEXT: **Comparison of Security Frameworks and Related Datasets**: This chunk contrasts various security frameworks, highlighting the suitability of OWASP ASVS for fine-grained security requirement classification, and reviews existing security-related requirement datasets, emphasizing their limitations and relevance to automated classification research.\n\nCONTENT: Implicit Security Requirements Classification 7\nSeveral established frameworks, while influential, are not designed for this\npurpose. MITRE ATT&ACK 2 framework is a threat-based model of adver-\nsary behaviors, not a taxonomy of software requirements. Microsoft’s STRIDE\noperates at a high level of abstraction (e.g., “Spoofing”, “Tampering”) which\nis useful for threat modeling but lacks the granularity needed for require-\nment classification (Khan et al., 2017). Similarly, the NIST Secure Software\nDevelopment Framework (SSDF) defines high-level secure process practices\nrather than atomic requirement categories (Souppaya et al., 2022), and the\nCommon Criteria (CC) 3 is a template-based framework designed for formal\ncertification, making it impractical for fine-grained, natural-language analysis\n(Infrastructure and Profile, 2002).\nIn contrast, the Open Web Application Security Project (OWASP)4 Appli-\ncation Security Verification Standard (ASVS)5 is well suited to the objectives\nof this study. ASVS provides a detailed, verifiable, and developer-oriented\ntaxonomy explicitly intended for requirement-level security analysis. Its orga-\nnization into distinct, actionable security categories supports direct mapping\nto functional and non-functional security controls. Previous studies have suc-\ncessfully applied ASVS in requirements and design contexts ( Lukasiewicz and\nCyga´ nska, 2019; Tan et al., 2021; Wen and Katt, 2023). Its consistency with\nstandards such as NIST 800-63B supports its use in both academic research\nand industrial settings.\n2.3 Related Work on Security Related Requirement Datasets\nHigh-quality benchmark datasets are essential for developing automated clas-\nsification models, ensuring research reproducibility, and assessing model gen-\neralizability. In response to this need, the research community has developed\na limited number of foundational datasets for security requirements analysis,\neach offering distinct advantages and limitations. The three most represen-\ntative datasets are briefly described below, and their key characteristics are\nsummarized in Table 1.\n2.3.1 PROMISEExp\nIntroduced by Lima et al. (Lima et al., 2019), to expand the well-established\ntera-PROMISE repository, this dataset resulted from a systematic curation\nof publicly available SRS documents. The curation process relied on man-\nual extraction and expert consensus to ensure high-quality annotations. Al-\nthough it offers significant project diversity compared to its predecessor, its\nprimary challenge for modern research is its “High Dimension, Low Sample\nSize” (HDLSS) nature. The high feature-to-instance ratio and inherent class\n2 https://attack.mitre.org/\n3 https://www.commoncriteriaportal.org/cc/\n4 https://owasp.org/\n5 https://owasp.org/www-project-application-security-verification-standard/', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb', 'CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr']","The Electronic Health Domain Dataset is considered limited for this study's purpose due to its narrow focus on the electronic healthcare industry. While it provides a large-scale, authentic resource for healthcare-specific tasks and employs a rigorous multi-stage annotation methodology, its domain-specific nature restricts the generalizability of models to other industries. Additionally, its high-level security objectives are too coarse for detailed technical analysis, which limits its suitability for fine-grained security requirement classification tasks. 

**Source:** temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf","It is limited to a narrow domain (healthcare) and uses coarse-grained labels (6 security objectives) rather than detailed technical categories[cite: 58, 164].",,,
What preprocessing steps were applied to the raw SRS documents?,"['CONTEXT: This chunk discusses the curation and preprocessing of the ASRD dataset, detailing the data collection process from real-world Software Requirements Specification (SRS) documents, the multi-stage preprocessing pipeline for sentence extraction and anonymization, and how the dataset addresses gaps in prior work by incorporating industrial complexity and linguistic diversity.\n\nCONTENT: Implicit Security Requirements Classification 9\n2.3.3 Electronic Health Domain Dataset\nThis corpus focuses on the electronic healthcare industry, a sector defined\nby stringent regulatory and high-assurance demands (Riaz et al., 2014). The\ndataset’s strength lies in its rigorous multi-stage annotation methodology,\nwhich utilized independent researchers and a mediator to ensure high inter-\nannotator agreement. While it provides a large-scale, authentic resource for\nhealthcare-specific tasks, its narrow focus may limit the generalizability of\nmodels to other industries, and its high-level security objectives may be too\ncoarse for detailed technical analysis.\n2.3.4 Summary of Datasets\nAs summarized in Table 1, these datasets vary significantly in their suitability\nfor tasks ranging from general non-functional requirement (NFR) classifica-\ntion to detailed security analysis. Our proposed Agency Security Require-\nments Dataset (ASRD) addresses gaps in prior work by adopting the OWASP\nASVS taxonomy for multi-label annotation. Furthermore, by utilizing real-\nworld projects originally written in Turkish, ASRD introduces both industrial\ncomplexity and linguistic diversity to the field.\n3 Dataset Curation, Annotation, and Evaluation\n3.1 Data Collection and Preprocessing\nThe dataset compilation began with the collection of six Software Require-\nments Specification (SRS) documents from an Agency’s Security Department.\nThese documents were selected from an initial pool of 19 projects executed\nbetween 2019 and 2023, specifically chosen for their domain diversity and\namenability to effective anonymization. The original documents were provided\nin standard document formats (e.g., PDF, DOCX) where requirements were\norganized in itemized lists. To transform these documents into a machine-\nreadable dataset, we employed a multi-stage preprocessing pipeline:\n1. Sentence Segmentation and Extraction: As the source SRS documents uti-\nlized standard itemization for requirements, we employed a rule-based ex-\ntraction method. We utilized pattern matching to identify requirement\nblocks based on hierarchical numbering schemes and line breaks. Each iden-\ntified requirement was extracted and treated as a single processing unit,\npreserving the structural integrity of the original specification.\n2. Anonymization: To protect sensitive data, a semi-automated anonymiza-\ntion process was implemented. Custom scripts replaced entities such as\nproject names, specific URLs, and IP addresses with generic placeholders.\nThis was followed by a manual review by domain experts to ensure that\nthe removal of personally identifiable information (PII) did not compromise\nthe semantic meaning or contextual integrity of the requirements.', 'CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr', 'CONTEXT: This chunk discusses the challenges of identifying implicit security requirements in software requirements engineering (SRE), emphasizing the limitations of existing datasets and the need for AI-driven NLP methods, while highlighting the role of the OWASP ASVS framework in addressing these gaps through standardized security practices.\n\nCONTENT: Implicit Security Requirements Classification 3\n“The system will allow the user to print documents,” carries numerous implicit\nsecurity needs, including verifying user authorization, maintaining a valid ses-\nsion, and recording the action for accountability. These concerns correspond\nto common security control areas, such as access control, session management,\nand logging. This complexity requires substantial guidance. Manually iden-\ntifying and validating this network of implicit security dependencies across\nthousands of requirements is error prone, inconsistent, and not scalable (Ye\net al., 2025).\nGiven the limitations of manual SRA, automation through Artificial In-\ntelligence (AI) based Natural Language Processing (NLP) methods, offers a\npromising path forward. Although AI based approaches for RE have received\ngrowing attention (Abbasi et al., 2025; Zadenoori et al., 2025), recent evidence\nshows a gap between experimental advances and validated industrial solutions.\nFor example, an analysis of 74 primary studies found that most AI based tools\nare evaluated in controlled settings, with limited industrial adoption and weak\nintegration into real workflows (Bolanos et al., 2024). Similarly, another study\nreports a clear mismatch between expectations and practical outcomes in SRE\nin real world use (Karhu et al., 2025).\nThe main problem is the lack of suitable data, not the availability of ef-\nfective modeling approaches. The development and validation of data driven\napproaches is constrained by the scarcity and limited quality of domain spe-\ncific datasets (Wang et al., 2024; Zadenoori et al., 2025). This concern ex-\ntends beyond SRE, as leading NLP venues highlight dataset limitations that\nmake reliable evaluation difficult (Muresan et al., 2022; Goldberg et al., 2022;\nChristodoulopoulos et al., 2025).\nThis challenge is especially evident in SRE. Identifying implicit security\nrequirements relies on large collections of functional requirements annotated\nby security experts to reflect underlying security concerns. Current datasets do\nnot meet this need. For instance, PROMISE exp (Lima et al., 2019) includes\nonly a single, high-level security category; DOSSPRE (Kadebu et al., 2023)\nis based on student projects and lacks industry realism; and the Healthcare\ndataset (Riaz et al., 2014) is limited to a narrow domain and uses coarse-\ngrained labels. As a result, existing resources offer limited support for devel-\noping and evaluating methods aimed at uncovering implicit security require-\nments.\nThe OWASP Application Security Verification Standard (ASVS)1 offers a\nstandardized, systematic, and verifiable framework for defining and evaluating\napplication security controls. ASVS emphasizes the principle of “security by\ndesign” by facilitating the integration of security considerations early in the\nsoftware development lifecycle. Its comprehensive set of requirements can be\ndirectly mapped to verifiable test cases and secure coding practices, ensuring\ntraceability throughout the development process. This approach enables the\nearly identification and remediation of vulnerabilities, which is both more effi-\n1 https://owasp.org/www-project-application-security-verification-standard/', ""CONTEXT: This chunk provides examples of system requirements from a Software Requirements Specification (SRS) document and their classification into OWASP ASVS security categories (V2–V13), along with corresponding security analyses and recommendations, demonstrating the application of the ASRD dataset and classification models discussed in the document.\n\nCONTENT: sonlandıracaktır.|0|1|0|0|0|1|0|0|0|0|0| Session Management (V3), Debugging and Logging (V7):  Session \ntimeouts enhance security and should be logged. \nAnalysis & Recommendations:  Enforce session timeouts to prevent unauthorized access from unattended \nsessions.  Log session termination events for security monitoring. \n \n27|Sistem, çerez kullanımında gerekli tüm güvenlik ayarlarının uygulanmasını zorunlu \nkılacaktır.|0|1|0|0|0|1|1|0|0|0|0| Session Management (V3), Debugging and Logging (V7), Data Protection \n(V8): Secure cookie handling is crucial for protecting user sessions. \nAnalysis & Recommendations:  Use secure cookies with the HttpOnly flag.  Encrypt sensitive data stored in \ncookies.  Implement proper cookie expiration policies. \n \n28|Sistem, kullanıcıların en az yetki prensibine göre işlem yapabilmesini sağlayacaktır.|1|1|1|0|0|1|0|0|0|0|0| \nIdentity Verification (V2), Session Management (V3), Access Controls (V4), Debugging and Logging (V7):  \nEnforcing least privilege requires proper authentication, authorization, and logging. \nAnalysis & Recommendations:  Implement role-based access control (RBAC) to manage user permissions \neffectively.  Regularly review and update user permissions. \n \n29|Sistem, kullanıcı hareketlerinin kaydını tutacaktır.|1|1|1|0|0|1|0|0|0|0|0| Identity Verification (V2), \nSession Management (V3), Access Controls (V4), Debugging and Logging (V7): User activity logging is \ncrucial for security auditing and incident response. \nAnalysis & Recommendations:  Log user actions with sufficient detail for security analysis.  Protect log files \nfrom unauthorized access and modification. \n \n30|Sistemde kullanılan eklentilerin güvenlik doğrulaması yapılacaktır.|0|0|0|0|0|1|1|0|1|0|1| Debugging and \nLogging (V7), Data Protection (V8), Malicious Code (V10), Files and Resources (V12), API and Web \nServices (V13): Plugin security is crucial to prevent vulnerabilities. \nAnalysis & Recommendations:  Validate plugins before installation and use.  Regularly update plugins to \npatch security vulnerabilities.  Restrict plugin permissions to limit potential damage. \n********* \nOutput (PSV- The requirements that are classified): \nWe need each requirement response in given format below within new line separator: \n<Requirement Number>|<Requirement \nDescription>|<V2>|<V3>|<V4>|<V5>|<V6>|<V7>|<V8>|<V9>|<V10>|<V12>|<V13>|<Explanation> format. \nand will contain: \n   - Requirement Number (integer) \n   - Requirement Description (string) \n   - <V2> through <V13>: (either 1 (if the requirement aligns with the category) or 0 (if it doesn't)) \n   - Explanation (string) \n***** \nInput (PSV - The requirements you want to classify): \n1|Sistem, kullanıcının konaklama ücret tipi bilgilerini girmesini sağlayacaktır \n3|Sistem, kullanıcının konaklama ücret tipi bilgilerini silmesini sağlayacaktır \n5|Sistem, kullanıcının oda tiplerini güncellemesini sağlayacaktır \n16|Sistem, kullanıcının otele giriş nedeni bilgisini girmesini sağlayacaktır \n22|Sistem, kullanıcının çalışma tip bilgisini girmesini sağlayacaktır \n28|Sistem, kullanıcının otel rezervasyon para yatırma süre bilgisini girmesini sağlayacaktır \n31|Sistem, kullanıcının misafir türü kaydetmesini sağlayacaktır. \n37|Sistem, kullanıcının oda tiplerini listelemesini sağlayacaktır. \n41|Sistem, kullanıcının otele giriş neden bilgilerini listelemesini sağlayacaktır.\n\n44|Sistem, kullanıcının arananlar bilgisini listelemesini sağlayacaktır. \n52|Sistem, kullanıcının yakınlık tanım bilgisini seçilen kriterlere göre sorgulayabilmesini sağlayacaktır. \n54|Sistem, kullanıcının arananlar bilgisini seçilen kriterlere göre sorgulayabilmesini sağlayacaktır. \n55|Sistem, kullanıcının otel rezervasyon iptal süre bilgisini seçilen kriterlere göre sorgulayabilmesini \nsağlayacaktır. \n65|Sistem, kullanıcının otelin katlarındaki oda doluluk oranlarını seçilen kriterlere göre sorgulayabilmesini \nsağlayacaktır. \n70|Sistem, kullanıcının otel raporlarında kullanıcı imza bilgisi girmesini sağlayacaktır."", 'CONTEXT: **Advancements in LLM-Assisted Security and Related Frameworks**: This chunk discusses the application of transformer-based models and LLMs in security requirements engineering (SRE), highlighting their capabilities, challenges, and the importance of high-quality datasets and evaluation frameworks. It also reviews the role of security frameworks in systematically identifying and classifying security requirements in automated settings.\n\nCONTENT: 6 Yusuf G¨ ur et al.\nBeyond requirements classification, security research has also turned to\ntask-specific models for narrowly defined problems. For instance, deep learning\napproaches such as BiLSTMs have been used to detect re-entrancy vulnerabil-\nities in smart contracts, where generic models are insufficient (Maturi et al.,\n2025). This work highlights the importance of explainability, as security de-\ncisions must be understandable to support assurance and auditing. Although\nthis line of research addresses a different problem, it reflects a shift toward\ndomain-aware and interpretable models.\nTransformer-based models have enabled new capabilities in automated text\nunderstanding(Zhou et al., 2025). They possess emergent abilities like in-\ncontext learning, instruction following, and step-by-step reasoning (Zhu et al.,\n2025), which allow them to perform complex tasks, including requirements\nclassification, with minimal or no labeled data (Liu et al., 2023b; Zhu et al.,\n2025). Recent trends show a growing interest in applying LLMs to RE tasks,\nincluding requirements classification, prioritization, and traceability (Rajbhoj\net al., 2024; White et al., 2024). LLMs can perform zero-shot and few-shot\nlearning, reducing the need for large annotated datasets and facilitating adap-\ntation to specialized domains like SRE (Labrak et al., 2023). Techniques such\nas prompt engineering and integration with external knowledge bases (e.g.,\nRetrieval-Augmented Generation) further improve their performance and con-\ntextual relevance (Masoudifard et al., 2024).\nLLM-assisted security solutions typically follow a three-step process: pre-\nprocessing (extracting context like documentation or target units), prompt\ngeneration (using instructions and unfilled slots for the model to complete\nwith artifacts like fuzz drivers or patches), and post-processing (validating\noutputs, e.g., checking if generated code successfully compiles) (Zhu et al.,\n2025).\nWhile these models provide powerful automation, they can also introduce\nnew risks and errors if applied without careful oversight. This underscores the\nneed for realistic, high-quality datasets and standardized evaluation frame-\nworks to reliably assess automated security requirement classification, ensuring\nboth effectiveness and safety in practice.\nThe use of automated models in security highlights both their potential and\nthe risks they can introduce. Ensuring accurate and reliable classification of\nsecurity requirements requires evaluation against high-quality, domain-specific\nbenchmarks (Jeong, 2024). This underscores the need for realistic datasets and\nstandardized evaluation frameworks tailored to SRE.\n2.2 Related Work on Security Frameworks\nAn appropriate security framework is necessary to ensure systematic and con-\nsistent identification and classification of security requirements, particularly in\nautomated settings. This section reviews widely adopted security frameworks\nand evaluates their suitability for requirement analysis.', 'CONTEXT: **Comparison of Fine-Tuned Models and LLMs for Security Requirements Classification**: This chunk discusses the performance comparison between fine-tuned transformer models (e.g., BERT) and few-shot prompting with LLMs (e.g., Gemini 2.0) for classifying implicit security requirements in SRS documents, emphasizing the practicality of LLMs as a resource-efficient alternative while highlighting challenges in Security Requirements Engineering (SRE).\n\nCONTENT: 2 Yusuf G¨ ur et al.\ntional fine-tuned transformer models and contemporary Large Language Mod-\nels (LLMs) employing few-shot and zero-shot prompt engineering strategies.\nThe results show that a few-shot prompting with Gemini 2.0 achieves a macro-\naverage F1 score of 0.941, directly comparable to the fine-tuned BERT model’s\n0.942. This study culminates in two primary findings: first, the validation and\npublication of the ASRD, a high-granularity, multi-label dataset for implicit\nsecurity requirements based on OWASP ASVS V2-V13; and second, the di-\nrect comparison demonstrating that few-shot Large Language Models (LLMs)\nachieve competitive multi-label classification performance (Macro-F1 0.941)\nnearly equal to resource-intensive fine-tuned transformer models (Macro-F1\n0.942). This confirms that LLMs represent a highly practical and resource-\nsaving strategy for automating the identification of embedded (implicit) secu-\nrity requirements for software security in industrial SRS documents\nKeywordsCybersecurity requirement elicitation·OWASP based security\nrequirement classification·OWASP ASVS-based Requirement Labeling·\nLLM based classification\n1 Introduction\nRequirements Engineering (RE) concerns the identification, documentation,\nand management of software requirements (Sommerville and Sawyer, 1997).\nThe increasing interconnectivity of information systems forces organizations\nto provide secure services in cyberspace. Integrating security during initial\nrequirements analysis is essential to proactively mitigate risks, reduce vulner-\nabilities, and reduce the high costs associated with downstream remediation\n(Villamizar et al., 2018). This proactive approach is central to the ”Shift-\nLeft” security paradigm, which advocates for the identification and mitigation\nof vulnerabilities as early as possible in the Software Development Life Cycle\n(SDLC).\nAlthough Security Requirements Engineering (SRE) has matured as a dis-\ncipline, its effective application in practice remains challenging. The issue is\nnot the absence of security considerations, but the difficulty of ensuring that\nsecurity requirements are properly validated and verified. An empirical investi-\ngation that combines a systematic literature review with a survey of 58 indus-\ntry professionals highlights this gap (Alam et al., 2025). While practitioners\nreported a moderate understanding of SRE practices, Security Requirements\nAssurance (SRA) was found to be poorly understood and rarely applied in\nindustrial contexts. The study concludes that validating and ensuring security\nrequirements remains a major and unresolved challenge in practice.\nThis assurance gap persists due to the documented lack of specialized se-\ncurity training for developers in early-phase RE (Andrade et al., 2023). The\ntask relies heavily on scarce specialized expertise and time-intensive manual\nanalysis. The main challenge is that critical security requirements are often not\nexplicitly stated. Instead, they are implicitly embedded within standard func-\ntional descriptions. For example, a seemingly simple functional requirement,', 'CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the', ""CONTEXT: **Comparative Analysis of Security Requirement Datasets**: This chunk provides a detailed comparison of the ASRD dataset with other prominent security requirement datasets, highlighting differences in size, domain coverage, annotation methodologies, and granularity, while emphasizing ASRD's strengths in industrial complexity, multi-domain applicability, and alignment with OWASP ASVS standards.\n\nCONTENT: 8 Yusuf G¨ ur et al.\nTable 1: Comparative Analysis of Security Requirement Datasets\nCharacteristic PROMISE\nexp\nDOSSPRE Healthcare\nDataset\nASRD (Ours)\nTotal Require-\nments\n969 1,317 10,963 2,652\nData Source Public SRS\ndocuments\n(expanded to\n49 projects)\n105 Student\nproject docu-\nments\n6 Official Cana-\ndian and U.S.\nSRS documents\n6 Real-world\nSRS docs from\na gov’t agency\nDomain General /\nCross-domain\nGeneral / Aca-\ndemic\nElectronic\nHealthcare\nMulti-domain:\nLegal, Const.,\nEdu., etc.\nPrimary Task FR vs. NFR,\nMulti-class\nNFR\nSR vs. NSR,\nMulti-class SR\nMulti-label\nSecurity Objec-\ntives\nMulti-label Im-\nplicit Security\nClass.\nSecurity Granu-\nlarity\nSingle SE\nclass\n10 security\nclasses\n6 security objec-\ntives\n11 OWASP\nASVS classes\nLanguage English English English Turkish\nAnnotation\nMethodology\nExpert Con-\nsensus: Man-\nual extraction\nand valida-\ntion\nAuthor Com-\npilation: Cat-\negorized by\nauthors only,\nlimited rigorous\nvalidation\nMulti-Stage\nConsensus: 2\nresearchers +\nmediator, high\nagreement\nMATTER Cy-\ncle: 3 SMEs\nwith adjudica-\ntion, iterative\nrefinement and\nabjudication\nKey Strength Established\nbenchmark\nand project\ndiversity\nFine-grained\nsecurity-specific\ntaxonomy\nLarge scale and\ndomain authen-\nticity\nIndustrial\ncomplexity +\nOWASP ASVS\nKey Limitation Small size\nand class\nimbalance\nPotential lack of\nprofessional re-\nalism\nDomain-\nspecific; coarse-\ngrained labels\nReal-world class\nimbalance in\nspecific cate-\ngories\nimbalance often restrict its suitability for training complex deep learning ar-\nchitectures.\n2.3.2 DOSSPRE\nThe Dataset of Students’ Software Projects Requirements (DOSSPRE) was\ncompiled by Kadebu et al. from documentation within academic curricula\n(Kadebu et al., 2023), likely from the Harare Institute of Technology. It pro-\nvides a fine-grained classification through a detailed taxonomy for both se-\ncurity and non-security requirements. However, as the requirements were au-\nthored by students, they may not fully reflect the realism and complexity of\nindustry-grade requirements.""]","The preprocessing steps applied to the raw SRS documents included the following:

1. **Sentence Segmentation and Extraction**: A rule-based extraction method was used to identify requirement blocks based on hierarchical numbering schemes and line breaks. Each identified requirement was extracted and treated as a single processing unit, preserving the structural integrity of the original specification.

2. **Anonymization**: A semi-automated anonymization process was implemented to protect sensitive data. Custom scripts replaced entities such as project names, specific URLs, and IP addresses with generic placeholders. This was followed by a manual review by domain experts to ensure that the removal of personally identifiable information (PII) did not compromise the semantic meaning or contextual integrity of the requirements.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","The steps included Sentence Segmentation and Extraction (using rule-based pattern matching), Anonymization (removing PII and entities), Filtering (removing administrative/ambiguous items), and Randomization[cite: 174, 175, 178, 183, 186].",,,
What are the six business domains covered in the ASRD?,"['CONTEXT: **ASRD Dataset Filtering and Composition**: This chunk details the rigorous filtering, randomization, and composition process used to create the ASRD dataset, highlighting its focus on functional requirements across six business domains and its alignment with OWASP ASVS security classes for security requirements classification.\n\nCONTENT: 10 Yusuf G¨ ur et al.\n3. Filtering: The initial extraction yielded 3,264 items. To ensure the qual-\nity of the dataset, domain experts conducted a rigorous manual filtering\npass to remove 612 items. This exclusion process went beyond simple for-\nmatting artifacts (such as headers or tables of contents). We specifically\nremoved non-functional administrative clauses that addressed the vendor\nrather than the system (e.g., “The contractor must provide training man-\nuals”), project management constraints (e.g., “The project must be deliv-\nered by Q3”), and requirements with ambiguous scope that lacked clear\nverification criteria.\n4. Randomization: The remaining requirements were randomized and masked\nto mitigate potential annotation bias related to the document source or the\nsequence of requirements.\nThe resulting ASRD comprises 2,652 well-formed functional requirements\nacross six distinct business areas: Construction (1,202), Legal (177), Education\n(312), Software (199), Meeting (126), and Accommodation (636). A sample of\nthese requirements is provided in Table 2. The requirements included in this\nsample were selected based on three specific criteria to ensure a representative\noverview:\n–Samples were chosen to reflect the varied terminology and phrasing styles\nused across the six different business domains.\n–We prioritized requirements that demonstrate how standard functional de-\nscriptions conceal underlying security dependencies.\n–We ensured that the sample includes representative examples for all 11\nOWASP ASVS security classes used in the study to demonstrate the full\nscope of the classification task.\nIt is important to note that the ASRD is a Turkish-language corpus; all experi-\nments detailed in this study, including BERT fine-tuning and LLM prompting,\nwere conducted exclusively on the original text. English translations are pro-\nvided only for readability.\nTable 2: Sample Requirements from ASRD\nNo Original Requirements Translated Requirements\n1 Sistem, yetkili kullanıcının hukuk\ndosyası t¨ ur¨ u kayıt etmesini\nsa˘ glayacaktır.\nThe system shall allow authorized\nusers to record the legal file type.\n2 Sistem, kullanıcının kullanılmamı¸ s\nhukuk dosyası t¨ ur¨ un¨ u g¨ uncellemesini\nsa˘ glayacaktır.\nThe system shall allow the user to up-\ndate an unused legal file type.\n3 Sistem, kullanıcının kullanılmamı¸ s\nolan hukuk dosyası t¨ ur¨ un¨ u silmesini\nsa˘ glayacaktır.\nThe system shall allow the user to\ndelete an unused legal file type.\n4 Sistem, kullanıcının hukuk dosyası\nt¨ urlerini sorgulamasını ve listelemesini\nsa˘ glayacaktır.\nThe system shall allow the user to\nquery and list legal file types.', 'CONTEXT: This chunk discusses the curation and preprocessing of the ASRD dataset, detailing the data collection process from real-world Software Requirements Specification (SRS) documents, the multi-stage preprocessing pipeline for sentence extraction and anonymization, and how the dataset addresses gaps in prior work by incorporating industrial complexity and linguistic diversity.\n\nCONTENT: Implicit Security Requirements Classification 9\n2.3.3 Electronic Health Domain Dataset\nThis corpus focuses on the electronic healthcare industry, a sector defined\nby stringent regulatory and high-assurance demands (Riaz et al., 2014). The\ndataset’s strength lies in its rigorous multi-stage annotation methodology,\nwhich utilized independent researchers and a mediator to ensure high inter-\nannotator agreement. While it provides a large-scale, authentic resource for\nhealthcare-specific tasks, its narrow focus may limit the generalizability of\nmodels to other industries, and its high-level security objectives may be too\ncoarse for detailed technical analysis.\n2.3.4 Summary of Datasets\nAs summarized in Table 1, these datasets vary significantly in their suitability\nfor tasks ranging from general non-functional requirement (NFR) classifica-\ntion to detailed security analysis. Our proposed Agency Security Require-\nments Dataset (ASRD) addresses gaps in prior work by adopting the OWASP\nASVS taxonomy for multi-label annotation. Furthermore, by utilizing real-\nworld projects originally written in Turkish, ASRD introduces both industrial\ncomplexity and linguistic diversity to the field.\n3 Dataset Curation, Annotation, and Evaluation\n3.1 Data Collection and Preprocessing\nThe dataset compilation began with the collection of six Software Require-\nments Specification (SRS) documents from an Agency’s Security Department.\nThese documents were selected from an initial pool of 19 projects executed\nbetween 2019 and 2023, specifically chosen for their domain diversity and\namenability to effective anonymization. The original documents were provided\nin standard document formats (e.g., PDF, DOCX) where requirements were\norganized in itemized lists. To transform these documents into a machine-\nreadable dataset, we employed a multi-stage preprocessing pipeline:\n1. Sentence Segmentation and Extraction: As the source SRS documents uti-\nlized standard itemization for requirements, we employed a rule-based ex-\ntraction method. We utilized pattern matching to identify requirement\nblocks based on hierarchical numbering schemes and line breaks. Each iden-\ntified requirement was extracted and treated as a single processing unit,\npreserving the structural integrity of the original specification.\n2. Anonymization: To protect sensitive data, a semi-automated anonymiza-\ntion process was implemented. Custom scripts replaced entities such as\nproject names, specific URLs, and IP addresses with generic placeholders.\nThis was followed by a manual review by domain experts to ensure that\nthe removal of personally identifiable information (PII) did not compromise\nthe semantic meaning or contextual integrity of the requirements.', 'CONTEXT: This chunk details the **annotation methodology** and **dataset curation process** for the ASRD, following the MATTER cycle framework. It describes annotator selection, corpus preparation, and the iterative development of annotation guidelines aligned with OWASP ASVS categories to ensure high-quality, domain-specific annotations.\n\nCONTENT: Implicit Security Requirements Classification 15\n3.3 Annotation Methodology (MATTER Cycle) & Dataset Curation\nThe annotation process followed the MATTER development cycle, an estab-\nlished iterative framework for corpus annotation (Pustejovsky and Stubbs,\n2012). Crucially, the annotation task was defined as a multi-label text classifi-\ncation problem. It consists of the phases Model, Annotate, Train, Test, Eval-\nuate, and Revise. The annotation guidelines were developed and iteratively\nrefined to ensure consistency and clarity.\nThe Model–Annotate cycle involved writing guidelines, selecting annota-\ntors, conducting trial annotations, and refining the process. Once stabilized,\nthis cycle was expanded to the full dataset to generate a Gold Standard corpus.\nThe annotation workflow included the following processes:\n–Annotator Selection: Following Bayerl and Paul’s recommendation to use\ndomain-aligned annotators (Bayerl and Paul, 2011), three cybersecurity\nsubject matter experts (SME) from the agency, each with over 15 years\nof experience in designing security architectures, analyzing threat models,\nand identifying security requirements, performed the annotations. Their\ndeep practical experience ensured accurate and context-aware interpreta-\ntion which aligned with the requirement “experts must demonstrate signif-\nicant skills, knowledge, and experience” emphasized by Hopkins (Hopkins\nand Unger, 2017). The senior manager among them also provided over-\nsight and led the adjudication process. The senior SME acted as both an\nannotator and the final adjudicator for resolving disagreements. They also\nprovided feedback to improve the quality and clarity of the annotation\nguideline.\n–Corpus Selection and Preparation: Cohen (Cohen et al., 2005) recommends\nthat during corpus design, balance and representativeness of the corpus\nis important. In line with his recommendation, of the 19 initial project\ndocuments, six were chosen for their domain diversity and potential for\neffective anonymization by the SMEs. These documents underwent a semi-\nautomated anonymization process to remove all project-specific and per-\nsonally identifiable information (PII). The process targeted entities such\nas names of individuals and organizations, project codenames, and specific\ntechnical identifiers. This was done using custom scripts with placeholder\nreplacement, followed by manual review to ensure that anonymization did\nnot alter the meaning, structure, or intent of the original requirements. The\nextracted requirements were then randomized and masked to prevent po-\ntential bias related to document origin or sequence during the annotation\nphase. Total corpus has 2,652 requirements (30 pilot + 2,622 independent\nannotations).\n–Annotation Guideline Development: The Annotation Guidelines’ develop-\nment involved an initial iterative process, refining the guidelines three times\nto resolve ambiguities before the formal assessment phase. Annotation rules\nwere based on OWASP ASVS categories V2–V13 and refined iteratively\nusing example annotations. Following best practices suggested by Cohen\n(Cohen et al., 2005), the guidelines and annotation documents ensured:', 'CONTEXT: This chunk provides detailed definitions of OWASP ASVS security requirement classes (V5–V14), which are critical for categorizing and addressing specific security concerns in software applications, as discussed in the broader context of automating security requirements classification using AI and the ASRD dataset.\n\nCONTENT: 14 Yusuf G¨ ur et al.\nTable 3 – continued from previous page\nClass Id Class Name Definition\nV5 Malicious Input Handling This class focuses on requirements\nfor validating and sanitizing all input\ndata to prevent injection attacks, such\nas SQL injection, Cross-Site Scripting\n(XSS), and others.\nV6 Stored Cryptography This class addresses the secure stor-\nage of cryptographic keys and sensi-\ntive data at rest, ensuring they are pro-\ntected from unauthorized disclosure or\nmodification.\nV7 Error Handling and Logging This class ensures that applications\nhandle errors gracefully without leak-\ning sensitive information and that\nsecurity-relevant events are logged for\nmonitoring and analysis.\nV8 Data Protection This class covers the requirements for\nprotecting sensitive data during tran-\nsit and in storage, focusing on confi-\ndentiality, integrity, and classification.\nV9 Communications Security This class focuses on securing commu-\nnication channels between system com-\nponents, such as between the client and\nserver, to prevent eavesdropping, tam-\npering, or spoofing.\nV10 Malicious Code This class deals with ensuring the ap-\nplication code is free from malicious\ncode, backdoors, or other unintended\nsecurity vulnerabilities introduced in-\ntentionally or unintentionally.\nV11 Business Logic This class addresses security con-\ncerns within the application’s business\nlogic, preventing attackers from abus-\ning workflows or functionalities for un-\nintended purposes.\nV12 File and Resources This class covers the secure handling of\nfiles and other resources, including up-\nload, download, and management, to\nprevent path traversal and other re-\nlated attacks.\nV13 API and Web Service This class provides security require-\nments specifically for APIs and web\nservices, covering aspects like authen-\ntication, authorization, and protection\nagainst common API attacks.\nV14 Configuration This class focuses on securing the con-\nfiguration of all application compo-\nnents, including the application server,\nplatform, and third-party libraries, to\nprevent security misconfigurations.', ""CONTEXT: **Comparative Analysis of Security Requirement Datasets**: This chunk provides a detailed comparison of the ASRD dataset with other prominent security requirement datasets, highlighting differences in size, domain coverage, annotation methodologies, and granularity, while emphasizing ASRD's strengths in industrial complexity, multi-domain applicability, and alignment with OWASP ASVS standards.\n\nCONTENT: 8 Yusuf G¨ ur et al.\nTable 1: Comparative Analysis of Security Requirement Datasets\nCharacteristic PROMISE\nexp\nDOSSPRE Healthcare\nDataset\nASRD (Ours)\nTotal Require-\nments\n969 1,317 10,963 2,652\nData Source Public SRS\ndocuments\n(expanded to\n49 projects)\n105 Student\nproject docu-\nments\n6 Official Cana-\ndian and U.S.\nSRS documents\n6 Real-world\nSRS docs from\na gov’t agency\nDomain General /\nCross-domain\nGeneral / Aca-\ndemic\nElectronic\nHealthcare\nMulti-domain:\nLegal, Const.,\nEdu., etc.\nPrimary Task FR vs. NFR,\nMulti-class\nNFR\nSR vs. NSR,\nMulti-class SR\nMulti-label\nSecurity Objec-\ntives\nMulti-label Im-\nplicit Security\nClass.\nSecurity Granu-\nlarity\nSingle SE\nclass\n10 security\nclasses\n6 security objec-\ntives\n11 OWASP\nASVS classes\nLanguage English English English Turkish\nAnnotation\nMethodology\nExpert Con-\nsensus: Man-\nual extraction\nand valida-\ntion\nAuthor Com-\npilation: Cat-\negorized by\nauthors only,\nlimited rigorous\nvalidation\nMulti-Stage\nConsensus: 2\nresearchers +\nmediator, high\nagreement\nMATTER Cy-\ncle: 3 SMEs\nwith adjudica-\ntion, iterative\nrefinement and\nabjudication\nKey Strength Established\nbenchmark\nand project\ndiversity\nFine-grained\nsecurity-specific\ntaxonomy\nLarge scale and\ndomain authen-\nticity\nIndustrial\ncomplexity +\nOWASP ASVS\nKey Limitation Small size\nand class\nimbalance\nPotential lack of\nprofessional re-\nalism\nDomain-\nspecific; coarse-\ngrained labels\nReal-world class\nimbalance in\nspecific cate-\ngories\nimbalance often restrict its suitability for training complex deep learning ar-\nchitectures.\n2.3.2 DOSSPRE\nThe Dataset of Students’ Software Projects Requirements (DOSSPRE) was\ncompiled by Kadebu et al. from documentation within academic curricula\n(Kadebu et al., 2023), likely from the Harare Institute of Technology. It pro-\nvides a fine-grained classification through a detailed taxonomy for both se-\ncurity and non-security requirements. However, as the requirements were au-\nthored by students, they may not fully reflect the realism and complexity of\nindustry-grade requirements."", 'CONTEXT: This chunk focuses on the introduction of the **Agency Security Requirements Dataset (ASRD)**, detailing its real-world data sources, expert annotation process, and alignment with OWASP ASVS categories, as well as outlining the research questions and comparative evaluation of fine-tuned transformer models versus prompt-based approaches for security requirements classification.\n\nCONTENT: 4 Yusuf G¨ ur et al.\ncient and cost-effective compared to addressing security issues at later stages\nof development ((Khan et al., 2024).\nThis paper proposes a machine learning-based system to automatically an-\nalyze SRS documents and classify security requirements according to OWASP\nASVS. Its main contribution is the Agency Security Requirements Dataset\n(ASRD), a publicly available corpus created to support research in automated\nSRA. The ASRD comprises:\n–Real-World Data: 2,652 Software Requirements Specification (SRS) sen-\ntences extracted from six diverse, real-world industry projects,\n–Expert Annotation: Meticulously annotated by three cybersecurity experts,\neach with over 15 years of industry experience,\n–Rigorous Methodology: Developed using the iterative MATTER cycle an-\nnotation framework (Pustejovsky and Stubbs, 2012),\n–High Granularity and Multi-label Structure: Mapped to 11 distinct, action-\nable security categories from the industry-standard OWASP Application\nSecurity Verification Standard (ASVS,V2–V13), allowing each require-\nment to be associated with multiple categories.\nThe ASRD is intended as a shared research resource and benchmark. Using\nthis dataset, the study conducts an empirical analysis of automated classifica-\ntion approaches and addresses the following research questions:\n1. To what extent can fine-tuned transformer models accurately perform\nmulti-label classification of implicit security requirements into OWASP\nASVS categories using the ASRD?\n2. How does the performance of prompt-based approaches (zero-shot and few-\nshot) using modern LLMs compare to fine-tuned BERT-based models and\nnaive baselines for this task?\nThe results show that few-shot prompting with a modern language model\n(Gemini 2.0) achieves a macro-average F1 score of 0.941, closely matching the\nbest fine-tuned BERT-based model (0.942). This demonstrates that example-\nguided inference can reach performance comparable to supervised fine-tuning\nwhile requiring substantially less annotated data and model retraining. The\nevaluation compares fine-tuned transformer models (e.g., SecureBERT) with\nprompt-based methods in zero-shot and few-shot settings across multiple con-\ntemporary models, demonstrating that prompt-based approaches provide a\npractical and resource-efficient alternative for identifying implicit security re-\nquirements in industrial SRS documents.\nThe remainder of this paper is organized as follows. Section 2 reviews re-\nlated work on NLP-based requirements classification, security frameworks, and\nexisting security datasets. Section 3 describes the curation and expert anno-\ntation of the ASRD and summarizes its key characteristics. Section 4 outlines\nthe experimental setup and classification methods, including fine-tuned BERT\nmodels and prompt-based approaches. Section 5 reports the experimental re-\nsults. Section 6 discusses the findings and their implications, with a com-\nparative analysis of fine-tuning and prompting strategies. Section 7 examines', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb']","The six business domains covered in the ASRD are:

1. **Construction** (1,202 requirements)
2. **Legal** (177 requirements)
3. **Education** (312 requirements)
4. **Software** (199 requirements)
5. **Meeting** (126 requirements)
6. **Accommodation** (636 requirements)

These domains represent the diverse real-world industry projects from which the ASRD dataset was curated. (Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","The domains are Construction, Legal, Education, Software, Meeting, and Accommodation[cite: 187].",,,
In what language is the ASRD corpus written?,"['CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr', 'CONTEXT: This chunk discusses the curation and preprocessing of the ASRD dataset, detailing the data collection process from real-world Software Requirements Specification (SRS) documents, the multi-stage preprocessing pipeline for sentence extraction and anonymization, and how the dataset addresses gaps in prior work by incorporating industrial complexity and linguistic diversity.\n\nCONTENT: Implicit Security Requirements Classification 9\n2.3.3 Electronic Health Domain Dataset\nThis corpus focuses on the electronic healthcare industry, a sector defined\nby stringent regulatory and high-assurance demands (Riaz et al., 2014). The\ndataset’s strength lies in its rigorous multi-stage annotation methodology,\nwhich utilized independent researchers and a mediator to ensure high inter-\nannotator agreement. While it provides a large-scale, authentic resource for\nhealthcare-specific tasks, its narrow focus may limit the generalizability of\nmodels to other industries, and its high-level security objectives may be too\ncoarse for detailed technical analysis.\n2.3.4 Summary of Datasets\nAs summarized in Table 1, these datasets vary significantly in their suitability\nfor tasks ranging from general non-functional requirement (NFR) classifica-\ntion to detailed security analysis. Our proposed Agency Security Require-\nments Dataset (ASRD) addresses gaps in prior work by adopting the OWASP\nASVS taxonomy for multi-label annotation. Furthermore, by utilizing real-\nworld projects originally written in Turkish, ASRD introduces both industrial\ncomplexity and linguistic diversity to the field.\n3 Dataset Curation, Annotation, and Evaluation\n3.1 Data Collection and Preprocessing\nThe dataset compilation began with the collection of six Software Require-\nments Specification (SRS) documents from an Agency’s Security Department.\nThese documents were selected from an initial pool of 19 projects executed\nbetween 2019 and 2023, specifically chosen for their domain diversity and\namenability to effective anonymization. The original documents were provided\nin standard document formats (e.g., PDF, DOCX) where requirements were\norganized in itemized lists. To transform these documents into a machine-\nreadable dataset, we employed a multi-stage preprocessing pipeline:\n1. Sentence Segmentation and Extraction: As the source SRS documents uti-\nlized standard itemization for requirements, we employed a rule-based ex-\ntraction method. We utilized pattern matching to identify requirement\nblocks based on hierarchical numbering schemes and line breaks. Each iden-\ntified requirement was extracted and treated as a single processing unit,\npreserving the structural integrity of the original specification.\n2. Anonymization: To protect sensitive data, a semi-automated anonymiza-\ntion process was implemented. Custom scripts replaced entities such as\nproject names, specific URLs, and IP addresses with generic placeholders.\nThis was followed by a manual review by domain experts to ensure that\nthe removal of personally identifiable information (PII) did not compromise\nthe semantic meaning or contextual integrity of the requirements.', 'CONTEXT: This chunk details the **annotation methodology** and **dataset curation process** for the ASRD, following the MATTER cycle framework. It describes annotator selection, corpus preparation, and the iterative development of annotation guidelines aligned with OWASP ASVS categories to ensure high-quality, domain-specific annotations.\n\nCONTENT: Implicit Security Requirements Classification 15\n3.3 Annotation Methodology (MATTER Cycle) & Dataset Curation\nThe annotation process followed the MATTER development cycle, an estab-\nlished iterative framework for corpus annotation (Pustejovsky and Stubbs,\n2012). Crucially, the annotation task was defined as a multi-label text classifi-\ncation problem. It consists of the phases Model, Annotate, Train, Test, Eval-\nuate, and Revise. The annotation guidelines were developed and iteratively\nrefined to ensure consistency and clarity.\nThe Model–Annotate cycle involved writing guidelines, selecting annota-\ntors, conducting trial annotations, and refining the process. Once stabilized,\nthis cycle was expanded to the full dataset to generate a Gold Standard corpus.\nThe annotation workflow included the following processes:\n–Annotator Selection: Following Bayerl and Paul’s recommendation to use\ndomain-aligned annotators (Bayerl and Paul, 2011), three cybersecurity\nsubject matter experts (SME) from the agency, each with over 15 years\nof experience in designing security architectures, analyzing threat models,\nand identifying security requirements, performed the annotations. Their\ndeep practical experience ensured accurate and context-aware interpreta-\ntion which aligned with the requirement “experts must demonstrate signif-\nicant skills, knowledge, and experience” emphasized by Hopkins (Hopkins\nand Unger, 2017). The senior manager among them also provided over-\nsight and led the adjudication process. The senior SME acted as both an\nannotator and the final adjudicator for resolving disagreements. They also\nprovided feedback to improve the quality and clarity of the annotation\nguideline.\n–Corpus Selection and Preparation: Cohen (Cohen et al., 2005) recommends\nthat during corpus design, balance and representativeness of the corpus\nis important. In line with his recommendation, of the 19 initial project\ndocuments, six were chosen for their domain diversity and potential for\neffective anonymization by the SMEs. These documents underwent a semi-\nautomated anonymization process to remove all project-specific and per-\nsonally identifiable information (PII). The process targeted entities such\nas names of individuals and organizations, project codenames, and specific\ntechnical identifiers. This was done using custom scripts with placeholder\nreplacement, followed by manual review to ensure that anonymization did\nnot alter the meaning, structure, or intent of the original requirements. The\nextracted requirements were then randomized and masked to prevent po-\ntential bias related to document origin or sequence during the annotation\nphase. Total corpus has 2,652 requirements (30 pilot + 2,622 independent\nannotations).\n–Annotation Guideline Development: The Annotation Guidelines’ develop-\nment involved an initial iterative process, refining the guidelines three times\nto resolve ambiguities before the formal assessment phase. Annotation rules\nwere based on OWASP ASVS categories V2–V13 and refined iteratively\nusing example annotations. Following best practices suggested by Cohen\n(Cohen et al., 2005), the guidelines and annotation documents ensured:', 'CONTEXT: **ASRD Dataset Filtering and Composition**: This chunk details the rigorous filtering, randomization, and composition process used to create the ASRD dataset, highlighting its focus on functional requirements across six business domains and its alignment with OWASP ASVS security classes for security requirements classification.\n\nCONTENT: 10 Yusuf G¨ ur et al.\n3. Filtering: The initial extraction yielded 3,264 items. To ensure the qual-\nity of the dataset, domain experts conducted a rigorous manual filtering\npass to remove 612 items. This exclusion process went beyond simple for-\nmatting artifacts (such as headers or tables of contents). We specifically\nremoved non-functional administrative clauses that addressed the vendor\nrather than the system (e.g., “The contractor must provide training man-\nuals”), project management constraints (e.g., “The project must be deliv-\nered by Q3”), and requirements with ambiguous scope that lacked clear\nverification criteria.\n4. Randomization: The remaining requirements were randomized and masked\nto mitigate potential annotation bias related to the document source or the\nsequence of requirements.\nThe resulting ASRD comprises 2,652 well-formed functional requirements\nacross six distinct business areas: Construction (1,202), Legal (177), Education\n(312), Software (199), Meeting (126), and Accommodation (636). A sample of\nthese requirements is provided in Table 2. The requirements included in this\nsample were selected based on three specific criteria to ensure a representative\noverview:\n–Samples were chosen to reflect the varied terminology and phrasing styles\nused across the six different business domains.\n–We prioritized requirements that demonstrate how standard functional de-\nscriptions conceal underlying security dependencies.\n–We ensured that the sample includes representative examples for all 11\nOWASP ASVS security classes used in the study to demonstrate the full\nscope of the classification task.\nIt is important to note that the ASRD is a Turkish-language corpus; all experi-\nments detailed in this study, including BERT fine-tuning and LLM prompting,\nwere conducted exclusively on the original text. English translations are pro-\nvided only for readability.\nTable 2: Sample Requirements from ASRD\nNo Original Requirements Translated Requirements\n1 Sistem, yetkili kullanıcının hukuk\ndosyası t¨ ur¨ u kayıt etmesini\nsa˘ glayacaktır.\nThe system shall allow authorized\nusers to record the legal file type.\n2 Sistem, kullanıcının kullanılmamı¸ s\nhukuk dosyası t¨ ur¨ un¨ u g¨ uncellemesini\nsa˘ glayacaktır.\nThe system shall allow the user to up-\ndate an unused legal file type.\n3 Sistem, kullanıcının kullanılmamı¸ s\nolan hukuk dosyası t¨ ur¨ un¨ u silmesini\nsa˘ glayacaktır.\nThe system shall allow the user to\ndelete an unused legal file type.\n4 Sistem, kullanıcının hukuk dosyası\nt¨ urlerini sorgulamasını ve listelemesini\nsa˘ glayacaktır.\nThe system shall allow the user to\nquery and list legal file types.', 'CONTEXT: This chunk focuses on the introduction of the **Agency Security Requirements Dataset (ASRD)**, detailing its real-world data sources, expert annotation process, and alignment with OWASP ASVS categories, as well as outlining the research questions and comparative evaluation of fine-tuned transformer models versus prompt-based approaches for security requirements classification.\n\nCONTENT: 4 Yusuf G¨ ur et al.\ncient and cost-effective compared to addressing security issues at later stages\nof development ((Khan et al., 2024).\nThis paper proposes a machine learning-based system to automatically an-\nalyze SRS documents and classify security requirements according to OWASP\nASVS. Its main contribution is the Agency Security Requirements Dataset\n(ASRD), a publicly available corpus created to support research in automated\nSRA. The ASRD comprises:\n–Real-World Data: 2,652 Software Requirements Specification (SRS) sen-\ntences extracted from six diverse, real-world industry projects,\n–Expert Annotation: Meticulously annotated by three cybersecurity experts,\neach with over 15 years of industry experience,\n–Rigorous Methodology: Developed using the iterative MATTER cycle an-\nnotation framework (Pustejovsky and Stubbs, 2012),\n–High Granularity and Multi-label Structure: Mapped to 11 distinct, action-\nable security categories from the industry-standard OWASP Application\nSecurity Verification Standard (ASVS,V2–V13), allowing each require-\nment to be associated with multiple categories.\nThe ASRD is intended as a shared research resource and benchmark. Using\nthis dataset, the study conducts an empirical analysis of automated classifica-\ntion approaches and addresses the following research questions:\n1. To what extent can fine-tuned transformer models accurately perform\nmulti-label classification of implicit security requirements into OWASP\nASVS categories using the ASRD?\n2. How does the performance of prompt-based approaches (zero-shot and few-\nshot) using modern LLMs compare to fine-tuned BERT-based models and\nnaive baselines for this task?\nThe results show that few-shot prompting with a modern language model\n(Gemini 2.0) achieves a macro-average F1 score of 0.941, closely matching the\nbest fine-tuned BERT-based model (0.942). This demonstrates that example-\nguided inference can reach performance comparable to supervised fine-tuning\nwhile requiring substantially less annotated data and model retraining. The\nevaluation compares fine-tuned transformer models (e.g., SecureBERT) with\nprompt-based methods in zero-shot and few-shot settings across multiple con-\ntemporary models, demonstrating that prompt-based approaches provide a\npractical and resource-efficient alternative for identifying implicit security re-\nquirements in industrial SRS documents.\nThe remainder of this paper is organized as follows. Section 2 reviews re-\nlated work on NLP-based requirements classification, security frameworks, and\nexisting security datasets. Section 3 describes the curation and expert anno-\ntation of the ASRD and summarizes its key characteristics. Section 4 outlines\nthe experimental setup and classification methods, including fine-tuned BERT\nmodels and prompt-based approaches. Section 5 reports the experimental re-\nsults. Section 6 discusses the findings and their implications, with a com-\nparative analysis of fine-tuning and prompting strategies. Section 7 examines', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb', 'CONTEXT: **Annotation Process and Quality Assurance in ASRD Development**: This chunk details the iterative annotation process for the ASRD dataset, including pilot and independent annotation phases, adjudication meetings, and the use of agreement metrics (e.g., Fleiss’s Kappa) to ensure high annotation quality and consistency among cybersecurity experts.\n\nCONTENT: 16 Yusuf G¨ ur et al.\n(1) original text and annotations were recoverable, (2) clear documenta-\ntion was maintained, (3) annotation quality was consistently high. The\nannotation template included fields for the software requirement text, se-\nlected OWASP labels, and annotator comments or questions. All versions\nof the guideline and annotation documents were preserved to track revi-\nsions based on annotator feedback. For the annotation process, a sample\ncorpus from the requirement set has been selected by inter agreement of\nSMEs. The first version of the Annotation Guideline based on OWASP\nASVS security classes has been developed, where each annotator has in-\ndividually classified the sample corpus by annotating it with one or more\nlabels following the instructions provided in the first Annotation Guide-\nline. After the initial annotation, the SMEs met under the guidance of the\nsenior SME, who is also the branch manager, to review and discuss the\nannotation decisions. Each of the 30 software requirements was examined\nindividually, and in cases where there were differing opinions among the\nannotators, efforts were made to persuade and convince others by provid-\ning explanations and reasons for their choices. After three iterations of\ndiscussions and deliberations, a full agreement was reached for 30 software\nrequirements.\n–Pilot Annotation: An initial batch of 30 software requirements was anno-\ntated early in the study, prompting multiple discussion rounds and three\nupdates to the guidelines. Adjudication meetings enabled the resolution\nof non-consensus requirements through SME-led discussions, during which\nthe rationale for classification was articulated. Discrepancies arising from\nquality issues, such as guideline violations, were addressed by implement-\ning corrections to ensure conformity with established criteria. Each SME\nprovided justifications for their decisions, which facilitated informed dis-\ncussions and enhanced understanding during adjudication. This iterative\nprocess resolved discrepancies across 98 requirements throughout the entire\ncorpus and was important in establishing the finalized annotation frame-\nwork.\n–Independent Annotation: Each SME classified all remaining 2622 require-\nments independently, using the finalized guideline. Annotators were re-\nquired to justify each decision. This practice proved important for facili-\ntating informed discussions and understanding annotator reasoning during\nthe subsequent adjudication phase. The process took 284 days and 267\nperson-hours of expert time.\n–Agreement Metrics: Inter-Annotator Agreement (IAA) was calculated us-\ning Fleiss’s Kappa and pairwise Cohen’s Kappa to assess consistency. IAA\nscores were instrumental in identifying instances of disagreement among\nannotators, thereby highlighting areas where the guidelines might require\nfurther clarification or where ambiguous requirement phrasings contributed\nto annotation discrepancies. Fleiss’s Kappa coefficient of 0.82 was obtained\nacross the three annotators, indicating strong agreement that significantly\nexceeded random chance. Pairwise Cohen’s Kappa values, ranging from', 'CONTEXT: **Annotation Process and Dataset Composition**: This chunk details the multi-stage annotation methodology used to create the ASRD dataset, addressing class distribution, challenges with imbalanced categories (e.g., V6 Cryptography, V12 Files/Resources), and the inclusion of true negatives to ensure realistic and high-quality security requirement classification.\n\nCONTENT: Implicit Security Requirements Classification 17\n0.71 to 0.79, further confirmed substantial agreement between individual\nannotator pairs.\n–Adjudication: Disagreements were resolved through structured expert dis-\ncussions led by the senior SME. When the two annotators disagreed on a\nrequirement, it was resolved through a structured process:\n–Both annotators presented their choice and their reasons.\n–The senior expert reviewed both positions against the guideline.\n–If the guideline clearly supported one choice, that one was used. If not,\nthe senior expert led a discussion to decide.\n–Final decision and the reason was written down.\nThe goal was to reach unanimous agreement for each disputed requirement.\nThis process produced final Gold Standard annotations for 135 contested\nitems, ensuring consistency and validation of the dataset.\nThis multi-stage annotation methodology produced a reliable dataset which\ncomprises 2,652 annotated security-relevant requirements. The category dis-\ntributions of the requirements can be seen in Figure 1. The class distribution\namong the classes are largely balanced (90%) except the V6(Stored Cryptog-\nraphy) and V12 (Files & Resources) as 6% each. This imbalance is considered\na reflection of the source projects, where requirements for these two categories\nare inherently less frequent than pervasive controls like access control or input\nvalidation. Stored cryptography requirements are typically captured as holis-\ntic, architectural decisions rather than numerous, distinct functional require-\nments. Similarly, explicit security controls for file handling are less ubiquitous,\nappearing only in projects with specific file processing features, which explains\ntheir low frequency in our corpus. Sample annotated requirements can be seen\nin Table 4.\nThis imbalance mirrors real-world security requirement frequency - most\nsoftware functions involve access and data; few involve file uploads or encryp-\ntion configuration - and introduces a challenge for machine learning. Partic-\nularly, the sparsity in V6 and V12 categories may hinder generalization and\ncalls for class imbalance handling techniques. Despite this, the dataset presents\na realistic and high-quality foundation for developing and evaluating security-\naware NLP and classification models.\nTwenty-six requirements (0.98% of the data) labeled as “UNASSIGNED”\nwere requirements unanimously determined by the experts to be purely func-\ntional requirements with no discernible implicit security component (e.g., “The\nsystem will enable application software to be developed with an object-oriented\nprogramming approach”,). These items were intentionally retained in the dataset\nas true negatives to ensure a realistic distribution and test the models’ ability\nto correctly reject non-security items.\n\n18 Yusuf G¨ ur et al.\nFig. 1: Distribution of Classes']","The ASRD corpus is written in Turkish. All experiments detailed in the study, including BERT fine-tuning and LLM prompting, were conducted exclusively on the original Turkish text. English translations are provided only for readability. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)",The ASRD is a Turkish-language corpus[cite: 192].,,,
Which fine-tuned BERT model achieved the highest Weighted-F1 score?,"['CONTEXT: **Performance Analysis of Models for Security Requirements Classification**  \nThis chunk provides a detailed comparison of F1-scores across various LLMs, fine-tuned BERT models, and a baseline approach, highlighting their performance in classifying security requirements, particularly in handling class imbalance and underrepresented categories.\n\nCONTENT: Implicit Security Requirements Classification 25\nTable 7: Aggregated F1-Scores for LLM, BERT Models, and Baseline\nModel Prompting Strategy Macro-F1 Micro-F1 Weighted-F1\nLarge Language Model Results\nLlama 3 70b Zero Shot 0.813 0.941 0.941\nLlama 3 70b Few Shot 0.802 0.925 0.925\nDeepSeek R1 Zero Shot 0.812 0.921 0.916\nDeepSeek R1 Few Shot 0.820 0.927 0.921\nGemini 2.5 Zero Shot 0.8290.957 0.953\nGemini 2.5 Few Shot 0.8170.963 0.959\nGemini 2.0 Zero Shot0.8900.925 0.921\nGemini 2.0 Few Shot0.9410.938 0.938\nGemini 2.0 Pro Zero Shot 0.830 0.908 0.904\nGemini 2.0 Pro Few Shot 0.889 0.959 0.953\nGemma 3 27b Zero Shot 0.806 0.912 0.907\nGemma 3 27b Few Shot 0.802 0.917 0.912\nGemma 3 4b Zero Shot 0.605 0.738 0.742\nGemma 3 4b Few Shot 0.723 0.871 0.867\nGpt 4o Zero Shot 0.790 0.912 0.907\nGpt 4o Few Shot 0.814 0.943 0.939\nGpt 4o mini Zero Shot 0.703 0.803 0.809\nGpt 4o mini Few Shot 0.754 0.852 0.854\nBERT Fine-Tuning Results\nbert-base-multilingual-uncased Fine-Tuning0.942 0.985 0.983\nbert-base-turkish-cased Fine-Tuning 0.933 0.983 0.981\nbert-base-uncased Fine-Tuning 0.914 0.978 0.976\nSecureBERT Fine-Tuning 0.918 0.979 0.976\nBaseline\nNaive Baseline Majority Class 0.774 0.940 0.933\nrepresented categories. The bert-base-multilingual-uncased model achieved the\nhighest Weighted-F1 score at 0.983, while the lowest among the group was\n0.976 for both bert-base-uncased and SecureBERT. However, these results ob-\nscure the impact of class imbalance. Macro-F1 scores, which give equal weight\nto all categories, were lower, ranging from 0.942 to 0.914, revealing reduced\nperformance on less frequent classes.\nThis pattern is clear in the category-level results (Appendix C). Perfor-\nmance was high for common categories such as V8 (Data Protection), where\nthe bert-base-multilingual-uncased model achieved an F1-score of 0.992. In\ncontrast, results declined significantly for sparsely represented categories. For\nV6 (38 samples), F1-scores fell to 0.714 for bert-base-uncased and 0.734 for\nSecureBERT. The weakest performance was observed for V10 (27 samples),\nwith F1-scores around 0.60, indicating limited generalization due to limited\ndata.\nAn analysis of precision and recall for these difficult classes reveals specific\nfailure patterns. For class V10, the bert-base-uncased model has a low Recall of\n0.481. This indicates that while its predictions were often correct (Precision:\n0.813), it failed to identify more than half of the actual V10 requirements,\nresulting in a high number of false negatives. For class V6, the same model', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: **Comparison of Fine-Tuned Models and LLMs for Security Requirements Classification**: This chunk discusses the performance comparison between fine-tuned transformer models (e.g., BERT) and few-shot prompting with LLMs (e.g., Gemini 2.0) for classifying implicit security requirements in SRS documents, emphasizing the practicality of LLMs as a resource-efficient alternative while highlighting challenges in Security Requirements Engineering (SRE).\n\nCONTENT: 2 Yusuf G¨ ur et al.\ntional fine-tuned transformer models and contemporary Large Language Mod-\nels (LLMs) employing few-shot and zero-shot prompt engineering strategies.\nThe results show that a few-shot prompting with Gemini 2.0 achieves a macro-\naverage F1 score of 0.941, directly comparable to the fine-tuned BERT model’s\n0.942. This study culminates in two primary findings: first, the validation and\npublication of the ASRD, a high-granularity, multi-label dataset for implicit\nsecurity requirements based on OWASP ASVS V2-V13; and second, the di-\nrect comparison demonstrating that few-shot Large Language Models (LLMs)\nachieve competitive multi-label classification performance (Macro-F1 0.941)\nnearly equal to resource-intensive fine-tuned transformer models (Macro-F1\n0.942). This confirms that LLMs represent a highly practical and resource-\nsaving strategy for automating the identification of embedded (implicit) secu-\nrity requirements for software security in industrial SRS documents\nKeywordsCybersecurity requirement elicitation·OWASP based security\nrequirement classification·OWASP ASVS-based Requirement Labeling·\nLLM based classification\n1 Introduction\nRequirements Engineering (RE) concerns the identification, documentation,\nand management of software requirements (Sommerville and Sawyer, 1997).\nThe increasing interconnectivity of information systems forces organizations\nto provide secure services in cyberspace. Integrating security during initial\nrequirements analysis is essential to proactively mitigate risks, reduce vulner-\nabilities, and reduce the high costs associated with downstream remediation\n(Villamizar et al., 2018). This proactive approach is central to the ”Shift-\nLeft” security paradigm, which advocates for the identification and mitigation\nof vulnerabilities as early as possible in the Software Development Life Cycle\n(SDLC).\nAlthough Security Requirements Engineering (SRE) has matured as a dis-\ncipline, its effective application in practice remains challenging. The issue is\nnot the absence of security considerations, but the difficulty of ensuring that\nsecurity requirements are properly validated and verified. An empirical investi-\ngation that combines a systematic literature review with a survey of 58 indus-\ntry professionals highlights this gap (Alam et al., 2025). While practitioners\nreported a moderate understanding of SRE practices, Security Requirements\nAssurance (SRA) was found to be poorly understood and rarely applied in\nindustrial contexts. The study concludes that validating and ensuring security\nrequirements remains a major and unresolved challenge in practice.\nThis assurance gap persists due to the documented lack of specialized se-\ncurity training for developers in early-phase RE (Andrade et al., 2023). The\ntask relies heavily on scarce specialized expertise and time-intensive manual\nanalysis. The main challenge is that critical security requirements are often not\nexplicitly stated. Instead, they are implicitly embedded within standard func-\ntional descriptions. For example, a seemingly simple functional requirement,', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to', 'CONTEXT: **Comparison of Effort vs. Performance and Validation of ASRD**: This chunk compares the effort and performance of different approaches (BERT fine-tuning, few-shot, and zero-shot LLMs) for security requirement classification, highlights the advantages of the ASRD dataset over existing benchmarks, and emphasizes the challenges of eliciting implicit security requirements in real-world industrial contexts.\n\nCONTENT: 34 Yusuf G¨ ur et al.\nTable 9: Comparison of Effort vs. Performance across Approaches\nApproach Data Requirement Est. Setup Effort Best Macro-F1\nBERT Fine-Tuning High (∼2,600 ex) High (267 hours)0.942\nLLM Few-Shot Low (∼30 ex) Low (<10 hours)0.941\nLLM Zero-Shot None Minimal (<2 hours) 0.890\nLLM Few-Shot approach (using Gemini 2.0) achieved a similar performance\n(Macro-F1 0.941) while requiring only the selection of a small number of in-\ncontext examples (approx. 30 examples per prompt).\nThis comparison points to diminishing returns from large-scale annotation\nwhen capable LLMs are available. Although extensive annotation was required\nhere to establish a reliable ground truth and validate the test set, the results\nindicate that, in industrial settings, a few-shot LLM approach can offer a more\nfavorable balance between effort and accuracy. Comparable performance can\nbe reached with substantially less data preparation, reducing the need for\nprolonged expert annotation.\nThe main contribution of this work is the introduction and validation of\nthe ASRD. The consistent performance of both fine-tuned BERT models and\nLLM-based approaches on ASRD supports its reliability and practical value.\nThe dataset addresses a persistent limitation in SRE research which is the\nlack of large, well-curated, professionally sourced benchmarks for security re-\nquirement classification. Compared with existing datasets, ASRD offers sev-\neral advantages. Unlike DOSSPRE (Kadebu et al., 2023), which is derived\nfrom student projects, ASRD includes 2,652 requirements from six commer-\ncial software systems, reflecting real industrial language and complexity. Its\nOWASP ASVS–based taxonomy spans 11 security classes, providing finer de-\ntail than PROMISE exp (Lima et al., 2019), where security is treated as a\nsingle category. Although the healthcare dataset by Riaz et al. (Riaz et al.,\n2014) is larger, it focuses on six broad objectives within a single domain, lim-\niting its scope. By contrast, ASRD supports cross-domain analysis and aligns\nwith a framework widely used in practice.\nThe dataset also benefits from a rigorous annotation process. Three cy-\nbersecurity specialists, each with over 15 years of experience, labeled the data\nusing an iterative MATTER-based procedure. This resulted in strong agree-\nment (Fleiss’ Kappa = 0.82) and helps mitigate the subjectivity that often\naffects security-related requirement datasets.\nBeyond the dataset construction, this study highlights the complexity of\nimplicit security requirement elicitation. A significant portion of security vul-\nnerabilities stems not from missing explicit security constraints (e.g., “The\nsystem shall encrypt passwords”), but from functional requirements that im-\nplicitly demand robust security controls. Our analysis of the ASRD reveals\nthat functional descriptions of business logic often conceal a dense network of\nsecurity dependencies. A representative example from our results is Require-\nment No. 2 (“The system will carry out the asset handover process”). While', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**: This chunk focuses on the statistical evaluation of model performance, comparing fine-tuned models, few-shot, and zero-shot LLM approaches, highlighting significant pairwise differences, and visualizing results through a Critical Difference (CD) diagram to identify top-performing models in the domain.\n\nCONTENT: Implicit Security Requirements Classification 29\nThe analysis (Table 8) highlights the significant pairwise contrasts and\nreveals important performance distinctions:\n–Baseline vs. Advanced Models: The Naive Baseline was consistently out-\nperformed by the advanced models. The difference between the Baseline\nand models such as SecureBERT (p <0.001) and Gemini 2.0 Few-Shot\n(p <0.001) was statistically significant, confirming that the high Weighted-\nF1 scores of these models reflect genuine learning beyond simple majority-\nclass prediction.\n–Fine-Tuning vs. Zero-Shot LLMs: Fine-tuned models like SecureBERT\ndemonstrated statistically significant performance distinctions (p <0.001)\nwhen compared to general-purpose LLMs operating in a zero-shot setting,\nsuch as GPT-4o (p <0.001) and Llama 3 70B (p <0.001). This indi-\ncates that without in-context examples, domain-specific fine-tuning retains\na measurable statistical advantage.\n–Fine-Tuning vs. Few-Shot State-of-the-Art: The pairwise comparison be-\ntween the best fine-tuned model (SecureBERT) and the best LLM ap-\nproach (Gemini 2.0 Few-Shot) yielded ap-value of 0.102. This value is not\nstatistically significant at theα= 0.05 level, supporting our finding that\nfew-shot prompting with state-of-the-art LLMs can effectively match the\nperformance of specialized, fine-tuned BERT models in this domain.\nTable 8: Significant Pairwise Differences (Wilcoxon Signed-Rank Test)\nModel A Model B Statistic p-value\nNaive Baseline SecureBERT 0.0 0.00098\nNaive Baseline BERT Turkish 0.0 0.00098\nNaive Baseline Gemini 2.0 (Few-Shot) 0.0 0.00098\nNaive Baseline Gemini 2.0 Pro (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Few-Shot) 0.0 0.00098\nSecureBERT Gemini 2.0 (Zero-Shot) 25.0 0.501\nSecureBERT Gemini 2.0 (Few-Shot) 14.5 0.102\nTo visualize the relative performance and statistical significance groups\nof all evaluated models, we constructed a Critical Difference (CD) diagram\n(Figure 2) using the Nemenyi post-hoc test.\nIn the CD diagram, models are arranged along the horizontal axis accord-\ning to their average rank. The best performing models, such as Gemini 2.0\nPro (Few-Shot) and BERT-Multilingual, appear on the left (lowest ranks).\nA horizontal bar connects groups of models that are not statistically signifi-\ncantly different from one another. The wide span of the CD bar (10.46) reflects\nthe high number of models compared (23) relative to the number of datasets\n(11). Despite this conservative threshold, the diagram clearly separates the\ntop-tier models (Fine-tuned BERTs and Few-Shot Gemini/GPT-4o) from the\nlower-performing group (Naive Baseline, Zero-Shot Gemma/Llama).', 'CONTEXT: **Performance Metrics for Security Requirement Classification Models**: This chunk presents the precision, recall, F1 scores, and support metrics for various OWASP ASVS categories, highlighting the performance of BERT models and a naive baseline in classifying implicit security requirements, with a focus on challenges like class imbalance and underrepresented categories.\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.960 0.950 0.960 0.790 0.000 0.980 0.970 0.960 0.750 0.000 0.800RECALL 1.000 1.000 1.000 1.000 0.000 1.000 1.000 1.000 1.000 0.000 1.000F1 0.980 0.980 0.980 0.880 0.000 0.990 0.980 0.980 0.860 0.000 0.890SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nTest Results of the BERT models and Naïve Baseline used in the study\nImplicit Security Requirements Classification 55\nC Test Results of the Bert Models']","The fine-tuned BERT model that achieved the highest Weighted-F1 score is the **bert-base-multilingual-uncased** model, with a Weighted-F1 score of **0.983**. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)",The bert-base-multilingual-uncased model achieved the highest Weighted-F1 score at 0.983[cite: 438].,,,
What was the Macro-F1 score for the Gemini 2.0 Few-Shot approach?,"['CONTEXT: **Performance Analysis of Models for Security Requirements Classification**  \nThis chunk provides a detailed comparison of F1-scores across various LLMs, fine-tuned BERT models, and a baseline approach, highlighting their performance in classifying security requirements, particularly in handling class imbalance and underrepresented categories.\n\nCONTENT: Implicit Security Requirements Classification 25\nTable 7: Aggregated F1-Scores for LLM, BERT Models, and Baseline\nModel Prompting Strategy Macro-F1 Micro-F1 Weighted-F1\nLarge Language Model Results\nLlama 3 70b Zero Shot 0.813 0.941 0.941\nLlama 3 70b Few Shot 0.802 0.925 0.925\nDeepSeek R1 Zero Shot 0.812 0.921 0.916\nDeepSeek R1 Few Shot 0.820 0.927 0.921\nGemini 2.5 Zero Shot 0.8290.957 0.953\nGemini 2.5 Few Shot 0.8170.963 0.959\nGemini 2.0 Zero Shot0.8900.925 0.921\nGemini 2.0 Few Shot0.9410.938 0.938\nGemini 2.0 Pro Zero Shot 0.830 0.908 0.904\nGemini 2.0 Pro Few Shot 0.889 0.959 0.953\nGemma 3 27b Zero Shot 0.806 0.912 0.907\nGemma 3 27b Few Shot 0.802 0.917 0.912\nGemma 3 4b Zero Shot 0.605 0.738 0.742\nGemma 3 4b Few Shot 0.723 0.871 0.867\nGpt 4o Zero Shot 0.790 0.912 0.907\nGpt 4o Few Shot 0.814 0.943 0.939\nGpt 4o mini Zero Shot 0.703 0.803 0.809\nGpt 4o mini Few Shot 0.754 0.852 0.854\nBERT Fine-Tuning Results\nbert-base-multilingual-uncased Fine-Tuning0.942 0.985 0.983\nbert-base-turkish-cased Fine-Tuning 0.933 0.983 0.981\nbert-base-uncased Fine-Tuning 0.914 0.978 0.976\nSecureBERT Fine-Tuning 0.918 0.979 0.976\nBaseline\nNaive Baseline Majority Class 0.774 0.940 0.933\nrepresented categories. The bert-base-multilingual-uncased model achieved the\nhighest Weighted-F1 score at 0.983, while the lowest among the group was\n0.976 for both bert-base-uncased and SecureBERT. However, these results ob-\nscure the impact of class imbalance. Macro-F1 scores, which give equal weight\nto all categories, were lower, ranging from 0.942 to 0.914, revealing reduced\nperformance on less frequent classes.\nThis pattern is clear in the category-level results (Appendix C). Perfor-\nmance was high for common categories such as V8 (Data Protection), where\nthe bert-base-multilingual-uncased model achieved an F1-score of 0.992. In\ncontrast, results declined significantly for sparsely represented categories. For\nV6 (38 samples), F1-scores fell to 0.714 for bert-base-uncased and 0.734 for\nSecureBERT. The weakest performance was observed for V10 (27 samples),\nwith F1-scores around 0.60, indicating limited generalization due to limited\ndata.\nAn analysis of precision and recall for these difficult classes reveals specific\nfailure patterns. For class V10, the bert-base-uncased model has a low Recall of\n0.481. This indicates that while its predictions were often correct (Precision:\n0.813), it failed to identify more than half of the actual V10 requirements,\nresulting in a high number of false negatives. For class V6, the same model', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.', 'CONTEXT: **Comparison of Fine-Tuned Models and LLMs for Security Requirements Classification**: This chunk discusses the performance comparison between fine-tuned transformer models (e.g., BERT) and few-shot prompting with LLMs (e.g., Gemini 2.0) for classifying implicit security requirements in SRS documents, emphasizing the practicality of LLMs as a resource-efficient alternative while highlighting challenges in Security Requirements Engineering (SRE).\n\nCONTENT: 2 Yusuf G¨ ur et al.\ntional fine-tuned transformer models and contemporary Large Language Mod-\nels (LLMs) employing few-shot and zero-shot prompt engineering strategies.\nThe results show that a few-shot prompting with Gemini 2.0 achieves a macro-\naverage F1 score of 0.941, directly comparable to the fine-tuned BERT model’s\n0.942. This study culminates in two primary findings: first, the validation and\npublication of the ASRD, a high-granularity, multi-label dataset for implicit\nsecurity requirements based on OWASP ASVS V2-V13; and second, the di-\nrect comparison demonstrating that few-shot Large Language Models (LLMs)\nachieve competitive multi-label classification performance (Macro-F1 0.941)\nnearly equal to resource-intensive fine-tuned transformer models (Macro-F1\n0.942). This confirms that LLMs represent a highly practical and resource-\nsaving strategy for automating the identification of embedded (implicit) secu-\nrity requirements for software security in industrial SRS documents\nKeywordsCybersecurity requirement elicitation·OWASP based security\nrequirement classification·OWASP ASVS-based Requirement Labeling·\nLLM based classification\n1 Introduction\nRequirements Engineering (RE) concerns the identification, documentation,\nand management of software requirements (Sommerville and Sawyer, 1997).\nThe increasing interconnectivity of information systems forces organizations\nto provide secure services in cyberspace. Integrating security during initial\nrequirements analysis is essential to proactively mitigate risks, reduce vulner-\nabilities, and reduce the high costs associated with downstream remediation\n(Villamizar et al., 2018). This proactive approach is central to the ”Shift-\nLeft” security paradigm, which advocates for the identification and mitigation\nof vulnerabilities as early as possible in the Software Development Life Cycle\n(SDLC).\nAlthough Security Requirements Engineering (SRE) has matured as a dis-\ncipline, its effective application in practice remains challenging. The issue is\nnot the absence of security considerations, but the difficulty of ensuring that\nsecurity requirements are properly validated and verified. An empirical investi-\ngation that combines a systematic literature review with a survey of 58 indus-\ntry professionals highlights this gap (Alam et al., 2025). While practitioners\nreported a moderate understanding of SRE practices, Security Requirements\nAssurance (SRA) was found to be poorly understood and rarely applied in\nindustrial contexts. The study concludes that validating and ensuring security\nrequirements remains a major and unresolved challenge in practice.\nThis assurance gap persists due to the documented lack of specialized se-\ncurity training for developers in early-phase RE (Andrade et al., 2023). The\ntask relies heavily on scarce specialized expertise and time-intensive manual\nanalysis. The main challenge is that critical security requirements are often not\nexplicitly stated. Instead, they are implicitly embedded within standard func-\ntional descriptions. For example, a seemingly simple functional requirement,', 'CONTEXT: This chunk provides detailed performance metrics (precision, recall, F1 scores, and support) for various machine learning models, including Meta Llama 3 70B, DeepSeek R1, and Gemini 2.5, in both zero-shot and few-shot settings, specifically for classifying security requirements based on OWASP ASVS categories.\n\nCONTENT: Meta_Llama_3_70b_Zero_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.969 0.961 0.974 0.897 0.077 0.967 0.946 0.956 0.849 0.258 0.917RECALL 0.987 0.982 0.984 0.968 0.077 0.979 0.964 0.974 0.957 0.286 0.978F1 0.978 0.971 0.979 0.931 0.077 0.973 0.955 0.965 0.900 0.271 0.947SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nMeta_Llama_3_70b_Few_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.974 0.964 0.974 0.875 0.077 0.977 0.956 0.956 0.882 0.214 0.919RECALL 0.984 0.976 0.979 0.889 0.077 0.987 0.969 0.961 0.897 0.214 0.959F1 0.979 0.970 0.977 0.882 0.077 0.982 0.962 0.958 0.889 0.214 0.938SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nDeepSeek_R1_Zero_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.953 0.927 0.972 0.876 0.082 0.926 0.910 0.907 0.875 0.455 0.887RECALL 0.963 0.937 0.979 0.940 0.205 0.933 0.924 0.921 0.930 0.536 0.912F1 0.958 0.932 0.975 0.907 0.117 0.930 0.917 0.914 0.901 0.492 0.899SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nDeepSeek_R1_Few_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.972 0.959 0.972 0.922 0.143 0.982 0.964 0.930 0.909 0.200 0.880RECALL 0.987 0.976 0.982 0.940 0.154 0.992 0.982 0.942 0.930 0.750 0.899F1 0.979 0.967 0.977 0.931 0.148 0.987 0.973 0.936 0.919 0.316 0.890SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nGemini_2_5_Zero_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements', 'CONTEXT: **Comparison of Effort vs. Performance and Validation of ASRD**: This chunk compares the effort and performance of different approaches (BERT fine-tuning, few-shot, and zero-shot LLMs) for security requirement classification, highlights the advantages of the ASRD dataset over existing benchmarks, and emphasizes the challenges of eliciting implicit security requirements in real-world industrial contexts.\n\nCONTENT: 34 Yusuf G¨ ur et al.\nTable 9: Comparison of Effort vs. Performance across Approaches\nApproach Data Requirement Est. Setup Effort Best Macro-F1\nBERT Fine-Tuning High (∼2,600 ex) High (267 hours)0.942\nLLM Few-Shot Low (∼30 ex) Low (<10 hours)0.941\nLLM Zero-Shot None Minimal (<2 hours) 0.890\nLLM Few-Shot approach (using Gemini 2.0) achieved a similar performance\n(Macro-F1 0.941) while requiring only the selection of a small number of in-\ncontext examples (approx. 30 examples per prompt).\nThis comparison points to diminishing returns from large-scale annotation\nwhen capable LLMs are available. Although extensive annotation was required\nhere to establish a reliable ground truth and validate the test set, the results\nindicate that, in industrial settings, a few-shot LLM approach can offer a more\nfavorable balance between effort and accuracy. Comparable performance can\nbe reached with substantially less data preparation, reducing the need for\nprolonged expert annotation.\nThe main contribution of this work is the introduction and validation of\nthe ASRD. The consistent performance of both fine-tuned BERT models and\nLLM-based approaches on ASRD supports its reliability and practical value.\nThe dataset addresses a persistent limitation in SRE research which is the\nlack of large, well-curated, professionally sourced benchmarks for security re-\nquirement classification. Compared with existing datasets, ASRD offers sev-\neral advantages. Unlike DOSSPRE (Kadebu et al., 2023), which is derived\nfrom student projects, ASRD includes 2,652 requirements from six commer-\ncial software systems, reflecting real industrial language and complexity. Its\nOWASP ASVS–based taxonomy spans 11 security classes, providing finer de-\ntail than PROMISE exp (Lima et al., 2019), where security is treated as a\nsingle category. Although the healthcare dataset by Riaz et al. (Riaz et al.,\n2014) is larger, it focuses on six broad objectives within a single domain, lim-\niting its scope. By contrast, ASRD supports cross-domain analysis and aligns\nwith a framework widely used in practice.\nThe dataset also benefits from a rigorous annotation process. Three cy-\nbersecurity specialists, each with over 15 years of experience, labeled the data\nusing an iterative MATTER-based procedure. This resulted in strong agree-\nment (Fleiss’ Kappa = 0.82) and helps mitigate the subjectivity that often\naffects security-related requirement datasets.\nBeyond the dataset construction, this study highlights the complexity of\nimplicit security requirement elicitation. A significant portion of security vul-\nnerabilities stems not from missing explicit security constraints (e.g., “The\nsystem shall encrypt passwords”), but from functional requirements that im-\nplicitly demand robust security controls. Our analysis of the ASRD reveals\nthat functional descriptions of business logic often conceal a dense network of\nsecurity dependencies. A representative example from our results is Require-\nment No. 2 (“The system will carry out the asset handover process”). While', 'CONTEXT: **Performance Evaluation of LLMs for Security Requirements Classification**: This chunk presents detailed test results and performance metrics (e.g., precision, recall, F1 scores) of various Gemini LLM variants (Few-Shot and Zero-Shot) in classifying security requirements across OWASP ASVS categories, highlighting their effectiveness and challenges in handling specific verification requirements.\n\nCONTENT: Test Results of the LLMs used in the study\nGemini_2_5_Few_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.979 0.972 0.980 0.914 0.229 0.985 0.972 0.974 0.868 0.203 0.900RECALL 0.997 0.992 0.992 0.984 0.641 0.995 0.992 0.995 0.967 0.964 0.994F1 0.988 0.982 0.986 0.948 0.338 0.990 0.982 0.984 0.915 0.335 0.945SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nGemini_2_0_Zero_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.967 0.940 0.972 0.894 0.819 0.960 0.962 0.955 0.812 0.937 0.897RECALL 0.967 0.939 0.972 0.882 0.280 0.960 0.962 0.954 0.783 0.479 0.884F1 0.990 0.963 0.990 0.994 0.718 0.977 0.984 0.982 0.900 0.821 0.981SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nGemini_2_0_Few_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.982 0.972 0.985 0.922 0.754 0.985 0.967 0.975 0.894 0.764 0.917RECALL 0.982 0.972 0.985 0.910 0.210 0.985 0.967 0.974 0.874 0.223 0.905F1 0.997 0.990 0.992 0.990 0.667 0.995 0.987 0.995 0.973 0.964 0.994SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nGemini_2_0_Pro_Zero_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.975 0.902 0.972 0.910 0.837 0.910 0.952 0.905 0.847 0.942 0.899RECALL 0.974 0.900 0.972 0.897 0.188 0.909 0.952 0.902 0.820 0.410 0.881F1 0.992 0.919 0.992 0.990 0.385 0.923 0.971 0.919 0.923 0.571 0.934SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nGemini_2_0_Pro_Few_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements', 'CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**: This chunk focuses on the statistical evaluation of model performance, comparing fine-tuned models, few-shot, and zero-shot LLM approaches, highlighting significant pairwise differences, and visualizing results through a Critical Difference (CD) diagram to identify top-performing models in the domain.\n\nCONTENT: Implicit Security Requirements Classification 29\nThe analysis (Table 8) highlights the significant pairwise contrasts and\nreveals important performance distinctions:\n–Baseline vs. Advanced Models: The Naive Baseline was consistently out-\nperformed by the advanced models. The difference between the Baseline\nand models such as SecureBERT (p <0.001) and Gemini 2.0 Few-Shot\n(p <0.001) was statistically significant, confirming that the high Weighted-\nF1 scores of these models reflect genuine learning beyond simple majority-\nclass prediction.\n–Fine-Tuning vs. Zero-Shot LLMs: Fine-tuned models like SecureBERT\ndemonstrated statistically significant performance distinctions (p <0.001)\nwhen compared to general-purpose LLMs operating in a zero-shot setting,\nsuch as GPT-4o (p <0.001) and Llama 3 70B (p <0.001). This indi-\ncates that without in-context examples, domain-specific fine-tuning retains\na measurable statistical advantage.\n–Fine-Tuning vs. Few-Shot State-of-the-Art: The pairwise comparison be-\ntween the best fine-tuned model (SecureBERT) and the best LLM ap-\nproach (Gemini 2.0 Few-Shot) yielded ap-value of 0.102. This value is not\nstatistically significant at theα= 0.05 level, supporting our finding that\nfew-shot prompting with state-of-the-art LLMs can effectively match the\nperformance of specialized, fine-tuned BERT models in this domain.\nTable 8: Significant Pairwise Differences (Wilcoxon Signed-Rank Test)\nModel A Model B Statistic p-value\nNaive Baseline SecureBERT 0.0 0.00098\nNaive Baseline BERT Turkish 0.0 0.00098\nNaive Baseline Gemini 2.0 (Few-Shot) 0.0 0.00098\nNaive Baseline Gemini 2.0 Pro (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Few-Shot) 0.0 0.00098\nSecureBERT Gemini 2.0 (Zero-Shot) 25.0 0.501\nSecureBERT Gemini 2.0 (Few-Shot) 14.5 0.102\nTo visualize the relative performance and statistical significance groups\nof all evaluated models, we constructed a Critical Difference (CD) diagram\n(Figure 2) using the Nemenyi post-hoc test.\nIn the CD diagram, models are arranged along the horizontal axis accord-\ning to their average rank. The best performing models, such as Gemini 2.0\nPro (Few-Shot) and BERT-Multilingual, appear on the left (lowest ranks).\nA horizontal bar connects groups of models that are not statistically signifi-\ncantly different from one another. The wide span of the CD bar (10.46) reflects\nthe high number of models compared (23) relative to the number of datasets\n(11). Despite this conservative threshold, the diagram clearly separates the\ntop-tier models (Fine-tuned BERTs and Few-Shot Gemini/GPT-4o) from the\nlower-performing group (Naive Baseline, Zero-Shot Gemma/Llama).']",The Macro-F1 score for the Gemini 2.0 Few-Shot approach was **0.941**. (Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf),"Gemini 2.0 Few-Shot achieved a Macro-F1 score of 0.941[cite: 24, 78].",,,
How does the performance of Gemini 2.0 Few-Shot compare to the best fine-tuned BERT model?,"['CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**  \nThis chunk provides a detailed comparison of F1-scores across various LLMs, fine-tuned BERT models, and a baseline approach, highlighting their performance in classifying security requirements, particularly in handling class imbalance and underrepresented categories.\n\nCONTENT: Implicit Security Requirements Classification 25\nTable 7: Aggregated F1-Scores for LLM, BERT Models, and Baseline\nModel Prompting Strategy Macro-F1 Micro-F1 Weighted-F1\nLarge Language Model Results\nLlama 3 70b Zero Shot 0.813 0.941 0.941\nLlama 3 70b Few Shot 0.802 0.925 0.925\nDeepSeek R1 Zero Shot 0.812 0.921 0.916\nDeepSeek R1 Few Shot 0.820 0.927 0.921\nGemini 2.5 Zero Shot 0.8290.957 0.953\nGemini 2.5 Few Shot 0.8170.963 0.959\nGemini 2.0 Zero Shot0.8900.925 0.921\nGemini 2.0 Few Shot0.9410.938 0.938\nGemini 2.0 Pro Zero Shot 0.830 0.908 0.904\nGemini 2.0 Pro Few Shot 0.889 0.959 0.953\nGemma 3 27b Zero Shot 0.806 0.912 0.907\nGemma 3 27b Few Shot 0.802 0.917 0.912\nGemma 3 4b Zero Shot 0.605 0.738 0.742\nGemma 3 4b Few Shot 0.723 0.871 0.867\nGpt 4o Zero Shot 0.790 0.912 0.907\nGpt 4o Few Shot 0.814 0.943 0.939\nGpt 4o mini Zero Shot 0.703 0.803 0.809\nGpt 4o mini Few Shot 0.754 0.852 0.854\nBERT Fine-Tuning Results\nbert-base-multilingual-uncased Fine-Tuning0.942 0.985 0.983\nbert-base-turkish-cased Fine-Tuning 0.933 0.983 0.981\nbert-base-uncased Fine-Tuning 0.914 0.978 0.976\nSecureBERT Fine-Tuning 0.918 0.979 0.976\nBaseline\nNaive Baseline Majority Class 0.774 0.940 0.933\nrepresented categories. The bert-base-multilingual-uncased model achieved the\nhighest Weighted-F1 score at 0.983, while the lowest among the group was\n0.976 for both bert-base-uncased and SecureBERT. However, these results ob-\nscure the impact of class imbalance. Macro-F1 scores, which give equal weight\nto all categories, were lower, ranging from 0.942 to 0.914, revealing reduced\nperformance on less frequent classes.\nThis pattern is clear in the category-level results (Appendix C). Perfor-\nmance was high for common categories such as V8 (Data Protection), where\nthe bert-base-multilingual-uncased model achieved an F1-score of 0.992. In\ncontrast, results declined significantly for sparsely represented categories. For\nV6 (38 samples), F1-scores fell to 0.714 for bert-base-uncased and 0.734 for\nSecureBERT. The weakest performance was observed for V10 (27 samples),\nwith F1-scores around 0.60, indicating limited generalization due to limited\ndata.\nAn analysis of precision and recall for these difficult classes reveals specific\nfailure patterns. For class V10, the bert-base-uncased model has a low Recall of\n0.481. This indicates that while its predictions were often correct (Precision:\n0.813), it failed to identify more than half of the actual V10 requirements,\nresulting in a high number of false negatives. For class V6, the same model', 'CONTEXT: **Comparison of Fine-Tuned Models and LLMs for Security Requirements Classification**: This chunk discusses the performance comparison between fine-tuned transformer models (e.g., BERT) and few-shot prompting with LLMs (e.g., Gemini 2.0) for classifying implicit security requirements in SRS documents, emphasizing the practicality of LLMs as a resource-efficient alternative while highlighting challenges in Security Requirements Engineering (SRE).\n\nCONTENT: 2 Yusuf G¨ ur et al.\ntional fine-tuned transformer models and contemporary Large Language Mod-\nels (LLMs) employing few-shot and zero-shot prompt engineering strategies.\nThe results show that a few-shot prompting with Gemini 2.0 achieves a macro-\naverage F1 score of 0.941, directly comparable to the fine-tuned BERT model’s\n0.942. This study culminates in two primary findings: first, the validation and\npublication of the ASRD, a high-granularity, multi-label dataset for implicit\nsecurity requirements based on OWASP ASVS V2-V13; and second, the di-\nrect comparison demonstrating that few-shot Large Language Models (LLMs)\nachieve competitive multi-label classification performance (Macro-F1 0.941)\nnearly equal to resource-intensive fine-tuned transformer models (Macro-F1\n0.942). This confirms that LLMs represent a highly practical and resource-\nsaving strategy for automating the identification of embedded (implicit) secu-\nrity requirements for software security in industrial SRS documents\nKeywordsCybersecurity requirement elicitation·OWASP based security\nrequirement classification·OWASP ASVS-based Requirement Labeling·\nLLM based classification\n1 Introduction\nRequirements Engineering (RE) concerns the identification, documentation,\nand management of software requirements (Sommerville and Sawyer, 1997).\nThe increasing interconnectivity of information systems forces organizations\nto provide secure services in cyberspace. Integrating security during initial\nrequirements analysis is essential to proactively mitigate risks, reduce vulner-\nabilities, and reduce the high costs associated with downstream remediation\n(Villamizar et al., 2018). This proactive approach is central to the ”Shift-\nLeft” security paradigm, which advocates for the identification and mitigation\nof vulnerabilities as early as possible in the Software Development Life Cycle\n(SDLC).\nAlthough Security Requirements Engineering (SRE) has matured as a dis-\ncipline, its effective application in practice remains challenging. The issue is\nnot the absence of security considerations, but the difficulty of ensuring that\nsecurity requirements are properly validated and verified. An empirical investi-\ngation that combines a systematic literature review with a survey of 58 indus-\ntry professionals highlights this gap (Alam et al., 2025). While practitioners\nreported a moderate understanding of SRE practices, Security Requirements\nAssurance (SRA) was found to be poorly understood and rarely applied in\nindustrial contexts. The study concludes that validating and ensuring security\nrequirements remains a major and unresolved challenge in practice.\nThis assurance gap persists due to the documented lack of specialized se-\ncurity training for developers in early-phase RE (Andrade et al., 2023). The\ntask relies heavily on scarce specialized expertise and time-intensive manual\nanalysis. The main challenge is that critical security requirements are often not\nexplicitly stated. Instead, they are implicitly embedded within standard func-\ntional descriptions. For example, a seemingly simple functional requirement,', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**: This chunk focuses on the statistical evaluation of model performance, comparing fine-tuned models, few-shot, and zero-shot LLM approaches, highlighting significant pairwise differences, and visualizing results through a Critical Difference (CD) diagram to identify top-performing models in the domain.\n\nCONTENT: Implicit Security Requirements Classification 29\nThe analysis (Table 8) highlights the significant pairwise contrasts and\nreveals important performance distinctions:\n–Baseline vs. Advanced Models: The Naive Baseline was consistently out-\nperformed by the advanced models. The difference between the Baseline\nand models such as SecureBERT (p <0.001) and Gemini 2.0 Few-Shot\n(p <0.001) was statistically significant, confirming that the high Weighted-\nF1 scores of these models reflect genuine learning beyond simple majority-\nclass prediction.\n–Fine-Tuning vs. Zero-Shot LLMs: Fine-tuned models like SecureBERT\ndemonstrated statistically significant performance distinctions (p <0.001)\nwhen compared to general-purpose LLMs operating in a zero-shot setting,\nsuch as GPT-4o (p <0.001) and Llama 3 70B (p <0.001). This indi-\ncates that without in-context examples, domain-specific fine-tuning retains\na measurable statistical advantage.\n–Fine-Tuning vs. Few-Shot State-of-the-Art: The pairwise comparison be-\ntween the best fine-tuned model (SecureBERT) and the best LLM ap-\nproach (Gemini 2.0 Few-Shot) yielded ap-value of 0.102. This value is not\nstatistically significant at theα= 0.05 level, supporting our finding that\nfew-shot prompting with state-of-the-art LLMs can effectively match the\nperformance of specialized, fine-tuned BERT models in this domain.\nTable 8: Significant Pairwise Differences (Wilcoxon Signed-Rank Test)\nModel A Model B Statistic p-value\nNaive Baseline SecureBERT 0.0 0.00098\nNaive Baseline BERT Turkish 0.0 0.00098\nNaive Baseline Gemini 2.0 (Few-Shot) 0.0 0.00098\nNaive Baseline Gemini 2.0 Pro (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Few-Shot) 0.0 0.00098\nSecureBERT Gemini 2.0 (Zero-Shot) 25.0 0.501\nSecureBERT Gemini 2.0 (Few-Shot) 14.5 0.102\nTo visualize the relative performance and statistical significance groups\nof all evaluated models, we constructed a Critical Difference (CD) diagram\n(Figure 2) using the Nemenyi post-hoc test.\nIn the CD diagram, models are arranged along the horizontal axis accord-\ning to their average rank. The best performing models, such as Gemini 2.0\nPro (Few-Shot) and BERT-Multilingual, appear on the left (lowest ranks).\nA horizontal bar connects groups of models that are not statistically signifi-\ncantly different from one another. The wide span of the CD bar (10.46) reflects\nthe high number of models compared (23) relative to the number of datasets\n(11). Despite this conservative threshold, the diagram clearly separates the\ntop-tier models (Fine-tuned BERTs and Few-Shot Gemini/GPT-4o) from the\nlower-performing group (Naive Baseline, Zero-Shot Gemma/Llama).', 'CONTEXT: **Comparison of Effort vs. Performance and Validation of ASRD**: This chunk compares the effort and performance of different approaches (BERT fine-tuning, few-shot, and zero-shot LLMs) for security requirement classification, highlights the advantages of the ASRD dataset over existing benchmarks, and emphasizes the challenges of eliciting implicit security requirements in real-world industrial contexts.\n\nCONTENT: 34 Yusuf G¨ ur et al.\nTable 9: Comparison of Effort vs. Performance across Approaches\nApproach Data Requirement Est. Setup Effort Best Macro-F1\nBERT Fine-Tuning High (∼2,600 ex) High (267 hours)0.942\nLLM Few-Shot Low (∼30 ex) Low (<10 hours)0.941\nLLM Zero-Shot None Minimal (<2 hours) 0.890\nLLM Few-Shot approach (using Gemini 2.0) achieved a similar performance\n(Macro-F1 0.941) while requiring only the selection of a small number of in-\ncontext examples (approx. 30 examples per prompt).\nThis comparison points to diminishing returns from large-scale annotation\nwhen capable LLMs are available. Although extensive annotation was required\nhere to establish a reliable ground truth and validate the test set, the results\nindicate that, in industrial settings, a few-shot LLM approach can offer a more\nfavorable balance between effort and accuracy. Comparable performance can\nbe reached with substantially less data preparation, reducing the need for\nprolonged expert annotation.\nThe main contribution of this work is the introduction and validation of\nthe ASRD. The consistent performance of both fine-tuned BERT models and\nLLM-based approaches on ASRD supports its reliability and practical value.\nThe dataset addresses a persistent limitation in SRE research which is the\nlack of large, well-curated, professionally sourced benchmarks for security re-\nquirement classification. Compared with existing datasets, ASRD offers sev-\neral advantages. Unlike DOSSPRE (Kadebu et al., 2023), which is derived\nfrom student projects, ASRD includes 2,652 requirements from six commer-\ncial software systems, reflecting real industrial language and complexity. Its\nOWASP ASVS–based taxonomy spans 11 security classes, providing finer de-\ntail than PROMISE exp (Lima et al., 2019), where security is treated as a\nsingle category. Although the healthcare dataset by Riaz et al. (Riaz et al.,\n2014) is larger, it focuses on six broad objectives within a single domain, lim-\niting its scope. By contrast, ASRD supports cross-domain analysis and aligns\nwith a framework widely used in practice.\nThe dataset also benefits from a rigorous annotation process. Three cy-\nbersecurity specialists, each with over 15 years of experience, labeled the data\nusing an iterative MATTER-based procedure. This resulted in strong agree-\nment (Fleiss’ Kappa = 0.82) and helps mitigate the subjectivity that often\naffects security-related requirement datasets.\nBeyond the dataset construction, this study highlights the complexity of\nimplicit security requirement elicitation. A significant portion of security vul-\nnerabilities stems not from missing explicit security constraints (e.g., “The\nsystem shall encrypt passwords”), but from functional requirements that im-\nplicitly demand robust security controls. Our analysis of the ASRD reveals\nthat functional descriptions of business logic often conceal a dense network of\nsecurity dependencies. A representative example from our results is Require-\nment No. 2 (“The system will carry out the asset handover process”). While', 'CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to']","The performance of Gemini 2.0 Few-Shot is nearly identical to the best fine-tuned BERT model. Specifically, Gemini 2.0 Few-Shot achieved a Macro-F1 score of 0.941, while the best fine-tuned BERT model (bert-base-multilingual-uncased) achieved a Macro-F1 score of 0.942. This demonstrates that few-shot prompting with a powerful LLM like Gemini 2.0 can match the performance of a specialized, fine-tuned model. However, fine-tuned BERT models generally retain a slight edge in performance, particularly for minority classes, and are more consistent across categories. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","It is directly comparable, with Gemini 2.0 Few-Shot scoring 0.941 Macro-F1 versus the fine-tuned BERT model's 0.942[cite: 24, 26].",,,
Which categories were identified as 'minority classes' or underrepresented in the dataset?,"['CONTEXT: **Analysis of Minority Class Performance and Annotation Challenges in SRE**: This chunk discusses the performance gap between majority and minority security classes in SRE, the expert-driven annotation process using the MATTER cycle, and the measures taken to mitigate subjectivity and ensure realistic, industry-relevant model evaluation.\n\nCONTENT: 32 Yusuf G¨ ur et al.\nFig. 4:Minority vs. Majority Class Performance Gap.A comparative\nanalysis revealing that while advanced LLMs and fine-tuned models achieve\nnear-parity on Majority Classes (Blue), a significant performance gap remains\non Minority Classes (Red), underscoring the “Long Tail” challenge in SRE.\nAnnotation was performed by three experienced cybersecurity experts.\nWhile their domain knowledge ensured quality, the small annotator pool may\nintroduce subjective bias and limit the range of interpretations. This was mit-\nigated through the iterative MATTER cycle which includes training, iterative\nguideline refinement, and consensus-based adjudication.\nA key threat to internal validity is subjectivity as classifications rely heavily\non the latent domain knowledge and industry experience, rather than explicit\nindicators within the requirement text itself. This expert-driven approach pro-\nvides a “gold standard” for realistic industrial needs but it may introduce in-\nconsistencies if replicated by annotators with different backgrounds or if the\nbroader system context is not explicitly documented.\nThe test set was manually selected to balance computational efficiency and\ngeneralizability assessment. While cross-validation could improve test calibra-\ntion, it was avoided due to its high computational cost.\nTo minimize researcher bias and ensure the results reflect real-world in-\ndustry needs, domain experts used for the selection of both the test set and\nthe LLM suite. Rather than selecting data or models arbitrarily, these experts\ncurated a test set containing the most complex, “implicit” security scenarios\nto challenge the models beyond simple pattern matching. For the model suite,\nthey prioritized architectures with advanced reasoning capabilities, hypothe-\nsizing that these specific technical features are essential for the multi-step de-\nduction required in security requirements engineering. Although the experts', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.', 'CONTEXT: **Performance Metrics for OWASP ASVS Verification Categories**: This chunk presents precision, recall, F1 scores, and support metrics for various OWASP ASVS verification categories, highlighting model performance across security requirements, with particular challenges in underrepresented classes like V6 (Cryptography) and V12 (Files/Resources).\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.943 0.922 0.967 0.905 0.214 0.903 0.918 0.906 0.876 0.250 0.880RECALL 0.950 0.932 0.974 0.943 0.231 0.907 0.927 0.914 0.920 0.250 0.899F1 0.947 0.927 0.970 0.924 0.222 0.905 0.922 0.910 0.898 0.250 0.890SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398', 'CONTEXT: **Annotation Process and Dataset Composition**: This chunk details the multi-stage annotation methodology used to create the ASRD dataset, addressing class distribution, challenges with imbalanced categories (e.g., V6 Cryptography, V12 Files/Resources), and the inclusion of true negatives to ensure realistic and high-quality security requirement classification.\n\nCONTENT: Implicit Security Requirements Classification 17\n0.71 to 0.79, further confirmed substantial agreement between individual\nannotator pairs.\n–Adjudication: Disagreements were resolved through structured expert dis-\ncussions led by the senior SME. When the two annotators disagreed on a\nrequirement, it was resolved through a structured process:\n–Both annotators presented their choice and their reasons.\n–The senior expert reviewed both positions against the guideline.\n–If the guideline clearly supported one choice, that one was used. If not,\nthe senior expert led a discussion to decide.\n–Final decision and the reason was written down.\nThe goal was to reach unanimous agreement for each disputed requirement.\nThis process produced final Gold Standard annotations for 135 contested\nitems, ensuring consistency and validation of the dataset.\nThis multi-stage annotation methodology produced a reliable dataset which\ncomprises 2,652 annotated security-relevant requirements. The category dis-\ntributions of the requirements can be seen in Figure 1. The class distribution\namong the classes are largely balanced (90%) except the V6(Stored Cryptog-\nraphy) and V12 (Files & Resources) as 6% each. This imbalance is considered\na reflection of the source projects, where requirements for these two categories\nare inherently less frequent than pervasive controls like access control or input\nvalidation. Stored cryptography requirements are typically captured as holis-\ntic, architectural decisions rather than numerous, distinct functional require-\nments. Similarly, explicit security controls for file handling are less ubiquitous,\nappearing only in projects with specific file processing features, which explains\ntheir low frequency in our corpus. Sample annotated requirements can be seen\nin Table 4.\nThis imbalance mirrors real-world security requirement frequency - most\nsoftware functions involve access and data; few involve file uploads or encryp-\ntion configuration - and introduces a challenge for machine learning. Partic-\nularly, the sparsity in V6 and V12 categories may hinder generalization and\ncalls for class imbalance handling techniques. Despite this, the dataset presents\na realistic and high-quality foundation for developing and evaluating security-\naware NLP and classification models.\nTwenty-six requirements (0.98% of the data) labeled as “UNASSIGNED”\nwere requirements unanimously determined by the experts to be purely func-\ntional requirements with no discernible implicit security component (e.g., “The\nsystem will enable application software to be developed with an object-oriented\nprogramming approach”,). These items were intentionally retained in the dataset\nas true negatives to ensure a realistic distribution and test the models’ ability\nto correctly reject non-security items.\n\n18 Yusuf G¨ ur et al.\nFig. 1: Distribution of Classes', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference', 'CONTEXT: This chunk provides detailed definitions of OWASP ASVS security requirement classes (V5–V14), which are critical for categorizing and addressing specific security concerns in software applications, as discussed in the broader context of automating security requirements classification using AI and the ASRD dataset.\n\nCONTENT: 14 Yusuf G¨ ur et al.\nTable 3 – continued from previous page\nClass Id Class Name Definition\nV5 Malicious Input Handling This class focuses on requirements\nfor validating and sanitizing all input\ndata to prevent injection attacks, such\nas SQL injection, Cross-Site Scripting\n(XSS), and others.\nV6 Stored Cryptography This class addresses the secure stor-\nage of cryptographic keys and sensi-\ntive data at rest, ensuring they are pro-\ntected from unauthorized disclosure or\nmodification.\nV7 Error Handling and Logging This class ensures that applications\nhandle errors gracefully without leak-\ning sensitive information and that\nsecurity-relevant events are logged for\nmonitoring and analysis.\nV8 Data Protection This class covers the requirements for\nprotecting sensitive data during tran-\nsit and in storage, focusing on confi-\ndentiality, integrity, and classification.\nV9 Communications Security This class focuses on securing commu-\nnication channels between system com-\nponents, such as between the client and\nserver, to prevent eavesdropping, tam-\npering, or spoofing.\nV10 Malicious Code This class deals with ensuring the ap-\nplication code is free from malicious\ncode, backdoors, or other unintended\nsecurity vulnerabilities introduced in-\ntentionally or unintentionally.\nV11 Business Logic This class addresses security con-\ncerns within the application’s business\nlogic, preventing attackers from abus-\ning workflows or functionalities for un-\nintended purposes.\nV12 File and Resources This class covers the secure handling of\nfiles and other resources, including up-\nload, download, and management, to\nprevent path traversal and other re-\nlated attacks.\nV13 API and Web Service This class provides security require-\nments specifically for APIs and web\nservices, covering aspects like authen-\ntication, authorization, and protection\nagainst common API attacks.\nV14 Configuration This class focuses on securing the con-\nfiguration of all application compo-\nnents, including the application server,\nplatform, and third-party libraries, to\nprevent security misconfigurations.']","The categories identified as ""minority classes"" or underrepresented in the dataset are **V6 (Stored Cryptography)** and **V12 (File and Resources)**. These categories were noted to have significantly lower representation compared to others, each comprising only 6% of the dataset. This imbalance reflects the real-world frequency of such requirements, where cryptographic storage and file handling are less common than more pervasive controls like authentication or access control. The sparsity in these categories poses challenges for model learning and generalization. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","The minority classes are V6 (Stored Cryptography) and V12 (Files and Resources)[cite: 291, 452].",,,
What was the performance of the Naive Baseline model?,"['CONTEXT: **Performance Metrics for Security Requirement Classification Models**: This chunk presents the precision, recall, F1 scores, and support metrics for various OWASP ASVS categories, highlighting the performance of BERT models and a naive baseline in classifying implicit security requirements, with a focus on challenges like class imbalance and underrepresented categories.\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.960 0.950 0.960 0.790 0.000 0.980 0.970 0.960 0.750 0.000 0.800RECALL 1.000 1.000 1.000 1.000 0.000 1.000 1.000 1.000 1.000 0.000 1.000F1 0.980 0.980 0.980 0.880 0.000 0.990 0.980 0.980 0.860 0.000 0.890SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nTest Results of the BERT models and Naïve Baseline used in the study\nImplicit Security Requirements Classification 55\nC Test Results of the Bert Models', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**: This chunk focuses on the statistical evaluation of model performance, comparing fine-tuned models, few-shot, and zero-shot LLM approaches, highlighting significant pairwise differences, and visualizing results through a Critical Difference (CD) diagram to identify top-performing models in the domain.\n\nCONTENT: Implicit Security Requirements Classification 29\nThe analysis (Table 8) highlights the significant pairwise contrasts and\nreveals important performance distinctions:\n–Baseline vs. Advanced Models: The Naive Baseline was consistently out-\nperformed by the advanced models. The difference between the Baseline\nand models such as SecureBERT (p <0.001) and Gemini 2.0 Few-Shot\n(p <0.001) was statistically significant, confirming that the high Weighted-\nF1 scores of these models reflect genuine learning beyond simple majority-\nclass prediction.\n–Fine-Tuning vs. Zero-Shot LLMs: Fine-tuned models like SecureBERT\ndemonstrated statistically significant performance distinctions (p <0.001)\nwhen compared to general-purpose LLMs operating in a zero-shot setting,\nsuch as GPT-4o (p <0.001) and Llama 3 70B (p <0.001). This indi-\ncates that without in-context examples, domain-specific fine-tuning retains\na measurable statistical advantage.\n–Fine-Tuning vs. Few-Shot State-of-the-Art: The pairwise comparison be-\ntween the best fine-tuned model (SecureBERT) and the best LLM ap-\nproach (Gemini 2.0 Few-Shot) yielded ap-value of 0.102. This value is not\nstatistically significant at theα= 0.05 level, supporting our finding that\nfew-shot prompting with state-of-the-art LLMs can effectively match the\nperformance of specialized, fine-tuned BERT models in this domain.\nTable 8: Significant Pairwise Differences (Wilcoxon Signed-Rank Test)\nModel A Model B Statistic p-value\nNaive Baseline SecureBERT 0.0 0.00098\nNaive Baseline BERT Turkish 0.0 0.00098\nNaive Baseline Gemini 2.0 (Few-Shot) 0.0 0.00098\nNaive Baseline Gemini 2.0 Pro (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Few-Shot) 0.0 0.00098\nSecureBERT Gemini 2.0 (Zero-Shot) 25.0 0.501\nSecureBERT Gemini 2.0 (Few-Shot) 14.5 0.102\nTo visualize the relative performance and statistical significance groups\nof all evaluated models, we constructed a Critical Difference (CD) diagram\n(Figure 2) using the Nemenyi post-hoc test.\nIn the CD diagram, models are arranged along the horizontal axis accord-\ning to their average rank. The best performing models, such as Gemini 2.0\nPro (Few-Shot) and BERT-Multilingual, appear on the left (lowest ranks).\nA horizontal bar connects groups of models that are not statistically signifi-\ncantly different from one another. The wide span of the CD bar (10.46) reflects\nthe high number of models compared (23) relative to the number of datasets\n(11). Despite this conservative threshold, the diagram clearly separates the\ntop-tier models (Fine-tuned BERTs and Few-Shot Gemini/GPT-4o) from the\nlower-performing group (Naive Baseline, Zero-Shot Gemma/Llama).', 'CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**  \nThis chunk provides a detailed comparison of F1-scores across various LLMs, fine-tuned BERT models, and a baseline approach, highlighting their performance in classifying security requirements, particularly in handling class imbalance and underrepresented categories.\n\nCONTENT: Implicit Security Requirements Classification 25\nTable 7: Aggregated F1-Scores for LLM, BERT Models, and Baseline\nModel Prompting Strategy Macro-F1 Micro-F1 Weighted-F1\nLarge Language Model Results\nLlama 3 70b Zero Shot 0.813 0.941 0.941\nLlama 3 70b Few Shot 0.802 0.925 0.925\nDeepSeek R1 Zero Shot 0.812 0.921 0.916\nDeepSeek R1 Few Shot 0.820 0.927 0.921\nGemini 2.5 Zero Shot 0.8290.957 0.953\nGemini 2.5 Few Shot 0.8170.963 0.959\nGemini 2.0 Zero Shot0.8900.925 0.921\nGemini 2.0 Few Shot0.9410.938 0.938\nGemini 2.0 Pro Zero Shot 0.830 0.908 0.904\nGemini 2.0 Pro Few Shot 0.889 0.959 0.953\nGemma 3 27b Zero Shot 0.806 0.912 0.907\nGemma 3 27b Few Shot 0.802 0.917 0.912\nGemma 3 4b Zero Shot 0.605 0.738 0.742\nGemma 3 4b Few Shot 0.723 0.871 0.867\nGpt 4o Zero Shot 0.790 0.912 0.907\nGpt 4o Few Shot 0.814 0.943 0.939\nGpt 4o mini Zero Shot 0.703 0.803 0.809\nGpt 4o mini Few Shot 0.754 0.852 0.854\nBERT Fine-Tuning Results\nbert-base-multilingual-uncased Fine-Tuning0.942 0.985 0.983\nbert-base-turkish-cased Fine-Tuning 0.933 0.983 0.981\nbert-base-uncased Fine-Tuning 0.914 0.978 0.976\nSecureBERT Fine-Tuning 0.918 0.979 0.976\nBaseline\nNaive Baseline Majority Class 0.774 0.940 0.933\nrepresented categories. The bert-base-multilingual-uncased model achieved the\nhighest Weighted-F1 score at 0.983, while the lowest among the group was\n0.976 for both bert-base-uncased and SecureBERT. However, these results ob-\nscure the impact of class imbalance. Macro-F1 scores, which give equal weight\nto all categories, were lower, ranging from 0.942 to 0.914, revealing reduced\nperformance on less frequent classes.\nThis pattern is clear in the category-level results (Appendix C). Perfor-\nmance was high for common categories such as V8 (Data Protection), where\nthe bert-base-multilingual-uncased model achieved an F1-score of 0.992. In\ncontrast, results declined significantly for sparsely represented categories. For\nV6 (38 samples), F1-scores fell to 0.714 for bert-base-uncased and 0.734 for\nSecureBERT. The weakest performance was observed for V10 (27 samples),\nwith F1-scores around 0.60, indicating limited generalization due to limited\ndata.\nAn analysis of precision and recall for these difficult classes reveals specific\nfailure patterns. For class V10, the bert-base-uncased model has a low Recall of\n0.481. This indicates that while its predictions were often correct (Precision:\n0.813), it failed to identify more than half of the actual V10 requirements,\nresulting in a high number of false negatives. For class V6, the same model', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.', 'CONTEXT: **Analysis of Minority Class Performance and Annotation Challenges in SRE**: This chunk discusses the performance gap between majority and minority security classes in SRE, the expert-driven annotation process using the MATTER cycle, and the measures taken to mitigate subjectivity and ensure realistic, industry-relevant model evaluation.\n\nCONTENT: 32 Yusuf G¨ ur et al.\nFig. 4:Minority vs. Majority Class Performance Gap.A comparative\nanalysis revealing that while advanced LLMs and fine-tuned models achieve\nnear-parity on Majority Classes (Blue), a significant performance gap remains\non Minority Classes (Red), underscoring the “Long Tail” challenge in SRE.\nAnnotation was performed by three experienced cybersecurity experts.\nWhile their domain knowledge ensured quality, the small annotator pool may\nintroduce subjective bias and limit the range of interpretations. This was mit-\nigated through the iterative MATTER cycle which includes training, iterative\nguideline refinement, and consensus-based adjudication.\nA key threat to internal validity is subjectivity as classifications rely heavily\non the latent domain knowledge and industry experience, rather than explicit\nindicators within the requirement text itself. This expert-driven approach pro-\nvides a “gold standard” for realistic industrial needs but it may introduce in-\nconsistencies if replicated by annotators with different backgrounds or if the\nbroader system context is not explicitly documented.\nThe test set was manually selected to balance computational efficiency and\ngeneralizability assessment. While cross-validation could improve test calibra-\ntion, it was avoided due to its high computational cost.\nTo minimize researcher bias and ensure the results reflect real-world in-\ndustry needs, domain experts used for the selection of both the test set and\nthe LLM suite. Rather than selecting data or models arbitrarily, these experts\ncurated a test set containing the most complex, “implicit” security scenarios\nto challenge the models beyond simple pattern matching. For the model suite,\nthey prioritized architectures with advanced reasoning capabilities, hypothe-\nsizing that these specific technical features are essential for the multi-step de-\nduction required in security requirements engineering. Although the experts', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the']","The Naive Baseline model's performance was as follows:

- **Macro-F1 Score**: 0.774  
- **Micro-F1 Score**: 0.940  
- **Weighted-F1 Score**: 0.933  

The Naive Baseline model, which always predicts the most frequent class, achieved high Micro-F1 and Weighted-F1 scores due to the dataset's class imbalance. However, its Macro-F1 score was significantly lower compared to fine-tuned models, indicating poor performance on minority classes. For example, its F1 score was 0.00 for underrepresented categories like V6 (Stored Cryptography) and V12 (Files and Resources), as expected. This highlights its inability to generalize beyond majority-class predictions.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","The Naive Baseline achieved a Weighted-F1 of 0.933 but a significantly lower Macro-F1 of 0.774, with 0.00 scores for minority classes[cite: 495, 499].",,,
Why did the Naive Baseline achieve a high Weighted-F1 score despite poor overall classification?,"['CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1', 'CONTEXT: **Performance Metrics for Security Requirement Classification Models**: This chunk presents the precision, recall, F1 scores, and support metrics for various OWASP ASVS categories, highlighting the performance of BERT models and a naive baseline in classifying implicit security requirements, with a focus on challenges like class imbalance and underrepresented categories.\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.960 0.950 0.960 0.790 0.000 0.980 0.970 0.960 0.750 0.000 0.800RECALL 1.000 1.000 1.000 1.000 0.000 1.000 1.000 1.000 1.000 0.000 1.000F1 0.980 0.980 0.980 0.880 0.000 0.990 0.980 0.980 0.860 0.000 0.890SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nTest Results of the BERT models and Naïve Baseline used in the study\nImplicit Security Requirements Classification 55\nC Test Results of the Bert Models', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**: This chunk focuses on the statistical evaluation of model performance, comparing fine-tuned models, few-shot, and zero-shot LLM approaches, highlighting significant pairwise differences, and visualizing results through a Critical Difference (CD) diagram to identify top-performing models in the domain.\n\nCONTENT: Implicit Security Requirements Classification 29\nThe analysis (Table 8) highlights the significant pairwise contrasts and\nreveals important performance distinctions:\n–Baseline vs. Advanced Models: The Naive Baseline was consistently out-\nperformed by the advanced models. The difference between the Baseline\nand models such as SecureBERT (p <0.001) and Gemini 2.0 Few-Shot\n(p <0.001) was statistically significant, confirming that the high Weighted-\nF1 scores of these models reflect genuine learning beyond simple majority-\nclass prediction.\n–Fine-Tuning vs. Zero-Shot LLMs: Fine-tuned models like SecureBERT\ndemonstrated statistically significant performance distinctions (p <0.001)\nwhen compared to general-purpose LLMs operating in a zero-shot setting,\nsuch as GPT-4o (p <0.001) and Llama 3 70B (p <0.001). This indi-\ncates that without in-context examples, domain-specific fine-tuning retains\na measurable statistical advantage.\n–Fine-Tuning vs. Few-Shot State-of-the-Art: The pairwise comparison be-\ntween the best fine-tuned model (SecureBERT) and the best LLM ap-\nproach (Gemini 2.0 Few-Shot) yielded ap-value of 0.102. This value is not\nstatistically significant at theα= 0.05 level, supporting our finding that\nfew-shot prompting with state-of-the-art LLMs can effectively match the\nperformance of specialized, fine-tuned BERT models in this domain.\nTable 8: Significant Pairwise Differences (Wilcoxon Signed-Rank Test)\nModel A Model B Statistic p-value\nNaive Baseline SecureBERT 0.0 0.00098\nNaive Baseline BERT Turkish 0.0 0.00098\nNaive Baseline Gemini 2.0 (Few-Shot) 0.0 0.00098\nNaive Baseline Gemini 2.0 Pro (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Few-Shot) 0.0 0.00098\nSecureBERT Gemini 2.0 (Zero-Shot) 25.0 0.501\nSecureBERT Gemini 2.0 (Few-Shot) 14.5 0.102\nTo visualize the relative performance and statistical significance groups\nof all evaluated models, we constructed a Critical Difference (CD) diagram\n(Figure 2) using the Nemenyi post-hoc test.\nIn the CD diagram, models are arranged along the horizontal axis accord-\ning to their average rank. The best performing models, such as Gemini 2.0\nPro (Few-Shot) and BERT-Multilingual, appear on the left (lowest ranks).\nA horizontal bar connects groups of models that are not statistically signifi-\ncantly different from one another. The wide span of the CD bar (10.46) reflects\nthe high number of models compared (23) relative to the number of datasets\n(11). Despite this conservative threshold, the diagram clearly separates the\ntop-tier models (Fine-tuned BERTs and Few-Shot Gemini/GPT-4o) from the\nlower-performing group (Naive Baseline, Zero-Shot Gemma/Llama).', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**  \nThis chunk provides a detailed comparison of F1-scores across various LLMs, fine-tuned BERT models, and a baseline approach, highlighting their performance in classifying security requirements, particularly in handling class imbalance and underrepresented categories.\n\nCONTENT: Implicit Security Requirements Classification 25\nTable 7: Aggregated F1-Scores for LLM, BERT Models, and Baseline\nModel Prompting Strategy Macro-F1 Micro-F1 Weighted-F1\nLarge Language Model Results\nLlama 3 70b Zero Shot 0.813 0.941 0.941\nLlama 3 70b Few Shot 0.802 0.925 0.925\nDeepSeek R1 Zero Shot 0.812 0.921 0.916\nDeepSeek R1 Few Shot 0.820 0.927 0.921\nGemini 2.5 Zero Shot 0.8290.957 0.953\nGemini 2.5 Few Shot 0.8170.963 0.959\nGemini 2.0 Zero Shot0.8900.925 0.921\nGemini 2.0 Few Shot0.9410.938 0.938\nGemini 2.0 Pro Zero Shot 0.830 0.908 0.904\nGemini 2.0 Pro Few Shot 0.889 0.959 0.953\nGemma 3 27b Zero Shot 0.806 0.912 0.907\nGemma 3 27b Few Shot 0.802 0.917 0.912\nGemma 3 4b Zero Shot 0.605 0.738 0.742\nGemma 3 4b Few Shot 0.723 0.871 0.867\nGpt 4o Zero Shot 0.790 0.912 0.907\nGpt 4o Few Shot 0.814 0.943 0.939\nGpt 4o mini Zero Shot 0.703 0.803 0.809\nGpt 4o mini Few Shot 0.754 0.852 0.854\nBERT Fine-Tuning Results\nbert-base-multilingual-uncased Fine-Tuning0.942 0.985 0.983\nbert-base-turkish-cased Fine-Tuning 0.933 0.983 0.981\nbert-base-uncased Fine-Tuning 0.914 0.978 0.976\nSecureBERT Fine-Tuning 0.918 0.979 0.976\nBaseline\nNaive Baseline Majority Class 0.774 0.940 0.933\nrepresented categories. The bert-base-multilingual-uncased model achieved the\nhighest Weighted-F1 score at 0.983, while the lowest among the group was\n0.976 for both bert-base-uncased and SecureBERT. However, these results ob-\nscure the impact of class imbalance. Macro-F1 scores, which give equal weight\nto all categories, were lower, ranging from 0.942 to 0.914, revealing reduced\nperformance on less frequent classes.\nThis pattern is clear in the category-level results (Appendix C). Perfor-\nmance was high for common categories such as V8 (Data Protection), where\nthe bert-base-multilingual-uncased model achieved an F1-score of 0.992. In\ncontrast, results declined significantly for sparsely represented categories. For\nV6 (38 samples), F1-scores fell to 0.714 for bert-base-uncased and 0.734 for\nSecureBERT. The weakest performance was observed for V10 (27 samples),\nwith F1-scores around 0.60, indicating limited generalization due to limited\ndata.\nAn analysis of precision and recall for these difficult classes reveals specific\nfailure patterns. For class V10, the bert-base-uncased model has a low Recall of\n0.481. This indicates that while its predictions were often correct (Precision:\n0.813), it failed to identify more than half of the actual V10 requirements,\nresulting in a high number of false negatives. For class V6, the same model', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.', 'CONTEXT: **Performance Visualization and Analysis of Classifiers**: This chunk focuses on the comparative performance analysis of 20 classifiers across OWASP ASVS classes, using critical difference diagrams, heatmaps, and gap analysis to highlight strengths and weaknesses, particularly in handling rare security classes like V6 (Stored Cryptography) and V12 (Files and Resources). It also discusses dataset diversity, threats to validity, and the generalizability of findings.\n\nCONTENT: 30 Yusuf G¨ ur et al.\nFig. 2: Critical Difference (CD) diagram visualizing the statistical comparison\nof classifiers. The horizontal axis represents the average rank of each model\nacross all 11 OWASP ASVS classes (lower ranks indicate better performance).\nThe Critical Difference (CD = 10.46) represents the minimum difference in\naverage rank required for two models to be considered statistically significantly\ndifferent atp <0.05.\n5.6 Comparative Visualization Analysis\nTo complement the statistical rankings, we visualized the performance land-\nscape across all 20 model configurations.\nHeatmap Analysis: Figure 3 shows F1-scores by class. Requirements related\nto V2 (Authentication), V3 (Session Management), and V4 (Access Control)\nare handled well by nearly all models, with scores typically above 0.95. These\ncategories are common and appear consistently across training sources. In\ncontrast, V6 (Stored Cryptography) and V12 (Files and Resources) show low\nscores across the board, including for GPT-4o and Gemini 2.0 Pro. This pat-\ntern points to a systematic difficulty with sparse categories rather than a\nweakness of a particular model.\nGap Analysis: Figure 4 contrasts average performance on frequent and in-\nfrequent classes. Fine-tuned models such as SecureBERT and BERT-Multilingual\nperform better on rare classes, with F1-scores around 0.70–0.80. Zero-shot\nLLMs perform poorly in these cases, often below 0.30. Few-shot prompting\nimproves results for some models, such as Gemini 2.0, but the gap remains\nsubstantial.\n6 Threats to Validity\nOur dataset consists of 2,652 requirements derived from six Software Require-\nments Specification (SRS) documents. While the number of source documents\n\nImplicit Security Requirements Classification 31\nFig. 3:Comprehensive Performance Heatmap.F1-scores for all 20 eval-\nuated models across 11 OWASP ASVS classes. The visualization highlights\nthe “zone of failure” (red) for classes V6 and V12 across models, contrasting\nwith the high performance (green) on ubiquitous classes like V2 and V4.\nis limited, potential bias was mitigated by strategically selecting projects from\nsix distinct business domains: Construction, Legal, Education, Software, Meet-\ning Management, and Accommodation. This semantic diversity ensures that\nthe models are evaluated on a broad vocabulary and varied functional contexts\nrather than a single industry vertical. A specific consideration regarding the\nexternal validity of this study is that the ASRD is a Turkish-language corpus\nwhich allows for the evaluation of automated tools in linguistically diverse\nindustrial contexts.\nFurthermore, because security requirements (e.g., Authentication, Log-\nging) represent cross-cutting concerns that apply universally across software\nsystems, we believe the fundamental patterns captured in the ASRD are trans-\nferable to other industries. Our current evaluation used a stratified split across\nthe entire dataset, meaning requirements from all six source projects are\npresent in the training, validation, and test sets. However, we acknowledge\nthat this approach does not fully measure the models’ ability to generalize to\nentirely new projects with different authors or linguistic styles, as the test set\nis not completely “unseen” in terms of project context.', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to', 'CONTEXT: **Analysis of Minority Class Performance and Annotation Challenges in SRE**: This chunk discusses the performance gap between majority and minority security classes in SRE, the expert-driven annotation process using the MATTER cycle, and the measures taken to mitigate subjectivity and ensure realistic, industry-relevant model evaluation.\n\nCONTENT: 32 Yusuf G¨ ur et al.\nFig. 4:Minority vs. Majority Class Performance Gap.A comparative\nanalysis revealing that while advanced LLMs and fine-tuned models achieve\nnear-parity on Majority Classes (Blue), a significant performance gap remains\non Minority Classes (Red), underscoring the “Long Tail” challenge in SRE.\nAnnotation was performed by three experienced cybersecurity experts.\nWhile their domain knowledge ensured quality, the small annotator pool may\nintroduce subjective bias and limit the range of interpretations. This was mit-\nigated through the iterative MATTER cycle which includes training, iterative\nguideline refinement, and consensus-based adjudication.\nA key threat to internal validity is subjectivity as classifications rely heavily\non the latent domain knowledge and industry experience, rather than explicit\nindicators within the requirement text itself. This expert-driven approach pro-\nvides a “gold standard” for realistic industrial needs but it may introduce in-\nconsistencies if replicated by annotators with different backgrounds or if the\nbroader system context is not explicitly documented.\nThe test set was manually selected to balance computational efficiency and\ngeneralizability assessment. While cross-validation could improve test calibra-\ntion, it was avoided due to its high computational cost.\nTo minimize researcher bias and ensure the results reflect real-world in-\ndustry needs, domain experts used for the selection of both the test set and\nthe LLM suite. Rather than selecting data or models arbitrarily, these experts\ncurated a test set containing the most complex, “implicit” security scenarios\nto challenge the models beyond simple pattern matching. For the model suite,\nthey prioritized architectures with advanced reasoning capabilities, hypothe-\nsizing that these specific technical features are essential for the multi-step de-\nduction required in security requirements engineering. Although the experts']","The Naive Baseline achieved a high Weighted-F1 score despite poor overall classification because it always predicts the most frequent class. This approach benefits from the class imbalance in the dataset, where the majority class dominates. As a result, the Weighted-F1 score, which accounts for the support (number of instances) of each class, is inflated by the high performance on the majority class, even though the model performs poorly on minority classes. For example, the Naive Baseline had an F1 score of 0.00 for minority classes like V6 and V12, but its overall Weighted-F1 score remained high due to the dominance of the majority class in the dataset.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)",Because the dataset's class imbalance allows a trivial classifier to achieve high accuracy by simply predicting the most frequent classes and ignoring minority ones[cite: 498].,,,
What prompting strategy was used for the Zero-Shot experiments?,"['CONTEXT: **Optimization and Prompting Strategies for Security Classification Models**: This chunk discusses the optimization of BERT variants through systematic hyperparameter tuning and explores the use of large language models (LLMs) for security requirement classification, focusing on zero-shot and few-shot prompting strategies to enhance task-specific performance without modifying the base model.\n\nCONTENT: 22 Yusuf G¨ ur et al.\nWe performed a systematic grid search using the Weights & Biases 12\nplatform to identify the optimal configuration for each BERT variant using\nthe validation dataset. The search space included the following parameters:\n–Maximum Sequence Length:[128, 256]tokens\n–Batch Size:[4, 8, 16]\n–Number of Epochs:[16, 24, 32]\n–Learning Rate:[1e-5, 2e-5, 3e-5]\n–Decision Threshold:[0.3, 0.4, 0.5]\nTo prevent overfitting, we monitored validation loss and implemented early\nstopping with a patience of 2–4 epochs. The checkpoint achieving the lowest\nvalidation loss for each model was selected for the final evaluation on the test\nset.\n4.3 Classification using LLM Models\nLLMs are transformer-based models trained on massive corpora for general-\npurpose natural language understanding and generation. This study adopted\nthe “pre-train, prompt, and predict” paradigm, which replaces traditional\n“pre-train, fine-tune” approaches (Liu et al., 2023a). Rather than adjusting\nthe model’s objective or architecture, prompt engineering is used to steer the\nmodel toward task-specific outputs through carefully designed textual inputs.\nPrompt engineering involves designing prompts that elicit accurate re-\nsponses for specific tasks. In zero-shot prompting, an LLM is directly used\nwithout any task-specific training. Few-shot prompting introduces a small\nnumber of labeled examples in the prompt, which allows the model to learn\nthe task pattern. This is particularly beneficial when labeled training data is\nlimited.\nFour main prompting strategies were proposed by (Liu et al., 2023a):\n–Tuning-free prompting: Requires no model changes, suitable for zero-shot\nsettings, but often demands complex prompt design.\n–Fixed-LLM prompt tuning: Involves learning soft prompts while keep-\ning the model fixed; effective for few-shot tasks but typically lacks inter-\npretability.\n–Fixed-prompt LLM tuning: Fine-tunes the model on a fixed prompt; im-\nproves performance in few-shot settings.\n–Prompt + LLM tuning: Jointly tunes both model and prompts; highly\nexpressive but prone to overfitting on small datasets.\nIn this study, we evaluated the first two of these strategies, as they do\nnot require modification of the base LLM’s weights. For our zero-shot experi-\nments, we implemented tuning-free prompting, relying on carefully engineered\nprompts to guide the models. For our few-shot analysis, our approach aligns\n12 https://wandb.ai/site', 'CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1', 'CONTEXT: **Evaluation of Model Challenges and Prompt Engineering Strategies**: This chunk discusses the challenges faced by models, particularly with underrepresented OWASP ASVS categories (e.g., V6 Cryptography, V12 Files/Resources), and outlines the experimental setup for prompt engineering in LLMs, including zero-shot and few-shot configurations, persona-based prompting, and strategies to ensure consistency and adherence to security standards.\n\nCONTENT: 26 Yusuf G¨ ur et al.\nshowed both low Recall (0.658) and low Precision (0.781), indicating it was\nboth missing true cases and incorrectly labeling other requirements as V6.\nModels struggle significantly with underrepresented categories, particularly\nV12 (File and Resources) and V6 (Stored Cryptography). This is evident in\nthe high number of false negatives, where the models fail to identify true\ninstances of these classes. For example, the baseline BERT model incorrectly\nclassified over half of the V12 requirements as negative (14 false negatives vs.\n13 true positives). Conversely, the matrices show that models often misclassify\nrequirements by incorrectly assigning them to other categories. The BERT\nBase model, for example, incorrectly labeled 92 different requirements as V10\n(Malicious Code) and 78 requirements as V5 (Malicious Input Handling).\n5.2 Experimental Setup for LLM Prompt Engineering\nWe adapted prompt engineering strategies from Ronanki (Ronanki et al.,\n2024), originally used for multi-class requirement classification. Two configu-\nrations were evaluated: zero-shot prompting (Appendix A), which relied solely\non task instructions and the input requirement, and few-shot prompting (Ap-\npendix B), which additionally incorporated labeled examples. The few-shot\nsetup used 30 training instances that were chosen to (i) capture multi-label\ncases where a single requirement spans multiple security categories, (ii) cover\nall 11 OWASP ASVS categories, and (iii) reflect requirements from different\nbusiness domains to preserve linguistic variation.\nPersona-based prompting was applied in both configurations by instruct-\ning the model to act as an experienced cybersecurity specialist. This alignment\nhelped reduce output variance by grounding responses in professional domain\nexpertise rather than general conversational patterns. The final prompt was\nobtained after five iterations. These iterations focused on three primary ar-\neas: (1) instruction clarity to prevent the model from defaulting to binary\nsecurity labels; (2) contextual grounding, by iteratively refining the OWASP\nASVS category definitions to ensure the model adhered to provided standards;\n(3) constraint formatting, to stabilize the PSV output structure for machine-\nreadability and ensure the inclusion of mandatory explanation fields. All ex-\nperiments were conducted with fixed parameters (Temperature = 0, Top-p =\n0.95) and repeated three times. The reported results are averaged to reduce\nthe impact of any minor, non-deterministic fluctuations in the models’ token\nselection during individual inferences.\nPrompt-based methods can be sensitive to phrasing, structure, and exam-\nple selection. To manage prompt sensitivity and contextual bias, we adopted a\nunified Persona–Context–Constraint strategy. A single prompt structure was\nused across all models, without model-specific tuning or iterative optimization\naimed at maximizing scores. The few-shot examples were chosen for representa-\ntiveness with respect to the OWASP ASVS taxonomy rather than performance\ngains.', 'CONTEXT: This chunk focuses on the evaluation of various language models, including open-source and commercial models, for implicit security requirements classification, detailing their technical specifications, rationale for selection, and experimental setup involving zero-shot and few-shot prompting strategies.\n\nCONTENT: Implicit Security Requirements Classification 23\nwith fixed-LLM prompt tuning, where we provided in-context examples within\nthe prompt to guide the model’s predictions. The latter two strategies involv-\ning model fine-tuning Fixed-prompt LLM tuning and Prompt + LLM tuning)\nwere not considered due to their high computational cost. The zero shot and\nfew shot prompts can be found in Appendix A and Appendix B.\nIn these experiments, we evaluated nine language models, including open-\nsource models deployed on local infrastructure and commercial models ac-\ncessed via external application programming interfaces (APIs). The technical\nspecifications of each model and the rationale for their selection are summa-\nrized in Table 7. The requirements were processed in batches of 15 because\nproviding the full set in a single prompt exceeded the models’ context limits.\nTable 6: Details and Rationale of the LLMs Used in the Study\nModel Name Description Rationale in Study\nOpen-Source Models\ngemma-3-27b\n(Dense Trans-\nformer; 27B\nParams)\nA Google-developed lan-\nguage model trained on\na large, diverse corpus of\nweb text.13 (The Google\nGemma Team, 2025)\nTo evaluate a powerful, next-generation\nopen-source model from a major AI research\nlab, establishing a baseline for locally deploy-\nable high-parameter models.\ngemma-3-4b\n(Dense Trans-\nformer; 4B\nParams)\nA smaller, efficient model\nfrom the Gemma 3 fam-\nily, designed for resource-\nconstrained environ-\nments.13 (The Google\nGemma Team, 2025)\nTo assess the performance of a highly ef-\nficient, small-scale model to determine if\nlower-parameter models can effectively han-\ndle complex security classification tasks.\nmeta.llama3-\n3-70b-instruct-\nv1:0\n(Dense Trans-\nformer; 70B\nParams)\nAPI version of Meta’s\nLlama 3 70B Instruct.\nAn open-weight model\npre-trained on over 15T\ntokens. 14 (AI at Meta,\n2024)\nTo benchmark against a leading open-weight\nmodel known for strong reasoning and\ninstruction-following capabilities, represent-\ning the state-of-the-art in non-proprietary\nmodels.\nDeepSeek-R1\n(Mixture-of-\nExperts (MoE))\nAn API-accessible model\nfrom DeepSeek AI. As-\nsumed to be based on the\nDeepSeek-V2 architecture\n(236B total/21B active\nparams). 15 (DeepSeek AI,\n2024)\nTo include a model with a different architec-\nture (MoE) that represents an alternative,\nhighly efficient approach to scaling, specif-\nically testing its reasoning capabilities in\nsecurity contexts.\nCommercial Models (API Access)\n13 https://blog.google/technology/developers/\n14 https://ai.meta.com/blog/meta-llama-3/\n15 https://deepseek.com/', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference', 'CONTEXT: **Comparison of Fine-Tuned Models and LLMs for Security Requirements Classification**: This chunk discusses the performance comparison between fine-tuned transformer models (e.g., BERT) and few-shot prompting with LLMs (e.g., Gemini 2.0) for classifying implicit security requirements in SRS documents, emphasizing the practicality of LLMs as a resource-efficient alternative while highlighting challenges in Security Requirements Engineering (SRE).\n\nCONTENT: 2 Yusuf G¨ ur et al.\ntional fine-tuned transformer models and contemporary Large Language Mod-\nels (LLMs) employing few-shot and zero-shot prompt engineering strategies.\nThe results show that a few-shot prompting with Gemini 2.0 achieves a macro-\naverage F1 score of 0.941, directly comparable to the fine-tuned BERT model’s\n0.942. This study culminates in two primary findings: first, the validation and\npublication of the ASRD, a high-granularity, multi-label dataset for implicit\nsecurity requirements based on OWASP ASVS V2-V13; and second, the di-\nrect comparison demonstrating that few-shot Large Language Models (LLMs)\nachieve competitive multi-label classification performance (Macro-F1 0.941)\nnearly equal to resource-intensive fine-tuned transformer models (Macro-F1\n0.942). This confirms that LLMs represent a highly practical and resource-\nsaving strategy for automating the identification of embedded (implicit) secu-\nrity requirements for software security in industrial SRS documents\nKeywordsCybersecurity requirement elicitation·OWASP based security\nrequirement classification·OWASP ASVS-based Requirement Labeling·\nLLM based classification\n1 Introduction\nRequirements Engineering (RE) concerns the identification, documentation,\nand management of software requirements (Sommerville and Sawyer, 1997).\nThe increasing interconnectivity of information systems forces organizations\nto provide secure services in cyberspace. Integrating security during initial\nrequirements analysis is essential to proactively mitigate risks, reduce vulner-\nabilities, and reduce the high costs associated with downstream remediation\n(Villamizar et al., 2018). This proactive approach is central to the ”Shift-\nLeft” security paradigm, which advocates for the identification and mitigation\nof vulnerabilities as early as possible in the Software Development Life Cycle\n(SDLC).\nAlthough Security Requirements Engineering (SRE) has matured as a dis-\ncipline, its effective application in practice remains challenging. The issue is\nnot the absence of security considerations, but the difficulty of ensuring that\nsecurity requirements are properly validated and verified. An empirical investi-\ngation that combines a systematic literature review with a survey of 58 indus-\ntry professionals highlights this gap (Alam et al., 2025). While practitioners\nreported a moderate understanding of SRE practices, Security Requirements\nAssurance (SRA) was found to be poorly understood and rarely applied in\nindustrial contexts. The study concludes that validating and ensuring security\nrequirements remains a major and unresolved challenge in practice.\nThis assurance gap persists due to the documented lack of specialized se-\ncurity training for developers in early-phase RE (Andrade et al., 2023). The\ntask relies heavily on scarce specialized expertise and time-intensive manual\nanalysis. The main challenge is that critical security requirements are often not\nexplicitly stated. Instead, they are implicitly embedded within standard func-\ntional descriptions. For example, a seemingly simple functional requirement,']","The prompting strategy used for the Zero-Shot experiments was **tuning-free prompting**. This approach involves using carefully engineered textual prompts to guide the model toward task-specific outputs without modifying the base model's weights. It relies solely on task instructions and the input requirement, without any task-specific training or labeled examples. This strategy was chosen for its simplicity and suitability for zero-shot settings, as it does not require model changes but often demands complex prompt design.

**Source:** temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf","Tuning-free prompting was used, relying on carefully engineered prompts to guide the models without any task-specific training[cite: 401, 407].",,,
What prompting strategy was used for the Few-Shot experiments?,"['CONTEXT: **Optimization and Prompting Strategies for Security Classification Models**: This chunk discusses the optimization of BERT variants through systematic hyperparameter tuning and explores the use of large language models (LLMs) for security requirement classification, focusing on zero-shot and few-shot prompting strategies to enhance task-specific performance without modifying the base model.\n\nCONTENT: 22 Yusuf G¨ ur et al.\nWe performed a systematic grid search using the Weights & Biases 12\nplatform to identify the optimal configuration for each BERT variant using\nthe validation dataset. The search space included the following parameters:\n–Maximum Sequence Length:[128, 256]tokens\n–Batch Size:[4, 8, 16]\n–Number of Epochs:[16, 24, 32]\n–Learning Rate:[1e-5, 2e-5, 3e-5]\n–Decision Threshold:[0.3, 0.4, 0.5]\nTo prevent overfitting, we monitored validation loss and implemented early\nstopping with a patience of 2–4 epochs. The checkpoint achieving the lowest\nvalidation loss for each model was selected for the final evaluation on the test\nset.\n4.3 Classification using LLM Models\nLLMs are transformer-based models trained on massive corpora for general-\npurpose natural language understanding and generation. This study adopted\nthe “pre-train, prompt, and predict” paradigm, which replaces traditional\n“pre-train, fine-tune” approaches (Liu et al., 2023a). Rather than adjusting\nthe model’s objective or architecture, prompt engineering is used to steer the\nmodel toward task-specific outputs through carefully designed textual inputs.\nPrompt engineering involves designing prompts that elicit accurate re-\nsponses for specific tasks. In zero-shot prompting, an LLM is directly used\nwithout any task-specific training. Few-shot prompting introduces a small\nnumber of labeled examples in the prompt, which allows the model to learn\nthe task pattern. This is particularly beneficial when labeled training data is\nlimited.\nFour main prompting strategies were proposed by (Liu et al., 2023a):\n–Tuning-free prompting: Requires no model changes, suitable for zero-shot\nsettings, but often demands complex prompt design.\n–Fixed-LLM prompt tuning: Involves learning soft prompts while keep-\ning the model fixed; effective for few-shot tasks but typically lacks inter-\npretability.\n–Fixed-prompt LLM tuning: Fine-tunes the model on a fixed prompt; im-\nproves performance in few-shot settings.\n–Prompt + LLM tuning: Jointly tunes both model and prompts; highly\nexpressive but prone to overfitting on small datasets.\nIn this study, we evaluated the first two of these strategies, as they do\nnot require modification of the base LLM’s weights. For our zero-shot experi-\nments, we implemented tuning-free prompting, relying on carefully engineered\nprompts to guide the models. For our few-shot analysis, our approach aligns\n12 https://wandb.ai/site', 'CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1', 'CONTEXT: **Evaluation of Model Challenges and Prompt Engineering Strategies**: This chunk discusses the challenges faced by models, particularly with underrepresented OWASP ASVS categories (e.g., V6 Cryptography, V12 Files/Resources), and outlines the experimental setup for prompt engineering in LLMs, including zero-shot and few-shot configurations, persona-based prompting, and strategies to ensure consistency and adherence to security standards.\n\nCONTENT: 26 Yusuf G¨ ur et al.\nshowed both low Recall (0.658) and low Precision (0.781), indicating it was\nboth missing true cases and incorrectly labeling other requirements as V6.\nModels struggle significantly with underrepresented categories, particularly\nV12 (File and Resources) and V6 (Stored Cryptography). This is evident in\nthe high number of false negatives, where the models fail to identify true\ninstances of these classes. For example, the baseline BERT model incorrectly\nclassified over half of the V12 requirements as negative (14 false negatives vs.\n13 true positives). Conversely, the matrices show that models often misclassify\nrequirements by incorrectly assigning them to other categories. The BERT\nBase model, for example, incorrectly labeled 92 different requirements as V10\n(Malicious Code) and 78 requirements as V5 (Malicious Input Handling).\n5.2 Experimental Setup for LLM Prompt Engineering\nWe adapted prompt engineering strategies from Ronanki (Ronanki et al.,\n2024), originally used for multi-class requirement classification. Two configu-\nrations were evaluated: zero-shot prompting (Appendix A), which relied solely\non task instructions and the input requirement, and few-shot prompting (Ap-\npendix B), which additionally incorporated labeled examples. The few-shot\nsetup used 30 training instances that were chosen to (i) capture multi-label\ncases where a single requirement spans multiple security categories, (ii) cover\nall 11 OWASP ASVS categories, and (iii) reflect requirements from different\nbusiness domains to preserve linguistic variation.\nPersona-based prompting was applied in both configurations by instruct-\ning the model to act as an experienced cybersecurity specialist. This alignment\nhelped reduce output variance by grounding responses in professional domain\nexpertise rather than general conversational patterns. The final prompt was\nobtained after five iterations. These iterations focused on three primary ar-\neas: (1) instruction clarity to prevent the model from defaulting to binary\nsecurity labels; (2) contextual grounding, by iteratively refining the OWASP\nASVS category definitions to ensure the model adhered to provided standards;\n(3) constraint formatting, to stabilize the PSV output structure for machine-\nreadability and ensure the inclusion of mandatory explanation fields. All ex-\nperiments were conducted with fixed parameters (Temperature = 0, Top-p =\n0.95) and repeated three times. The reported results are averaged to reduce\nthe impact of any minor, non-deterministic fluctuations in the models’ token\nselection during individual inferences.\nPrompt-based methods can be sensitive to phrasing, structure, and exam-\nple selection. To manage prompt sensitivity and contextual bias, we adopted a\nunified Persona–Context–Constraint strategy. A single prompt structure was\nused across all models, without model-specific tuning or iterative optimization\naimed at maximizing scores. The few-shot examples were chosen for representa-\ntiveness with respect to the OWASP ASVS taxonomy rather than performance\ngains.', 'CONTEXT: This chunk focuses on the evaluation of various language models, including open-source and commercial models, for implicit security requirements classification, detailing their technical specifications, rationale for selection, and experimental setup involving zero-shot and few-shot prompting strategies.\n\nCONTENT: Implicit Security Requirements Classification 23\nwith fixed-LLM prompt tuning, where we provided in-context examples within\nthe prompt to guide the model’s predictions. The latter two strategies involv-\ning model fine-tuning Fixed-prompt LLM tuning and Prompt + LLM tuning)\nwere not considered due to their high computational cost. The zero shot and\nfew shot prompts can be found in Appendix A and Appendix B.\nIn these experiments, we evaluated nine language models, including open-\nsource models deployed on local infrastructure and commercial models ac-\ncessed via external application programming interfaces (APIs). The technical\nspecifications of each model and the rationale for their selection are summa-\nrized in Table 7. The requirements were processed in batches of 15 because\nproviding the full set in a single prompt exceeded the models’ context limits.\nTable 6: Details and Rationale of the LLMs Used in the Study\nModel Name Description Rationale in Study\nOpen-Source Models\ngemma-3-27b\n(Dense Trans-\nformer; 27B\nParams)\nA Google-developed lan-\nguage model trained on\na large, diverse corpus of\nweb text.13 (The Google\nGemma Team, 2025)\nTo evaluate a powerful, next-generation\nopen-source model from a major AI research\nlab, establishing a baseline for locally deploy-\nable high-parameter models.\ngemma-3-4b\n(Dense Trans-\nformer; 4B\nParams)\nA smaller, efficient model\nfrom the Gemma 3 fam-\nily, designed for resource-\nconstrained environ-\nments.13 (The Google\nGemma Team, 2025)\nTo assess the performance of a highly ef-\nficient, small-scale model to determine if\nlower-parameter models can effectively han-\ndle complex security classification tasks.\nmeta.llama3-\n3-70b-instruct-\nv1:0\n(Dense Trans-\nformer; 70B\nParams)\nAPI version of Meta’s\nLlama 3 70B Instruct.\nAn open-weight model\npre-trained on over 15T\ntokens. 14 (AI at Meta,\n2024)\nTo benchmark against a leading open-weight\nmodel known for strong reasoning and\ninstruction-following capabilities, represent-\ning the state-of-the-art in non-proprietary\nmodels.\nDeepSeek-R1\n(Mixture-of-\nExperts (MoE))\nAn API-accessible model\nfrom DeepSeek AI. As-\nsumed to be based on the\nDeepSeek-V2 architecture\n(236B total/21B active\nparams). 15 (DeepSeek AI,\n2024)\nTo include a model with a different architec-\nture (MoE) that represents an alternative,\nhighly efficient approach to scaling, specif-\nically testing its reasoning capabilities in\nsecurity contexts.\nCommercial Models (API Access)\n13 https://blog.google/technology/developers/\n14 https://ai.meta.com/blog/meta-llama-3/\n15 https://deepseek.com/', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to', 'CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the']","The prompting strategy used for the Few-Shot experiments involved incorporating a small number of labeled examples into the prompt to guide the model's predictions. Specifically:

1. **Few-Shot Prompting Setup**:  
   - The few-shot setup included 30 training instances selected to:
     - Capture multi-label cases where a single requirement spans multiple security categories.
     - Cover all 11 OWASP ASVS categories.
     - Reflect requirements from different business domains to preserve linguistic variation.
   - Persona-based prompting was applied, instructing the model to act as an experienced cybersecurity specialist. This alignment helped reduce output variance and ground responses in professional domain expertise.

2. **Prompt Design and Refinement**:  
   - The final prompt was iteratively refined over five iterations, focusing on:
     - Instruction clarity to prevent binary security labels.
     - Contextual grounding by refining OWASP ASVS category definitions.
     - Constraint formatting to stabilize output structure and ensure machine-readability.

3. **Unified Prompting Strategy**:  
   - A unified Persona–Context–Constraint strategy was adopted to manage prompt sensitivity and contextual bias. A single prompt structure was used across all models without model-specific tuning.

4. **Experimental Parameters**:  
   - Fixed parameters were used (e.g., Temperature = 0, Top-p = 0.95), and experiments were repeated three times with averaged results to reduce non-deterministic fluctuations.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","Fixed-LLM prompt tuning was used, where in-context examples were provided within the prompt to guide the model's predictions[cite: 402, 408].",,,
How many examples were used in the Few-Shot prompts?,"['CONTEXT: This chunk provides a detailed example of a few-shot prompt designed for classifying software requirements based on the OWASP ASVS 4.0.3-tr categories, demonstrating how project requirements are analyzed and aligned with security standards using AI models, particularly in the context of implicit security requirements classification.\n\nCONTENT: - <V2> through <V13>: (either 1 (if the requirement aligns with the category) or 0 (if it doesn\'t)) \n   - Explanation (string) \n***** \nInput (PSV - The requirements you want to classify): \n1|Sistem, kullanıcının konaklama ücret tipi bilgilerini girmesini sağlayacaktır \n3|Sistem, kullanıcının konaklama ücret tipi bilgilerini silmesini sağlayacaktır \n5|Sistem, kullanıcının oda tiplerini güncellemesini sağlayacaktır \n16|Sistem, kullanıcının otele giriş nedeni bilgisini girmesini sağlayacaktır \n22|Sistem, kullanıcının çalışma tip bilgisini girmesini sağlayacaktır \n28|Sistem, kullanıcının otel rezervasyon para yatırma süre bilgisini girmesini sağlayacaktır \n31|Sistem, kullanıcının misafir türü kaydetmesini sağlayacaktır. \n37|Sistem, kullanıcının oda tiplerini listelemesini sağlayacaktır. \n41|Sistem, kullanıcının otele giriş neden bilgilerini listelemesini sağlayacaktır. \n44|Sistem, kullanıcının arananlar bilgisini listelemesini sağlayacaktır. \n52|Sistem, kullanıcının yakınlık tanım bilgisini seçilen kriterlere göre sorgulayabilmesini sağlayacaktır. \n54|Sistem, kullanıcının arananlar bilgisini seçilen kriterlere göre sorgulayabilmesini sağlayacaktır. \n55|Sistem, kullanıcının otel rezervasyon iptal süre bilgisini seçilen kriterlere göre sorgulayabilmesini \nsağlayacaktır. \n65|Sistem, kullanıcının otelin katlarındaki oda doluluk oranlarını seçilen kriterlere göre sorgulayabilmesini \nsağlayacaktır. \n70|Sistem, kullanıcının otel raporlarında kullanıcı imza bilgisi girmesini sağlayacaktır.\n\nFEW SHOTS PROMPT \nPersona: You are an experienced cybersecurity specialist with extensive knowledge of the OWASP ASVS \n4.0.3-tr and secure software development practices. You are meticulous, detail-oriented, and focused on \nidentifying potential security vulnerabilities and ensuring that applications meet the highest security \nstandards. \n \n********* \n \nTask: Classify and analyze project requirements based on their security and functional aspects from a \ncybersecurity perspective, aligning with the OWASP Application Security Verification Standard (ASVS) \n4.0.3-tr. Provide detailed explanations for all classifications and potential security concerns. \n \n********* \n \nInstructions: \n \n1.  You will receive a list of project requirements in PSV (Pipe Separated Values) format. \n2.  Each line in the input will represent a requirement in “Requirement Number|Requirement Description” \nformat and will contain: \n    * Requirement Number (integer) \n    * Requirement Description (string) \n3.  For each requirement, classify it into the categories defined in the table below, which are derived from \nthe OWASP ASVS 4.0.3-tr. \n4.  Output the classification in PSV format, including all columns from the table, AND an ""Explanation"" \ncolumn within a new line. \n5.  Use ""1"" if the requirement aligns with the ASVS category, and ""0"" if it does not. \n6.  Provide a concise explanation for each classification, justifying why you assigned a ""1"" or ""0"" to each \ncategory. \n7.  Ensure the output has the same number of rows as the input. \n8.  Use the Extra Information for Choosing Categories to aid classification. \n \n********* \n \nContext: \n \nThe categories below are based on the OWASP Application Security Verification Standard (ASVS) 4.0.3-tr. \nRefer to the ASVS documentation for detailed information on each category. The specific ASVS levels (L1, \nL2, L3) are not explicitly represented in the columns, but the categories themselves align with the ASVS \nrequirements. \n \n********* \n \nCategories (Aligned with OWASP ASVS 4.0.3-tr): \n \nV2, Kimlik Doğrulama (Identity Verification) - Covers requirements related to user authentication, \npassword management, and session handling (e.g., ASVS 2.0). \nV3, Oturum Yönetimi (Session Management) - Covers requirements related to secure session handling, \nincluding session timeouts, protection against session fixation, and secure cookie management (e.g., ASVS \n3.0). \nImplicit Security Requirements Classification 47\nB Few-shot Prompt', 'CONTEXT: This chunk focuses on the evaluation of various language models, including open-source and commercial models, for implicit security requirements classification, detailing their technical specifications, rationale for selection, and experimental setup involving zero-shot and few-shot prompting strategies.\n\nCONTENT: Implicit Security Requirements Classification 23\nwith fixed-LLM prompt tuning, where we provided in-context examples within\nthe prompt to guide the model’s predictions. The latter two strategies involv-\ning model fine-tuning Fixed-prompt LLM tuning and Prompt + LLM tuning)\nwere not considered due to their high computational cost. The zero shot and\nfew shot prompts can be found in Appendix A and Appendix B.\nIn these experiments, we evaluated nine language models, including open-\nsource models deployed on local infrastructure and commercial models ac-\ncessed via external application programming interfaces (APIs). The technical\nspecifications of each model and the rationale for their selection are summa-\nrized in Table 7. The requirements were processed in batches of 15 because\nproviding the full set in a single prompt exceeded the models’ context limits.\nTable 6: Details and Rationale of the LLMs Used in the Study\nModel Name Description Rationale in Study\nOpen-Source Models\ngemma-3-27b\n(Dense Trans-\nformer; 27B\nParams)\nA Google-developed lan-\nguage model trained on\na large, diverse corpus of\nweb text.13 (The Google\nGemma Team, 2025)\nTo evaluate a powerful, next-generation\nopen-source model from a major AI research\nlab, establishing a baseline for locally deploy-\nable high-parameter models.\ngemma-3-4b\n(Dense Trans-\nformer; 4B\nParams)\nA smaller, efficient model\nfrom the Gemma 3 fam-\nily, designed for resource-\nconstrained environ-\nments.13 (The Google\nGemma Team, 2025)\nTo assess the performance of a highly ef-\nficient, small-scale model to determine if\nlower-parameter models can effectively han-\ndle complex security classification tasks.\nmeta.llama3-\n3-70b-instruct-\nv1:0\n(Dense Trans-\nformer; 70B\nParams)\nAPI version of Meta’s\nLlama 3 70B Instruct.\nAn open-weight model\npre-trained on over 15T\ntokens. 14 (AI at Meta,\n2024)\nTo benchmark against a leading open-weight\nmodel known for strong reasoning and\ninstruction-following capabilities, represent-\ning the state-of-the-art in non-proprietary\nmodels.\nDeepSeek-R1\n(Mixture-of-\nExperts (MoE))\nAn API-accessible model\nfrom DeepSeek AI. As-\nsumed to be based on the\nDeepSeek-V2 architecture\n(236B total/21B active\nparams). 15 (DeepSeek AI,\n2024)\nTo include a model with a different architec-\nture (MoE) that represents an alternative,\nhighly efficient approach to scaling, specif-\nically testing its reasoning capabilities in\nsecurity contexts.\nCommercial Models (API Access)\n13 https://blog.google/technology/developers/\n14 https://ai.meta.com/blog/meta-llama-3/\n15 https://deepseek.com/', 'CONTEXT: **Evaluation of Model Challenges and Prompt Engineering Strategies**: This chunk discusses the challenges faced by models, particularly with underrepresented OWASP ASVS categories (e.g., V6 Cryptography, V12 Files/Resources), and outlines the experimental setup for prompt engineering in LLMs, including zero-shot and few-shot configurations, persona-based prompting, and strategies to ensure consistency and adherence to security standards.\n\nCONTENT: 26 Yusuf G¨ ur et al.\nshowed both low Recall (0.658) and low Precision (0.781), indicating it was\nboth missing true cases and incorrectly labeling other requirements as V6.\nModels struggle significantly with underrepresented categories, particularly\nV12 (File and Resources) and V6 (Stored Cryptography). This is evident in\nthe high number of false negatives, where the models fail to identify true\ninstances of these classes. For example, the baseline BERT model incorrectly\nclassified over half of the V12 requirements as negative (14 false negatives vs.\n13 true positives). Conversely, the matrices show that models often misclassify\nrequirements by incorrectly assigning them to other categories. The BERT\nBase model, for example, incorrectly labeled 92 different requirements as V10\n(Malicious Code) and 78 requirements as V5 (Malicious Input Handling).\n5.2 Experimental Setup for LLM Prompt Engineering\nWe adapted prompt engineering strategies from Ronanki (Ronanki et al.,\n2024), originally used for multi-class requirement classification. Two configu-\nrations were evaluated: zero-shot prompting (Appendix A), which relied solely\non task instructions and the input requirement, and few-shot prompting (Ap-\npendix B), which additionally incorporated labeled examples. The few-shot\nsetup used 30 training instances that were chosen to (i) capture multi-label\ncases where a single requirement spans multiple security categories, (ii) cover\nall 11 OWASP ASVS categories, and (iii) reflect requirements from different\nbusiness domains to preserve linguistic variation.\nPersona-based prompting was applied in both configurations by instruct-\ning the model to act as an experienced cybersecurity specialist. This alignment\nhelped reduce output variance by grounding responses in professional domain\nexpertise rather than general conversational patterns. The final prompt was\nobtained after five iterations. These iterations focused on three primary ar-\neas: (1) instruction clarity to prevent the model from defaulting to binary\nsecurity labels; (2) contextual grounding, by iteratively refining the OWASP\nASVS category definitions to ensure the model adhered to provided standards;\n(3) constraint formatting, to stabilize the PSV output structure for machine-\nreadability and ensure the inclusion of mandatory explanation fields. All ex-\nperiments were conducted with fixed parameters (Temperature = 0, Top-p =\n0.95) and repeated three times. The reported results are averaged to reduce\nthe impact of any minor, non-deterministic fluctuations in the models’ token\nselection during individual inferences.\nPrompt-based methods can be sensitive to phrasing, structure, and exam-\nple selection. To manage prompt sensitivity and contextual bias, we adopted a\nunified Persona–Context–Constraint strategy. A single prompt structure was\nused across all models, without model-specific tuning or iterative optimization\naimed at maximizing scores. The few-shot examples were chosen for representa-\ntiveness with respect to the OWASP ASVS taxonomy rather than performance\ngains.', 'CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1', 'CONTEXT: **Optimization and Prompting Strategies for Security Classification Models**: This chunk discusses the optimization of BERT variants through systematic hyperparameter tuning and explores the use of large language models (LLMs) for security requirement classification, focusing on zero-shot and few-shot prompting strategies to enhance task-specific performance without modifying the base model.\n\nCONTENT: 22 Yusuf G¨ ur et al.\nWe performed a systematic grid search using the Weights & Biases 12\nplatform to identify the optimal configuration for each BERT variant using\nthe validation dataset. The search space included the following parameters:\n–Maximum Sequence Length:[128, 256]tokens\n–Batch Size:[4, 8, 16]\n–Number of Epochs:[16, 24, 32]\n–Learning Rate:[1e-5, 2e-5, 3e-5]\n–Decision Threshold:[0.3, 0.4, 0.5]\nTo prevent overfitting, we monitored validation loss and implemented early\nstopping with a patience of 2–4 epochs. The checkpoint achieving the lowest\nvalidation loss for each model was selected for the final evaluation on the test\nset.\n4.3 Classification using LLM Models\nLLMs are transformer-based models trained on massive corpora for general-\npurpose natural language understanding and generation. This study adopted\nthe “pre-train, prompt, and predict” paradigm, which replaces traditional\n“pre-train, fine-tune” approaches (Liu et al., 2023a). Rather than adjusting\nthe model’s objective or architecture, prompt engineering is used to steer the\nmodel toward task-specific outputs through carefully designed textual inputs.\nPrompt engineering involves designing prompts that elicit accurate re-\nsponses for specific tasks. In zero-shot prompting, an LLM is directly used\nwithout any task-specific training. Few-shot prompting introduces a small\nnumber of labeled examples in the prompt, which allows the model to learn\nthe task pattern. This is particularly beneficial when labeled training data is\nlimited.\nFour main prompting strategies were proposed by (Liu et al., 2023a):\n–Tuning-free prompting: Requires no model changes, suitable for zero-shot\nsettings, but often demands complex prompt design.\n–Fixed-LLM prompt tuning: Involves learning soft prompts while keep-\ning the model fixed; effective for few-shot tasks but typically lacks inter-\npretability.\n–Fixed-prompt LLM tuning: Fine-tunes the model on a fixed prompt; im-\nproves performance in few-shot settings.\n–Prompt + LLM tuning: Jointly tunes both model and prompts; highly\nexpressive but prone to overfitting on small datasets.\nIn this study, we evaluated the first two of these strategies, as they do\nnot require modification of the base LLM’s weights. For our zero-shot experi-\nments, we implemented tuning-free prompting, relying on carefully engineered\nprompts to guide the models. For our few-shot analysis, our approach aligns\n12 https://wandb.ai/site', 'CONTEXT: This chunk provides a detailed example of a **zero-shot prompt** designed for classifying project requirements based on the OWASP ASVS 4.0.3-tr categories, highlighting the methodology for aligning security requirements with specific ASVS standards and offering explanations for classifications.\n\nCONTENT: Implicit Security Requirements Classification 43\nAdvanced Intelligent Systems 6(7):2300798\nWen SF, Katt B (2023) A quantitative security evaluation and analysis model\nfor web applications based on owasp application security verification stan-\ndard. Computers & Security 135:103532, DOI 10.1016/j.cose.2023.103532\nWhite J, Hays S, Fu Q, Spencer-Smith J, Schmidt DC (2024) Chatgpt prompt\npatterns for improving code quality, refactoring, requirements elicitation,\nand software design. In: Generative AI for Effective Software Development,\nSpringer, pp 71–108\nYe J, Yao Z, Huang Z, Pan L, Liu J, Bai Y, Xin A, Weichuan L, Che X,\nHou L, et al. (2025) How do transformers learn implicit reasoning? In: The\nThirty-ninth Annual Conference on Neural Information Processing Systems\nZadenoori MA, Dabrowski J, Alhoshan W, Zhao L, Ferrari A (2025) Large\nlanguage models (llms) for requirements engineering (re): A systematic lit-\nerature review. arXiv preprint arXiv:250911446\nZhou X, Li Y, Chen H (2025) The transformer architecture: Foundations and\nadvances. IEEE Transactions on Neural Networks and Learning Systems\nForthcoming\nZhu Y, Wang J, Liu K (2025) Emergent abilities of large language models:\nIn-context learning, instruction following, and reasoning. Nature Machine\nIntelligence In press\n Lukasiewicz K, Cyga´ nska S (2019) Security-oriented agile approach with\nagilesafe and owasp asvs. In: 2019 Federated Conference on Computer\nScience and Information Systems (FedCSIS), IEEE, pp 653–662, DOI\n10.23919/FedCSIS.2019.00012\n\nZERO SHOT PROMPT \n \nPersona: You are an experienced cybersecurity specialist with extensive knowledge of the OWASP ASVS \n4.0.3-tr and secure software development practices. You are meticulous, detail-oriented, and focused on \nidentifying potential security vulnerabilities and ensuring that applications meet the highest security \nstandards. \n \n********* \n \nTask: Classify and analyze project requirements based on their security and functional aspects from a \ncybersecurity perspective, aligning with the OWASP Application Security Verification Standard (ASVS) \n4.0.3-tr. Provide detailed explanations for all classifications and potential security concerns. \n \n********* \n \nInstructions: \n \n1.  You will receive a list of project requirements in PSV (Pipe Separated Values) format. \n2.  Each line in the input will represent a requirement in “Requirement Number|Requirement Description” \nformat and will contain: \n    * Requirement Number (integer) \n    * Requirement Description (string) \n3.  For each requirement, classify it into the categories defined in the table below, which are derived from \nthe OWASP ASVS 4.0.3-tr. \n4.  Output the classification in PSV format, including all columns from the table, AND an ""Explanation"" \ncolumn within a new line. \n5.  Use ""1"" if the requirement aligns with the ASVS category, and ""0"" if it does not. \n6.  Provide a concise explanation for each classification, justifying why you assigned a ""1"" or ""0"" to each \ncategory. \n7.  Ensure the output has the same number of rows as the input. \n8.  Use the Extra Information for Choosing Categories to aid classification. \n \n********* \n \nContext: \n \nThe categories below are based on the OWASP Application Security Verification Standard (ASVS) 4.0.3-tr. \nRefer to the ASVS documentation for detailed information on each category. The specific ASVS levels (L1, \nL2, L3) are not explicitly represented in the columns, but the categories themselves align with the ASVS \nrequirements. \n \n********* \n \nCategories (Aligned with OWASP ASVS 4.0.3-tr): \n \nV2, Kimlik Doğrulama (Identity Verification) - Covers requirements related to user authentication, \npassword management, and session handling (e.g., ASVS 2.0). \nV3, Oturum Yönetimi (Session Management) - Covers requirements related to secure session handling, \nincluding session timeouts, protection against session fixation, and secure cookie management (e.g., ASVS \n44 Yusuf G¨ ur et al.\nA Zero-shot Prompt', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to']","Based on the provided Context, the few-shot prompts used **30 examples**. These examples were chosen to capture multi-label cases, cover all 11 OWASP ASVS categories, and reflect requirements from different business domains to ensure linguistic variation. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)",Approximately 30 labeled examples were used in the few-shot setup[cite: 460].,,,
What specific elements were included in the 'Persona-Context-Constraint' prompt structure?,"['CONTEXT: This chunk provides a detailed example of a **zero-shot prompt** designed for classifying project requirements based on the OWASP ASVS 4.0.3-tr categories, highlighting the methodology for aligning security requirements with specific ASVS standards and offering explanations for classifications.\n\nCONTENT: Implicit Security Requirements Classification 43\nAdvanced Intelligent Systems 6(7):2300798\nWen SF, Katt B (2023) A quantitative security evaluation and analysis model\nfor web applications based on owasp application security verification stan-\ndard. Computers & Security 135:103532, DOI 10.1016/j.cose.2023.103532\nWhite J, Hays S, Fu Q, Spencer-Smith J, Schmidt DC (2024) Chatgpt prompt\npatterns for improving code quality, refactoring, requirements elicitation,\nand software design. In: Generative AI for Effective Software Development,\nSpringer, pp 71–108\nYe J, Yao Z, Huang Z, Pan L, Liu J, Bai Y, Xin A, Weichuan L, Che X,\nHou L, et al. (2025) How do transformers learn implicit reasoning? In: The\nThirty-ninth Annual Conference on Neural Information Processing Systems\nZadenoori MA, Dabrowski J, Alhoshan W, Zhao L, Ferrari A (2025) Large\nlanguage models (llms) for requirements engineering (re): A systematic lit-\nerature review. arXiv preprint arXiv:250911446\nZhou X, Li Y, Chen H (2025) The transformer architecture: Foundations and\nadvances. IEEE Transactions on Neural Networks and Learning Systems\nForthcoming\nZhu Y, Wang J, Liu K (2025) Emergent abilities of large language models:\nIn-context learning, instruction following, and reasoning. Nature Machine\nIntelligence In press\n Lukasiewicz K, Cyga´ nska S (2019) Security-oriented agile approach with\nagilesafe and owasp asvs. In: 2019 Federated Conference on Computer\nScience and Information Systems (FedCSIS), IEEE, pp 653–662, DOI\n10.23919/FedCSIS.2019.00012\n\nZERO SHOT PROMPT \n \nPersona: You are an experienced cybersecurity specialist with extensive knowledge of the OWASP ASVS \n4.0.3-tr and secure software development practices. You are meticulous, detail-oriented, and focused on \nidentifying potential security vulnerabilities and ensuring that applications meet the highest security \nstandards. \n \n********* \n \nTask: Classify and analyze project requirements based on their security and functional aspects from a \ncybersecurity perspective, aligning with the OWASP Application Security Verification Standard (ASVS) \n4.0.3-tr. Provide detailed explanations for all classifications and potential security concerns. \n \n********* \n \nInstructions: \n \n1.  You will receive a list of project requirements in PSV (Pipe Separated Values) format. \n2.  Each line in the input will represent a requirement in “Requirement Number|Requirement Description” \nformat and will contain: \n    * Requirement Number (integer) \n    * Requirement Description (string) \n3.  For each requirement, classify it into the categories defined in the table below, which are derived from \nthe OWASP ASVS 4.0.3-tr. \n4.  Output the classification in PSV format, including all columns from the table, AND an ""Explanation"" \ncolumn within a new line. \n5.  Use ""1"" if the requirement aligns with the ASVS category, and ""0"" if it does not. \n6.  Provide a concise explanation for each classification, justifying why you assigned a ""1"" or ""0"" to each \ncategory. \n7.  Ensure the output has the same number of rows as the input. \n8.  Use the Extra Information for Choosing Categories to aid classification. \n \n********* \n \nContext: \n \nThe categories below are based on the OWASP Application Security Verification Standard (ASVS) 4.0.3-tr. \nRefer to the ASVS documentation for detailed information on each category. The specific ASVS levels (L1, \nL2, L3) are not explicitly represented in the columns, but the categories themselves align with the ASVS \nrequirements. \n \n********* \n \nCategories (Aligned with OWASP ASVS 4.0.3-tr): \n \nV2, Kimlik Doğrulama (Identity Verification) - Covers requirements related to user authentication, \npassword management, and session handling (e.g., ASVS 2.0). \nV3, Oturum Yönetimi (Session Management) - Covers requirements related to secure session handling, \nincluding session timeouts, protection against session fixation, and secure cookie management (e.g., ASVS \n44 Yusuf G¨ ur et al.\nA Zero-shot Prompt', 'CONTEXT: **Evaluation of Model Challenges and Prompt Engineering Strategies**: This chunk discusses the challenges faced by models, particularly with underrepresented OWASP ASVS categories (e.g., V6 Cryptography, V12 Files/Resources), and outlines the experimental setup for prompt engineering in LLMs, including zero-shot and few-shot configurations, persona-based prompting, and strategies to ensure consistency and adherence to security standards.\n\nCONTENT: 26 Yusuf G¨ ur et al.\nshowed both low Recall (0.658) and low Precision (0.781), indicating it was\nboth missing true cases and incorrectly labeling other requirements as V6.\nModels struggle significantly with underrepresented categories, particularly\nV12 (File and Resources) and V6 (Stored Cryptography). This is evident in\nthe high number of false negatives, where the models fail to identify true\ninstances of these classes. For example, the baseline BERT model incorrectly\nclassified over half of the V12 requirements as negative (14 false negatives vs.\n13 true positives). Conversely, the matrices show that models often misclassify\nrequirements by incorrectly assigning them to other categories. The BERT\nBase model, for example, incorrectly labeled 92 different requirements as V10\n(Malicious Code) and 78 requirements as V5 (Malicious Input Handling).\n5.2 Experimental Setup for LLM Prompt Engineering\nWe adapted prompt engineering strategies from Ronanki (Ronanki et al.,\n2024), originally used for multi-class requirement classification. Two configu-\nrations were evaluated: zero-shot prompting (Appendix A), which relied solely\non task instructions and the input requirement, and few-shot prompting (Ap-\npendix B), which additionally incorporated labeled examples. The few-shot\nsetup used 30 training instances that were chosen to (i) capture multi-label\ncases where a single requirement spans multiple security categories, (ii) cover\nall 11 OWASP ASVS categories, and (iii) reflect requirements from different\nbusiness domains to preserve linguistic variation.\nPersona-based prompting was applied in both configurations by instruct-\ning the model to act as an experienced cybersecurity specialist. This alignment\nhelped reduce output variance by grounding responses in professional domain\nexpertise rather than general conversational patterns. The final prompt was\nobtained after five iterations. These iterations focused on three primary ar-\neas: (1) instruction clarity to prevent the model from defaulting to binary\nsecurity labels; (2) contextual grounding, by iteratively refining the OWASP\nASVS category definitions to ensure the model adhered to provided standards;\n(3) constraint formatting, to stabilize the PSV output structure for machine-\nreadability and ensure the inclusion of mandatory explanation fields. All ex-\nperiments were conducted with fixed parameters (Temperature = 0, Top-p =\n0.95) and repeated three times. The reported results are averaged to reduce\nthe impact of any minor, non-deterministic fluctuations in the models’ token\nselection during individual inferences.\nPrompt-based methods can be sensitive to phrasing, structure, and exam-\nple selection. To manage prompt sensitivity and contextual bias, we adopted a\nunified Persona–Context–Constraint strategy. A single prompt structure was\nused across all models, without model-specific tuning or iterative optimization\naimed at maximizing scores. The few-shot examples were chosen for representa-\ntiveness with respect to the OWASP ASVS taxonomy rather than performance\ngains.', 'CONTEXT: **Optimization and Prompting Strategies for Security Classification Models**: This chunk discusses the optimization of BERT variants through systematic hyperparameter tuning and explores the use of large language models (LLMs) for security requirement classification, focusing on zero-shot and few-shot prompting strategies to enhance task-specific performance without modifying the base model.\n\nCONTENT: 22 Yusuf G¨ ur et al.\nWe performed a systematic grid search using the Weights & Biases 12\nplatform to identify the optimal configuration for each BERT variant using\nthe validation dataset. The search space included the following parameters:\n–Maximum Sequence Length:[128, 256]tokens\n–Batch Size:[4, 8, 16]\n–Number of Epochs:[16, 24, 32]\n–Learning Rate:[1e-5, 2e-5, 3e-5]\n–Decision Threshold:[0.3, 0.4, 0.5]\nTo prevent overfitting, we monitored validation loss and implemented early\nstopping with a patience of 2–4 epochs. The checkpoint achieving the lowest\nvalidation loss for each model was selected for the final evaluation on the test\nset.\n4.3 Classification using LLM Models\nLLMs are transformer-based models trained on massive corpora for general-\npurpose natural language understanding and generation. This study adopted\nthe “pre-train, prompt, and predict” paradigm, which replaces traditional\n“pre-train, fine-tune” approaches (Liu et al., 2023a). Rather than adjusting\nthe model’s objective or architecture, prompt engineering is used to steer the\nmodel toward task-specific outputs through carefully designed textual inputs.\nPrompt engineering involves designing prompts that elicit accurate re-\nsponses for specific tasks. In zero-shot prompting, an LLM is directly used\nwithout any task-specific training. Few-shot prompting introduces a small\nnumber of labeled examples in the prompt, which allows the model to learn\nthe task pattern. This is particularly beneficial when labeled training data is\nlimited.\nFour main prompting strategies were proposed by (Liu et al., 2023a):\n–Tuning-free prompting: Requires no model changes, suitable for zero-shot\nsettings, but often demands complex prompt design.\n–Fixed-LLM prompt tuning: Involves learning soft prompts while keep-\ning the model fixed; effective for few-shot tasks but typically lacks inter-\npretability.\n–Fixed-prompt LLM tuning: Fine-tunes the model on a fixed prompt; im-\nproves performance in few-shot settings.\n–Prompt + LLM tuning: Jointly tunes both model and prompts; highly\nexpressive but prone to overfitting on small datasets.\nIn this study, we evaluated the first two of these strategies, as they do\nnot require modification of the base LLM’s weights. For our zero-shot experi-\nments, we implemented tuning-free prompting, relying on carefully engineered\nprompts to guide the models. For our few-shot analysis, our approach aligns\n12 https://wandb.ai/site', 'CONTEXT: This chunk focuses on the evaluation of various language models, including open-source and commercial models, for implicit security requirements classification, detailing their technical specifications, rationale for selection, and experimental setup involving zero-shot and few-shot prompting strategies.\n\nCONTENT: Implicit Security Requirements Classification 23\nwith fixed-LLM prompt tuning, where we provided in-context examples within\nthe prompt to guide the model’s predictions. The latter two strategies involv-\ning model fine-tuning Fixed-prompt LLM tuning and Prompt + LLM tuning)\nwere not considered due to their high computational cost. The zero shot and\nfew shot prompts can be found in Appendix A and Appendix B.\nIn these experiments, we evaluated nine language models, including open-\nsource models deployed on local infrastructure and commercial models ac-\ncessed via external application programming interfaces (APIs). The technical\nspecifications of each model and the rationale for their selection are summa-\nrized in Table 7. The requirements were processed in batches of 15 because\nproviding the full set in a single prompt exceeded the models’ context limits.\nTable 6: Details and Rationale of the LLMs Used in the Study\nModel Name Description Rationale in Study\nOpen-Source Models\ngemma-3-27b\n(Dense Trans-\nformer; 27B\nParams)\nA Google-developed lan-\nguage model trained on\na large, diverse corpus of\nweb text.13 (The Google\nGemma Team, 2025)\nTo evaluate a powerful, next-generation\nopen-source model from a major AI research\nlab, establishing a baseline for locally deploy-\nable high-parameter models.\ngemma-3-4b\n(Dense Trans-\nformer; 4B\nParams)\nA smaller, efficient model\nfrom the Gemma 3 fam-\nily, designed for resource-\nconstrained environ-\nments.13 (The Google\nGemma Team, 2025)\nTo assess the performance of a highly ef-\nficient, small-scale model to determine if\nlower-parameter models can effectively han-\ndle complex security classification tasks.\nmeta.llama3-\n3-70b-instruct-\nv1:0\n(Dense Trans-\nformer; 70B\nParams)\nAPI version of Meta’s\nLlama 3 70B Instruct.\nAn open-weight model\npre-trained on over 15T\ntokens. 14 (AI at Meta,\n2024)\nTo benchmark against a leading open-weight\nmodel known for strong reasoning and\ninstruction-following capabilities, represent-\ning the state-of-the-art in non-proprietary\nmodels.\nDeepSeek-R1\n(Mixture-of-\nExperts (MoE))\nAn API-accessible model\nfrom DeepSeek AI. As-\nsumed to be based on the\nDeepSeek-V2 architecture\n(236B total/21B active\nparams). 15 (DeepSeek AI,\n2024)\nTo include a model with a different architec-\nture (MoE) that represents an alternative,\nhighly efficient approach to scaling, specif-\nically testing its reasoning capabilities in\nsecurity contexts.\nCommercial Models (API Access)\n13 https://blog.google/technology/developers/\n14 https://ai.meta.com/blog/meta-llama-3/\n15 https://deepseek.com/', 'CONTEXT: This chunk provides a detailed example of a few-shot prompt designed for classifying software requirements based on the OWASP ASVS 4.0.3-tr categories, demonstrating how project requirements are analyzed and aligned with security standards using AI models, particularly in the context of implicit security requirements classification.\n\nCONTENT: - <V2> through <V13>: (either 1 (if the requirement aligns with the category) or 0 (if it doesn\'t)) \n   - Explanation (string) \n***** \nInput (PSV - The requirements you want to classify): \n1|Sistem, kullanıcının konaklama ücret tipi bilgilerini girmesini sağlayacaktır \n3|Sistem, kullanıcının konaklama ücret tipi bilgilerini silmesini sağlayacaktır \n5|Sistem, kullanıcının oda tiplerini güncellemesini sağlayacaktır \n16|Sistem, kullanıcının otele giriş nedeni bilgisini girmesini sağlayacaktır \n22|Sistem, kullanıcının çalışma tip bilgisini girmesini sağlayacaktır \n28|Sistem, kullanıcının otel rezervasyon para yatırma süre bilgisini girmesini sağlayacaktır \n31|Sistem, kullanıcının misafir türü kaydetmesini sağlayacaktır. \n37|Sistem, kullanıcının oda tiplerini listelemesini sağlayacaktır. \n41|Sistem, kullanıcının otele giriş neden bilgilerini listelemesini sağlayacaktır. \n44|Sistem, kullanıcının arananlar bilgisini listelemesini sağlayacaktır. \n52|Sistem, kullanıcının yakınlık tanım bilgisini seçilen kriterlere göre sorgulayabilmesini sağlayacaktır. \n54|Sistem, kullanıcının arananlar bilgisini seçilen kriterlere göre sorgulayabilmesini sağlayacaktır. \n55|Sistem, kullanıcının otel rezervasyon iptal süre bilgisini seçilen kriterlere göre sorgulayabilmesini \nsağlayacaktır. \n65|Sistem, kullanıcının otelin katlarındaki oda doluluk oranlarını seçilen kriterlere göre sorgulayabilmesini \nsağlayacaktır. \n70|Sistem, kullanıcının otel raporlarında kullanıcı imza bilgisi girmesini sağlayacaktır.\n\nFEW SHOTS PROMPT \nPersona: You are an experienced cybersecurity specialist with extensive knowledge of the OWASP ASVS \n4.0.3-tr and secure software development practices. You are meticulous, detail-oriented, and focused on \nidentifying potential security vulnerabilities and ensuring that applications meet the highest security \nstandards. \n \n********* \n \nTask: Classify and analyze project requirements based on their security and functional aspects from a \ncybersecurity perspective, aligning with the OWASP Application Security Verification Standard (ASVS) \n4.0.3-tr. Provide detailed explanations for all classifications and potential security concerns. \n \n********* \n \nInstructions: \n \n1.  You will receive a list of project requirements in PSV (Pipe Separated Values) format. \n2.  Each line in the input will represent a requirement in “Requirement Number|Requirement Description” \nformat and will contain: \n    * Requirement Number (integer) \n    * Requirement Description (string) \n3.  For each requirement, classify it into the categories defined in the table below, which are derived from \nthe OWASP ASVS 4.0.3-tr. \n4.  Output the classification in PSV format, including all columns from the table, AND an ""Explanation"" \ncolumn within a new line. \n5.  Use ""1"" if the requirement aligns with the ASVS category, and ""0"" if it does not. \n6.  Provide a concise explanation for each classification, justifying why you assigned a ""1"" or ""0"" to each \ncategory. \n7.  Ensure the output has the same number of rows as the input. \n8.  Use the Extra Information for Choosing Categories to aid classification. \n \n********* \n \nContext: \n \nThe categories below are based on the OWASP Application Security Verification Standard (ASVS) 4.0.3-tr. \nRefer to the ASVS documentation for detailed information on each category. The specific ASVS levels (L1, \nL2, L3) are not explicitly represented in the columns, but the categories themselves align with the ASVS \nrequirements. \n \n********* \n \nCategories (Aligned with OWASP ASVS 4.0.3-tr): \n \nV2, Kimlik Doğrulama (Identity Verification) - Covers requirements related to user authentication, \npassword management, and session handling (e.g., ASVS 2.0). \nV3, Oturum Yönetimi (Session Management) - Covers requirements related to secure session handling, \nincluding session timeouts, protection against session fixation, and secure cookie management (e.g., ASVS \n3.0). \nImplicit Security Requirements Classification 47\nB Few-shot Prompt', 'CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the', 'CONTEXT: This chunk details the **annotation methodology** and **dataset curation process** for the ASRD, following the MATTER cycle framework. It describes annotator selection, corpus preparation, and the iterative development of annotation guidelines aligned with OWASP ASVS categories to ensure high-quality, domain-specific annotations.\n\nCONTENT: Implicit Security Requirements Classification 15\n3.3 Annotation Methodology (MATTER Cycle) & Dataset Curation\nThe annotation process followed the MATTER development cycle, an estab-\nlished iterative framework for corpus annotation (Pustejovsky and Stubbs,\n2012). Crucially, the annotation task was defined as a multi-label text classifi-\ncation problem. It consists of the phases Model, Annotate, Train, Test, Eval-\nuate, and Revise. The annotation guidelines were developed and iteratively\nrefined to ensure consistency and clarity.\nThe Model–Annotate cycle involved writing guidelines, selecting annota-\ntors, conducting trial annotations, and refining the process. Once stabilized,\nthis cycle was expanded to the full dataset to generate a Gold Standard corpus.\nThe annotation workflow included the following processes:\n–Annotator Selection: Following Bayerl and Paul’s recommendation to use\ndomain-aligned annotators (Bayerl and Paul, 2011), three cybersecurity\nsubject matter experts (SME) from the agency, each with over 15 years\nof experience in designing security architectures, analyzing threat models,\nand identifying security requirements, performed the annotations. Their\ndeep practical experience ensured accurate and context-aware interpreta-\ntion which aligned with the requirement “experts must demonstrate signif-\nicant skills, knowledge, and experience” emphasized by Hopkins (Hopkins\nand Unger, 2017). The senior manager among them also provided over-\nsight and led the adjudication process. The senior SME acted as both an\nannotator and the final adjudicator for resolving disagreements. They also\nprovided feedback to improve the quality and clarity of the annotation\nguideline.\n–Corpus Selection and Preparation: Cohen (Cohen et al., 2005) recommends\nthat during corpus design, balance and representativeness of the corpus\nis important. In line with his recommendation, of the 19 initial project\ndocuments, six were chosen for their domain diversity and potential for\neffective anonymization by the SMEs. These documents underwent a semi-\nautomated anonymization process to remove all project-specific and per-\nsonally identifiable information (PII). The process targeted entities such\nas names of individuals and organizations, project codenames, and specific\ntechnical identifiers. This was done using custom scripts with placeholder\nreplacement, followed by manual review to ensure that anonymization did\nnot alter the meaning, structure, or intent of the original requirements. The\nextracted requirements were then randomized and masked to prevent po-\ntential bias related to document origin or sequence during the annotation\nphase. Total corpus has 2,652 requirements (30 pilot + 2,622 independent\nannotations).\n–Annotation Guideline Development: The Annotation Guidelines’ develop-\nment involved an initial iterative process, refining the guidelines three times\nto resolve ambiguities before the formal assessment phase. Annotation rules\nwere based on OWASP ASVS categories V2–V13 and refined iteratively\nusing example annotations. Following best practices suggested by Cohen\n(Cohen et al., 2005), the guidelines and annotation documents ensured:', 'CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1']","The 'Persona-Context-Constraint' prompt structure included the following specific elements:

1. **Persona**: The model was instructed to act as an experienced cybersecurity specialist with extensive knowledge of the OWASP ASVS 4.0.3-tr and secure software development practices. This persona emphasized being meticulous, detail-oriented, and focused on identifying potential security vulnerabilities and ensuring applications meet the highest security standards.

2. **Context**: The context provided detailed task instructions, including:
   - Classifying and analyzing project requirements based on their security and functional aspects.
   - Aligning the classifications with the OWASP ASVS 4.0.3-tr categories.
   - Providing detailed explanations for all classifications and potential security concerns.

3. **Constraint**: The constraints included:
   - Input format: Requirements were provided in PSV (Pipe Separated Values) format, with each line containing a ""Requirement Number|Requirement Description.""
   - Output format: The output was required to include classifications for each requirement in PSV format, with binary indicators (""1"" for alignment, ""0"" for non-alignment) for each OWASP ASVS category, along with an ""Explanation"" column.
   - Specific instructions to ensure consistency, such as maintaining the same number of rows in the output as in the input and using extra information to aid classification.

These elements were designed to ensure clarity, consistency, and adherence to the OWASP ASVS standards during the classification task. (Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","The prompt included a persona (cybersecurity specialist), context (OWASP ASVS definitions and 'Extra Information' rules), and constraints (PSV output format)[cite: 461, 469, 475].",,,
What is 'Contextual Anchoring' in the context of this study's prompt engineering?,"['CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1', 'CONTEXT: **Advancements in LLM-Assisted Security and Related Frameworks**: This chunk discusses the application of transformer-based models and LLMs in security requirements engineering (SRE), highlighting their capabilities, challenges, and the importance of high-quality datasets and evaluation frameworks. It also reviews the role of security frameworks in systematically identifying and classifying security requirements in automated settings.\n\nCONTENT: 6 Yusuf G¨ ur et al.\nBeyond requirements classification, security research has also turned to\ntask-specific models for narrowly defined problems. For instance, deep learning\napproaches such as BiLSTMs have been used to detect re-entrancy vulnerabil-\nities in smart contracts, where generic models are insufficient (Maturi et al.,\n2025). This work highlights the importance of explainability, as security de-\ncisions must be understandable to support assurance and auditing. Although\nthis line of research addresses a different problem, it reflects a shift toward\ndomain-aware and interpretable models.\nTransformer-based models have enabled new capabilities in automated text\nunderstanding(Zhou et al., 2025). They possess emergent abilities like in-\ncontext learning, instruction following, and step-by-step reasoning (Zhu et al.,\n2025), which allow them to perform complex tasks, including requirements\nclassification, with minimal or no labeled data (Liu et al., 2023b; Zhu et al.,\n2025). Recent trends show a growing interest in applying LLMs to RE tasks,\nincluding requirements classification, prioritization, and traceability (Rajbhoj\net al., 2024; White et al., 2024). LLMs can perform zero-shot and few-shot\nlearning, reducing the need for large annotated datasets and facilitating adap-\ntation to specialized domains like SRE (Labrak et al., 2023). Techniques such\nas prompt engineering and integration with external knowledge bases (e.g.,\nRetrieval-Augmented Generation) further improve their performance and con-\ntextual relevance (Masoudifard et al., 2024).\nLLM-assisted security solutions typically follow a three-step process: pre-\nprocessing (extracting context like documentation or target units), prompt\ngeneration (using instructions and unfilled slots for the model to complete\nwith artifacts like fuzz drivers or patches), and post-processing (validating\noutputs, e.g., checking if generated code successfully compiles) (Zhu et al.,\n2025).\nWhile these models provide powerful automation, they can also introduce\nnew risks and errors if applied without careful oversight. This underscores the\nneed for realistic, high-quality datasets and standardized evaluation frame-\nworks to reliably assess automated security requirement classification, ensuring\nboth effectiveness and safety in practice.\nThe use of automated models in security highlights both their potential and\nthe risks they can introduce. Ensuring accurate and reliable classification of\nsecurity requirements requires evaluation against high-quality, domain-specific\nbenchmarks (Jeong, 2024). This underscores the need for realistic datasets and\nstandardized evaluation frameworks tailored to SRE.\n2.2 Related Work on Security Frameworks\nAn appropriate security framework is necessary to ensure systematic and con-\nsistent identification and classification of security requirements, particularly in\nautomated settings. This section reviews widely adopted security frameworks\nand evaluates their suitability for requirement analysis.', 'CONTEXT: **Evaluation of Model Challenges and Prompt Engineering Strategies**: This chunk discusses the challenges faced by models, particularly with underrepresented OWASP ASVS categories (e.g., V6 Cryptography, V12 Files/Resources), and outlines the experimental setup for prompt engineering in LLMs, including zero-shot and few-shot configurations, persona-based prompting, and strategies to ensure consistency and adherence to security standards.\n\nCONTENT: 26 Yusuf G¨ ur et al.\nshowed both low Recall (0.658) and low Precision (0.781), indicating it was\nboth missing true cases and incorrectly labeling other requirements as V6.\nModels struggle significantly with underrepresented categories, particularly\nV12 (File and Resources) and V6 (Stored Cryptography). This is evident in\nthe high number of false negatives, where the models fail to identify true\ninstances of these classes. For example, the baseline BERT model incorrectly\nclassified over half of the V12 requirements as negative (14 false negatives vs.\n13 true positives). Conversely, the matrices show that models often misclassify\nrequirements by incorrectly assigning them to other categories. The BERT\nBase model, for example, incorrectly labeled 92 different requirements as V10\n(Malicious Code) and 78 requirements as V5 (Malicious Input Handling).\n5.2 Experimental Setup for LLM Prompt Engineering\nWe adapted prompt engineering strategies from Ronanki (Ronanki et al.,\n2024), originally used for multi-class requirement classification. Two configu-\nrations were evaluated: zero-shot prompting (Appendix A), which relied solely\non task instructions and the input requirement, and few-shot prompting (Ap-\npendix B), which additionally incorporated labeled examples. The few-shot\nsetup used 30 training instances that were chosen to (i) capture multi-label\ncases where a single requirement spans multiple security categories, (ii) cover\nall 11 OWASP ASVS categories, and (iii) reflect requirements from different\nbusiness domains to preserve linguistic variation.\nPersona-based prompting was applied in both configurations by instruct-\ning the model to act as an experienced cybersecurity specialist. This alignment\nhelped reduce output variance by grounding responses in professional domain\nexpertise rather than general conversational patterns. The final prompt was\nobtained after five iterations. These iterations focused on three primary ar-\neas: (1) instruction clarity to prevent the model from defaulting to binary\nsecurity labels; (2) contextual grounding, by iteratively refining the OWASP\nASVS category definitions to ensure the model adhered to provided standards;\n(3) constraint formatting, to stabilize the PSV output structure for machine-\nreadability and ensure the inclusion of mandatory explanation fields. All ex-\nperiments were conducted with fixed parameters (Temperature = 0, Top-p =\n0.95) and repeated three times. The reported results are averaged to reduce\nthe impact of any minor, non-deterministic fluctuations in the models’ token\nselection during individual inferences.\nPrompt-based methods can be sensitive to phrasing, structure, and exam-\nple selection. To manage prompt sensitivity and contextual bias, we adopted a\nunified Persona–Context–Constraint strategy. A single prompt structure was\nused across all models, without model-specific tuning or iterative optimization\naimed at maximizing scores. The few-shot examples were chosen for representa-\ntiveness with respect to the OWASP ASVS taxonomy rather than performance\ngains.', 'CONTEXT: This chunk provides a detailed example of a **zero-shot prompt** designed for classifying project requirements based on the OWASP ASVS 4.0.3-tr categories, highlighting the methodology for aligning security requirements with specific ASVS standards and offering explanations for classifications.\n\nCONTENT: Implicit Security Requirements Classification 43\nAdvanced Intelligent Systems 6(7):2300798\nWen SF, Katt B (2023) A quantitative security evaluation and analysis model\nfor web applications based on owasp application security verification stan-\ndard. Computers & Security 135:103532, DOI 10.1016/j.cose.2023.103532\nWhite J, Hays S, Fu Q, Spencer-Smith J, Schmidt DC (2024) Chatgpt prompt\npatterns for improving code quality, refactoring, requirements elicitation,\nand software design. In: Generative AI for Effective Software Development,\nSpringer, pp 71–108\nYe J, Yao Z, Huang Z, Pan L, Liu J, Bai Y, Xin A, Weichuan L, Che X,\nHou L, et al. (2025) How do transformers learn implicit reasoning? In: The\nThirty-ninth Annual Conference on Neural Information Processing Systems\nZadenoori MA, Dabrowski J, Alhoshan W, Zhao L, Ferrari A (2025) Large\nlanguage models (llms) for requirements engineering (re): A systematic lit-\nerature review. arXiv preprint arXiv:250911446\nZhou X, Li Y, Chen H (2025) The transformer architecture: Foundations and\nadvances. IEEE Transactions on Neural Networks and Learning Systems\nForthcoming\nZhu Y, Wang J, Liu K (2025) Emergent abilities of large language models:\nIn-context learning, instruction following, and reasoning. Nature Machine\nIntelligence In press\n Lukasiewicz K, Cyga´ nska S (2019) Security-oriented agile approach with\nagilesafe and owasp asvs. In: 2019 Federated Conference on Computer\nScience and Information Systems (FedCSIS), IEEE, pp 653–662, DOI\n10.23919/FedCSIS.2019.00012\n\nZERO SHOT PROMPT \n \nPersona: You are an experienced cybersecurity specialist with extensive knowledge of the OWASP ASVS \n4.0.3-tr and secure software development practices. You are meticulous, detail-oriented, and focused on \nidentifying potential security vulnerabilities and ensuring that applications meet the highest security \nstandards. \n \n********* \n \nTask: Classify and analyze project requirements based on their security and functional aspects from a \ncybersecurity perspective, aligning with the OWASP Application Security Verification Standard (ASVS) \n4.0.3-tr. Provide detailed explanations for all classifications and potential security concerns. \n \n********* \n \nInstructions: \n \n1.  You will receive a list of project requirements in PSV (Pipe Separated Values) format. \n2.  Each line in the input will represent a requirement in “Requirement Number|Requirement Description” \nformat and will contain: \n    * Requirement Number (integer) \n    * Requirement Description (string) \n3.  For each requirement, classify it into the categories defined in the table below, which are derived from \nthe OWASP ASVS 4.0.3-tr. \n4.  Output the classification in PSV format, including all columns from the table, AND an ""Explanation"" \ncolumn within a new line. \n5.  Use ""1"" if the requirement aligns with the ASVS category, and ""0"" if it does not. \n6.  Provide a concise explanation for each classification, justifying why you assigned a ""1"" or ""0"" to each \ncategory. \n7.  Ensure the output has the same number of rows as the input. \n8.  Use the Extra Information for Choosing Categories to aid classification. \n \n********* \n \nContext: \n \nThe categories below are based on the OWASP Application Security Verification Standard (ASVS) 4.0.3-tr. \nRefer to the ASVS documentation for detailed information on each category. The specific ASVS levels (L1, \nL2, L3) are not explicitly represented in the columns, but the categories themselves align with the ASVS \nrequirements. \n \n********* \n \nCategories (Aligned with OWASP ASVS 4.0.3-tr): \n \nV2, Kimlik Doğrulama (Identity Verification) - Covers requirements related to user authentication, \npassword management, and session handling (e.g., ASVS 2.0). \nV3, Oturum Yönetimi (Session Management) - Covers requirements related to secure session handling, \nincluding session timeouts, protection against session fixation, and secure cookie management (e.g., ASVS \n44 Yusuf G¨ ur et al.\nA Zero-shot Prompt', 'CONTEXT: This chunk focuses on the evaluation of various language models, including open-source and commercial models, for implicit security requirements classification, detailing their technical specifications, rationale for selection, and experimental setup involving zero-shot and few-shot prompting strategies.\n\nCONTENT: Implicit Security Requirements Classification 23\nwith fixed-LLM prompt tuning, where we provided in-context examples within\nthe prompt to guide the model’s predictions. The latter two strategies involv-\ning model fine-tuning Fixed-prompt LLM tuning and Prompt + LLM tuning)\nwere not considered due to their high computational cost. The zero shot and\nfew shot prompts can be found in Appendix A and Appendix B.\nIn these experiments, we evaluated nine language models, including open-\nsource models deployed on local infrastructure and commercial models ac-\ncessed via external application programming interfaces (APIs). The technical\nspecifications of each model and the rationale for their selection are summa-\nrized in Table 7. The requirements were processed in batches of 15 because\nproviding the full set in a single prompt exceeded the models’ context limits.\nTable 6: Details and Rationale of the LLMs Used in the Study\nModel Name Description Rationale in Study\nOpen-Source Models\ngemma-3-27b\n(Dense Trans-\nformer; 27B\nParams)\nA Google-developed lan-\nguage model trained on\na large, diverse corpus of\nweb text.13 (The Google\nGemma Team, 2025)\nTo evaluate a powerful, next-generation\nopen-source model from a major AI research\nlab, establishing a baseline for locally deploy-\nable high-parameter models.\ngemma-3-4b\n(Dense Trans-\nformer; 4B\nParams)\nA smaller, efficient model\nfrom the Gemma 3 fam-\nily, designed for resource-\nconstrained environ-\nments.13 (The Google\nGemma Team, 2025)\nTo assess the performance of a highly ef-\nficient, small-scale model to determine if\nlower-parameter models can effectively han-\ndle complex security classification tasks.\nmeta.llama3-\n3-70b-instruct-\nv1:0\n(Dense Trans-\nformer; 70B\nParams)\nAPI version of Meta’s\nLlama 3 70B Instruct.\nAn open-weight model\npre-trained on over 15T\ntokens. 14 (AI at Meta,\n2024)\nTo benchmark against a leading open-weight\nmodel known for strong reasoning and\ninstruction-following capabilities, represent-\ning the state-of-the-art in non-proprietary\nmodels.\nDeepSeek-R1\n(Mixture-of-\nExperts (MoE))\nAn API-accessible model\nfrom DeepSeek AI. As-\nsumed to be based on the\nDeepSeek-V2 architecture\n(236B total/21B active\nparams). 15 (DeepSeek AI,\n2024)\nTo include a model with a different architec-\nture (MoE) that represents an alternative,\nhighly efficient approach to scaling, specif-\nically testing its reasoning capabilities in\nsecurity contexts.\nCommercial Models (API Access)\n13 https://blog.google/technology/developers/\n14 https://ai.meta.com/blog/meta-llama-3/\n15 https://deepseek.com/', 'CONTEXT: This chunk discusses the challenges of identifying implicit security requirements in software requirements engineering (SRE), emphasizing the limitations of existing datasets and the need for AI-driven NLP methods, while highlighting the role of the OWASP ASVS framework in addressing these gaps through standardized security practices.\n\nCONTENT: Implicit Security Requirements Classification 3\n“The system will allow the user to print documents,” carries numerous implicit\nsecurity needs, including verifying user authorization, maintaining a valid ses-\nsion, and recording the action for accountability. These concerns correspond\nto common security control areas, such as access control, session management,\nand logging. This complexity requires substantial guidance. Manually iden-\ntifying and validating this network of implicit security dependencies across\nthousands of requirements is error prone, inconsistent, and not scalable (Ye\net al., 2025).\nGiven the limitations of manual SRA, automation through Artificial In-\ntelligence (AI) based Natural Language Processing (NLP) methods, offers a\npromising path forward. Although AI based approaches for RE have received\ngrowing attention (Abbasi et al., 2025; Zadenoori et al., 2025), recent evidence\nshows a gap between experimental advances and validated industrial solutions.\nFor example, an analysis of 74 primary studies found that most AI based tools\nare evaluated in controlled settings, with limited industrial adoption and weak\nintegration into real workflows (Bolanos et al., 2024). Similarly, another study\nreports a clear mismatch between expectations and practical outcomes in SRE\nin real world use (Karhu et al., 2025).\nThe main problem is the lack of suitable data, not the availability of ef-\nfective modeling approaches. The development and validation of data driven\napproaches is constrained by the scarcity and limited quality of domain spe-\ncific datasets (Wang et al., 2024; Zadenoori et al., 2025). This concern ex-\ntends beyond SRE, as leading NLP venues highlight dataset limitations that\nmake reliable evaluation difficult (Muresan et al., 2022; Goldberg et al., 2022;\nChristodoulopoulos et al., 2025).\nThis challenge is especially evident in SRE. Identifying implicit security\nrequirements relies on large collections of functional requirements annotated\nby security experts to reflect underlying security concerns. Current datasets do\nnot meet this need. For instance, PROMISE exp (Lima et al., 2019) includes\nonly a single, high-level security category; DOSSPRE (Kadebu et al., 2023)\nis based on student projects and lacks industry realism; and the Healthcare\ndataset (Riaz et al., 2014) is limited to a narrow domain and uses coarse-\ngrained labels. As a result, existing resources offer limited support for devel-\noping and evaluating methods aimed at uncovering implicit security require-\nments.\nThe OWASP Application Security Verification Standard (ASVS)1 offers a\nstandardized, systematic, and verifiable framework for defining and evaluating\napplication security controls. ASVS emphasizes the principle of “security by\ndesign” by facilitating the integration of security considerations early in the\nsoftware development lifecycle. Its comprehensive set of requirements can be\ndirectly mapped to verifiable test cases and secure coding practices, ensuring\ntraceability throughout the development process. This approach enables the\nearly identification and remediation of vulnerabilities, which is both more effi-\n1 https://owasp.org/www-project-application-security-verification-standard/', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference', 'CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the']","'Contextual Anchoring' in the context of this study's prompt engineering refers to a strategy used to mitigate contextual bias in large language models (LLMs). This bias occurs when a model relies on its general training data rather than the specific task definitions provided. To address this, the study incorporated explicit definitions of the 11 OWASP ASVS classes and a set of heuristic ""Extra Information"" rules (e.g., mapping CRUD operations to specific security categories) directly into the prompt's context window. By embedding this information, the models were guided to adhere to the specified standards, resulting in more consistent classifications.

This approach was part of the study's effort to ensure experimental control and cross-model comparability, prioritizing adherence to security standards over optimizing performance. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","It involves injecting explicit definitions of the 11 OWASP ASVS classes and heuristic 'Extra Information' rules directly into the prompt to mitigate contextual bias[cite: 474, 475].",,,
Which statistical test was used to reject the null hypothesis regarding classifier performance?,"['CONTEXT: **Analysis of Minority Class Performance and Annotation Challenges in SRE**: This chunk discusses the performance gap between majority and minority security classes in SRE, the expert-driven annotation process using the MATTER cycle, and the measures taken to mitigate subjectivity and ensure realistic, industry-relevant model evaluation.\n\nCONTENT: 32 Yusuf G¨ ur et al.\nFig. 4:Minority vs. Majority Class Performance Gap.A comparative\nanalysis revealing that while advanced LLMs and fine-tuned models achieve\nnear-parity on Majority Classes (Blue), a significant performance gap remains\non Minority Classes (Red), underscoring the “Long Tail” challenge in SRE.\nAnnotation was performed by three experienced cybersecurity experts.\nWhile their domain knowledge ensured quality, the small annotator pool may\nintroduce subjective bias and limit the range of interpretations. This was mit-\nigated through the iterative MATTER cycle which includes training, iterative\nguideline refinement, and consensus-based adjudication.\nA key threat to internal validity is subjectivity as classifications rely heavily\non the latent domain knowledge and industry experience, rather than explicit\nindicators within the requirement text itself. This expert-driven approach pro-\nvides a “gold standard” for realistic industrial needs but it may introduce in-\nconsistencies if replicated by annotators with different backgrounds or if the\nbroader system context is not explicitly documented.\nThe test set was manually selected to balance computational efficiency and\ngeneralizability assessment. While cross-validation could improve test calibra-\ntion, it was avoided due to its high computational cost.\nTo minimize researcher bias and ensure the results reflect real-world in-\ndustry needs, domain experts used for the selection of both the test set and\nthe LLM suite. Rather than selecting data or models arbitrarily, these experts\ncurated a test set containing the most complex, “implicit” security scenarios\nto challenge the models beyond simple pattern matching. For the model suite,\nthey prioritized architectures with advanced reasoning capabilities, hypothe-\nsizing that these specific technical features are essential for the multi-step de-\nduction required in security requirements engineering. Although the experts', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: **Performance Visualization and Analysis of Classifiers**: This chunk focuses on the comparative performance analysis of 20 classifiers across OWASP ASVS classes, using critical difference diagrams, heatmaps, and gap analysis to highlight strengths and weaknesses, particularly in handling rare security classes like V6 (Stored Cryptography) and V12 (Files and Resources). It also discusses dataset diversity, threats to validity, and the generalizability of findings.\n\nCONTENT: 30 Yusuf G¨ ur et al.\nFig. 2: Critical Difference (CD) diagram visualizing the statistical comparison\nof classifiers. The horizontal axis represents the average rank of each model\nacross all 11 OWASP ASVS classes (lower ranks indicate better performance).\nThe Critical Difference (CD = 10.46) represents the minimum difference in\naverage rank required for two models to be considered statistically significantly\ndifferent atp <0.05.\n5.6 Comparative Visualization Analysis\nTo complement the statistical rankings, we visualized the performance land-\nscape across all 20 model configurations.\nHeatmap Analysis: Figure 3 shows F1-scores by class. Requirements related\nto V2 (Authentication), V3 (Session Management), and V4 (Access Control)\nare handled well by nearly all models, with scores typically above 0.95. These\ncategories are common and appear consistently across training sources. In\ncontrast, V6 (Stored Cryptography) and V12 (Files and Resources) show low\nscores across the board, including for GPT-4o and Gemini 2.0 Pro. This pat-\ntern points to a systematic difficulty with sparse categories rather than a\nweakness of a particular model.\nGap Analysis: Figure 4 contrasts average performance on frequent and in-\nfrequent classes. Fine-tuned models such as SecureBERT and BERT-Multilingual\nperform better on rare classes, with F1-scores around 0.70–0.80. Zero-shot\nLLMs perform poorly in these cases, often below 0.30. Few-shot prompting\nimproves results for some models, such as Gemini 2.0, but the gap remains\nsubstantial.\n6 Threats to Validity\nOur dataset consists of 2,652 requirements derived from six Software Require-\nments Specification (SRS) documents. While the number of source documents\n\nImplicit Security Requirements Classification 31\nFig. 3:Comprehensive Performance Heatmap.F1-scores for all 20 eval-\nuated models across 11 OWASP ASVS classes. The visualization highlights\nthe “zone of failure” (red) for classes V6 and V12 across models, contrasting\nwith the high performance (green) on ubiquitous classes like V2 and V4.\nis limited, potential bias was mitigated by strategically selecting projects from\nsix distinct business domains: Construction, Legal, Education, Software, Meet-\ning Management, and Accommodation. This semantic diversity ensures that\nthe models are evaluated on a broad vocabulary and varied functional contexts\nrather than a single industry vertical. A specific consideration regarding the\nexternal validity of this study is that the ASRD is a Turkish-language corpus\nwhich allows for the evaluation of automated tools in linguistically diverse\nindustrial contexts.\nFurthermore, because security requirements (e.g., Authentication, Log-\nging) represent cross-cutting concerns that apply universally across software\nsystems, we believe the fundamental patterns captured in the ASRD are trans-\nferable to other industries. Our current evaluation used a stratified split across\nthe entire dataset, meaning requirements from all six source projects are\npresent in the training, validation, and test sets. However, we acknowledge\nthat this approach does not fully measure the models’ ability to generalize to\nentirely new projects with different authors or linguistic styles, as the test set\nis not completely “unseen” in terms of project context.', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**: This chunk focuses on the statistical evaluation of model performance, comparing fine-tuned models, few-shot, and zero-shot LLM approaches, highlighting significant pairwise differences, and visualizing results through a Critical Difference (CD) diagram to identify top-performing models in the domain.\n\nCONTENT: Implicit Security Requirements Classification 29\nThe analysis (Table 8) highlights the significant pairwise contrasts and\nreveals important performance distinctions:\n–Baseline vs. Advanced Models: The Naive Baseline was consistently out-\nperformed by the advanced models. The difference between the Baseline\nand models such as SecureBERT (p <0.001) and Gemini 2.0 Few-Shot\n(p <0.001) was statistically significant, confirming that the high Weighted-\nF1 scores of these models reflect genuine learning beyond simple majority-\nclass prediction.\n–Fine-Tuning vs. Zero-Shot LLMs: Fine-tuned models like SecureBERT\ndemonstrated statistically significant performance distinctions (p <0.001)\nwhen compared to general-purpose LLMs operating in a zero-shot setting,\nsuch as GPT-4o (p <0.001) and Llama 3 70B (p <0.001). This indi-\ncates that without in-context examples, domain-specific fine-tuning retains\na measurable statistical advantage.\n–Fine-Tuning vs. Few-Shot State-of-the-Art: The pairwise comparison be-\ntween the best fine-tuned model (SecureBERT) and the best LLM ap-\nproach (Gemini 2.0 Few-Shot) yielded ap-value of 0.102. This value is not\nstatistically significant at theα= 0.05 level, supporting our finding that\nfew-shot prompting with state-of-the-art LLMs can effectively match the\nperformance of specialized, fine-tuned BERT models in this domain.\nTable 8: Significant Pairwise Differences (Wilcoxon Signed-Rank Test)\nModel A Model B Statistic p-value\nNaive Baseline SecureBERT 0.0 0.00098\nNaive Baseline BERT Turkish 0.0 0.00098\nNaive Baseline Gemini 2.0 (Few-Shot) 0.0 0.00098\nNaive Baseline Gemini 2.0 Pro (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Few-Shot) 0.0 0.00098\nSecureBERT Gemini 2.0 (Zero-Shot) 25.0 0.501\nSecureBERT Gemini 2.0 (Few-Shot) 14.5 0.102\nTo visualize the relative performance and statistical significance groups\nof all evaluated models, we constructed a Critical Difference (CD) diagram\n(Figure 2) using the Nemenyi post-hoc test.\nIn the CD diagram, models are arranged along the horizontal axis accord-\ning to their average rank. The best performing models, such as Gemini 2.0\nPro (Few-Shot) and BERT-Multilingual, appear on the left (lowest ranks).\nA horizontal bar connects groups of models that are not statistically signifi-\ncantly different from one another. The wide span of the CD bar (10.46) reflects\nthe high number of models compared (23) relative to the number of datasets\n(11). Despite this conservative threshold, the diagram clearly separates the\ntop-tier models (Fine-tuned BERTs and Few-Shot Gemini/GPT-4o) from the\nlower-performing group (Naive Baseline, Zero-Shot Gemma/Llama).', 'CONTEXT: **Performance Metrics for Security Verification Categories and LLM Evaluation**: This chunk presents detailed performance metrics (precision, recall, F1 scores, and support) for various OWASP ASVS security verification categories, highlighting the classification results of LLMs used in the study, with a focus on challenges in underrepresented categories like cryptography and file/resource verification.\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.967 0.939 0.972 0.882 0.280 0.960 0.962 0.954 0.783 0.479 0.884RECALL 0.990 0.963 0.990 0.994 0.718 0.977 0.984 0.982 0.900 0.821 0.981F1 0.978 0.951 0.981 0.934 0.403 0.968 0.973 0.968 0.837 0.605 0.930SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nTest Results of the LLMs used in the study\n56 Yusuf G¨ ur et al.\nD Test Results of the LLMs', 'CONTEXT: **Performance Metrics for Security Requirement Classification Models**: This chunk presents the precision, recall, F1 scores, and support metrics for various OWASP ASVS categories, highlighting the performance of BERT models and a naive baseline in classifying implicit security requirements, with a focus on challenges like class imbalance and underrepresented categories.\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.960 0.950 0.960 0.790 0.000 0.980 0.970 0.960 0.750 0.000 0.800RECALL 1.000 1.000 1.000 1.000 0.000 1.000 1.000 1.000 1.000 0.000 1.000F1 0.980 0.980 0.980 0.880 0.000 0.990 0.980 0.980 0.860 0.000 0.890SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nTest Results of the BERT models and Naïve Baseline used in the study\nImplicit Security Requirements Classification 55\nC Test Results of the Bert Models', 'CONTEXT: **Performance Evaluation of GPT-4o Models in Security Requirement Classification**: This chunk presents the precision, recall, F1 scores, and support metrics for GPT-4o models (Few-Shot and Zero-Shot) across OWASP ASVS security categories, highlighting their effectiveness and limitations in classifying security requirements, particularly for underrepresented classes.\n\nCONTENT: Test Results of the LLMs used in the study\nGpt_4o_Few_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.969 0.956 0.969 0.946 0.205 0.974 0.961 0.951 0.928 0.357 0.938RECALL 0.982 0.971 0.977 0.949 0.205 0.982 0.974 0.961 0.943 0.357 0.953F1 0.975 0.964 0.973 0.948 0.205 0.978 0.968 0.956 0.936 0.357 0.945SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nGpt_4o_mini_Zero_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.953 0.865 0.928 0.829 0.254 0.824 0.671 0.779 0.659 0.093 0.720RECALL 0.963 0.877 0.938 0.863 0.385 0.828 0.680 0.785 0.690 0.250 0.736F1 0.958 0.871 0.933 0.846 0.306 0.826 0.675 0.782 0.674 0.136 0.728SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nGpt_4o_mini_Few_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.969 0.956 0.964 0.821 0.128 0.959 0.871 0.862 0.768 0.179 0.813RECALL 0.976 0.966 0.969 0.829 0.128 0.964 0.878 0.866 0.773 0.179 0.821F1 0.973 0.961 0.966 0.825 0.128 0.962 0.874 0.864 0.771 0.179 0.817SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398']","The statistical tests used to reject the null hypothesis regarding classifier performance were the **Friedman test** and the **Wilcoxon Signed-Rank test**. 

The Friedman test was employed to compare the distributions of classifier performance scores across 11 OWASP ASVS security classes, treating them as independent domains. The test yielded a statistic of 188.103 with a p-value of 2.38×10⁻²⁸, which confirmed that the observed performance differences across the models were statistically significant (p < 0.05). 

Following the rejection of the null hypothesis, pairwise comparisons between classifiers were conducted using the Wilcoxon Signed-Rank test. This test was chosen as a robust non-parametric alternative to the paired t-test, ensuring that outliers did not disproportionately skew the results.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","The Friedman test was used, yielding a p-value of 2.38 x 10^-28, rejecting the null hypothesis[cite: 514].",,,
Which post-hoc test was used to visualize performance differences in the Critical Difference diagram?,"['CONTEXT: **Performance Analysis of Models for Security Requirements Classification**: This chunk focuses on the statistical evaluation of model performance, comparing fine-tuned models, few-shot, and zero-shot LLM approaches, highlighting significant pairwise differences, and visualizing results through a Critical Difference (CD) diagram to identify top-performing models in the domain.\n\nCONTENT: Implicit Security Requirements Classification 29\nThe analysis (Table 8) highlights the significant pairwise contrasts and\nreveals important performance distinctions:\n–Baseline vs. Advanced Models: The Naive Baseline was consistently out-\nperformed by the advanced models. The difference between the Baseline\nand models such as SecureBERT (p <0.001) and Gemini 2.0 Few-Shot\n(p <0.001) was statistically significant, confirming that the high Weighted-\nF1 scores of these models reflect genuine learning beyond simple majority-\nclass prediction.\n–Fine-Tuning vs. Zero-Shot LLMs: Fine-tuned models like SecureBERT\ndemonstrated statistically significant performance distinctions (p <0.001)\nwhen compared to general-purpose LLMs operating in a zero-shot setting,\nsuch as GPT-4o (p <0.001) and Llama 3 70B (p <0.001). This indi-\ncates that without in-context examples, domain-specific fine-tuning retains\na measurable statistical advantage.\n–Fine-Tuning vs. Few-Shot State-of-the-Art: The pairwise comparison be-\ntween the best fine-tuned model (SecureBERT) and the best LLM ap-\nproach (Gemini 2.0 Few-Shot) yielded ap-value of 0.102. This value is not\nstatistically significant at theα= 0.05 level, supporting our finding that\nfew-shot prompting with state-of-the-art LLMs can effectively match the\nperformance of specialized, fine-tuned BERT models in this domain.\nTable 8: Significant Pairwise Differences (Wilcoxon Signed-Rank Test)\nModel A Model B Statistic p-value\nNaive Baseline SecureBERT 0.0 0.00098\nNaive Baseline BERT Turkish 0.0 0.00098\nNaive Baseline Gemini 2.0 (Few-Shot) 0.0 0.00098\nNaive Baseline Gemini 2.0 Pro (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Few-Shot) 0.0 0.00098\nSecureBERT Gemini 2.0 (Zero-Shot) 25.0 0.501\nSecureBERT Gemini 2.0 (Few-Shot) 14.5 0.102\nTo visualize the relative performance and statistical significance groups\nof all evaluated models, we constructed a Critical Difference (CD) diagram\n(Figure 2) using the Nemenyi post-hoc test.\nIn the CD diagram, models are arranged along the horizontal axis accord-\ning to their average rank. The best performing models, such as Gemini 2.0\nPro (Few-Shot) and BERT-Multilingual, appear on the left (lowest ranks).\nA horizontal bar connects groups of models that are not statistically signifi-\ncantly different from one another. The wide span of the CD bar (10.46) reflects\nthe high number of models compared (23) relative to the number of datasets\n(11). Despite this conservative threshold, the diagram clearly separates the\ntop-tier models (Fine-tuned BERTs and Few-Shot Gemini/GPT-4o) from the\nlower-performing group (Naive Baseline, Zero-Shot Gemma/Llama).', 'CONTEXT: **Performance Visualization and Analysis of Classifiers**: This chunk focuses on the comparative performance analysis of 20 classifiers across OWASP ASVS classes, using critical difference diagrams, heatmaps, and gap analysis to highlight strengths and weaknesses, particularly in handling rare security classes like V6 (Stored Cryptography) and V12 (Files and Resources). It also discusses dataset diversity, threats to validity, and the generalizability of findings.\n\nCONTENT: 30 Yusuf G¨ ur et al.\nFig. 2: Critical Difference (CD) diagram visualizing the statistical comparison\nof classifiers. The horizontal axis represents the average rank of each model\nacross all 11 OWASP ASVS classes (lower ranks indicate better performance).\nThe Critical Difference (CD = 10.46) represents the minimum difference in\naverage rank required for two models to be considered statistically significantly\ndifferent atp <0.05.\n5.6 Comparative Visualization Analysis\nTo complement the statistical rankings, we visualized the performance land-\nscape across all 20 model configurations.\nHeatmap Analysis: Figure 3 shows F1-scores by class. Requirements related\nto V2 (Authentication), V3 (Session Management), and V4 (Access Control)\nare handled well by nearly all models, with scores typically above 0.95. These\ncategories are common and appear consistently across training sources. In\ncontrast, V6 (Stored Cryptography) and V12 (Files and Resources) show low\nscores across the board, including for GPT-4o and Gemini 2.0 Pro. This pat-\ntern points to a systematic difficulty with sparse categories rather than a\nweakness of a particular model.\nGap Analysis: Figure 4 contrasts average performance on frequent and in-\nfrequent classes. Fine-tuned models such as SecureBERT and BERT-Multilingual\nperform better on rare classes, with F1-scores around 0.70–0.80. Zero-shot\nLLMs perform poorly in these cases, often below 0.30. Few-shot prompting\nimproves results for some models, such as Gemini 2.0, but the gap remains\nsubstantial.\n6 Threats to Validity\nOur dataset consists of 2,652 requirements derived from six Software Require-\nments Specification (SRS) documents. While the number of source documents\n\nImplicit Security Requirements Classification 31\nFig. 3:Comprehensive Performance Heatmap.F1-scores for all 20 eval-\nuated models across 11 OWASP ASVS classes. The visualization highlights\nthe “zone of failure” (red) for classes V6 and V12 across models, contrasting\nwith the high performance (green) on ubiquitous classes like V2 and V4.\nis limited, potential bias was mitigated by strategically selecting projects from\nsix distinct business domains: Construction, Legal, Education, Software, Meet-\ning Management, and Accommodation. This semantic diversity ensures that\nthe models are evaluated on a broad vocabulary and varied functional contexts\nrather than a single industry vertical. A specific consideration regarding the\nexternal validity of this study is that the ASRD is a Turkish-language corpus\nwhich allows for the evaluation of automated tools in linguistically diverse\nindustrial contexts.\nFurthermore, because security requirements (e.g., Authentication, Log-\nging) represent cross-cutting concerns that apply universally across software\nsystems, we believe the fundamental patterns captured in the ASRD are trans-\nferable to other industries. Our current evaluation used a stratified split across\nthe entire dataset, meaning requirements from all six source projects are\npresent in the training, validation, and test sets. However, we acknowledge\nthat this approach does not fully measure the models’ ability to generalize to\nentirely new projects with different authors or linguistic styles, as the test set\nis not completely “unseen” in terms of project context.', 'CONTEXT: **Analysis of Minority Class Performance and Annotation Challenges in SRE**: This chunk discusses the performance gap between majority and minority security classes in SRE, the expert-driven annotation process using the MATTER cycle, and the measures taken to mitigate subjectivity and ensure realistic, industry-relevant model evaluation.\n\nCONTENT: 32 Yusuf G¨ ur et al.\nFig. 4:Minority vs. Majority Class Performance Gap.A comparative\nanalysis revealing that while advanced LLMs and fine-tuned models achieve\nnear-parity on Majority Classes (Blue), a significant performance gap remains\non Minority Classes (Red), underscoring the “Long Tail” challenge in SRE.\nAnnotation was performed by three experienced cybersecurity experts.\nWhile their domain knowledge ensured quality, the small annotator pool may\nintroduce subjective bias and limit the range of interpretations. This was mit-\nigated through the iterative MATTER cycle which includes training, iterative\nguideline refinement, and consensus-based adjudication.\nA key threat to internal validity is subjectivity as classifications rely heavily\non the latent domain knowledge and industry experience, rather than explicit\nindicators within the requirement text itself. This expert-driven approach pro-\nvides a “gold standard” for realistic industrial needs but it may introduce in-\nconsistencies if replicated by annotators with different backgrounds or if the\nbroader system context is not explicitly documented.\nThe test set was manually selected to balance computational efficiency and\ngeneralizability assessment. While cross-validation could improve test calibra-\ntion, it was avoided due to its high computational cost.\nTo minimize researcher bias and ensure the results reflect real-world in-\ndustry needs, domain experts used for the selection of both the test set and\nthe LLM suite. Rather than selecting data or models arbitrarily, these experts\ncurated a test set containing the most complex, “implicit” security scenarios\nto challenge the models beyond simple pattern matching. For the model suite,\nthey prioritized architectures with advanced reasoning capabilities, hypothe-\nsizing that these specific technical features are essential for the multi-step de-\nduction required in security requirements engineering. Although the experts', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.', 'CONTEXT: **Comparison of Effort vs. Performance and Validation of ASRD**: This chunk compares the effort and performance of different approaches (BERT fine-tuning, few-shot, and zero-shot LLMs) for security requirement classification, highlights the advantages of the ASRD dataset over existing benchmarks, and emphasizes the challenges of eliciting implicit security requirements in real-world industrial contexts.\n\nCONTENT: 34 Yusuf G¨ ur et al.\nTable 9: Comparison of Effort vs. Performance across Approaches\nApproach Data Requirement Est. Setup Effort Best Macro-F1\nBERT Fine-Tuning High (∼2,600 ex) High (267 hours)0.942\nLLM Few-Shot Low (∼30 ex) Low (<10 hours)0.941\nLLM Zero-Shot None Minimal (<2 hours) 0.890\nLLM Few-Shot approach (using Gemini 2.0) achieved a similar performance\n(Macro-F1 0.941) while requiring only the selection of a small number of in-\ncontext examples (approx. 30 examples per prompt).\nThis comparison points to diminishing returns from large-scale annotation\nwhen capable LLMs are available. Although extensive annotation was required\nhere to establish a reliable ground truth and validate the test set, the results\nindicate that, in industrial settings, a few-shot LLM approach can offer a more\nfavorable balance between effort and accuracy. Comparable performance can\nbe reached with substantially less data preparation, reducing the need for\nprolonged expert annotation.\nThe main contribution of this work is the introduction and validation of\nthe ASRD. The consistent performance of both fine-tuned BERT models and\nLLM-based approaches on ASRD supports its reliability and practical value.\nThe dataset addresses a persistent limitation in SRE research which is the\nlack of large, well-curated, professionally sourced benchmarks for security re-\nquirement classification. Compared with existing datasets, ASRD offers sev-\neral advantages. Unlike DOSSPRE (Kadebu et al., 2023), which is derived\nfrom student projects, ASRD includes 2,652 requirements from six commer-\ncial software systems, reflecting real industrial language and complexity. Its\nOWASP ASVS–based taxonomy spans 11 security classes, providing finer de-\ntail than PROMISE exp (Lima et al., 2019), where security is treated as a\nsingle category. Although the healthcare dataset by Riaz et al. (Riaz et al.,\n2014) is larger, it focuses on six broad objectives within a single domain, lim-\niting its scope. By contrast, ASRD supports cross-domain analysis and aligns\nwith a framework widely used in practice.\nThe dataset also benefits from a rigorous annotation process. Three cy-\nbersecurity specialists, each with over 15 years of experience, labeled the data\nusing an iterative MATTER-based procedure. This resulted in strong agree-\nment (Fleiss’ Kappa = 0.82) and helps mitigate the subjectivity that often\naffects security-related requirement datasets.\nBeyond the dataset construction, this study highlights the complexity of\nimplicit security requirement elicitation. A significant portion of security vul-\nnerabilities stems not from missing explicit security constraints (e.g., “The\nsystem shall encrypt passwords”), but from functional requirements that im-\nplicitly demand robust security controls. Our analysis of the ASRD reveals\nthat functional descriptions of business logic often conceal a dense network of\nsecurity dependencies. A representative example from our results is Require-\nment No. 2 (“The system will carry out the asset handover process”). While', 'CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1', 'CONTEXT: **Performance Metrics for Security Verification Categories and LLM Evaluation**: This chunk presents detailed performance metrics (precision, recall, F1 scores, and support) for various OWASP ASVS security verification categories, highlighting the classification results of LLMs used in the study, with a focus on challenges in underrepresented categories like cryptography and file/resource verification.\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.967 0.939 0.972 0.882 0.280 0.960 0.962 0.954 0.783 0.479 0.884RECALL 0.990 0.963 0.990 0.994 0.718 0.977 0.984 0.982 0.900 0.821 0.981F1 0.978 0.951 0.981 0.934 0.403 0.968 0.973 0.968 0.837 0.605 0.930SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nTest Results of the LLMs used in the study\n56 Yusuf G¨ ur et al.\nD Test Results of the LLMs']",The Nemenyi post-hoc test was used to visualize performance differences in the Critical Difference (CD) diagram. This test was employed to identify statistically significant differences in the average ranks of the evaluated models. (Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf),The Nemenyi post-hoc test was used to construct the Critical Difference (CD) diagram[cite: 532].,,,
What does the 'zone of failure' in the performance heatmap refer to?,"['CONTEXT: **Performance Visualization and Analysis of Classifiers**: This chunk focuses on the comparative performance analysis of 20 classifiers across OWASP ASVS classes, using critical difference diagrams, heatmaps, and gap analysis to highlight strengths and weaknesses, particularly in handling rare security classes like V6 (Stored Cryptography) and V12 (Files and Resources). It also discusses dataset diversity, threats to validity, and the generalizability of findings.\n\nCONTENT: 30 Yusuf G¨ ur et al.\nFig. 2: Critical Difference (CD) diagram visualizing the statistical comparison\nof classifiers. The horizontal axis represents the average rank of each model\nacross all 11 OWASP ASVS classes (lower ranks indicate better performance).\nThe Critical Difference (CD = 10.46) represents the minimum difference in\naverage rank required for two models to be considered statistically significantly\ndifferent atp <0.05.\n5.6 Comparative Visualization Analysis\nTo complement the statistical rankings, we visualized the performance land-\nscape across all 20 model configurations.\nHeatmap Analysis: Figure 3 shows F1-scores by class. Requirements related\nto V2 (Authentication), V3 (Session Management), and V4 (Access Control)\nare handled well by nearly all models, with scores typically above 0.95. These\ncategories are common and appear consistently across training sources. In\ncontrast, V6 (Stored Cryptography) and V12 (Files and Resources) show low\nscores across the board, including for GPT-4o and Gemini 2.0 Pro. This pat-\ntern points to a systematic difficulty with sparse categories rather than a\nweakness of a particular model.\nGap Analysis: Figure 4 contrasts average performance on frequent and in-\nfrequent classes. Fine-tuned models such as SecureBERT and BERT-Multilingual\nperform better on rare classes, with F1-scores around 0.70–0.80. Zero-shot\nLLMs perform poorly in these cases, often below 0.30. Few-shot prompting\nimproves results for some models, such as Gemini 2.0, but the gap remains\nsubstantial.\n6 Threats to Validity\nOur dataset consists of 2,652 requirements derived from six Software Require-\nments Specification (SRS) documents. While the number of source documents\n\nImplicit Security Requirements Classification 31\nFig. 3:Comprehensive Performance Heatmap.F1-scores for all 20 eval-\nuated models across 11 OWASP ASVS classes. The visualization highlights\nthe “zone of failure” (red) for classes V6 and V12 across models, contrasting\nwith the high performance (green) on ubiquitous classes like V2 and V4.\nis limited, potential bias was mitigated by strategically selecting projects from\nsix distinct business domains: Construction, Legal, Education, Software, Meet-\ning Management, and Accommodation. This semantic diversity ensures that\nthe models are evaluated on a broad vocabulary and varied functional contexts\nrather than a single industry vertical. A specific consideration regarding the\nexternal validity of this study is that the ASRD is a Turkish-language corpus\nwhich allows for the evaluation of automated tools in linguistically diverse\nindustrial contexts.\nFurthermore, because security requirements (e.g., Authentication, Log-\nging) represent cross-cutting concerns that apply universally across software\nsystems, we believe the fundamental patterns captured in the ASRD are trans-\nferable to other industries. Our current evaluation used a stratified split across\nthe entire dataset, meaning requirements from all six source projects are\npresent in the training, validation, and test sets. However, we acknowledge\nthat this approach does not fully measure the models’ ability to generalize to\nentirely new projects with different authors or linguistic styles, as the test set\nis not completely “unseen” in terms of project context.', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to', 'CONTEXT: **Performance Metrics for OWASP ASVS Verification Categories**: This chunk presents precision, recall, F1 scores, and support metrics for various OWASP ASVS verification categories, highlighting model performance across security requirements, with particular challenges in underrepresented classes like V6 (Cryptography) and V12 (Files/Resources).\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.943 0.922 0.967 0.905 0.214 0.903 0.918 0.906 0.876 0.250 0.880RECALL 0.950 0.932 0.974 0.943 0.231 0.907 0.927 0.914 0.920 0.250 0.899F1 0.947 0.927 0.970 0.924 0.222 0.905 0.922 0.910 0.898 0.250 0.890SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398', 'CONTEXT: **Performance Metrics for OWASP ASVS Verification Categories**: This chunk presents precision, recall, F1 scores, and support metrics for various OWASP ASVS verification categories, highlighting model performance across security requirements, with a focus on challenges in underrepresented classes like V6 Cryptography and V12 File/Resources.\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.975 0.972 0.975 0.970 0.917 0.985 0.975 0.975 0.930 0.869 0.962RECALL 0.974 0.972 0.974 0.963 0.175 0.985 0.974 0.974 0.911 0.350 0.955F1 0.992 0.992 0.990 0.987 0.179 0.997 0.995 0.995 0.960 1.000 0.994SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398', 'CONTEXT: **Performance Metrics for Security Verification Categories and LLM Evaluation**: This chunk presents detailed performance metrics (precision, recall, F1 scores, and support) for various OWASP ASVS security verification categories, highlighting the classification results of LLMs used in the study, with a focus on challenges in underrepresented categories like cryptography and file/resource verification.\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.967 0.939 0.972 0.882 0.280 0.960 0.962 0.954 0.783 0.479 0.884RECALL 0.990 0.963 0.990 0.994 0.718 0.977 0.984 0.982 0.900 0.821 0.981F1 0.978 0.951 0.981 0.934 0.403 0.968 0.973 0.968 0.837 0.605 0.930SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nTest Results of the LLMs used in the study\n56 Yusuf G¨ ur et al.\nD Test Results of the LLMs', 'CONTEXT: **Comparison of Effort vs. Performance and Validation of ASRD**: This chunk compares the effort and performance of different approaches (BERT fine-tuning, few-shot, and zero-shot LLMs) for security requirement classification, highlights the advantages of the ASRD dataset over existing benchmarks, and emphasizes the challenges of eliciting implicit security requirements in real-world industrial contexts.\n\nCONTENT: 34 Yusuf G¨ ur et al.\nTable 9: Comparison of Effort vs. Performance across Approaches\nApproach Data Requirement Est. Setup Effort Best Macro-F1\nBERT Fine-Tuning High (∼2,600 ex) High (267 hours)0.942\nLLM Few-Shot Low (∼30 ex) Low (<10 hours)0.941\nLLM Zero-Shot None Minimal (<2 hours) 0.890\nLLM Few-Shot approach (using Gemini 2.0) achieved a similar performance\n(Macro-F1 0.941) while requiring only the selection of a small number of in-\ncontext examples (approx. 30 examples per prompt).\nThis comparison points to diminishing returns from large-scale annotation\nwhen capable LLMs are available. Although extensive annotation was required\nhere to establish a reliable ground truth and validate the test set, the results\nindicate that, in industrial settings, a few-shot LLM approach can offer a more\nfavorable balance between effort and accuracy. Comparable performance can\nbe reached with substantially less data preparation, reducing the need for\nprolonged expert annotation.\nThe main contribution of this work is the introduction and validation of\nthe ASRD. The consistent performance of both fine-tuned BERT models and\nLLM-based approaches on ASRD supports its reliability and practical value.\nThe dataset addresses a persistent limitation in SRE research which is the\nlack of large, well-curated, professionally sourced benchmarks for security re-\nquirement classification. Compared with existing datasets, ASRD offers sev-\neral advantages. Unlike DOSSPRE (Kadebu et al., 2023), which is derived\nfrom student projects, ASRD includes 2,652 requirements from six commer-\ncial software systems, reflecting real industrial language and complexity. Its\nOWASP ASVS–based taxonomy spans 11 security classes, providing finer de-\ntail than PROMISE exp (Lima et al., 2019), where security is treated as a\nsingle category. Although the healthcare dataset by Riaz et al. (Riaz et al.,\n2014) is larger, it focuses on six broad objectives within a single domain, lim-\niting its scope. By contrast, ASRD supports cross-domain analysis and aligns\nwith a framework widely used in practice.\nThe dataset also benefits from a rigorous annotation process. Three cy-\nbersecurity specialists, each with over 15 years of experience, labeled the data\nusing an iterative MATTER-based procedure. This resulted in strong agree-\nment (Fleiss’ Kappa = 0.82) and helps mitigate the subjectivity that often\naffects security-related requirement datasets.\nBeyond the dataset construction, this study highlights the complexity of\nimplicit security requirement elicitation. A significant portion of security vul-\nnerabilities stems not from missing explicit security constraints (e.g., “The\nsystem shall encrypt passwords”), but from functional requirements that im-\nplicitly demand robust security controls. Our analysis of the ASRD reveals\nthat functional descriptions of business logic often conceal a dense network of\nsecurity dependencies. A representative example from our results is Require-\nment No. 2 (“The system will carry out the asset handover process”). While', 'CONTEXT: **Performance Metrics for Security Requirement Classification Models**: This chunk presents the precision, recall, F1 scores, and support metrics for various OWASP ASVS categories, highlighting the performance of BERT models and a naive baseline in classifying implicit security requirements, with a focus on challenges like class imbalance and underrepresented categories.\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.960 0.950 0.960 0.790 0.000 0.980 0.970 0.960 0.750 0.000 0.800RECALL 1.000 1.000 1.000 1.000 0.000 1.000 1.000 1.000 1.000 0.000 1.000F1 0.980 0.980 0.980 0.880 0.000 0.990 0.980 0.980 0.860 0.000 0.890SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nTest Results of the BERT models and Naïve Baseline used in the study\nImplicit Security Requirements Classification 55\nC Test Results of the Bert Models', 'CONTEXT: This chunk provides a detailed comparison of the performance metrics (precision, recall, F1 scores, and support) for various BERT-based models, including SecureBERT, in classifying security requirements across OWASP ASVS categories, highlighting their effectiveness and challenges in handling underrepresented classes.\n\nCONTENT: bert-base-multilingual-uncased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.984 0.982 0.982 0.975 0.744 0.985 0.980 0.984 0.983 0.864 0.991RECALL 0.997 0.995 0.995 0.984 0.842 0.995 1.000 1.000 0.983 0.704 0.994F1 0.990 0.988 0.988 0.979 0.790 0.990 0.990 0.992 0.983 0.776 0.992SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nbert-base-turkish-cased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.974 0.974 0.980 0.975 0.756 0.985 0.982 0.974 0.980 0.800 0.972RECALL 0.997 0.997 1.000 0.994 0.816 0.997 1.000 1.000 0.977 0.593 0.994F1 0.985 0.985 0.990 0.984 0.785 0.991 0.991 0.987 0.978 0.681 0.983SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nbert-base-uncased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.982 0.979 0.982 0.981 0.781 0.985 0.980 0.974 0.977 0.813 0.978RECALL 0.995 0.995 0.995 0.975 0.658 0.992 0.997 0.997 0.987 0.481 0.987F1 0.988 0.987 0.988 0.978 0.714 0.988 0.988 0.985 0.982 0.604 0.982SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nSecureBERT\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.974 0.977 0.980 0.972 0.707 0.985 0.977 0.974 0.964 0.700 0.969RECALL 0.995 0.995 0.997 0.984 0.763 0.997 1.000 0.997 0.990 0.519 0.997F1 0.984 0.986 0.988 0.978 0.734 0.991 0.988 0.985 0.977 0.596 0.983SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nNaive Baseline\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements']","The ""zone of failure"" in the performance heatmap refers to the areas highlighted in red, which indicate poor performance across models for specific OWASP ASVS classes. In this study, the ""zone of failure"" is particularly associated with classes V6 (Stored Cryptography) and V12 (Files and Resources). These categories are underrepresented and systematically challenging for all evaluated models, including advanced ones like GPT-4o and Gemini 2.0 Pro. This contrasts with the high performance (green areas) observed for more common classes like V2 (Authentication) and V4 (Access Control), which are consistently well-handled due to their frequent appearance in training datasets.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","It refers to the red areas in the heatmap corresponding to classes V6 and V12, indicating low F1-scores across all models due to data sparsity[cite: 556, 606].",,,
How many person-hours were required to annotate the ASRD?,"['CONTEXT: **Comparison of Effort vs. Performance and Validation of ASRD**: This chunk compares the effort and performance of different approaches (BERT fine-tuning, few-shot, and zero-shot LLMs) for security requirement classification, highlights the advantages of the ASRD dataset over existing benchmarks, and emphasizes the challenges of eliciting implicit security requirements in real-world industrial contexts.\n\nCONTENT: 34 Yusuf G¨ ur et al.\nTable 9: Comparison of Effort vs. Performance across Approaches\nApproach Data Requirement Est. Setup Effort Best Macro-F1\nBERT Fine-Tuning High (∼2,600 ex) High (267 hours)0.942\nLLM Few-Shot Low (∼30 ex) Low (<10 hours)0.941\nLLM Zero-Shot None Minimal (<2 hours) 0.890\nLLM Few-Shot approach (using Gemini 2.0) achieved a similar performance\n(Macro-F1 0.941) while requiring only the selection of a small number of in-\ncontext examples (approx. 30 examples per prompt).\nThis comparison points to diminishing returns from large-scale annotation\nwhen capable LLMs are available. Although extensive annotation was required\nhere to establish a reliable ground truth and validate the test set, the results\nindicate that, in industrial settings, a few-shot LLM approach can offer a more\nfavorable balance between effort and accuracy. Comparable performance can\nbe reached with substantially less data preparation, reducing the need for\nprolonged expert annotation.\nThe main contribution of this work is the introduction and validation of\nthe ASRD. The consistent performance of both fine-tuned BERT models and\nLLM-based approaches on ASRD supports its reliability and practical value.\nThe dataset addresses a persistent limitation in SRE research which is the\nlack of large, well-curated, professionally sourced benchmarks for security re-\nquirement classification. Compared with existing datasets, ASRD offers sev-\neral advantages. Unlike DOSSPRE (Kadebu et al., 2023), which is derived\nfrom student projects, ASRD includes 2,652 requirements from six commer-\ncial software systems, reflecting real industrial language and complexity. Its\nOWASP ASVS–based taxonomy spans 11 security classes, providing finer de-\ntail than PROMISE exp (Lima et al., 2019), where security is treated as a\nsingle category. Although the healthcare dataset by Riaz et al. (Riaz et al.,\n2014) is larger, it focuses on six broad objectives within a single domain, lim-\niting its scope. By contrast, ASRD supports cross-domain analysis and aligns\nwith a framework widely used in practice.\nThe dataset also benefits from a rigorous annotation process. Three cy-\nbersecurity specialists, each with over 15 years of experience, labeled the data\nusing an iterative MATTER-based procedure. This resulted in strong agree-\nment (Fleiss’ Kappa = 0.82) and helps mitigate the subjectivity that often\naffects security-related requirement datasets.\nBeyond the dataset construction, this study highlights the complexity of\nimplicit security requirement elicitation. A significant portion of security vul-\nnerabilities stems not from missing explicit security constraints (e.g., “The\nsystem shall encrypt passwords”), but from functional requirements that im-\nplicitly demand robust security controls. Our analysis of the ASRD reveals\nthat functional descriptions of business logic often conceal a dense network of\nsecurity dependencies. A representative example from our results is Require-\nment No. 2 (“The system will carry out the asset handover process”). While', 'CONTEXT: **Annotation Process and Quality Assurance in ASRD Development**: This chunk details the iterative annotation process for the ASRD dataset, including pilot and independent annotation phases, adjudication meetings, and the use of agreement metrics (e.g., Fleiss’s Kappa) to ensure high annotation quality and consistency among cybersecurity experts.\n\nCONTENT: 16 Yusuf G¨ ur et al.\n(1) original text and annotations were recoverable, (2) clear documenta-\ntion was maintained, (3) annotation quality was consistently high. The\nannotation template included fields for the software requirement text, se-\nlected OWASP labels, and annotator comments or questions. All versions\nof the guideline and annotation documents were preserved to track revi-\nsions based on annotator feedback. For the annotation process, a sample\ncorpus from the requirement set has been selected by inter agreement of\nSMEs. The first version of the Annotation Guideline based on OWASP\nASVS security classes has been developed, where each annotator has in-\ndividually classified the sample corpus by annotating it with one or more\nlabels following the instructions provided in the first Annotation Guide-\nline. After the initial annotation, the SMEs met under the guidance of the\nsenior SME, who is also the branch manager, to review and discuss the\nannotation decisions. Each of the 30 software requirements was examined\nindividually, and in cases where there were differing opinions among the\nannotators, efforts were made to persuade and convince others by provid-\ning explanations and reasons for their choices. After three iterations of\ndiscussions and deliberations, a full agreement was reached for 30 software\nrequirements.\n–Pilot Annotation: An initial batch of 30 software requirements was anno-\ntated early in the study, prompting multiple discussion rounds and three\nupdates to the guidelines. Adjudication meetings enabled the resolution\nof non-consensus requirements through SME-led discussions, during which\nthe rationale for classification was articulated. Discrepancies arising from\nquality issues, such as guideline violations, were addressed by implement-\ning corrections to ensure conformity with established criteria. Each SME\nprovided justifications for their decisions, which facilitated informed dis-\ncussions and enhanced understanding during adjudication. This iterative\nprocess resolved discrepancies across 98 requirements throughout the entire\ncorpus and was important in establishing the finalized annotation frame-\nwork.\n–Independent Annotation: Each SME classified all remaining 2622 require-\nments independently, using the finalized guideline. Annotators were re-\nquired to justify each decision. This practice proved important for facili-\ntating informed discussions and understanding annotator reasoning during\nthe subsequent adjudication phase. The process took 284 days and 267\nperson-hours of expert time.\n–Agreement Metrics: Inter-Annotator Agreement (IAA) was calculated us-\ning Fleiss’s Kappa and pairwise Cohen’s Kappa to assess consistency. IAA\nscores were instrumental in identifying instances of disagreement among\nannotators, thereby highlighting areas where the guidelines might require\nfurther clarification or where ambiguous requirement phrasings contributed\nto annotation discrepancies. Fleiss’s Kappa coefficient of 0.82 was obtained\nacross the three annotators, indicating strong agreement that significantly\nexceeded random chance. Pairwise Cohen’s Kappa values, ranging from', 'CONTEXT: This chunk details the **annotation methodology** and **dataset curation process** for the ASRD, following the MATTER cycle framework. It describes annotator selection, corpus preparation, and the iterative development of annotation guidelines aligned with OWASP ASVS categories to ensure high-quality, domain-specific annotations.\n\nCONTENT: Implicit Security Requirements Classification 15\n3.3 Annotation Methodology (MATTER Cycle) & Dataset Curation\nThe annotation process followed the MATTER development cycle, an estab-\nlished iterative framework for corpus annotation (Pustejovsky and Stubbs,\n2012). Crucially, the annotation task was defined as a multi-label text classifi-\ncation problem. It consists of the phases Model, Annotate, Train, Test, Eval-\nuate, and Revise. The annotation guidelines were developed and iteratively\nrefined to ensure consistency and clarity.\nThe Model–Annotate cycle involved writing guidelines, selecting annota-\ntors, conducting trial annotations, and refining the process. Once stabilized,\nthis cycle was expanded to the full dataset to generate a Gold Standard corpus.\nThe annotation workflow included the following processes:\n–Annotator Selection: Following Bayerl and Paul’s recommendation to use\ndomain-aligned annotators (Bayerl and Paul, 2011), three cybersecurity\nsubject matter experts (SME) from the agency, each with over 15 years\nof experience in designing security architectures, analyzing threat models,\nand identifying security requirements, performed the annotations. Their\ndeep practical experience ensured accurate and context-aware interpreta-\ntion which aligned with the requirement “experts must demonstrate signif-\nicant skills, knowledge, and experience” emphasized by Hopkins (Hopkins\nand Unger, 2017). The senior manager among them also provided over-\nsight and led the adjudication process. The senior SME acted as both an\nannotator and the final adjudicator for resolving disagreements. They also\nprovided feedback to improve the quality and clarity of the annotation\nguideline.\n–Corpus Selection and Preparation: Cohen (Cohen et al., 2005) recommends\nthat during corpus design, balance and representativeness of the corpus\nis important. In line with his recommendation, of the 19 initial project\ndocuments, six were chosen for their domain diversity and potential for\neffective anonymization by the SMEs. These documents underwent a semi-\nautomated anonymization process to remove all project-specific and per-\nsonally identifiable information (PII). The process targeted entities such\nas names of individuals and organizations, project codenames, and specific\ntechnical identifiers. This was done using custom scripts with placeholder\nreplacement, followed by manual review to ensure that anonymization did\nnot alter the meaning, structure, or intent of the original requirements. The\nextracted requirements were then randomized and masked to prevent po-\ntential bias related to document origin or sequence during the annotation\nphase. Total corpus has 2,652 requirements (30 pilot + 2,622 independent\nannotations).\n–Annotation Guideline Development: The Annotation Guidelines’ develop-\nment involved an initial iterative process, refining the guidelines three times\nto resolve ambiguities before the formal assessment phase. Annotation rules\nwere based on OWASP ASVS categories V2–V13 and refined iteratively\nusing example annotations. Following best practices suggested by Cohen\n(Cohen et al., 2005), the guidelines and annotation documents ensured:', 'CONTEXT: **Annotation Process and Dataset Composition**: This chunk details the multi-stage annotation methodology used to create the ASRD dataset, addressing class distribution, challenges with imbalanced categories (e.g., V6 Cryptography, V12 Files/Resources), and the inclusion of true negatives to ensure realistic and high-quality security requirement classification.\n\nCONTENT: Implicit Security Requirements Classification 17\n0.71 to 0.79, further confirmed substantial agreement between individual\nannotator pairs.\n–Adjudication: Disagreements were resolved through structured expert dis-\ncussions led by the senior SME. When the two annotators disagreed on a\nrequirement, it was resolved through a structured process:\n–Both annotators presented their choice and their reasons.\n–The senior expert reviewed both positions against the guideline.\n–If the guideline clearly supported one choice, that one was used. If not,\nthe senior expert led a discussion to decide.\n–Final decision and the reason was written down.\nThe goal was to reach unanimous agreement for each disputed requirement.\nThis process produced final Gold Standard annotations for 135 contested\nitems, ensuring consistency and validation of the dataset.\nThis multi-stage annotation methodology produced a reliable dataset which\ncomprises 2,652 annotated security-relevant requirements. The category dis-\ntributions of the requirements can be seen in Figure 1. The class distribution\namong the classes are largely balanced (90%) except the V6(Stored Cryptog-\nraphy) and V12 (Files & Resources) as 6% each. This imbalance is considered\na reflection of the source projects, where requirements for these two categories\nare inherently less frequent than pervasive controls like access control or input\nvalidation. Stored cryptography requirements are typically captured as holis-\ntic, architectural decisions rather than numerous, distinct functional require-\nments. Similarly, explicit security controls for file handling are less ubiquitous,\nappearing only in projects with specific file processing features, which explains\ntheir low frequency in our corpus. Sample annotated requirements can be seen\nin Table 4.\nThis imbalance mirrors real-world security requirement frequency - most\nsoftware functions involve access and data; few involve file uploads or encryp-\ntion configuration - and introduces a challenge for machine learning. Partic-\nularly, the sparsity in V6 and V12 categories may hinder generalization and\ncalls for class imbalance handling techniques. Despite this, the dataset presents\na realistic and high-quality foundation for developing and evaluating security-\naware NLP and classification models.\nTwenty-six requirements (0.98% of the data) labeled as “UNASSIGNED”\nwere requirements unanimously determined by the experts to be purely func-\ntional requirements with no discernible implicit security component (e.g., “The\nsystem will enable application software to be developed with an object-oriented\nprogramming approach”,). These items were intentionally retained in the dataset\nas true negatives to ensure a realistic distribution and test the models’ ability\nto correctly reject non-security items.\n\n18 Yusuf G¨ ur et al.\nFig. 1: Distribution of Classes', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb', 'CONTEXT: This chunk focuses on the introduction of the **Agency Security Requirements Dataset (ASRD)**, detailing its real-world data sources, expert annotation process, and alignment with OWASP ASVS categories, as well as outlining the research questions and comparative evaluation of fine-tuned transformer models versus prompt-based approaches for security requirements classification.\n\nCONTENT: 4 Yusuf G¨ ur et al.\ncient and cost-effective compared to addressing security issues at later stages\nof development ((Khan et al., 2024).\nThis paper proposes a machine learning-based system to automatically an-\nalyze SRS documents and classify security requirements according to OWASP\nASVS. Its main contribution is the Agency Security Requirements Dataset\n(ASRD), a publicly available corpus created to support research in automated\nSRA. The ASRD comprises:\n–Real-World Data: 2,652 Software Requirements Specification (SRS) sen-\ntences extracted from six diverse, real-world industry projects,\n–Expert Annotation: Meticulously annotated by three cybersecurity experts,\neach with over 15 years of industry experience,\n–Rigorous Methodology: Developed using the iterative MATTER cycle an-\nnotation framework (Pustejovsky and Stubbs, 2012),\n–High Granularity and Multi-label Structure: Mapped to 11 distinct, action-\nable security categories from the industry-standard OWASP Application\nSecurity Verification Standard (ASVS,V2–V13), allowing each require-\nment to be associated with multiple categories.\nThe ASRD is intended as a shared research resource and benchmark. Using\nthis dataset, the study conducts an empirical analysis of automated classifica-\ntion approaches and addresses the following research questions:\n1. To what extent can fine-tuned transformer models accurately perform\nmulti-label classification of implicit security requirements into OWASP\nASVS categories using the ASRD?\n2. How does the performance of prompt-based approaches (zero-shot and few-\nshot) using modern LLMs compare to fine-tuned BERT-based models and\nnaive baselines for this task?\nThe results show that few-shot prompting with a modern language model\n(Gemini 2.0) achieves a macro-average F1 score of 0.941, closely matching the\nbest fine-tuned BERT-based model (0.942). This demonstrates that example-\nguided inference can reach performance comparable to supervised fine-tuning\nwhile requiring substantially less annotated data and model retraining. The\nevaluation compares fine-tuned transformer models (e.g., SecureBERT) with\nprompt-based methods in zero-shot and few-shot settings across multiple con-\ntemporary models, demonstrating that prompt-based approaches provide a\npractical and resource-efficient alternative for identifying implicit security re-\nquirements in industrial SRS documents.\nThe remainder of this paper is organized as follows. Section 2 reviews re-\nlated work on NLP-based requirements classification, security frameworks, and\nexisting security datasets. Section 3 describes the curation and expert anno-\ntation of the ASRD and summarizes its key characteristics. Section 4 outlines\nthe experimental setup and classification methods, including fine-tuned BERT\nmodels and prompt-based approaches. Section 5 reports the experimental re-\nsults. Section 6 discusses the findings and their implications, with a com-\nparative analysis of fine-tuning and prompting strategies. Section 7 examines', 'CONTEXT: This chunk discusses the curation and preprocessing of the ASRD dataset, detailing the data collection process from real-world Software Requirements Specification (SRS) documents, the multi-stage preprocessing pipeline for sentence extraction and anonymization, and how the dataset addresses gaps in prior work by incorporating industrial complexity and linguistic diversity.\n\nCONTENT: Implicit Security Requirements Classification 9\n2.3.3 Electronic Health Domain Dataset\nThis corpus focuses on the electronic healthcare industry, a sector defined\nby stringent regulatory and high-assurance demands (Riaz et al., 2014). The\ndataset’s strength lies in its rigorous multi-stage annotation methodology,\nwhich utilized independent researchers and a mediator to ensure high inter-\nannotator agreement. While it provides a large-scale, authentic resource for\nhealthcare-specific tasks, its narrow focus may limit the generalizability of\nmodels to other industries, and its high-level security objectives may be too\ncoarse for detailed technical analysis.\n2.3.4 Summary of Datasets\nAs summarized in Table 1, these datasets vary significantly in their suitability\nfor tasks ranging from general non-functional requirement (NFR) classifica-\ntion to detailed security analysis. Our proposed Agency Security Require-\nments Dataset (ASRD) addresses gaps in prior work by adopting the OWASP\nASVS taxonomy for multi-label annotation. Furthermore, by utilizing real-\nworld projects originally written in Turkish, ASRD introduces both industrial\ncomplexity and linguistic diversity to the field.\n3 Dataset Curation, Annotation, and Evaluation\n3.1 Data Collection and Preprocessing\nThe dataset compilation began with the collection of six Software Require-\nments Specification (SRS) documents from an Agency’s Security Department.\nThese documents were selected from an initial pool of 19 projects executed\nbetween 2019 and 2023, specifically chosen for their domain diversity and\namenability to effective anonymization. The original documents were provided\nin standard document formats (e.g., PDF, DOCX) where requirements were\norganized in itemized lists. To transform these documents into a machine-\nreadable dataset, we employed a multi-stage preprocessing pipeline:\n1. Sentence Segmentation and Extraction: As the source SRS documents uti-\nlized standard itemization for requirements, we employed a rule-based ex-\ntraction method. We utilized pattern matching to identify requirement\nblocks based on hierarchical numbering schemes and line breaks. Each iden-\ntified requirement was extracted and treated as a single processing unit,\npreserving the structural integrity of the original specification.\n2. Anonymization: To protect sensitive data, a semi-automated anonymiza-\ntion process was implemented. Custom scripts replaced entities such as\nproject names, specific URLs, and IP addresses with generic placeholders.\nThis was followed by a manual review by domain experts to ensure that\nthe removal of personally identifiable information (PII) did not compromise\nthe semantic meaning or contextual integrity of the requirements.']","The annotation of the ASRD dataset required **267 person-hours** of expert time. This effort was undertaken by three cybersecurity specialists with over 15 years of experience, following a rigorous iterative annotation process to ensure high-quality and consistent annotations. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","The annotation process took 267 person-hours of expert time[cite: 273, 650].",,,
What is the estimated setup effort for the LLM Few-Shot approach compared to BERT fine-tuning?,"['CONTEXT: **Comparison of Effort vs. Performance and Validation of ASRD**: This chunk compares the effort and performance of different approaches (BERT fine-tuning, few-shot, and zero-shot LLMs) for security requirement classification, highlights the advantages of the ASRD dataset over existing benchmarks, and emphasizes the challenges of eliciting implicit security requirements in real-world industrial contexts.\n\nCONTENT: 34 Yusuf G¨ ur et al.\nTable 9: Comparison of Effort vs. Performance across Approaches\nApproach Data Requirement Est. Setup Effort Best Macro-F1\nBERT Fine-Tuning High (∼2,600 ex) High (267 hours)0.942\nLLM Few-Shot Low (∼30 ex) Low (<10 hours)0.941\nLLM Zero-Shot None Minimal (<2 hours) 0.890\nLLM Few-Shot approach (using Gemini 2.0) achieved a similar performance\n(Macro-F1 0.941) while requiring only the selection of a small number of in-\ncontext examples (approx. 30 examples per prompt).\nThis comparison points to diminishing returns from large-scale annotation\nwhen capable LLMs are available. Although extensive annotation was required\nhere to establish a reliable ground truth and validate the test set, the results\nindicate that, in industrial settings, a few-shot LLM approach can offer a more\nfavorable balance between effort and accuracy. Comparable performance can\nbe reached with substantially less data preparation, reducing the need for\nprolonged expert annotation.\nThe main contribution of this work is the introduction and validation of\nthe ASRD. The consistent performance of both fine-tuned BERT models and\nLLM-based approaches on ASRD supports its reliability and practical value.\nThe dataset addresses a persistent limitation in SRE research which is the\nlack of large, well-curated, professionally sourced benchmarks for security re-\nquirement classification. Compared with existing datasets, ASRD offers sev-\neral advantages. Unlike DOSSPRE (Kadebu et al., 2023), which is derived\nfrom student projects, ASRD includes 2,652 requirements from six commer-\ncial software systems, reflecting real industrial language and complexity. Its\nOWASP ASVS–based taxonomy spans 11 security classes, providing finer de-\ntail than PROMISE exp (Lima et al., 2019), where security is treated as a\nsingle category. Although the healthcare dataset by Riaz et al. (Riaz et al.,\n2014) is larger, it focuses on six broad objectives within a single domain, lim-\niting its scope. By contrast, ASRD supports cross-domain analysis and aligns\nwith a framework widely used in practice.\nThe dataset also benefits from a rigorous annotation process. Three cy-\nbersecurity specialists, each with over 15 years of experience, labeled the data\nusing an iterative MATTER-based procedure. This resulted in strong agree-\nment (Fleiss’ Kappa = 0.82) and helps mitigate the subjectivity that often\naffects security-related requirement datasets.\nBeyond the dataset construction, this study highlights the complexity of\nimplicit security requirement elicitation. A significant portion of security vul-\nnerabilities stems not from missing explicit security constraints (e.g., “The\nsystem shall encrypt passwords”), but from functional requirements that im-\nplicitly demand robust security controls. Our analysis of the ASRD reveals\nthat functional descriptions of business logic often conceal a dense network of\nsecurity dependencies. A representative example from our results is Require-\nment No. 2 (“The system will carry out the asset handover process”). While', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**  \nThis chunk provides a detailed comparison of F1-scores across various LLMs, fine-tuned BERT models, and a baseline approach, highlighting their performance in classifying security requirements, particularly in handling class imbalance and underrepresented categories.\n\nCONTENT: Implicit Security Requirements Classification 25\nTable 7: Aggregated F1-Scores for LLM, BERT Models, and Baseline\nModel Prompting Strategy Macro-F1 Micro-F1 Weighted-F1\nLarge Language Model Results\nLlama 3 70b Zero Shot 0.813 0.941 0.941\nLlama 3 70b Few Shot 0.802 0.925 0.925\nDeepSeek R1 Zero Shot 0.812 0.921 0.916\nDeepSeek R1 Few Shot 0.820 0.927 0.921\nGemini 2.5 Zero Shot 0.8290.957 0.953\nGemini 2.5 Few Shot 0.8170.963 0.959\nGemini 2.0 Zero Shot0.8900.925 0.921\nGemini 2.0 Few Shot0.9410.938 0.938\nGemini 2.0 Pro Zero Shot 0.830 0.908 0.904\nGemini 2.0 Pro Few Shot 0.889 0.959 0.953\nGemma 3 27b Zero Shot 0.806 0.912 0.907\nGemma 3 27b Few Shot 0.802 0.917 0.912\nGemma 3 4b Zero Shot 0.605 0.738 0.742\nGemma 3 4b Few Shot 0.723 0.871 0.867\nGpt 4o Zero Shot 0.790 0.912 0.907\nGpt 4o Few Shot 0.814 0.943 0.939\nGpt 4o mini Zero Shot 0.703 0.803 0.809\nGpt 4o mini Few Shot 0.754 0.852 0.854\nBERT Fine-Tuning Results\nbert-base-multilingual-uncased Fine-Tuning0.942 0.985 0.983\nbert-base-turkish-cased Fine-Tuning 0.933 0.983 0.981\nbert-base-uncased Fine-Tuning 0.914 0.978 0.976\nSecureBERT Fine-Tuning 0.918 0.979 0.976\nBaseline\nNaive Baseline Majority Class 0.774 0.940 0.933\nrepresented categories. The bert-base-multilingual-uncased model achieved the\nhighest Weighted-F1 score at 0.983, while the lowest among the group was\n0.976 for both bert-base-uncased and SecureBERT. However, these results ob-\nscure the impact of class imbalance. Macro-F1 scores, which give equal weight\nto all categories, were lower, ranging from 0.942 to 0.914, revealing reduced\nperformance on less frequent classes.\nThis pattern is clear in the category-level results (Appendix C). Perfor-\nmance was high for common categories such as V8 (Data Protection), where\nthe bert-base-multilingual-uncased model achieved an F1-score of 0.992. In\ncontrast, results declined significantly for sparsely represented categories. For\nV6 (38 samples), F1-scores fell to 0.714 for bert-base-uncased and 0.734 for\nSecureBERT. The weakest performance was observed for V10 (27 samples),\nwith F1-scores around 0.60, indicating limited generalization due to limited\ndata.\nAn analysis of precision and recall for these difficult classes reveals specific\nfailure patterns. For class V10, the bert-base-uncased model has a low Recall of\n0.481. This indicates that while its predictions were often correct (Precision:\n0.813), it failed to identify more than half of the actual V10 requirements,\nresulting in a high number of false negatives. For class V6, the same model', 'CONTEXT: **Comparison of Fine-Tuned Models and LLMs for Security Requirements Classification**: This chunk discusses the performance comparison between fine-tuned transformer models (e.g., BERT) and few-shot prompting with LLMs (e.g., Gemini 2.0) for classifying implicit security requirements in SRS documents, emphasizing the practicality of LLMs as a resource-efficient alternative while highlighting challenges in Security Requirements Engineering (SRE).\n\nCONTENT: 2 Yusuf G¨ ur et al.\ntional fine-tuned transformer models and contemporary Large Language Mod-\nels (LLMs) employing few-shot and zero-shot prompt engineering strategies.\nThe results show that a few-shot prompting with Gemini 2.0 achieves a macro-\naverage F1 score of 0.941, directly comparable to the fine-tuned BERT model’s\n0.942. This study culminates in two primary findings: first, the validation and\npublication of the ASRD, a high-granularity, multi-label dataset for implicit\nsecurity requirements based on OWASP ASVS V2-V13; and second, the di-\nrect comparison demonstrating that few-shot Large Language Models (LLMs)\nachieve competitive multi-label classification performance (Macro-F1 0.941)\nnearly equal to resource-intensive fine-tuned transformer models (Macro-F1\n0.942). This confirms that LLMs represent a highly practical and resource-\nsaving strategy for automating the identification of embedded (implicit) secu-\nrity requirements for software security in industrial SRS documents\nKeywordsCybersecurity requirement elicitation·OWASP based security\nrequirement classification·OWASP ASVS-based Requirement Labeling·\nLLM based classification\n1 Introduction\nRequirements Engineering (RE) concerns the identification, documentation,\nand management of software requirements (Sommerville and Sawyer, 1997).\nThe increasing interconnectivity of information systems forces organizations\nto provide secure services in cyberspace. Integrating security during initial\nrequirements analysis is essential to proactively mitigate risks, reduce vulner-\nabilities, and reduce the high costs associated with downstream remediation\n(Villamizar et al., 2018). This proactive approach is central to the ”Shift-\nLeft” security paradigm, which advocates for the identification and mitigation\nof vulnerabilities as early as possible in the Software Development Life Cycle\n(SDLC).\nAlthough Security Requirements Engineering (SRE) has matured as a dis-\ncipline, its effective application in practice remains challenging. The issue is\nnot the absence of security considerations, but the difficulty of ensuring that\nsecurity requirements are properly validated and verified. An empirical investi-\ngation that combines a systematic literature review with a survey of 58 indus-\ntry professionals highlights this gap (Alam et al., 2025). While practitioners\nreported a moderate understanding of SRE practices, Security Requirements\nAssurance (SRA) was found to be poorly understood and rarely applied in\nindustrial contexts. The study concludes that validating and ensuring security\nrequirements remains a major and unresolved challenge in practice.\nThis assurance gap persists due to the documented lack of specialized se-\ncurity training for developers in early-phase RE (Andrade et al., 2023). The\ntask relies heavily on scarce specialized expertise and time-intensive manual\nanalysis. The main challenge is that critical security requirements are often not\nexplicitly stated. Instead, they are implicitly embedded within standard func-\ntional descriptions. For example, a seemingly simple functional requirement,', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**: This chunk focuses on the statistical evaluation of model performance, comparing fine-tuned models, few-shot, and zero-shot LLM approaches, highlighting significant pairwise differences, and visualizing results through a Critical Difference (CD) diagram to identify top-performing models in the domain.\n\nCONTENT: Implicit Security Requirements Classification 29\nThe analysis (Table 8) highlights the significant pairwise contrasts and\nreveals important performance distinctions:\n–Baseline vs. Advanced Models: The Naive Baseline was consistently out-\nperformed by the advanced models. The difference between the Baseline\nand models such as SecureBERT (p <0.001) and Gemini 2.0 Few-Shot\n(p <0.001) was statistically significant, confirming that the high Weighted-\nF1 scores of these models reflect genuine learning beyond simple majority-\nclass prediction.\n–Fine-Tuning vs. Zero-Shot LLMs: Fine-tuned models like SecureBERT\ndemonstrated statistically significant performance distinctions (p <0.001)\nwhen compared to general-purpose LLMs operating in a zero-shot setting,\nsuch as GPT-4o (p <0.001) and Llama 3 70B (p <0.001). This indi-\ncates that without in-context examples, domain-specific fine-tuning retains\na measurable statistical advantage.\n–Fine-Tuning vs. Few-Shot State-of-the-Art: The pairwise comparison be-\ntween the best fine-tuned model (SecureBERT) and the best LLM ap-\nproach (Gemini 2.0 Few-Shot) yielded ap-value of 0.102. This value is not\nstatistically significant at theα= 0.05 level, supporting our finding that\nfew-shot prompting with state-of-the-art LLMs can effectively match the\nperformance of specialized, fine-tuned BERT models in this domain.\nTable 8: Significant Pairwise Differences (Wilcoxon Signed-Rank Test)\nModel A Model B Statistic p-value\nNaive Baseline SecureBERT 0.0 0.00098\nNaive Baseline BERT Turkish 0.0 0.00098\nNaive Baseline Gemini 2.0 (Few-Shot) 0.0 0.00098\nNaive Baseline Gemini 2.0 Pro (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Few-Shot) 0.0 0.00098\nSecureBERT Gemini 2.0 (Zero-Shot) 25.0 0.501\nSecureBERT Gemini 2.0 (Few-Shot) 14.5 0.102\nTo visualize the relative performance and statistical significance groups\nof all evaluated models, we constructed a Critical Difference (CD) diagram\n(Figure 2) using the Nemenyi post-hoc test.\nIn the CD diagram, models are arranged along the horizontal axis accord-\ning to their average rank. The best performing models, such as Gemini 2.0\nPro (Few-Shot) and BERT-Multilingual, appear on the left (lowest ranks).\nA horizontal bar connects groups of models that are not statistically signifi-\ncantly different from one another. The wide span of the CD bar (10.46) reflects\nthe high number of models compared (23) relative to the number of datasets\n(11). Despite this conservative threshold, the diagram clearly separates the\ntop-tier models (Fine-tuned BERTs and Few-Shot Gemini/GPT-4o) from the\nlower-performing group (Naive Baseline, Zero-Shot Gemma/Llama).', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: **Optimization and Prompting Strategies for Security Classification Models**: This chunk discusses the optimization of BERT variants through systematic hyperparameter tuning and explores the use of large language models (LLMs) for security requirement classification, focusing on zero-shot and few-shot prompting strategies to enhance task-specific performance without modifying the base model.\n\nCONTENT: 22 Yusuf G¨ ur et al.\nWe performed a systematic grid search using the Weights & Biases 12\nplatform to identify the optimal configuration for each BERT variant using\nthe validation dataset. The search space included the following parameters:\n–Maximum Sequence Length:[128, 256]tokens\n–Batch Size:[4, 8, 16]\n–Number of Epochs:[16, 24, 32]\n–Learning Rate:[1e-5, 2e-5, 3e-5]\n–Decision Threshold:[0.3, 0.4, 0.5]\nTo prevent overfitting, we monitored validation loss and implemented early\nstopping with a patience of 2–4 epochs. The checkpoint achieving the lowest\nvalidation loss for each model was selected for the final evaluation on the test\nset.\n4.3 Classification using LLM Models\nLLMs are transformer-based models trained on massive corpora for general-\npurpose natural language understanding and generation. This study adopted\nthe “pre-train, prompt, and predict” paradigm, which replaces traditional\n“pre-train, fine-tune” approaches (Liu et al., 2023a). Rather than adjusting\nthe model’s objective or architecture, prompt engineering is used to steer the\nmodel toward task-specific outputs through carefully designed textual inputs.\nPrompt engineering involves designing prompts that elicit accurate re-\nsponses for specific tasks. In zero-shot prompting, an LLM is directly used\nwithout any task-specific training. Few-shot prompting introduces a small\nnumber of labeled examples in the prompt, which allows the model to learn\nthe task pattern. This is particularly beneficial when labeled training data is\nlimited.\nFour main prompting strategies were proposed by (Liu et al., 2023a):\n–Tuning-free prompting: Requires no model changes, suitable for zero-shot\nsettings, but often demands complex prompt design.\n–Fixed-LLM prompt tuning: Involves learning soft prompts while keep-\ning the model fixed; effective for few-shot tasks but typically lacks inter-\npretability.\n–Fixed-prompt LLM tuning: Fine-tunes the model on a fixed prompt; im-\nproves performance in few-shot settings.\n–Prompt + LLM tuning: Jointly tunes both model and prompts; highly\nexpressive but prone to overfitting on small datasets.\nIn this study, we evaluated the first two of these strategies, as they do\nnot require modification of the base LLM’s weights. For our zero-shot experi-\nments, we implemented tuning-free prompting, relying on carefully engineered\nprompts to guide the models. For our few-shot analysis, our approach aligns\n12 https://wandb.ai/site', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to']","The estimated setup effort for the LLM Few-Shot approach is significantly lower compared to BERT fine-tuning. Specifically:

- **BERT Fine-Tuning**: Requires high data preparation (approximately 2,600 examples) and a substantial setup effort of around 267 hours.
- **LLM Few-Shot**: Requires minimal data preparation (approximately 30 examples) and a much lower setup effort of less than 10 hours.

This demonstrates that the LLM Few-Shot approach offers a more resource-efficient alternative while achieving nearly identical performance (Macro-F1 of 0.941 for LLM Few-Shot vs. 0.942 for BERT fine-tuning). This efficiency makes it particularly advantageous in industrial settings where time and resources for extensive annotation are limited.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)",LLM Few-Shot requires low effort (<10 hours) compared to the high effort (267 hours) required for dataset curation for BERT fine-tuning[cite: 656].,,,
What is SecureBERT and why was it included in the study?,"['CONTEXT: This chunk provides a list of references and related works cited in the document, focusing on advancements in security requirements engineering, domain-specific language models like SecureBERT, and methodologies for automated classification and annotation in software security contexts.\n\nCONTENT: Implicit Security Requirements Classification 39\nAghaei E, Niu X, Shadid W, Al-Shaer E (2022) Securebert: A domain-specific\nlanguage model for cybersecurity. In: International Conference on Security\nand Privacy in Communication Systems, Springer, pp 39–56\nAghaei S, Al-Shaer E, Duan Z (2020) SecureBERT: A domain-specific language\nmodel for cybersecurity.2105.04293\nAI at Meta (2024) The llama 3 herd of models. Tech. rep.,\nMeta, URLhttps://ai.meta.com/research/publications/\nthe-llama-3-herd-of-models/\nAlam JA, Ayman M, Rehman GA, Sarlan AB, et al. (2025) Security require-\nments engineering: A review and analysis. Computers 14(10):429\nAndrade R, Torres J, Ortiz-Garc´ es I, Mi˜ no J, Almeida L (2023) An exploratory\nstudy gathering security requirements for the software development process.\nElectronics 12(17):3594\nAnwar Mohammad MN, Nazir M, Mustafa K (2019) A systematic review\nand analytical evaluation of security requirements engineering approaches.\nArabian Journal for Science and Engineering 44(11):8963–8987\nBatool R, Naseer A, Maqbool A, Kayani M (2025) Automated categorization of\nsoftware security requirements: an nlp and ml based approach. Requirements\nEngineering pp 1–13\nBayerl PS, Paul KI (2011) What determines inter-coder agreement in man-\nual annotations? a meta-analytic investigation. Computational Linguistics\n37(4):699–725\nBolanos F, Salatino A, Osborne F, Motta E (2024) Artificial intelligence for lit-\nerature reviews: Opportunities and challenges. Artificial Intelligence Review\n57(10):259\nChristodoulopoulos C, Chakraborty T, Rose C, Peng V (2025) Proceedings of\nthe 2025 conference on empirical methods in natural language processing.\nIn: Proceedings of the 2025 Conference on Empirical Methods in Natural\nLanguage Processing\nCohen KB, Fox L, Ogren P, Hunter L (2005) Corpus design for biomedical\nnatural language processing. In: Proceedings of the ACL-ISMB workshop\non linking biological literature, ontologies and databases: mining biological\nsemantics, pp 38–45\nDalpiaz F, Dell’Anna D, Aydemir FB, C ¸ evikol S (2019) Requirements clas-\nsification with interpretable machine learning and dependency parsing. In:\n2019 IEEE 27th International Requirements Engineering Conference (RE),\nIEEE, pp 142–152\nDeepSeek AI (2024) DeepSeek-V2: A strong, economical, and efficient mixture-\nof-experts language model. arXiv preprint arXiv:240504434 URLhttps:\n//arxiv.org/abs/2405.04434\nDekhtyar A, Fong V (2017) Re data challenge: Requirements identification\nwith word2vec and tensorflow. In: 2017 IEEE 25th International Require-\nments Engineering Conference (RE), IEEE, pp 484–489\nDemˇ sar J (2006) Statistical comparisons of classifiers over multiple data sets.\nJournal of Machine learning research 7(Jan):1–30', 'CONTEXT: This chunk provides background on NLP-based techniques for software requirements classification, highlighting the evolution from traditional supervised learning methods to transformer-based models like BERT and SecureBERT, and emphasizing the challenges of classifying implicit security requirements due to ambiguity and the lack of high-quality, domain-specific datasets.\n\nCONTENT: Implicit Security Requirements Classification 5\nthreats to validity, and Section 8 concludes with a summary of contributions\nand directions for future work.\n2 Background\nThis section reviews prior work on NLP-based techniques for requirements\nclassification, followed by an overview of relevant security frameworks. It con-\ncludes with a discussion of existing datasets used in security requirements\nresearch.\n2.1 Related Work on Requirements Classification using NLP Techniques\nSoftware requirements (SR) classification supports effective project manage-\nment by enabling prioritization and risk assessment (Batool et al., 2025). The\ntask typically involves distinguishing functional requirements (FRs) from non-\nfunctional requirements (NFRs) and further categorizing NFRs into classes\nsuch as security, usability, and performance. Security requirements may ap-\npear as explicit system behaviors or as quality attributes addressing confiden-\ntiality, integrity, and availability—the security triad—which are often abstract\nand difficult to specify precisely in practice (Anwar Mohammad et al., 2019).\nThis inherent ambiguity complicates the development of clear guidelines for\nseparating security-related requirements from non-security ones.\nEarly studies applied supervised learning techniques, including Bayesian\nclassifiers(Knauss et al., 2011), decision trees (Jindal et al., 2016), and Sup-\nport Vector Machines (SVMs) (Dalpiaz et al., 2019), but these approaches\ndepended heavily on manual feature engineering and rigid linguistic patterns.\nTo address these limitations, later work adopted neural models such as convo-\nlutional neural networks (CNN) combined with Word2Vec embeddings (Dekht-\nyar and Fong, 2017). The adoption of transformer-based models such as BERT\nenabled improved classification accuracy through transfer learning and fine-\ntuning, eliminating the need for handcrafted features (Devlin et al., 2019; Sub-\nahi, 2023). More recent work explores domain-adapted transformer models,\nsuch as NoRBERT (Hey et al., 2020) and SecureBERT (Aghaei et al., 2022),\nto better capture domain-specific semantics and mitigate overfitting. These\nmodels have shown improved capability in identifying implicit non-functional\nrequirements, a particularly challenging task in security-critical settings (Nec-\nula et al., 2024). However, further progress in SRE is limited by the availability\nof large, high-quality, and domain-specific annotated datasets.\nThe subjective nature of defining security requirements further complicates\nreliable classification (Riaz and Williams, 2012). Security Requirement Elic-\nitation highly depends on domain-relevant expertise which includes various\ncostly manual steps such as creating security requirement templates, deter-\nmining security classification levels according to natural language artifacts,\nand mapping the class labels to related requirement templates by identifying\nentities.', 'CONTEXT: **Evaluation of BERT-Based Models for Security Requirements Classification**: This chunk details the architecture, training data, and rationale behind the BERT-based models used in the study, including SecureBERT and multilingual variants, and explains the fine-tuning process and optimization techniques employed to adapt these models for multi-label security classification tasks.\n\nCONTENT: Implicit Security Requirements Classification 21\nTable 5: Details and Rationale of the BERT-based Models Used in the Study\nModel Name\n(Architecture /\nParameters)\nDescription, Training Data,\nand Source\nRationale in Study\nBERT Base (En-\nglish)\n(12 layers, 768\nhidden, 12 heads,\n110M params.)\nStandard BERT-base archi-\ntecture. Pre-trained on the\nBookCorpus and English\nWikipedia.8(Devlin et al., 2019)\nTo serve as a strong performance\nbaseline.\nSecureBERT\n(12 layers, 768\nhidden, 12 heads,\n125M params.)\nBased on the RoBERTa architec-\nture. Pre-trained on a 12GB cor-\npus of cybersecurity texts (NVD,\nCVE, CAPEC). 9(Aghaei et al.,\n2020)\nTo test the hypothesis that\ndomain-specific vocabulary and\ncontext improve classification ac-\ncuracy.\nBERT Base\nMultilingual\n(12 layers, 768\nhidden, 12 heads,\n179M params.)\nStandard BERT-base architec-\nture. Pre-trained on the top\n104 languages with the largest\nWikipedia datasets. 10(Devlin\net al., 2019)\nTo investigate whether training\non a broader set of languages\nprovides any generalization ben-\nefit.\nBERT Base\nTurkish\n(12 layers, 768\nhidden, 12 heads,\n110M params.)\nStandard BERT-base architec-\nture. Pre-trained on a 35GB,\n4.4B token Turkish corpus from\nmultiple sources. 11(Schweter,\n2020)\nTo explore the performance of\na model pre-trained on a lan-\nguage with a different morpho-\nlogical structure than English.\nthe final hidden state of the [CLS] token to a vector corresponding to our\n11 security classes. A sigmoid activation function was applied to this layer to\nproduce independent probabilities, facilitating multi-label classification. The\nfine-tuning process was performed from end-to-end; all weights were unfrozen\nand updated to adapt the models to the specific nuances of the security re-\nquirements text.\nThe models were trained using the PyTorch Lightning framework to ensure\nreproducibility. We employed the AdamW optimizer (Loshchilov and Hutter,\n2019), an extension of the Adam optimizer with improved weight decay, uti-\nlizing a linear learning rate schedule with a warmup phase covering the first\n20% of training steps. This strategy stabilizes training in the initial epochs and\nimproves convergence. Given the multi-label nature of the task, Binary Cross-\nEntropy (BCE) Loss was used as the primary objective function. Because the\nsecurity classes are unevenly distributed, the label assignment threshold (Deci-\nsion Threshold) was tuned rather than fixed at 0.5 to better balance precision\nand recall across categories.', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**: This chunk focuses on the statistical evaluation of model performance, comparing fine-tuned models, few-shot, and zero-shot LLM approaches, highlighting significant pairwise differences, and visualizing results through a Critical Difference (CD) diagram to identify top-performing models in the domain.\n\nCONTENT: Implicit Security Requirements Classification 29\nThe analysis (Table 8) highlights the significant pairwise contrasts and\nreveals important performance distinctions:\n–Baseline vs. Advanced Models: The Naive Baseline was consistently out-\nperformed by the advanced models. The difference between the Baseline\nand models such as SecureBERT (p <0.001) and Gemini 2.0 Few-Shot\n(p <0.001) was statistically significant, confirming that the high Weighted-\nF1 scores of these models reflect genuine learning beyond simple majority-\nclass prediction.\n–Fine-Tuning vs. Zero-Shot LLMs: Fine-tuned models like SecureBERT\ndemonstrated statistically significant performance distinctions (p <0.001)\nwhen compared to general-purpose LLMs operating in a zero-shot setting,\nsuch as GPT-4o (p <0.001) and Llama 3 70B (p <0.001). This indi-\ncates that without in-context examples, domain-specific fine-tuning retains\na measurable statistical advantage.\n–Fine-Tuning vs. Few-Shot State-of-the-Art: The pairwise comparison be-\ntween the best fine-tuned model (SecureBERT) and the best LLM ap-\nproach (Gemini 2.0 Few-Shot) yielded ap-value of 0.102. This value is not\nstatistically significant at theα= 0.05 level, supporting our finding that\nfew-shot prompting with state-of-the-art LLMs can effectively match the\nperformance of specialized, fine-tuned BERT models in this domain.\nTable 8: Significant Pairwise Differences (Wilcoxon Signed-Rank Test)\nModel A Model B Statistic p-value\nNaive Baseline SecureBERT 0.0 0.00098\nNaive Baseline BERT Turkish 0.0 0.00098\nNaive Baseline Gemini 2.0 (Few-Shot) 0.0 0.00098\nNaive Baseline Gemini 2.0 Pro (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Few-Shot) 0.0 0.00098\nSecureBERT Gemini 2.0 (Zero-Shot) 25.0 0.501\nSecureBERT Gemini 2.0 (Few-Shot) 14.5 0.102\nTo visualize the relative performance and statistical significance groups\nof all evaluated models, we constructed a Critical Difference (CD) diagram\n(Figure 2) using the Nemenyi post-hoc test.\nIn the CD diagram, models are arranged along the horizontal axis accord-\ning to their average rank. The best performing models, such as Gemini 2.0\nPro (Few-Shot) and BERT-Multilingual, appear on the left (lowest ranks).\nA horizontal bar connects groups of models that are not statistically signifi-\ncantly different from one another. The wide span of the CD bar (10.46) reflects\nthe high number of models compared (23) relative to the number of datasets\n(11). Despite this conservative threshold, the diagram clearly separates the\ntop-tier models (Fine-tuned BERTs and Few-Shot Gemini/GPT-4o) from the\nlower-performing group (Naive Baseline, Zero-Shot Gemma/Llama).', 'CONTEXT: This chunk provides a detailed comparison of the performance metrics (precision, recall, F1 scores, and support) for various BERT-based models, including SecureBERT, in classifying security requirements across OWASP ASVS categories, highlighting their effectiveness and challenges in handling underrepresented classes.\n\nCONTENT: bert-base-multilingual-uncased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.984 0.982 0.982 0.975 0.744 0.985 0.980 0.984 0.983 0.864 0.991RECALL 0.997 0.995 0.995 0.984 0.842 0.995 1.000 1.000 0.983 0.704 0.994F1 0.990 0.988 0.988 0.979 0.790 0.990 0.990 0.992 0.983 0.776 0.992SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nbert-base-turkish-cased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.974 0.974 0.980 0.975 0.756 0.985 0.982 0.974 0.980 0.800 0.972RECALL 0.997 0.997 1.000 0.994 0.816 0.997 1.000 1.000 0.977 0.593 0.994F1 0.985 0.985 0.990 0.984 0.785 0.991 0.991 0.987 0.978 0.681 0.983SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nbert-base-uncased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.982 0.979 0.982 0.981 0.781 0.985 0.980 0.974 0.977 0.813 0.978RECALL 0.995 0.995 0.995 0.975 0.658 0.992 0.997 0.997 0.987 0.481 0.987F1 0.988 0.987 0.988 0.978 0.714 0.988 0.988 0.985 0.982 0.604 0.982SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nSecureBERT\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.974 0.977 0.980 0.972 0.707 0.985 0.977 0.974 0.964 0.700 0.969RECALL 0.995 0.995 0.997 0.984 0.763 0.997 1.000 0.997 0.990 0.519 0.997F1 0.984 0.986 0.988 0.978 0.734 0.991 0.988 0.985 0.977 0.596 0.983SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nNaive Baseline\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements', 'CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb']","SecureBERT is a domain-specific language model designed for cybersecurity tasks. It is based on the RoBERTa architecture and pre-trained on a 12GB corpus of cybersecurity texts, including sources like NVD (National Vulnerability Database), CVE (Common Vulnerabilities and Exposures), and CAPEC (Common Attack Pattern Enumeration and Classification). SecureBERT was included in the study to test the hypothesis that domain-specific vocabulary and context improve classification accuracy for security requirements. The model demonstrated superior performance in identifying implicit security requirements, particularly in challenging and underrepresented classes, compared to general-purpose models. Its inclusion highlights the importance of fine-tuning models with domain-specific data to address the unique challenges of security requirements classification.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","SecureBERT is a domain-specific language model pre-trained on cybersecurity texts (NVD, CVE, CAPEC). It was included to test if domain-specific vocabulary improves classification accuracy[cite: 375].",,,
Why was the bert-base-turkish-cased model included?,"['CONTEXT: **Evaluation of BERT-Based Models for Security Requirements Classification**: This chunk details the architecture, training data, and rationale behind the BERT-based models used in the study, including SecureBERT and multilingual variants, and explains the fine-tuning process and optimization techniques employed to adapt these models for multi-label security classification tasks.\n\nCONTENT: Implicit Security Requirements Classification 21\nTable 5: Details and Rationale of the BERT-based Models Used in the Study\nModel Name\n(Architecture /\nParameters)\nDescription, Training Data,\nand Source\nRationale in Study\nBERT Base (En-\nglish)\n(12 layers, 768\nhidden, 12 heads,\n110M params.)\nStandard BERT-base archi-\ntecture. Pre-trained on the\nBookCorpus and English\nWikipedia.8(Devlin et al., 2019)\nTo serve as a strong performance\nbaseline.\nSecureBERT\n(12 layers, 768\nhidden, 12 heads,\n125M params.)\nBased on the RoBERTa architec-\nture. Pre-trained on a 12GB cor-\npus of cybersecurity texts (NVD,\nCVE, CAPEC). 9(Aghaei et al.,\n2020)\nTo test the hypothesis that\ndomain-specific vocabulary and\ncontext improve classification ac-\ncuracy.\nBERT Base\nMultilingual\n(12 layers, 768\nhidden, 12 heads,\n179M params.)\nStandard BERT-base architec-\nture. Pre-trained on the top\n104 languages with the largest\nWikipedia datasets. 10(Devlin\net al., 2019)\nTo investigate whether training\non a broader set of languages\nprovides any generalization ben-\nefit.\nBERT Base\nTurkish\n(12 layers, 768\nhidden, 12 heads,\n110M params.)\nStandard BERT-base architec-\nture. Pre-trained on a 35GB,\n4.4B token Turkish corpus from\nmultiple sources. 11(Schweter,\n2020)\nTo explore the performance of\na model pre-trained on a lan-\nguage with a different morpho-\nlogical structure than English.\nthe final hidden state of the [CLS] token to a vector corresponding to our\n11 security classes. A sigmoid activation function was applied to this layer to\nproduce independent probabilities, facilitating multi-label classification. The\nfine-tuning process was performed from end-to-end; all weights were unfrozen\nand updated to adapt the models to the specific nuances of the security re-\nquirements text.\nThe models were trained using the PyTorch Lightning framework to ensure\nreproducibility. We employed the AdamW optimizer (Loshchilov and Hutter,\n2019), an extension of the Adam optimizer with improved weight decay, uti-\nlizing a linear learning rate schedule with a warmup phase covering the first\n20% of training steps. This strategy stabilizes training in the initial epochs and\nimproves convergence. Given the multi-label nature of the task, Binary Cross-\nEntropy (BCE) Loss was used as the primary objective function. Because the\nsecurity classes are unevenly distributed, the label assignment threshold (Deci-\nsion Threshold) was tuned rather than fixed at 0.5 to better balance precision\nand recall across categories.', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**  \nThis chunk provides a detailed comparison of F1-scores across various LLMs, fine-tuned BERT models, and a baseline approach, highlighting their performance in classifying security requirements, particularly in handling class imbalance and underrepresented categories.\n\nCONTENT: Implicit Security Requirements Classification 25\nTable 7: Aggregated F1-Scores for LLM, BERT Models, and Baseline\nModel Prompting Strategy Macro-F1 Micro-F1 Weighted-F1\nLarge Language Model Results\nLlama 3 70b Zero Shot 0.813 0.941 0.941\nLlama 3 70b Few Shot 0.802 0.925 0.925\nDeepSeek R1 Zero Shot 0.812 0.921 0.916\nDeepSeek R1 Few Shot 0.820 0.927 0.921\nGemini 2.5 Zero Shot 0.8290.957 0.953\nGemini 2.5 Few Shot 0.8170.963 0.959\nGemini 2.0 Zero Shot0.8900.925 0.921\nGemini 2.0 Few Shot0.9410.938 0.938\nGemini 2.0 Pro Zero Shot 0.830 0.908 0.904\nGemini 2.0 Pro Few Shot 0.889 0.959 0.953\nGemma 3 27b Zero Shot 0.806 0.912 0.907\nGemma 3 27b Few Shot 0.802 0.917 0.912\nGemma 3 4b Zero Shot 0.605 0.738 0.742\nGemma 3 4b Few Shot 0.723 0.871 0.867\nGpt 4o Zero Shot 0.790 0.912 0.907\nGpt 4o Few Shot 0.814 0.943 0.939\nGpt 4o mini Zero Shot 0.703 0.803 0.809\nGpt 4o mini Few Shot 0.754 0.852 0.854\nBERT Fine-Tuning Results\nbert-base-multilingual-uncased Fine-Tuning0.942 0.985 0.983\nbert-base-turkish-cased Fine-Tuning 0.933 0.983 0.981\nbert-base-uncased Fine-Tuning 0.914 0.978 0.976\nSecureBERT Fine-Tuning 0.918 0.979 0.976\nBaseline\nNaive Baseline Majority Class 0.774 0.940 0.933\nrepresented categories. The bert-base-multilingual-uncased model achieved the\nhighest Weighted-F1 score at 0.983, while the lowest among the group was\n0.976 for both bert-base-uncased and SecureBERT. However, these results ob-\nscure the impact of class imbalance. Macro-F1 scores, which give equal weight\nto all categories, were lower, ranging from 0.942 to 0.914, revealing reduced\nperformance on less frequent classes.\nThis pattern is clear in the category-level results (Appendix C). Perfor-\nmance was high for common categories such as V8 (Data Protection), where\nthe bert-base-multilingual-uncased model achieved an F1-score of 0.992. In\ncontrast, results declined significantly for sparsely represented categories. For\nV6 (38 samples), F1-scores fell to 0.714 for bert-base-uncased and 0.734 for\nSecureBERT. The weakest performance was observed for V10 (27 samples),\nwith F1-scores around 0.60, indicating limited generalization due to limited\ndata.\nAn analysis of precision and recall for these difficult classes reveals specific\nfailure patterns. For class V10, the bert-base-uncased model has a low Recall of\n0.481. This indicates that while its predictions were often correct (Precision:\n0.813), it failed to identify more than half of the actual V10 requirements,\nresulting in a high number of false negatives. For class V6, the same model', 'CONTEXT: This chunk provides a detailed comparison of the performance metrics (precision, recall, F1 scores, and support) for various BERT-based models, including SecureBERT, in classifying security requirements across OWASP ASVS categories, highlighting their effectiveness and challenges in handling underrepresented classes.\n\nCONTENT: bert-base-multilingual-uncased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.984 0.982 0.982 0.975 0.744 0.985 0.980 0.984 0.983 0.864 0.991RECALL 0.997 0.995 0.995 0.984 0.842 0.995 1.000 1.000 0.983 0.704 0.994F1 0.990 0.988 0.988 0.979 0.790 0.990 0.990 0.992 0.983 0.776 0.992SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nbert-base-turkish-cased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.974 0.974 0.980 0.975 0.756 0.985 0.982 0.974 0.980 0.800 0.972RECALL 0.997 0.997 1.000 0.994 0.816 0.997 1.000 1.000 0.977 0.593 0.994F1 0.985 0.985 0.990 0.984 0.785 0.991 0.991 0.987 0.978 0.681 0.983SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nbert-base-uncased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.982 0.979 0.982 0.981 0.781 0.985 0.980 0.974 0.977 0.813 0.978RECALL 0.995 0.995 0.995 0.975 0.658 0.992 0.997 0.997 0.987 0.481 0.987F1 0.988 0.987 0.988 0.978 0.714 0.988 0.988 0.985 0.982 0.604 0.982SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nSecureBERT\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.974 0.977 0.980 0.972 0.707 0.985 0.977 0.974 0.964 0.700 0.969RECALL 0.995 0.995 0.997 0.984 0.763 0.997 1.000 0.997 0.990 0.519 0.997F1 0.984 0.986 0.988 0.978 0.734 0.991 0.988 0.985 0.977 0.596 0.983SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nNaive Baseline\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements', 'CONTEXT: **Optimization and Prompting Strategies for Security Classification Models**: This chunk discusses the optimization of BERT variants through systematic hyperparameter tuning and explores the use of large language models (LLMs) for security requirement classification, focusing on zero-shot and few-shot prompting strategies to enhance task-specific performance without modifying the base model.\n\nCONTENT: 22 Yusuf G¨ ur et al.\nWe performed a systematic grid search using the Weights & Biases 12\nplatform to identify the optimal configuration for each BERT variant using\nthe validation dataset. The search space included the following parameters:\n–Maximum Sequence Length:[128, 256]tokens\n–Batch Size:[4, 8, 16]\n–Number of Epochs:[16, 24, 32]\n–Learning Rate:[1e-5, 2e-5, 3e-5]\n–Decision Threshold:[0.3, 0.4, 0.5]\nTo prevent overfitting, we monitored validation loss and implemented early\nstopping with a patience of 2–4 epochs. The checkpoint achieving the lowest\nvalidation loss for each model was selected for the final evaluation on the test\nset.\n4.3 Classification using LLM Models\nLLMs are transformer-based models trained on massive corpora for general-\npurpose natural language understanding and generation. This study adopted\nthe “pre-train, prompt, and predict” paradigm, which replaces traditional\n“pre-train, fine-tune” approaches (Liu et al., 2023a). Rather than adjusting\nthe model’s objective or architecture, prompt engineering is used to steer the\nmodel toward task-specific outputs through carefully designed textual inputs.\nPrompt engineering involves designing prompts that elicit accurate re-\nsponses for specific tasks. In zero-shot prompting, an LLM is directly used\nwithout any task-specific training. Few-shot prompting introduces a small\nnumber of labeled examples in the prompt, which allows the model to learn\nthe task pattern. This is particularly beneficial when labeled training data is\nlimited.\nFour main prompting strategies were proposed by (Liu et al., 2023a):\n–Tuning-free prompting: Requires no model changes, suitable for zero-shot\nsettings, but often demands complex prompt design.\n–Fixed-LLM prompt tuning: Involves learning soft prompts while keep-\ning the model fixed; effective for few-shot tasks but typically lacks inter-\npretability.\n–Fixed-prompt LLM tuning: Fine-tunes the model on a fixed prompt; im-\nproves performance in few-shot settings.\n–Prompt + LLM tuning: Jointly tunes both model and prompts; highly\nexpressive but prone to overfitting on small datasets.\nIn this study, we evaluated the first two of these strategies, as they do\nnot require modification of the base LLM’s weights. For our zero-shot experi-\nments, we implemented tuning-free prompting, relying on carefully engineered\nprompts to guide the models. For our few-shot analysis, our approach aligns\n12 https://wandb.ai/site', 'CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: **Evaluation of Experimental and Commercial AI Models for Security Classification**: This chunk details the rationale and descriptions of experimental and commercial AI models, including Gemini and GPT-4o variants, used to benchmark their performance in nuanced security requirement classification, followed by an introduction to the results of fine-tuned BERT models.\n\nCONTENT: 24 Yusuf G¨ ur et al.\nTable 6 – continued from previous page\nModel Name Description Rationale in Study\ngemini-2.0-\nflash-thinking-\nexp-01-21\n(MoE Trans-\nformer;\nReasoning-\nOptimized)\nAn experimental API ver-\nsion of Google’s Gemini\nFlash model. This spe-\ncific version is optimized\nfor “thinking” (Chain-of-\nThought) processes while\nmaintaining the speed\nof the Flash series. 16\n(Google DeepMind, 2025a)\nTo evaluate the impact of built-in reasoning\non classification accuracy using an experi-\nmental commercial model accessed prior to\ngeneral availability.\ngemini-2.0-pro-\nexp-02-05\n(MoE Trans-\nformer; Large\nContext)\nAn experimental version of\nGoogle’s flagship Gemini\nPro model, representing\nthe state-of-the-art for\ncomplex, multimodal rea-\nsoning tasks. 16 (Google\nDeepMind, 2025a)\nTo assess frontier-level Gemini capabilities\nusing an experimental model accessed prior\nto general availability.\ngemini-2.5-\nflash-preview-\n04-17\n(MoE Trans-\nformer; Next-Gen\nArchitecture)\nA preview version of a\nnext-generation Gemini\nFlash model, likely offering\nenhancements in perfor-\nmance, context handling,\nand efficiency over the 2.0\nseries. 16 (Google Deep-\nMind, 2025b)\nTo assess whether preview architectural up-\ndates in an experimental, speed- and cost-\noptimized model improve detection of nu-\nanced security contexts (e.g., Stored Cryp-\ntography) using an experimental model ac-\ncessed prior to general availability.\ngpt-4o\n(Transformer;\nMultimodal)\nOpenAI’s flagship “omni”\nmodel, natively integrating\ntext, audio, and vision\nprocessing for faster and\nmore seamless interaction.\n17 (OpenAI, 2025)\nTo benchmark against the industry standard\nfor high-performance commercial models,\nserving as a control variable for proprietary\nmodel performance.\ngpt-4o-mini\n(Transformer;\nCost-Effective)\nA smaller, faster, and sig-\nnificantly cheaper version\nof GPT-4o, designed to\nmake near-GPT-4-level in-\ntelligence more accessible.\n17 (OpenAI, 2025)\nTo analyze the performance trade-off be-\ntween cost and quality, determining if\nsmaller proprietary models are sufficient for\nlarge-scale industrial requirements analysis.\n5 Results\nThis section presents both quantative and qualitative results.\n5.1 Results and Analysis for BERT Fine-Tuning\nTable 7 reports the overall results for the fine-tuned BERT variants. All mod-\nels achieved high Weighted-F1 scores, which show high performance on well-\n16 https://deepmind.google/technologies/gemini/\n17 https://openai.com/index/gpt-4o-mini-advancing-cost-effective-intelligence/', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.']","The **bert-base-turkish-cased** model was included in the study to explore the performance of a model pre-trained on a language with a different morphological structure than English. This model was pre-trained on a 35GB, 4.4 billion token Turkish corpus from multiple sources, and its inclusion aimed to assess how language-specific pre-training impacts classification accuracy, particularly in the context of security requirements classification tasks.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)",It was included to explore the performance of a model pre-trained on the native language (Turkish) of the dataset[cite: 375].,,,
What does the 'UNASSIGNED' label in the dataset represent?,"['CONTEXT: This chunk details the **annotation methodology** and **dataset curation process** for the ASRD, following the MATTER cycle framework. It describes annotator selection, corpus preparation, and the iterative development of annotation guidelines aligned with OWASP ASVS categories to ensure high-quality, domain-specific annotations.\n\nCONTENT: Implicit Security Requirements Classification 15\n3.3 Annotation Methodology (MATTER Cycle) & Dataset Curation\nThe annotation process followed the MATTER development cycle, an estab-\nlished iterative framework for corpus annotation (Pustejovsky and Stubbs,\n2012). Crucially, the annotation task was defined as a multi-label text classifi-\ncation problem. It consists of the phases Model, Annotate, Train, Test, Eval-\nuate, and Revise. The annotation guidelines were developed and iteratively\nrefined to ensure consistency and clarity.\nThe Model–Annotate cycle involved writing guidelines, selecting annota-\ntors, conducting trial annotations, and refining the process. Once stabilized,\nthis cycle was expanded to the full dataset to generate a Gold Standard corpus.\nThe annotation workflow included the following processes:\n–Annotator Selection: Following Bayerl and Paul’s recommendation to use\ndomain-aligned annotators (Bayerl and Paul, 2011), three cybersecurity\nsubject matter experts (SME) from the agency, each with over 15 years\nof experience in designing security architectures, analyzing threat models,\nand identifying security requirements, performed the annotations. Their\ndeep practical experience ensured accurate and context-aware interpreta-\ntion which aligned with the requirement “experts must demonstrate signif-\nicant skills, knowledge, and experience” emphasized by Hopkins (Hopkins\nand Unger, 2017). The senior manager among them also provided over-\nsight and led the adjudication process. The senior SME acted as both an\nannotator and the final adjudicator for resolving disagreements. They also\nprovided feedback to improve the quality and clarity of the annotation\nguideline.\n–Corpus Selection and Preparation: Cohen (Cohen et al., 2005) recommends\nthat during corpus design, balance and representativeness of the corpus\nis important. In line with his recommendation, of the 19 initial project\ndocuments, six were chosen for their domain diversity and potential for\neffective anonymization by the SMEs. These documents underwent a semi-\nautomated anonymization process to remove all project-specific and per-\nsonally identifiable information (PII). The process targeted entities such\nas names of individuals and organizations, project codenames, and specific\ntechnical identifiers. This was done using custom scripts with placeholder\nreplacement, followed by manual review to ensure that anonymization did\nnot alter the meaning, structure, or intent of the original requirements. The\nextracted requirements were then randomized and masked to prevent po-\ntential bias related to document origin or sequence during the annotation\nphase. Total corpus has 2,652 requirements (30 pilot + 2,622 independent\nannotations).\n–Annotation Guideline Development: The Annotation Guidelines’ develop-\nment involved an initial iterative process, refining the guidelines three times\nto resolve ambiguities before the formal assessment phase. Annotation rules\nwere based on OWASP ASVS categories V2–V13 and refined iteratively\nusing example annotations. Following best practices suggested by Cohen\n(Cohen et al., 2005), the guidelines and annotation documents ensured:', ""CONTEXT: **Comparative Analysis of Security Requirement Datasets**: This chunk provides a detailed comparison of the ASRD dataset with other prominent security requirement datasets, highlighting differences in size, domain coverage, annotation methodologies, and granularity, while emphasizing ASRD's strengths in industrial complexity, multi-domain applicability, and alignment with OWASP ASVS standards.\n\nCONTENT: 8 Yusuf G¨ ur et al.\nTable 1: Comparative Analysis of Security Requirement Datasets\nCharacteristic PROMISE\nexp\nDOSSPRE Healthcare\nDataset\nASRD (Ours)\nTotal Require-\nments\n969 1,317 10,963 2,652\nData Source Public SRS\ndocuments\n(expanded to\n49 projects)\n105 Student\nproject docu-\nments\n6 Official Cana-\ndian and U.S.\nSRS documents\n6 Real-world\nSRS docs from\na gov’t agency\nDomain General /\nCross-domain\nGeneral / Aca-\ndemic\nElectronic\nHealthcare\nMulti-domain:\nLegal, Const.,\nEdu., etc.\nPrimary Task FR vs. NFR,\nMulti-class\nNFR\nSR vs. NSR,\nMulti-class SR\nMulti-label\nSecurity Objec-\ntives\nMulti-label Im-\nplicit Security\nClass.\nSecurity Granu-\nlarity\nSingle SE\nclass\n10 security\nclasses\n6 security objec-\ntives\n11 OWASP\nASVS classes\nLanguage English English English Turkish\nAnnotation\nMethodology\nExpert Con-\nsensus: Man-\nual extraction\nand valida-\ntion\nAuthor Com-\npilation: Cat-\negorized by\nauthors only,\nlimited rigorous\nvalidation\nMulti-Stage\nConsensus: 2\nresearchers +\nmediator, high\nagreement\nMATTER Cy-\ncle: 3 SMEs\nwith adjudica-\ntion, iterative\nrefinement and\nabjudication\nKey Strength Established\nbenchmark\nand project\ndiversity\nFine-grained\nsecurity-specific\ntaxonomy\nLarge scale and\ndomain authen-\nticity\nIndustrial\ncomplexity +\nOWASP ASVS\nKey Limitation Small size\nand class\nimbalance\nPotential lack of\nprofessional re-\nalism\nDomain-\nspecific; coarse-\ngrained labels\nReal-world class\nimbalance in\nspecific cate-\ngories\nimbalance often restrict its suitability for training complex deep learning ar-\nchitectures.\n2.3.2 DOSSPRE\nThe Dataset of Students’ Software Projects Requirements (DOSSPRE) was\ncompiled by Kadebu et al. from documentation within academic curricula\n(Kadebu et al., 2023), likely from the Harare Institute of Technology. It pro-\nvides a fine-grained classification through a detailed taxonomy for both se-\ncurity and non-security requirements. However, as the requirements were au-\nthored by students, they may not fully reflect the realism and complexity of\nindustry-grade requirements."", 'CONTEXT: This chunk discusses the curation and preprocessing of the ASRD dataset, detailing the data collection process from real-world Software Requirements Specification (SRS) documents, the multi-stage preprocessing pipeline for sentence extraction and anonymization, and how the dataset addresses gaps in prior work by incorporating industrial complexity and linguistic diversity.\n\nCONTENT: Implicit Security Requirements Classification 9\n2.3.3 Electronic Health Domain Dataset\nThis corpus focuses on the electronic healthcare industry, a sector defined\nby stringent regulatory and high-assurance demands (Riaz et al., 2014). The\ndataset’s strength lies in its rigorous multi-stage annotation methodology,\nwhich utilized independent researchers and a mediator to ensure high inter-\nannotator agreement. While it provides a large-scale, authentic resource for\nhealthcare-specific tasks, its narrow focus may limit the generalizability of\nmodels to other industries, and its high-level security objectives may be too\ncoarse for detailed technical analysis.\n2.3.4 Summary of Datasets\nAs summarized in Table 1, these datasets vary significantly in their suitability\nfor tasks ranging from general non-functional requirement (NFR) classifica-\ntion to detailed security analysis. Our proposed Agency Security Require-\nments Dataset (ASRD) addresses gaps in prior work by adopting the OWASP\nASVS taxonomy for multi-label annotation. Furthermore, by utilizing real-\nworld projects originally written in Turkish, ASRD introduces both industrial\ncomplexity and linguistic diversity to the field.\n3 Dataset Curation, Annotation, and Evaluation\n3.1 Data Collection and Preprocessing\nThe dataset compilation began with the collection of six Software Require-\nments Specification (SRS) documents from an Agency’s Security Department.\nThese documents were selected from an initial pool of 19 projects executed\nbetween 2019 and 2023, specifically chosen for their domain diversity and\namenability to effective anonymization. The original documents were provided\nin standard document formats (e.g., PDF, DOCX) where requirements were\norganized in itemized lists. To transform these documents into a machine-\nreadable dataset, we employed a multi-stage preprocessing pipeline:\n1. Sentence Segmentation and Extraction: As the source SRS documents uti-\nlized standard itemization for requirements, we employed a rule-based ex-\ntraction method. We utilized pattern matching to identify requirement\nblocks based on hierarchical numbering schemes and line breaks. Each iden-\ntified requirement was extracted and treated as a single processing unit,\npreserving the structural integrity of the original specification.\n2. Anonymization: To protect sensitive data, a semi-automated anonymiza-\ntion process was implemented. Custom scripts replaced entities such as\nproject names, specific URLs, and IP addresses with generic placeholders.\nThis was followed by a manual review by domain experts to ensure that\nthe removal of personally identifiable information (PII) did not compromise\nthe semantic meaning or contextual integrity of the requirements.', 'CONTEXT: This chunk focuses on the introduction of the **Agency Security Requirements Dataset (ASRD)**, detailing its real-world data sources, expert annotation process, and alignment with OWASP ASVS categories, as well as outlining the research questions and comparative evaluation of fine-tuned transformer models versus prompt-based approaches for security requirements classification.\n\nCONTENT: 4 Yusuf G¨ ur et al.\ncient and cost-effective compared to addressing security issues at later stages\nof development ((Khan et al., 2024).\nThis paper proposes a machine learning-based system to automatically an-\nalyze SRS documents and classify security requirements according to OWASP\nASVS. Its main contribution is the Agency Security Requirements Dataset\n(ASRD), a publicly available corpus created to support research in automated\nSRA. The ASRD comprises:\n–Real-World Data: 2,652 Software Requirements Specification (SRS) sen-\ntences extracted from six diverse, real-world industry projects,\n–Expert Annotation: Meticulously annotated by three cybersecurity experts,\neach with over 15 years of industry experience,\n–Rigorous Methodology: Developed using the iterative MATTER cycle an-\nnotation framework (Pustejovsky and Stubbs, 2012),\n–High Granularity and Multi-label Structure: Mapped to 11 distinct, action-\nable security categories from the industry-standard OWASP Application\nSecurity Verification Standard (ASVS,V2–V13), allowing each require-\nment to be associated with multiple categories.\nThe ASRD is intended as a shared research resource and benchmark. Using\nthis dataset, the study conducts an empirical analysis of automated classifica-\ntion approaches and addresses the following research questions:\n1. To what extent can fine-tuned transformer models accurately perform\nmulti-label classification of implicit security requirements into OWASP\nASVS categories using the ASRD?\n2. How does the performance of prompt-based approaches (zero-shot and few-\nshot) using modern LLMs compare to fine-tuned BERT-based models and\nnaive baselines for this task?\nThe results show that few-shot prompting with a modern language model\n(Gemini 2.0) achieves a macro-average F1 score of 0.941, closely matching the\nbest fine-tuned BERT-based model (0.942). This demonstrates that example-\nguided inference can reach performance comparable to supervised fine-tuning\nwhile requiring substantially less annotated data and model retraining. The\nevaluation compares fine-tuned transformer models (e.g., SecureBERT) with\nprompt-based methods in zero-shot and few-shot settings across multiple con-\ntemporary models, demonstrating that prompt-based approaches provide a\npractical and resource-efficient alternative for identifying implicit security re-\nquirements in industrial SRS documents.\nThe remainder of this paper is organized as follows. Section 2 reviews re-\nlated work on NLP-based requirements classification, security frameworks, and\nexisting security datasets. Section 3 describes the curation and expert anno-\ntation of the ASRD and summarizes its key characteristics. Section 4 outlines\nthe experimental setup and classification methods, including fine-tuned BERT\nmodels and prompt-based approaches. Section 5 reports the experimental re-\nsults. Section 6 discusses the findings and their implications, with a com-\nparative analysis of fine-tuning and prompting strategies. Section 7 examines', 'CONTEXT: **Annotation Process and Quality Assurance in ASRD Development**: This chunk details the iterative annotation process for the ASRD dataset, including pilot and independent annotation phases, adjudication meetings, and the use of agreement metrics (e.g., Fleiss’s Kappa) to ensure high annotation quality and consistency among cybersecurity experts.\n\nCONTENT: 16 Yusuf G¨ ur et al.\n(1) original text and annotations were recoverable, (2) clear documenta-\ntion was maintained, (3) annotation quality was consistently high. The\nannotation template included fields for the software requirement text, se-\nlected OWASP labels, and annotator comments or questions. All versions\nof the guideline and annotation documents were preserved to track revi-\nsions based on annotator feedback. For the annotation process, a sample\ncorpus from the requirement set has been selected by inter agreement of\nSMEs. The first version of the Annotation Guideline based on OWASP\nASVS security classes has been developed, where each annotator has in-\ndividually classified the sample corpus by annotating it with one or more\nlabels following the instructions provided in the first Annotation Guide-\nline. After the initial annotation, the SMEs met under the guidance of the\nsenior SME, who is also the branch manager, to review and discuss the\nannotation decisions. Each of the 30 software requirements was examined\nindividually, and in cases where there were differing opinions among the\nannotators, efforts were made to persuade and convince others by provid-\ning explanations and reasons for their choices. After three iterations of\ndiscussions and deliberations, a full agreement was reached for 30 software\nrequirements.\n–Pilot Annotation: An initial batch of 30 software requirements was anno-\ntated early in the study, prompting multiple discussion rounds and three\nupdates to the guidelines. Adjudication meetings enabled the resolution\nof non-consensus requirements through SME-led discussions, during which\nthe rationale for classification was articulated. Discrepancies arising from\nquality issues, such as guideline violations, were addressed by implement-\ning corrections to ensure conformity with established criteria. Each SME\nprovided justifications for their decisions, which facilitated informed dis-\ncussions and enhanced understanding during adjudication. This iterative\nprocess resolved discrepancies across 98 requirements throughout the entire\ncorpus and was important in establishing the finalized annotation frame-\nwork.\n–Independent Annotation: Each SME classified all remaining 2622 require-\nments independently, using the finalized guideline. Annotators were re-\nquired to justify each decision. This practice proved important for facili-\ntating informed discussions and understanding annotator reasoning during\nthe subsequent adjudication phase. The process took 284 days and 267\nperson-hours of expert time.\n–Agreement Metrics: Inter-Annotator Agreement (IAA) was calculated us-\ning Fleiss’s Kappa and pairwise Cohen’s Kappa to assess consistency. IAA\nscores were instrumental in identifying instances of disagreement among\nannotators, thereby highlighting areas where the guidelines might require\nfurther clarification or where ambiguous requirement phrasings contributed\nto annotation discrepancies. Fleiss’s Kappa coefficient of 0.82 was obtained\nacross the three annotators, indicating strong agreement that significantly\nexceeded random chance. Pairwise Cohen’s Kappa values, ranging from', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb', 'CONTEXT: **Annotation Process and Dataset Composition**: This chunk details the multi-stage annotation methodology used to create the ASRD dataset, addressing class distribution, challenges with imbalanced categories (e.g., V6 Cryptography, V12 Files/Resources), and the inclusion of true negatives to ensure realistic and high-quality security requirement classification.\n\nCONTENT: Implicit Security Requirements Classification 17\n0.71 to 0.79, further confirmed substantial agreement between individual\nannotator pairs.\n–Adjudication: Disagreements were resolved through structured expert dis-\ncussions led by the senior SME. When the two annotators disagreed on a\nrequirement, it was resolved through a structured process:\n–Both annotators presented their choice and their reasons.\n–The senior expert reviewed both positions against the guideline.\n–If the guideline clearly supported one choice, that one was used. If not,\nthe senior expert led a discussion to decide.\n–Final decision and the reason was written down.\nThe goal was to reach unanimous agreement for each disputed requirement.\nThis process produced final Gold Standard annotations for 135 contested\nitems, ensuring consistency and validation of the dataset.\nThis multi-stage annotation methodology produced a reliable dataset which\ncomprises 2,652 annotated security-relevant requirements. The category dis-\ntributions of the requirements can be seen in Figure 1. The class distribution\namong the classes are largely balanced (90%) except the V6(Stored Cryptog-\nraphy) and V12 (Files & Resources) as 6% each. This imbalance is considered\na reflection of the source projects, where requirements for these two categories\nare inherently less frequent than pervasive controls like access control or input\nvalidation. Stored cryptography requirements are typically captured as holis-\ntic, architectural decisions rather than numerous, distinct functional require-\nments. Similarly, explicit security controls for file handling are less ubiquitous,\nappearing only in projects with specific file processing features, which explains\ntheir low frequency in our corpus. Sample annotated requirements can be seen\nin Table 4.\nThis imbalance mirrors real-world security requirement frequency - most\nsoftware functions involve access and data; few involve file uploads or encryp-\ntion configuration - and introduces a challenge for machine learning. Partic-\nularly, the sparsity in V6 and V12 categories may hinder generalization and\ncalls for class imbalance handling techniques. Despite this, the dataset presents\na realistic and high-quality foundation for developing and evaluating security-\naware NLP and classification models.\nTwenty-six requirements (0.98% of the data) labeled as “UNASSIGNED”\nwere requirements unanimously determined by the experts to be purely func-\ntional requirements with no discernible implicit security component (e.g., “The\nsystem will enable application software to be developed with an object-oriented\nprogramming approach”,). These items were intentionally retained in the dataset\nas true negatives to ensure a realistic distribution and test the models’ ability\nto correctly reject non-security items.\n\n18 Yusuf G¨ ur et al.\nFig. 1: Distribution of Classes', 'CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr']","The 'UNASSIGNED' label in the dataset represents requirements that were unanimously determined by the experts to be purely functional requirements with no discernible implicit security component. For example, a requirement like “The system will enable application software to be developed with an object-oriented programming approach” falls under this category. These items, which make up 0.98% of the dataset (26 requirements), were intentionally retained as true negatives to ensure a realistic distribution and to test the models’ ability to correctly reject non-security items.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","It represents requirements (0.98% of data) determined to be purely functional with no discernible implicit security component, retained as true negatives[cite: 300].",,,
What is the 'Long Tail' challenge described in the discussion?,"['CONTEXT: **Analysis of Minority Class Performance and Annotation Challenges in SRE**: This chunk discusses the performance gap between majority and minority security classes in SRE, the expert-driven annotation process using the MATTER cycle, and the measures taken to mitigate subjectivity and ensure realistic, industry-relevant model evaluation.\n\nCONTENT: 32 Yusuf G¨ ur et al.\nFig. 4:Minority vs. Majority Class Performance Gap.A comparative\nanalysis revealing that while advanced LLMs and fine-tuned models achieve\nnear-parity on Majority Classes (Blue), a significant performance gap remains\non Minority Classes (Red), underscoring the “Long Tail” challenge in SRE.\nAnnotation was performed by three experienced cybersecurity experts.\nWhile their domain knowledge ensured quality, the small annotator pool may\nintroduce subjective bias and limit the range of interpretations. This was mit-\nigated through the iterative MATTER cycle which includes training, iterative\nguideline refinement, and consensus-based adjudication.\nA key threat to internal validity is subjectivity as classifications rely heavily\non the latent domain knowledge and industry experience, rather than explicit\nindicators within the requirement text itself. This expert-driven approach pro-\nvides a “gold standard” for realistic industrial needs but it may introduce in-\nconsistencies if replicated by annotators with different backgrounds or if the\nbroader system context is not explicitly documented.\nThe test set was manually selected to balance computational efficiency and\ngeneralizability assessment. While cross-validation could improve test calibra-\ntion, it was avoided due to its high computational cost.\nTo minimize researcher bias and ensure the results reflect real-world in-\ndustry needs, domain experts used for the selection of both the test set and\nthe LLM suite. Rather than selecting data or models arbitrarily, these experts\ncurated a test set containing the most complex, “implicit” security scenarios\nto challenge the models beyond simple pattern matching. For the model suite,\nthey prioritized architectures with advanced reasoning capabilities, hypothe-\nsizing that these specific technical features are essential for the multi-step de-\nduction required in security requirements engineering. Although the experts', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference', 'CONTEXT: **Comparison of Effort vs. Performance and Validation of ASRD**: This chunk compares the effort and performance of different approaches (BERT fine-tuning, few-shot, and zero-shot LLMs) for security requirement classification, highlights the advantages of the ASRD dataset over existing benchmarks, and emphasizes the challenges of eliciting implicit security requirements in real-world industrial contexts.\n\nCONTENT: 34 Yusuf G¨ ur et al.\nTable 9: Comparison of Effort vs. Performance across Approaches\nApproach Data Requirement Est. Setup Effort Best Macro-F1\nBERT Fine-Tuning High (∼2,600 ex) High (267 hours)0.942\nLLM Few-Shot Low (∼30 ex) Low (<10 hours)0.941\nLLM Zero-Shot None Minimal (<2 hours) 0.890\nLLM Few-Shot approach (using Gemini 2.0) achieved a similar performance\n(Macro-F1 0.941) while requiring only the selection of a small number of in-\ncontext examples (approx. 30 examples per prompt).\nThis comparison points to diminishing returns from large-scale annotation\nwhen capable LLMs are available. Although extensive annotation was required\nhere to establish a reliable ground truth and validate the test set, the results\nindicate that, in industrial settings, a few-shot LLM approach can offer a more\nfavorable balance between effort and accuracy. Comparable performance can\nbe reached with substantially less data preparation, reducing the need for\nprolonged expert annotation.\nThe main contribution of this work is the introduction and validation of\nthe ASRD. The consistent performance of both fine-tuned BERT models and\nLLM-based approaches on ASRD supports its reliability and practical value.\nThe dataset addresses a persistent limitation in SRE research which is the\nlack of large, well-curated, professionally sourced benchmarks for security re-\nquirement classification. Compared with existing datasets, ASRD offers sev-\neral advantages. Unlike DOSSPRE (Kadebu et al., 2023), which is derived\nfrom student projects, ASRD includes 2,652 requirements from six commer-\ncial software systems, reflecting real industrial language and complexity. Its\nOWASP ASVS–based taxonomy spans 11 security classes, providing finer de-\ntail than PROMISE exp (Lima et al., 2019), where security is treated as a\nsingle category. Although the healthcare dataset by Riaz et al. (Riaz et al.,\n2014) is larger, it focuses on six broad objectives within a single domain, lim-\niting its scope. By contrast, ASRD supports cross-domain analysis and aligns\nwith a framework widely used in practice.\nThe dataset also benefits from a rigorous annotation process. Three cy-\nbersecurity specialists, each with over 15 years of experience, labeled the data\nusing an iterative MATTER-based procedure. This resulted in strong agree-\nment (Fleiss’ Kappa = 0.82) and helps mitigate the subjectivity that often\naffects security-related requirement datasets.\nBeyond the dataset construction, this study highlights the complexity of\nimplicit security requirement elicitation. A significant portion of security vul-\nnerabilities stems not from missing explicit security constraints (e.g., “The\nsystem shall encrypt passwords”), but from functional requirements that im-\nplicitly demand robust security controls. Our analysis of the ASRD reveals\nthat functional descriptions of business logic often conceal a dense network of\nsecurity dependencies. A representative example from our results is Require-\nment No. 2 (“The system will carry out the asset handover process”). While', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr', 'CONTEXT: **Evaluation of Model Challenges and Prompt Engineering Strategies**: This chunk discusses the challenges faced by models, particularly with underrepresented OWASP ASVS categories (e.g., V6 Cryptography, V12 Files/Resources), and outlines the experimental setup for prompt engineering in LLMs, including zero-shot and few-shot configurations, persona-based prompting, and strategies to ensure consistency and adherence to security standards.\n\nCONTENT: 26 Yusuf G¨ ur et al.\nshowed both low Recall (0.658) and low Precision (0.781), indicating it was\nboth missing true cases and incorrectly labeling other requirements as V6.\nModels struggle significantly with underrepresented categories, particularly\nV12 (File and Resources) and V6 (Stored Cryptography). This is evident in\nthe high number of false negatives, where the models fail to identify true\ninstances of these classes. For example, the baseline BERT model incorrectly\nclassified over half of the V12 requirements as negative (14 false negatives vs.\n13 true positives). Conversely, the matrices show that models often misclassify\nrequirements by incorrectly assigning them to other categories. The BERT\nBase model, for example, incorrectly labeled 92 different requirements as V10\n(Malicious Code) and 78 requirements as V5 (Malicious Input Handling).\n5.2 Experimental Setup for LLM Prompt Engineering\nWe adapted prompt engineering strategies from Ronanki (Ronanki et al.,\n2024), originally used for multi-class requirement classification. Two configu-\nrations were evaluated: zero-shot prompting (Appendix A), which relied solely\non task instructions and the input requirement, and few-shot prompting (Ap-\npendix B), which additionally incorporated labeled examples. The few-shot\nsetup used 30 training instances that were chosen to (i) capture multi-label\ncases where a single requirement spans multiple security categories, (ii) cover\nall 11 OWASP ASVS categories, and (iii) reflect requirements from different\nbusiness domains to preserve linguistic variation.\nPersona-based prompting was applied in both configurations by instruct-\ning the model to act as an experienced cybersecurity specialist. This alignment\nhelped reduce output variance by grounding responses in professional domain\nexpertise rather than general conversational patterns. The final prompt was\nobtained after five iterations. These iterations focused on three primary ar-\neas: (1) instruction clarity to prevent the model from defaulting to binary\nsecurity labels; (2) contextual grounding, by iteratively refining the OWASP\nASVS category definitions to ensure the model adhered to provided standards;\n(3) constraint formatting, to stabilize the PSV output structure for machine-\nreadability and ensure the inclusion of mandatory explanation fields. All ex-\nperiments were conducted with fixed parameters (Temperature = 0, Top-p =\n0.95) and repeated three times. The reported results are averaged to reduce\nthe impact of any minor, non-deterministic fluctuations in the models’ token\nselection during individual inferences.\nPrompt-based methods can be sensitive to phrasing, structure, and exam-\nple selection. To manage prompt sensitivity and contextual bias, we adopted a\nunified Persona–Context–Constraint strategy. A single prompt structure was\nused across all models, without model-specific tuning or iterative optimization\naimed at maximizing scores. The few-shot examples were chosen for representa-\ntiveness with respect to the OWASP ASVS taxonomy rather than performance\ngains.', 'CONTEXT: This chunk provides background on NLP-based techniques for software requirements classification, highlighting the evolution from traditional supervised learning methods to transformer-based models like BERT and SecureBERT, and emphasizing the challenges of classifying implicit security requirements due to ambiguity and the lack of high-quality, domain-specific datasets.\n\nCONTENT: Implicit Security Requirements Classification 5\nthreats to validity, and Section 8 concludes with a summary of contributions\nand directions for future work.\n2 Background\nThis section reviews prior work on NLP-based techniques for requirements\nclassification, followed by an overview of relevant security frameworks. It con-\ncludes with a discussion of existing datasets used in security requirements\nresearch.\n2.1 Related Work on Requirements Classification using NLP Techniques\nSoftware requirements (SR) classification supports effective project manage-\nment by enabling prioritization and risk assessment (Batool et al., 2025). The\ntask typically involves distinguishing functional requirements (FRs) from non-\nfunctional requirements (NFRs) and further categorizing NFRs into classes\nsuch as security, usability, and performance. Security requirements may ap-\npear as explicit system behaviors or as quality attributes addressing confiden-\ntiality, integrity, and availability—the security triad—which are often abstract\nand difficult to specify precisely in practice (Anwar Mohammad et al., 2019).\nThis inherent ambiguity complicates the development of clear guidelines for\nseparating security-related requirements from non-security ones.\nEarly studies applied supervised learning techniques, including Bayesian\nclassifiers(Knauss et al., 2011), decision trees (Jindal et al., 2016), and Sup-\nport Vector Machines (SVMs) (Dalpiaz et al., 2019), but these approaches\ndepended heavily on manual feature engineering and rigid linguistic patterns.\nTo address these limitations, later work adopted neural models such as convo-\nlutional neural networks (CNN) combined with Word2Vec embeddings (Dekht-\nyar and Fong, 2017). The adoption of transformer-based models such as BERT\nenabled improved classification accuracy through transfer learning and fine-\ntuning, eliminating the need for handcrafted features (Devlin et al., 2019; Sub-\nahi, 2023). More recent work explores domain-adapted transformer models,\nsuch as NoRBERT (Hey et al., 2020) and SecureBERT (Aghaei et al., 2022),\nto better capture domain-specific semantics and mitigate overfitting. These\nmodels have shown improved capability in identifying implicit non-functional\nrequirements, a particularly challenging task in security-critical settings (Nec-\nula et al., 2024). However, further progress in SRE is limited by the availability\nof large, high-quality, and domain-specific annotated datasets.\nThe subjective nature of defining security requirements further complicates\nreliable classification (Riaz and Williams, 2012). Security Requirement Elic-\nitation highly depends on domain-relevant expertise which includes various\ncostly manual steps such as creating security requirement templates, deter-\nmining security classification levels according to natural language artifacts,\nand mapping the class labels to related requirement templates by identifying\nentities.', 'CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the']","The ""Long Tail"" challenge described in the discussion refers to the significant performance gap between majority and minority security classes in Security Requirements Engineering (SRE). While advanced models, such as fine-tuned BERT and large language models (LLMs), achieve near-parity performance on majority classes, they struggle with underrepresented or minority classes. This issue arises due to the ""long-tail"" distribution of security requirements, where the most critical security failures often reside in the least represented categories. 

For example, architectural security concerns like cryptographic storage (V6) or file handling (V12) are far less common in typical specifications compared to user-facing controls like authentication (V2) or access control (V4). Standard supervised learning and even few-shot prompting methods struggle to generalize from the limited examples available for these minority classes. Addressing this challenge requires strategies like targeted data augmentation, retrieval-augmented generation (RAG), and hybrid approaches to improve classification performance for these underrepresented categories.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","It refers to the distribution where important security failures often reside in the least represented classes (like V6 and V12), which standard models struggle to learn[cite: 621, 706].",,,
What future work is proposed to handle rare security classes using RAG?,"['CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference', 'CONTEXT: This chunk provides background on NLP-based techniques for software requirements classification, highlighting the evolution from traditional supervised learning methods to transformer-based models like BERT and SecureBERT, and emphasizing the challenges of classifying implicit security requirements due to ambiguity and the lack of high-quality, domain-specific datasets.\n\nCONTENT: Implicit Security Requirements Classification 5\nthreats to validity, and Section 8 concludes with a summary of contributions\nand directions for future work.\n2 Background\nThis section reviews prior work on NLP-based techniques for requirements\nclassification, followed by an overview of relevant security frameworks. It con-\ncludes with a discussion of existing datasets used in security requirements\nresearch.\n2.1 Related Work on Requirements Classification using NLP Techniques\nSoftware requirements (SR) classification supports effective project manage-\nment by enabling prioritization and risk assessment (Batool et al., 2025). The\ntask typically involves distinguishing functional requirements (FRs) from non-\nfunctional requirements (NFRs) and further categorizing NFRs into classes\nsuch as security, usability, and performance. Security requirements may ap-\npear as explicit system behaviors or as quality attributes addressing confiden-\ntiality, integrity, and availability—the security triad—which are often abstract\nand difficult to specify precisely in practice (Anwar Mohammad et al., 2019).\nThis inherent ambiguity complicates the development of clear guidelines for\nseparating security-related requirements from non-security ones.\nEarly studies applied supervised learning techniques, including Bayesian\nclassifiers(Knauss et al., 2011), decision trees (Jindal et al., 2016), and Sup-\nport Vector Machines (SVMs) (Dalpiaz et al., 2019), but these approaches\ndepended heavily on manual feature engineering and rigid linguistic patterns.\nTo address these limitations, later work adopted neural models such as convo-\nlutional neural networks (CNN) combined with Word2Vec embeddings (Dekht-\nyar and Fong, 2017). The adoption of transformer-based models such as BERT\nenabled improved classification accuracy through transfer learning and fine-\ntuning, eliminating the need for handcrafted features (Devlin et al., 2019; Sub-\nahi, 2023). More recent work explores domain-adapted transformer models,\nsuch as NoRBERT (Hey et al., 2020) and SecureBERT (Aghaei et al., 2022),\nto better capture domain-specific semantics and mitigate overfitting. These\nmodels have shown improved capability in identifying implicit non-functional\nrequirements, a particularly challenging task in security-critical settings (Nec-\nula et al., 2024). However, further progress in SRE is limited by the availability\nof large, high-quality, and domain-specific annotated datasets.\nThe subjective nature of defining security requirements further complicates\nreliable classification (Riaz and Williams, 2012). Security Requirement Elic-\nitation highly depends on domain-relevant expertise which includes various\ncostly manual steps such as creating security requirement templates, deter-\nmining security classification levels according to natural language artifacts,\nand mapping the class labels to related requirement templates by identifying\nentities.', 'CONTEXT: **Performance Visualization and Analysis of Classifiers**: This chunk focuses on the comparative performance analysis of 20 classifiers across OWASP ASVS classes, using critical difference diagrams, heatmaps, and gap analysis to highlight strengths and weaknesses, particularly in handling rare security classes like V6 (Stored Cryptography) and V12 (Files and Resources). It also discusses dataset diversity, threats to validity, and the generalizability of findings.\n\nCONTENT: 30 Yusuf G¨ ur et al.\nFig. 2: Critical Difference (CD) diagram visualizing the statistical comparison\nof classifiers. The horizontal axis represents the average rank of each model\nacross all 11 OWASP ASVS classes (lower ranks indicate better performance).\nThe Critical Difference (CD = 10.46) represents the minimum difference in\naverage rank required for two models to be considered statistically significantly\ndifferent atp <0.05.\n5.6 Comparative Visualization Analysis\nTo complement the statistical rankings, we visualized the performance land-\nscape across all 20 model configurations.\nHeatmap Analysis: Figure 3 shows F1-scores by class. Requirements related\nto V2 (Authentication), V3 (Session Management), and V4 (Access Control)\nare handled well by nearly all models, with scores typically above 0.95. These\ncategories are common and appear consistently across training sources. In\ncontrast, V6 (Stored Cryptography) and V12 (Files and Resources) show low\nscores across the board, including for GPT-4o and Gemini 2.0 Pro. This pat-\ntern points to a systematic difficulty with sparse categories rather than a\nweakness of a particular model.\nGap Analysis: Figure 4 contrasts average performance on frequent and in-\nfrequent classes. Fine-tuned models such as SecureBERT and BERT-Multilingual\nperform better on rare classes, with F1-scores around 0.70–0.80. Zero-shot\nLLMs perform poorly in these cases, often below 0.30. Few-shot prompting\nimproves results for some models, such as Gemini 2.0, but the gap remains\nsubstantial.\n6 Threats to Validity\nOur dataset consists of 2,652 requirements derived from six Software Require-\nments Specification (SRS) documents. While the number of source documents\n\nImplicit Security Requirements Classification 31\nFig. 3:Comprehensive Performance Heatmap.F1-scores for all 20 eval-\nuated models across 11 OWASP ASVS classes. The visualization highlights\nthe “zone of failure” (red) for classes V6 and V12 across models, contrasting\nwith the high performance (green) on ubiquitous classes like V2 and V4.\nis limited, potential bias was mitigated by strategically selecting projects from\nsix distinct business domains: Construction, Legal, Education, Software, Meet-\ning Management, and Accommodation. This semantic diversity ensures that\nthe models are evaluated on a broad vocabulary and varied functional contexts\nrather than a single industry vertical. A specific consideration regarding the\nexternal validity of this study is that the ASRD is a Turkish-language corpus\nwhich allows for the evaluation of automated tools in linguistically diverse\nindustrial contexts.\nFurthermore, because security requirements (e.g., Authentication, Log-\nging) represent cross-cutting concerns that apply universally across software\nsystems, we believe the fundamental patterns captured in the ASRD are trans-\nferable to other industries. Our current evaluation used a stratified split across\nthe entire dataset, meaning requirements from all six source projects are\npresent in the training, validation, and test sets. However, we acknowledge\nthat this approach does not fully measure the models’ ability to generalize to\nentirely new projects with different authors or linguistic styles, as the test set\nis not completely “unseen” in terms of project context.', 'CONTEXT: This chunk provides detailed definitions of OWASP ASVS security requirement classes (V5–V14), which are critical for categorizing and addressing specific security concerns in software applications, as discussed in the broader context of automating security requirements classification using AI and the ASRD dataset.\n\nCONTENT: 14 Yusuf G¨ ur et al.\nTable 3 – continued from previous page\nClass Id Class Name Definition\nV5 Malicious Input Handling This class focuses on requirements\nfor validating and sanitizing all input\ndata to prevent injection attacks, such\nas SQL injection, Cross-Site Scripting\n(XSS), and others.\nV6 Stored Cryptography This class addresses the secure stor-\nage of cryptographic keys and sensi-\ntive data at rest, ensuring they are pro-\ntected from unauthorized disclosure or\nmodification.\nV7 Error Handling and Logging This class ensures that applications\nhandle errors gracefully without leak-\ning sensitive information and that\nsecurity-relevant events are logged for\nmonitoring and analysis.\nV8 Data Protection This class covers the requirements for\nprotecting sensitive data during tran-\nsit and in storage, focusing on confi-\ndentiality, integrity, and classification.\nV9 Communications Security This class focuses on securing commu-\nnication channels between system com-\nponents, such as between the client and\nserver, to prevent eavesdropping, tam-\npering, or spoofing.\nV10 Malicious Code This class deals with ensuring the ap-\nplication code is free from malicious\ncode, backdoors, or other unintended\nsecurity vulnerabilities introduced in-\ntentionally or unintentionally.\nV11 Business Logic This class addresses security con-\ncerns within the application’s business\nlogic, preventing attackers from abus-\ning workflows or functionalities for un-\nintended purposes.\nV12 File and Resources This class covers the secure handling of\nfiles and other resources, including up-\nload, download, and management, to\nprevent path traversal and other re-\nlated attacks.\nV13 API and Web Service This class provides security require-\nments specifically for APIs and web\nservices, covering aspects like authen-\ntication, authorization, and protection\nagainst common API attacks.\nV14 Configuration This class focuses on securing the con-\nfiguration of all application compo-\nnents, including the application server,\nplatform, and third-party libraries, to\nprevent security misconfigurations.', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to', 'CONTEXT: ""References and Related Work on Security Requirements Engineering and AI Applications"" – This chunk provides a list of references and prior research studies that underpin the advancements discussed in the document, focusing on security requirements engineering, AI-driven classification methods, and the application of LLMs in software development and compliance tasks.\n\nCONTENT: Implicit Security Requirements Classification 41\nISGTEurope.2017.8260283\nKhan RA, Akbar MA, Rafi S, Almagrabi AO, Alzahrani M (2024) Evaluation\nof requirement engineering best practices for secure software development in\ngsd: An ism analysis. Journal of Software: Evolution and Process 36(5):e2594\nKnauss E, Houmb S, Schneider K, Islam S, J¨ urjens J (2011) Supporting re-\nquirements engineers in recognising security issues. In: International Work-\ning Conference on Requirements Engineering: Foundation for Software Qual-\nity, Springer, pp 4–18\nLabrak Y, Rouvier M, Dufour R (2023) A zero-shot and few-shot study of\ninstruction-finetuned large language models applied to clinical and biomed-\nical tasks. arXiv preprint arXiv:230712114\nLima M, Valle V, Costa E, Lira F, Gadelha B (2019) Software engineering\nrepositories: expanding the promise database. In: Proceedings of the XXXIII\nBrazilian Symposium on Software Engineering, pp 427–436\nLiu P, Yuan W, Fu J, Jiang Z, Hayashi H, Neubig G (2023a) Pre-train, prompt,\nand predict: A systematic survey of prompting methods in natural language\nprocessing. ACM computing surveys 55(9):1–35\nLiu Y, Zhang H, Chen X (2023b) Large language models for requirements\nclassification: Zero-shot and few-shot approaches. In: Proceedings of the\n2023 IEEE International Requirements Engineering Conference (RE), IEEE,\npp 45–56, DOI 10.1109/RE.2023.00012\nLiu Z, Wang H, Xu T, Wang B (2025) Rag-driven multiple assertions genera-\ntion with large language models. Empirical Software Engineering 30(3):105\nLoshchilov I, Hutter F (2019) Decoupled weight decay regularization. arXiv\npreprint arXiv:171105101 URLhttps://arxiv.org/abs/1711.05101\nMann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P, Neelakantan A, Shyam\nP, Sastry G, Askell A, Agarwal S, et al. (2020) Language models are few-shot\nlearners. arXiv preprint arXiv:200514165 1(3):3\nMasoudifard A, Sorond MM, Madadi M, Sabokrou M, Habibi E (2024) Lever-\naging graph-rag and prompt engineering to enhance llm-based automated\nrequirement traceability and compliance checks. URLhttps://arxiv.org/\nabs/2412.08593,2412.08593\nMaturi A, Alshammari R, Alqahtani F, Alqahtani M (2025) Detecting reen-\ntrancy vulnerabilities for solidity smart contracts with bidirectional lstm and\nexplainable ai. In: 2025 IEEE International Conference on Blockchain and\nCryptocurrency (ICBC), IEEE, pp 1–8, DOI 10.1109/ICBC.2025.10926491,\nURLhttps://ieeexplore.ieee.org/document/10926491\nMuresan S, Nakov P, Villavicencio A (2022) Proceedings of the 60th annual\nmeeting of the association for computational linguistics (volume 1: Long\npapers). In: Proceedings of the 60th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers)\nNecula SC, Fotache D, Rieder E (2024) Assessing the impact of artificial in-\ntelligence tools on employee productivity: insights from a comprehensive\nsurvey analysis. Electronics 13(18):3758\nOpenAI (2025) GPT-4o mini: Advancing cost-\neffective intelligence.https://openai.com/index/', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the']","The proposed future work to handle rare security classes using Retrieval-Augmented Generation (RAG) includes the following advancements:

1. **Dynamic Few-Shot Selection with RAG**:  
   - Instead of relying on static few-shot examples, a retriever dynamically selects the most semantically similar valid requirements from the training set to serve as in-context examples for a specific query.  
   - This approach grounds the model with relevant architectural patterns (e.g., ""encryption"" vs. ""hashing"") rather than generic class examples, improving classification accuracy for rare security requirements.

2. **Human-AI Collaborative Multi-Agent Framework**:  
   - A multi-agent system combines automated classification with expert oversight for ambiguous or high-risk cases.  
   - A retrieval-augmented agent dynamically selects relevant annotated requirements, while another agent assesses classification confidence and flags unclear cases for human intervention.  
   - A supervisor agent consolidates inputs to ensure consistency with standards like OWASP ASVS, and an optimization agent learns from human feedback to refine retrieval strategies over time.

3. **Synthetic Data Injection**:  
   - A Teacher-Student Data Generation loop uses high-reasoning LLMs (e.g., GPT-4) to generate diverse synthetic requirements that trigger classifications for rare security classes (e.g., V6 and V12).  
   - These synthetic samples enhance the training set, enabling smaller supervised models (e.g., BERT) to learn robust decision boundaries without requiring extensive manual annotation.

These approaches aim to address data sparsity and improve the classification of underrepresented security classes in Security Requirements Engineering (SRE).  
(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","The study proposes using Retrieval-Augmented Generation (RAG) to dynamically retrieve explicit verification requirements and definitions relevant to the input text, substituting dense in-context examples[cite: 718, 725].",,,
What is the proposed 'Teacher-Student Data Generation' loop?,"['CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the', 'CONTEXT: **Advancements in LLM-Assisted Security and Related Frameworks**: This chunk discusses the application of transformer-based models and LLMs in security requirements engineering (SRE), highlighting their capabilities, challenges, and the importance of high-quality datasets and evaluation frameworks. It also reviews the role of security frameworks in systematically identifying and classifying security requirements in automated settings.\n\nCONTENT: 6 Yusuf G¨ ur et al.\nBeyond requirements classification, security research has also turned to\ntask-specific models for narrowly defined problems. For instance, deep learning\napproaches such as BiLSTMs have been used to detect re-entrancy vulnerabil-\nities in smart contracts, where generic models are insufficient (Maturi et al.,\n2025). This work highlights the importance of explainability, as security de-\ncisions must be understandable to support assurance and auditing. Although\nthis line of research addresses a different problem, it reflects a shift toward\ndomain-aware and interpretable models.\nTransformer-based models have enabled new capabilities in automated text\nunderstanding(Zhou et al., 2025). They possess emergent abilities like in-\ncontext learning, instruction following, and step-by-step reasoning (Zhu et al.,\n2025), which allow them to perform complex tasks, including requirements\nclassification, with minimal or no labeled data (Liu et al., 2023b; Zhu et al.,\n2025). Recent trends show a growing interest in applying LLMs to RE tasks,\nincluding requirements classification, prioritization, and traceability (Rajbhoj\net al., 2024; White et al., 2024). LLMs can perform zero-shot and few-shot\nlearning, reducing the need for large annotated datasets and facilitating adap-\ntation to specialized domains like SRE (Labrak et al., 2023). Techniques such\nas prompt engineering and integration with external knowledge bases (e.g.,\nRetrieval-Augmented Generation) further improve their performance and con-\ntextual relevance (Masoudifard et al., 2024).\nLLM-assisted security solutions typically follow a three-step process: pre-\nprocessing (extracting context like documentation or target units), prompt\ngeneration (using instructions and unfilled slots for the model to complete\nwith artifacts like fuzz drivers or patches), and post-processing (validating\noutputs, e.g., checking if generated code successfully compiles) (Zhu et al.,\n2025).\nWhile these models provide powerful automation, they can also introduce\nnew risks and errors if applied without careful oversight. This underscores the\nneed for realistic, high-quality datasets and standardized evaluation frame-\nworks to reliably assess automated security requirement classification, ensuring\nboth effectiveness and safety in practice.\nThe use of automated models in security highlights both their potential and\nthe risks they can introduce. Ensuring accurate and reliable classification of\nsecurity requirements requires evaluation against high-quality, domain-specific\nbenchmarks (Jeong, 2024). This underscores the need for realistic datasets and\nstandardized evaluation frameworks tailored to SRE.\n2.2 Related Work on Security Frameworks\nAn appropriate security framework is necessary to ensure systematic and con-\nsistent identification and classification of security requirements, particularly in\nautomated settings. This section reviews widely adopted security frameworks\nand evaluates their suitability for requirement analysis.', 'CONTEXT: This chunk introduces the motivation and objectives of the study, emphasizing the challenges of identifying implicit security requirements in Software Requirements Specification (SRS) documents and proposing a data-driven methodology using the newly developed ASRD dataset and machine learning models, including fine-tuned BERT variants and large language models, to address these challenges.\n\nCONTENT: Noname manuscript No.\n(will be inserted by the editor)\nImplicit Security Requirements Classification\nwith Large Language Models Using the OWASP\nApplication Security Verification Standard: A\nShift-Left Approach.\nYusuf G¨ ur·Tu˘ gba Ta¸ skaya Temizel·\nBanu G¨ unel Kılı¸ c\nReceived: date / Accepted: date\nAbstractCybersecurity threats require early integration of security, starting\nfrom the requirements analysis phase of the Software Development Life Cycle\n(SDLC). However, security requirements in Software Requirements Specifica-\ntion (SRS) documents are often implicitly embedded, making their manual\nidentification time-consuming, error-prone, and reliant on specialized exper-\ntise. The accurate classification of security requirements (SR) is important for\neffective resource allocation and risk management in software development.\nAutomated tools to extract implicit security requirements are lacking, largely\ndue to the scarcity of large, annotated datasets in Security Requirements En-\ngineering (SRE). This paper proposes a data-driven methodology to automate\nthe classification of implicit security requirements in SRS documents, sup-\nporting the early and systematic integration of security into software systems.\nWe introduce a novel multi-label corpus, the Agency Security Requirements\nDataset (ASRD), derived from 2,652 real-world requirement statements from\nsix diverse documents and annotated using a high-granularity taxonomy based\non the OWASP Application Security Verification Standard (ASVS) V2-V13\nand the MATTER cycle annotation framework by three cybersecurity experts.\nUsing this dataset, we evaluate both supervised fine-tuned BERT variants\n(such as SecureBERT) and general-purpose large-language models (LLMs) in-\ncluding Gemma, GPT, DeepSeek, Meta Llama, and Gemini under zero-shot\nand few-shot settings. We conduct an empirical comparison between tradi-\nYusuf G¨ ur\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: yusuf.gur@metu.edu.tr\nTu˘ gba Ta¸ skaya Temizel\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: ttemizel@metu.edu.tr\nBanu G¨ unel Kılı¸ c\nGraduate School of Informatics, Middle East Technical University, Ankara 06800, T¨ urkiye\nE-mail: bgunel@metu.edu.tr', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb', 'CONTEXT: This chunk focuses on the introduction of the **Agency Security Requirements Dataset (ASRD)**, detailing its real-world data sources, expert annotation process, and alignment with OWASP ASVS categories, as well as outlining the research questions and comparative evaluation of fine-tuned transformer models versus prompt-based approaches for security requirements classification.\n\nCONTENT: 4 Yusuf G¨ ur et al.\ncient and cost-effective compared to addressing security issues at later stages\nof development ((Khan et al., 2024).\nThis paper proposes a machine learning-based system to automatically an-\nalyze SRS documents and classify security requirements according to OWASP\nASVS. Its main contribution is the Agency Security Requirements Dataset\n(ASRD), a publicly available corpus created to support research in automated\nSRA. The ASRD comprises:\n–Real-World Data: 2,652 Software Requirements Specification (SRS) sen-\ntences extracted from six diverse, real-world industry projects,\n–Expert Annotation: Meticulously annotated by three cybersecurity experts,\neach with over 15 years of industry experience,\n–Rigorous Methodology: Developed using the iterative MATTER cycle an-\nnotation framework (Pustejovsky and Stubbs, 2012),\n–High Granularity and Multi-label Structure: Mapped to 11 distinct, action-\nable security categories from the industry-standard OWASP Application\nSecurity Verification Standard (ASVS,V2–V13), allowing each require-\nment to be associated with multiple categories.\nThe ASRD is intended as a shared research resource and benchmark. Using\nthis dataset, the study conducts an empirical analysis of automated classifica-\ntion approaches and addresses the following research questions:\n1. To what extent can fine-tuned transformer models accurately perform\nmulti-label classification of implicit security requirements into OWASP\nASVS categories using the ASRD?\n2. How does the performance of prompt-based approaches (zero-shot and few-\nshot) using modern LLMs compare to fine-tuned BERT-based models and\nnaive baselines for this task?\nThe results show that few-shot prompting with a modern language model\n(Gemini 2.0) achieves a macro-average F1 score of 0.941, closely matching the\nbest fine-tuned BERT-based model (0.942). This demonstrates that example-\nguided inference can reach performance comparable to supervised fine-tuning\nwhile requiring substantially less annotated data and model retraining. The\nevaluation compares fine-tuned transformer models (e.g., SecureBERT) with\nprompt-based methods in zero-shot and few-shot settings across multiple con-\ntemporary models, demonstrating that prompt-based approaches provide a\npractical and resource-efficient alternative for identifying implicit security re-\nquirements in industrial SRS documents.\nThe remainder of this paper is organized as follows. Section 2 reviews re-\nlated work on NLP-based requirements classification, security frameworks, and\nexisting security datasets. Section 3 describes the curation and expert anno-\ntation of the ASRD and summarizes its key characteristics. Section 4 outlines\nthe experimental setup and classification methods, including fine-tuned BERT\nmodels and prompt-based approaches. Section 5 reports the experimental re-\nsults. Section 6 discusses the findings and their implications, with a com-\nparative analysis of fine-tuning and prompting strategies. Section 7 examines', 'CONTEXT: This chunk discusses the curation and preprocessing of the ASRD dataset, detailing the data collection process from real-world Software Requirements Specification (SRS) documents, the multi-stage preprocessing pipeline for sentence extraction and anonymization, and how the dataset addresses gaps in prior work by incorporating industrial complexity and linguistic diversity.\n\nCONTENT: Implicit Security Requirements Classification 9\n2.3.3 Electronic Health Domain Dataset\nThis corpus focuses on the electronic healthcare industry, a sector defined\nby stringent regulatory and high-assurance demands (Riaz et al., 2014). The\ndataset’s strength lies in its rigorous multi-stage annotation methodology,\nwhich utilized independent researchers and a mediator to ensure high inter-\nannotator agreement. While it provides a large-scale, authentic resource for\nhealthcare-specific tasks, its narrow focus may limit the generalizability of\nmodels to other industries, and its high-level security objectives may be too\ncoarse for detailed technical analysis.\n2.3.4 Summary of Datasets\nAs summarized in Table 1, these datasets vary significantly in their suitability\nfor tasks ranging from general non-functional requirement (NFR) classifica-\ntion to detailed security analysis. Our proposed Agency Security Require-\nments Dataset (ASRD) addresses gaps in prior work by adopting the OWASP\nASVS taxonomy for multi-label annotation. Furthermore, by utilizing real-\nworld projects originally written in Turkish, ASRD introduces both industrial\ncomplexity and linguistic diversity to the field.\n3 Dataset Curation, Annotation, and Evaluation\n3.1 Data Collection and Preprocessing\nThe dataset compilation began with the collection of six Software Require-\nments Specification (SRS) documents from an Agency’s Security Department.\nThese documents were selected from an initial pool of 19 projects executed\nbetween 2019 and 2023, specifically chosen for their domain diversity and\namenability to effective anonymization. The original documents were provided\nin standard document formats (e.g., PDF, DOCX) where requirements were\norganized in itemized lists. To transform these documents into a machine-\nreadable dataset, we employed a multi-stage preprocessing pipeline:\n1. Sentence Segmentation and Extraction: As the source SRS documents uti-\nlized standard itemization for requirements, we employed a rule-based ex-\ntraction method. We utilized pattern matching to identify requirement\nblocks based on hierarchical numbering schemes and line breaks. Each iden-\ntified requirement was extracted and treated as a single processing unit,\npreserving the structural integrity of the original specification.\n2. Anonymization: To protect sensitive data, a semi-automated anonymiza-\ntion process was implemented. Custom scripts replaced entities such as\nproject names, specific URLs, and IP addresses with generic placeholders.\nThis was followed by a manual review by domain experts to ensure that\nthe removal of personally identifiable information (PII) did not compromise\nthe semantic meaning or contextual integrity of the requirements.']","The proposed ""Teacher-Student Data Generation"" loop is a method aimed at addressing data sparsity in supervised models, particularly in the context of security requirements classification. This approach involves using high-reasoning large language models (LLMs), such as GPT-4 or Gemini 2.5 Pro, to generate diverse synthetic security requirements. These synthetic samples are designed to implicitly trigger specific classifications (e.g., V6/V12 categories) and are then used to populate the training set. The goal is to enable smaller supervised models, like BERT, to learn robust decision boundaries without the need for expensive manual annotation. This method is part of a broader strategy to improve the classification of rare security requirements in Security Requirements Engineering (SRE).

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)",It involves using high-reasoning LLMs (like GPT-4o) to generate synthetic requirements for sparse classes (V6/V12) to populate the training set for smaller supervised models[cite: 734].,,,
Why were experimental LLMs (like Gemini 2.0 Flash Thinking) included in the evaluation?,"['CONTEXT: **Evaluation of Experimental and Commercial AI Models for Security Classification**: This chunk details the rationale and descriptions of experimental and commercial AI models, including Gemini and GPT-4o variants, used to benchmark their performance in nuanced security requirement classification, followed by an introduction to the results of fine-tuned BERT models.\n\nCONTENT: 24 Yusuf G¨ ur et al.\nTable 6 – continued from previous page\nModel Name Description Rationale in Study\ngemini-2.0-\nflash-thinking-\nexp-01-21\n(MoE Trans-\nformer;\nReasoning-\nOptimized)\nAn experimental API ver-\nsion of Google’s Gemini\nFlash model. This spe-\ncific version is optimized\nfor “thinking” (Chain-of-\nThought) processes while\nmaintaining the speed\nof the Flash series. 16\n(Google DeepMind, 2025a)\nTo evaluate the impact of built-in reasoning\non classification accuracy using an experi-\nmental commercial model accessed prior to\ngeneral availability.\ngemini-2.0-pro-\nexp-02-05\n(MoE Trans-\nformer; Large\nContext)\nAn experimental version of\nGoogle’s flagship Gemini\nPro model, representing\nthe state-of-the-art for\ncomplex, multimodal rea-\nsoning tasks. 16 (Google\nDeepMind, 2025a)\nTo assess frontier-level Gemini capabilities\nusing an experimental model accessed prior\nto general availability.\ngemini-2.5-\nflash-preview-\n04-17\n(MoE Trans-\nformer; Next-Gen\nArchitecture)\nA preview version of a\nnext-generation Gemini\nFlash model, likely offering\nenhancements in perfor-\nmance, context handling,\nand efficiency over the 2.0\nseries. 16 (Google Deep-\nMind, 2025b)\nTo assess whether preview architectural up-\ndates in an experimental, speed- and cost-\noptimized model improve detection of nu-\nanced security contexts (e.g., Stored Cryp-\ntography) using an experimental model ac-\ncessed prior to general availability.\ngpt-4o\n(Transformer;\nMultimodal)\nOpenAI’s flagship “omni”\nmodel, natively integrating\ntext, audio, and vision\nprocessing for faster and\nmore seamless interaction.\n17 (OpenAI, 2025)\nTo benchmark against the industry standard\nfor high-performance commercial models,\nserving as a control variable for proprietary\nmodel performance.\ngpt-4o-mini\n(Transformer;\nCost-Effective)\nA smaller, faster, and sig-\nnificantly cheaper version\nof GPT-4o, designed to\nmake near-GPT-4-level in-\ntelligence more accessible.\n17 (OpenAI, 2025)\nTo analyze the performance trade-off be-\ntween cost and quality, determining if\nsmaller proprietary models are sufficient for\nlarge-scale industrial requirements analysis.\n5 Results\nThis section presents both quantative and qualitative results.\n5.1 Results and Analysis for BERT Fine-Tuning\nTable 7 reports the overall results for the fine-tuned BERT variants. All mod-\nels achieved high Weighted-F1 scores, which show high performance on well-\n16 https://deepmind.google/technologies/gemini/\n17 https://openai.com/index/gpt-4o-mini-advancing-cost-effective-intelligence/', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: **Performance Evaluation of LLMs for Security Requirements Classification**: This chunk presents detailed test results and performance metrics (e.g., precision, recall, F1 scores) of various Gemini LLM variants (Few-Shot and Zero-Shot) in classifying security requirements across OWASP ASVS categories, highlighting their effectiveness and challenges in handling specific verification requirements.\n\nCONTENT: Test Results of the LLMs used in the study\nGemini_2_5_Few_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.979 0.972 0.980 0.914 0.229 0.985 0.972 0.974 0.868 0.203 0.900RECALL 0.997 0.992 0.992 0.984 0.641 0.995 0.992 0.995 0.967 0.964 0.994F1 0.988 0.982 0.986 0.948 0.338 0.990 0.982 0.984 0.915 0.335 0.945SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nGemini_2_0_Zero_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.967 0.940 0.972 0.894 0.819 0.960 0.962 0.955 0.812 0.937 0.897RECALL 0.967 0.939 0.972 0.882 0.280 0.960 0.962 0.954 0.783 0.479 0.884F1 0.990 0.963 0.990 0.994 0.718 0.977 0.984 0.982 0.900 0.821 0.981SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nGemini_2_0_Few_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.982 0.972 0.985 0.922 0.754 0.985 0.967 0.975 0.894 0.764 0.917RECALL 0.982 0.972 0.985 0.910 0.210 0.985 0.967 0.974 0.874 0.223 0.905F1 0.997 0.990 0.992 0.990 0.667 0.995 0.987 0.995 0.973 0.964 0.994SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nGemini_2_0_Pro_Zero_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.975 0.902 0.972 0.910 0.837 0.910 0.952 0.905 0.847 0.942 0.899RECALL 0.974 0.900 0.972 0.897 0.188 0.909 0.952 0.902 0.820 0.410 0.881F1 0.992 0.919 0.992 0.990 0.385 0.923 0.971 0.919 0.923 0.571 0.934SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nGemini_2_0_Pro_Few_Shot\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements', 'CONTEXT: **Comparison of Fine-Tuned Models and LLMs for Security Requirements Classification**: This chunk discusses the performance comparison between fine-tuned transformer models (e.g., BERT) and few-shot prompting with LLMs (e.g., Gemini 2.0) for classifying implicit security requirements in SRS documents, emphasizing the practicality of LLMs as a resource-efficient alternative while highlighting challenges in Security Requirements Engineering (SRE).\n\nCONTENT: 2 Yusuf G¨ ur et al.\ntional fine-tuned transformer models and contemporary Large Language Mod-\nels (LLMs) employing few-shot and zero-shot prompt engineering strategies.\nThe results show that a few-shot prompting with Gemini 2.0 achieves a macro-\naverage F1 score of 0.941, directly comparable to the fine-tuned BERT model’s\n0.942. This study culminates in two primary findings: first, the validation and\npublication of the ASRD, a high-granularity, multi-label dataset for implicit\nsecurity requirements based on OWASP ASVS V2-V13; and second, the di-\nrect comparison demonstrating that few-shot Large Language Models (LLMs)\nachieve competitive multi-label classification performance (Macro-F1 0.941)\nnearly equal to resource-intensive fine-tuned transformer models (Macro-F1\n0.942). This confirms that LLMs represent a highly practical and resource-\nsaving strategy for automating the identification of embedded (implicit) secu-\nrity requirements for software security in industrial SRS documents\nKeywordsCybersecurity requirement elicitation·OWASP based security\nrequirement classification·OWASP ASVS-based Requirement Labeling·\nLLM based classification\n1 Introduction\nRequirements Engineering (RE) concerns the identification, documentation,\nand management of software requirements (Sommerville and Sawyer, 1997).\nThe increasing interconnectivity of information systems forces organizations\nto provide secure services in cyberspace. Integrating security during initial\nrequirements analysis is essential to proactively mitigate risks, reduce vulner-\nabilities, and reduce the high costs associated with downstream remediation\n(Villamizar et al., 2018). This proactive approach is central to the ”Shift-\nLeft” security paradigm, which advocates for the identification and mitigation\nof vulnerabilities as early as possible in the Software Development Life Cycle\n(SDLC).\nAlthough Security Requirements Engineering (SRE) has matured as a dis-\ncipline, its effective application in practice remains challenging. The issue is\nnot the absence of security considerations, but the difficulty of ensuring that\nsecurity requirements are properly validated and verified. An empirical investi-\ngation that combines a systematic literature review with a survey of 58 indus-\ntry professionals highlights this gap (Alam et al., 2025). While practitioners\nreported a moderate understanding of SRE practices, Security Requirements\nAssurance (SRA) was found to be poorly understood and rarely applied in\nindustrial contexts. The study concludes that validating and ensuring security\nrequirements remains a major and unresolved challenge in practice.\nThis assurance gap persists due to the documented lack of specialized se-\ncurity training for developers in early-phase RE (Andrade et al., 2023). The\ntask relies heavily on scarce specialized expertise and time-intensive manual\nanalysis. The main challenge is that critical security requirements are often not\nexplicitly stated. Instead, they are implicitly embedded within standard func-\ntional descriptions. For example, a seemingly simple functional requirement,', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**: This chunk focuses on the statistical evaluation of model performance, comparing fine-tuned models, few-shot, and zero-shot LLM approaches, highlighting significant pairwise differences, and visualizing results through a Critical Difference (CD) diagram to identify top-performing models in the domain.\n\nCONTENT: Implicit Security Requirements Classification 29\nThe analysis (Table 8) highlights the significant pairwise contrasts and\nreveals important performance distinctions:\n–Baseline vs. Advanced Models: The Naive Baseline was consistently out-\nperformed by the advanced models. The difference between the Baseline\nand models such as SecureBERT (p <0.001) and Gemini 2.0 Few-Shot\n(p <0.001) was statistically significant, confirming that the high Weighted-\nF1 scores of these models reflect genuine learning beyond simple majority-\nclass prediction.\n–Fine-Tuning vs. Zero-Shot LLMs: Fine-tuned models like SecureBERT\ndemonstrated statistically significant performance distinctions (p <0.001)\nwhen compared to general-purpose LLMs operating in a zero-shot setting,\nsuch as GPT-4o (p <0.001) and Llama 3 70B (p <0.001). This indi-\ncates that without in-context examples, domain-specific fine-tuning retains\na measurable statistical advantage.\n–Fine-Tuning vs. Few-Shot State-of-the-Art: The pairwise comparison be-\ntween the best fine-tuned model (SecureBERT) and the best LLM ap-\nproach (Gemini 2.0 Few-Shot) yielded ap-value of 0.102. This value is not\nstatistically significant at theα= 0.05 level, supporting our finding that\nfew-shot prompting with state-of-the-art LLMs can effectively match the\nperformance of specialized, fine-tuned BERT models in this domain.\nTable 8: Significant Pairwise Differences (Wilcoxon Signed-Rank Test)\nModel A Model B Statistic p-value\nNaive Baseline SecureBERT 0.0 0.00098\nNaive Baseline BERT Turkish 0.0 0.00098\nNaive Baseline Gemini 2.0 (Few-Shot) 0.0 0.00098\nNaive Baseline Gemini 2.0 Pro (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Few-Shot) 0.0 0.00098\nSecureBERT Gemini 2.0 (Zero-Shot) 25.0 0.501\nSecureBERT Gemini 2.0 (Few-Shot) 14.5 0.102\nTo visualize the relative performance and statistical significance groups\nof all evaluated models, we constructed a Critical Difference (CD) diagram\n(Figure 2) using the Nemenyi post-hoc test.\nIn the CD diagram, models are arranged along the horizontal axis accord-\ning to their average rank. The best performing models, such as Gemini 2.0\nPro (Few-Shot) and BERT-Multilingual, appear on the left (lowest ranks).\nA horizontal bar connects groups of models that are not statistically signifi-\ncantly different from one another. The wide span of the CD bar (10.46) reflects\nthe high number of models compared (23) relative to the number of datasets\n(11). Despite this conservative threshold, the diagram clearly separates the\ntop-tier models (Fine-tuned BERTs and Few-Shot Gemini/GPT-4o) from the\nlower-performing group (Naive Baseline, Zero-Shot Gemma/Llama).', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.', 'CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1', 'CONTEXT: **Evaluation of Model Challenges and Prompt Engineering Strategies**: This chunk discusses the challenges faced by models, particularly with underrepresented OWASP ASVS categories (e.g., V6 Cryptography, V12 Files/Resources), and outlines the experimental setup for prompt engineering in LLMs, including zero-shot and few-shot configurations, persona-based prompting, and strategies to ensure consistency and adherence to security standards.\n\nCONTENT: 26 Yusuf G¨ ur et al.\nshowed both low Recall (0.658) and low Precision (0.781), indicating it was\nboth missing true cases and incorrectly labeling other requirements as V6.\nModels struggle significantly with underrepresented categories, particularly\nV12 (File and Resources) and V6 (Stored Cryptography). This is evident in\nthe high number of false negatives, where the models fail to identify true\ninstances of these classes. For example, the baseline BERT model incorrectly\nclassified over half of the V12 requirements as negative (14 false negatives vs.\n13 true positives). Conversely, the matrices show that models often misclassify\nrequirements by incorrectly assigning them to other categories. The BERT\nBase model, for example, incorrectly labeled 92 different requirements as V10\n(Malicious Code) and 78 requirements as V5 (Malicious Input Handling).\n5.2 Experimental Setup for LLM Prompt Engineering\nWe adapted prompt engineering strategies from Ronanki (Ronanki et al.,\n2024), originally used for multi-class requirement classification. Two configu-\nrations were evaluated: zero-shot prompting (Appendix A), which relied solely\non task instructions and the input requirement, and few-shot prompting (Ap-\npendix B), which additionally incorporated labeled examples. The few-shot\nsetup used 30 training instances that were chosen to (i) capture multi-label\ncases where a single requirement spans multiple security categories, (ii) cover\nall 11 OWASP ASVS categories, and (iii) reflect requirements from different\nbusiness domains to preserve linguistic variation.\nPersona-based prompting was applied in both configurations by instruct-\ning the model to act as an experienced cybersecurity specialist. This alignment\nhelped reduce output variance by grounding responses in professional domain\nexpertise rather than general conversational patterns. The final prompt was\nobtained after five iterations. These iterations focused on three primary ar-\neas: (1) instruction clarity to prevent the model from defaulting to binary\nsecurity labels; (2) contextual grounding, by iteratively refining the OWASP\nASVS category definitions to ensure the model adhered to provided standards;\n(3) constraint formatting, to stabilize the PSV output structure for machine-\nreadability and ensure the inclusion of mandatory explanation fields. All ex-\nperiments were conducted with fixed parameters (Temperature = 0, Top-p =\n0.95) and repeated three times. The reported results are averaged to reduce\nthe impact of any minor, non-deterministic fluctuations in the models’ token\nselection during individual inferences.\nPrompt-based methods can be sensitive to phrasing, structure, and exam-\nple selection. To manage prompt sensitivity and contextual bias, we adopted a\nunified Persona–Context–Constraint strategy. A single prompt structure was\nused across all models, without model-specific tuning or iterative optimization\naimed at maximizing scores. The few-shot examples were chosen for representa-\ntiveness with respect to the OWASP ASVS taxonomy rather than performance\ngains.']","Experimental LLMs, such as Gemini 2.0 Flash Thinking, were included in the evaluation to benchmark the absolute state-of-the-art capabilities in reasoning and architectural efficiency that are not yet present in General Availability (GA) versions. The study hypothesized that the improved reasoning capabilities of these models, particularly in ""Chain-of-Thought"" processes, would be advantageous for identifying implicit security requirements, which often require multi-step deduction rather than simple pattern matching. 

While the use of experimental models poses challenges to reproducibility due to potential deprecation or updates, their inclusion was deemed necessary to provide a forward-looking analysis of emerging LLM capabilities and their impact on Security Requirements Engineering. The study documented the exact model identifiers to ensure transparency regarding the specific technological generation evaluated.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","They were included to benchmark state-of-the-art capabilities in 'reasoning' (Chain-of-Thought) which were hypothesized to be advantageous for identifying implicit security requirements[cite: 640, 641].",,,
What specific threat to internal validity is associated with the use of experimental LLM endpoints?,"['CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: **Analysis of Minority Class Performance and Annotation Challenges in SRE**: This chunk discusses the performance gap between majority and minority security classes in SRE, the expert-driven annotation process using the MATTER cycle, and the measures taken to mitigate subjectivity and ensure realistic, industry-relevant model evaluation.\n\nCONTENT: 32 Yusuf G¨ ur et al.\nFig. 4:Minority vs. Majority Class Performance Gap.A comparative\nanalysis revealing that while advanced LLMs and fine-tuned models achieve\nnear-parity on Majority Classes (Blue), a significant performance gap remains\non Minority Classes (Red), underscoring the “Long Tail” challenge in SRE.\nAnnotation was performed by three experienced cybersecurity experts.\nWhile their domain knowledge ensured quality, the small annotator pool may\nintroduce subjective bias and limit the range of interpretations. This was mit-\nigated through the iterative MATTER cycle which includes training, iterative\nguideline refinement, and consensus-based adjudication.\nA key threat to internal validity is subjectivity as classifications rely heavily\non the latent domain knowledge and industry experience, rather than explicit\nindicators within the requirement text itself. This expert-driven approach pro-\nvides a “gold standard” for realistic industrial needs but it may introduce in-\nconsistencies if replicated by annotators with different backgrounds or if the\nbroader system context is not explicitly documented.\nThe test set was manually selected to balance computational efficiency and\ngeneralizability assessment. While cross-validation could improve test calibra-\ntion, it was avoided due to its high computational cost.\nTo minimize researcher bias and ensure the results reflect real-world in-\ndustry needs, domain experts used for the selection of both the test set and\nthe LLM suite. Rather than selecting data or models arbitrarily, these experts\ncurated a test set containing the most complex, “implicit” security scenarios\nto challenge the models beyond simple pattern matching. For the model suite,\nthey prioritized architectures with advanced reasoning capabilities, hypothe-\nsizing that these specific technical features are essential for the multi-step de-\nduction required in security requirements engineering. Although the experts', 'CONTEXT: **Performance Visualization and Analysis of Classifiers**: This chunk focuses on the comparative performance analysis of 20 classifiers across OWASP ASVS classes, using critical difference diagrams, heatmaps, and gap analysis to highlight strengths and weaknesses, particularly in handling rare security classes like V6 (Stored Cryptography) and V12 (Files and Resources). It also discusses dataset diversity, threats to validity, and the generalizability of findings.\n\nCONTENT: 30 Yusuf G¨ ur et al.\nFig. 2: Critical Difference (CD) diagram visualizing the statistical comparison\nof classifiers. The horizontal axis represents the average rank of each model\nacross all 11 OWASP ASVS classes (lower ranks indicate better performance).\nThe Critical Difference (CD = 10.46) represents the minimum difference in\naverage rank required for two models to be considered statistically significantly\ndifferent atp <0.05.\n5.6 Comparative Visualization Analysis\nTo complement the statistical rankings, we visualized the performance land-\nscape across all 20 model configurations.\nHeatmap Analysis: Figure 3 shows F1-scores by class. Requirements related\nto V2 (Authentication), V3 (Session Management), and V4 (Access Control)\nare handled well by nearly all models, with scores typically above 0.95. These\ncategories are common and appear consistently across training sources. In\ncontrast, V6 (Stored Cryptography) and V12 (Files and Resources) show low\nscores across the board, including for GPT-4o and Gemini 2.0 Pro. This pat-\ntern points to a systematic difficulty with sparse categories rather than a\nweakness of a particular model.\nGap Analysis: Figure 4 contrasts average performance on frequent and in-\nfrequent classes. Fine-tuned models such as SecureBERT and BERT-Multilingual\nperform better on rare classes, with F1-scores around 0.70–0.80. Zero-shot\nLLMs perform poorly in these cases, often below 0.30. Few-shot prompting\nimproves results for some models, such as Gemini 2.0, but the gap remains\nsubstantial.\n6 Threats to Validity\nOur dataset consists of 2,652 requirements derived from six Software Require-\nments Specification (SRS) documents. While the number of source documents\n\nImplicit Security Requirements Classification 31\nFig. 3:Comprehensive Performance Heatmap.F1-scores for all 20 eval-\nuated models across 11 OWASP ASVS classes. The visualization highlights\nthe “zone of failure” (red) for classes V6 and V12 across models, contrasting\nwith the high performance (green) on ubiquitous classes like V2 and V4.\nis limited, potential bias was mitigated by strategically selecting projects from\nsix distinct business domains: Construction, Legal, Education, Software, Meet-\ning Management, and Accommodation. This semantic diversity ensures that\nthe models are evaluated on a broad vocabulary and varied functional contexts\nrather than a single industry vertical. A specific consideration regarding the\nexternal validity of this study is that the ASRD is a Turkish-language corpus\nwhich allows for the evaluation of automated tools in linguistically diverse\nindustrial contexts.\nFurthermore, because security requirements (e.g., Authentication, Log-\nging) represent cross-cutting concerns that apply universally across software\nsystems, we believe the fundamental patterns captured in the ASRD are trans-\nferable to other industries. Our current evaluation used a stratified split across\nthe entire dataset, meaning requirements from all six source projects are\npresent in the training, validation, and test sets. However, we acknowledge\nthat this approach does not fully measure the models’ ability to generalize to\nentirely new projects with different authors or linguistic styles, as the test set\nis not completely “unseen” in terms of project context.', 'CONTEXT: **Advancements in LLM-Assisted Security and Related Frameworks**: This chunk discusses the application of transformer-based models and LLMs in security requirements engineering (SRE), highlighting their capabilities, challenges, and the importance of high-quality datasets and evaluation frameworks. It also reviews the role of security frameworks in systematically identifying and classifying security requirements in automated settings.\n\nCONTENT: 6 Yusuf G¨ ur et al.\nBeyond requirements classification, security research has also turned to\ntask-specific models for narrowly defined problems. For instance, deep learning\napproaches such as BiLSTMs have been used to detect re-entrancy vulnerabil-\nities in smart contracts, where generic models are insufficient (Maturi et al.,\n2025). This work highlights the importance of explainability, as security de-\ncisions must be understandable to support assurance and auditing. Although\nthis line of research addresses a different problem, it reflects a shift toward\ndomain-aware and interpretable models.\nTransformer-based models have enabled new capabilities in automated text\nunderstanding(Zhou et al., 2025). They possess emergent abilities like in-\ncontext learning, instruction following, and step-by-step reasoning (Zhu et al.,\n2025), which allow them to perform complex tasks, including requirements\nclassification, with minimal or no labeled data (Liu et al., 2023b; Zhu et al.,\n2025). Recent trends show a growing interest in applying LLMs to RE tasks,\nincluding requirements classification, prioritization, and traceability (Rajbhoj\net al., 2024; White et al., 2024). LLMs can perform zero-shot and few-shot\nlearning, reducing the need for large annotated datasets and facilitating adap-\ntation to specialized domains like SRE (Labrak et al., 2023). Techniques such\nas prompt engineering and integration with external knowledge bases (e.g.,\nRetrieval-Augmented Generation) further improve their performance and con-\ntextual relevance (Masoudifard et al., 2024).\nLLM-assisted security solutions typically follow a three-step process: pre-\nprocessing (extracting context like documentation or target units), prompt\ngeneration (using instructions and unfilled slots for the model to complete\nwith artifacts like fuzz drivers or patches), and post-processing (validating\noutputs, e.g., checking if generated code successfully compiles) (Zhu et al.,\n2025).\nWhile these models provide powerful automation, they can also introduce\nnew risks and errors if applied without careful oversight. This underscores the\nneed for realistic, high-quality datasets and standardized evaluation frame-\nworks to reliably assess automated security requirement classification, ensuring\nboth effectiveness and safety in practice.\nThe use of automated models in security highlights both their potential and\nthe risks they can introduce. Ensuring accurate and reliable classification of\nsecurity requirements requires evaluation against high-quality, domain-specific\nbenchmarks (Jeong, 2024). This underscores the need for realistic datasets and\nstandardized evaluation frameworks tailored to SRE.\n2.2 Related Work on Security Frameworks\nAn appropriate security framework is necessary to ensure systematic and con-\nsistent identification and classification of security requirements, particularly in\nautomated settings. This section reviews widely adopted security frameworks\nand evaluates their suitability for requirement analysis.', 'CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1', 'CONTEXT: **Optimization and Prompting Strategies for Security Classification Models**: This chunk discusses the optimization of BERT variants through systematic hyperparameter tuning and explores the use of large language models (LLMs) for security requirement classification, focusing on zero-shot and few-shot prompting strategies to enhance task-specific performance without modifying the base model.\n\nCONTENT: 22 Yusuf G¨ ur et al.\nWe performed a systematic grid search using the Weights & Biases 12\nplatform to identify the optimal configuration for each BERT variant using\nthe validation dataset. The search space included the following parameters:\n–Maximum Sequence Length:[128, 256]tokens\n–Batch Size:[4, 8, 16]\n–Number of Epochs:[16, 24, 32]\n–Learning Rate:[1e-5, 2e-5, 3e-5]\n–Decision Threshold:[0.3, 0.4, 0.5]\nTo prevent overfitting, we monitored validation loss and implemented early\nstopping with a patience of 2–4 epochs. The checkpoint achieving the lowest\nvalidation loss for each model was selected for the final evaluation on the test\nset.\n4.3 Classification using LLM Models\nLLMs are transformer-based models trained on massive corpora for general-\npurpose natural language understanding and generation. This study adopted\nthe “pre-train, prompt, and predict” paradigm, which replaces traditional\n“pre-train, fine-tune” approaches (Liu et al., 2023a). Rather than adjusting\nthe model’s objective or architecture, prompt engineering is used to steer the\nmodel toward task-specific outputs through carefully designed textual inputs.\nPrompt engineering involves designing prompts that elicit accurate re-\nsponses for specific tasks. In zero-shot prompting, an LLM is directly used\nwithout any task-specific training. Few-shot prompting introduces a small\nnumber of labeled examples in the prompt, which allows the model to learn\nthe task pattern. This is particularly beneficial when labeled training data is\nlimited.\nFour main prompting strategies were proposed by (Liu et al., 2023a):\n–Tuning-free prompting: Requires no model changes, suitable for zero-shot\nsettings, but often demands complex prompt design.\n–Fixed-LLM prompt tuning: Involves learning soft prompts while keep-\ning the model fixed; effective for few-shot tasks but typically lacks inter-\npretability.\n–Fixed-prompt LLM tuning: Fine-tunes the model on a fixed prompt; im-\nproves performance in few-shot settings.\n–Prompt + LLM tuning: Jointly tunes both model and prompts; highly\nexpressive but prone to overfitting on small datasets.\nIn this study, we evaluated the first two of these strategies, as they do\nnot require modification of the base LLM’s weights. For our zero-shot experi-\nments, we implemented tuning-free prompting, relying on carefully engineered\nprompts to guide the models. For our few-shot analysis, our approach aligns\n12 https://wandb.ai/site', 'CONTEXT: **Performance Metrics for Security Verification Categories and LLM Evaluation**: This chunk presents detailed performance metrics (precision, recall, F1 scores, and support) for various OWASP ASVS security verification categories, highlighting the classification results of LLMs used in the study, with a focus on challenges in underrepresented categories like cryptography and file/resource verification.\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.967 0.939 0.972 0.882 0.280 0.960 0.962 0.954 0.783 0.479 0.884RECALL 0.990 0.963 0.990 0.994 0.718 0.977 0.984 0.982 0.900 0.821 0.981F1 0.978 0.951 0.981 0.934 0.403 0.968 0.973 0.968 0.837 0.605 0.930SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nTest Results of the LLMs used in the study\n56 Yusuf G¨ ur et al.\nD Test Results of the LLMs']","The specific threat to internal validity associated with the use of experimental LLM endpoints is **reproducibility**. The rapid pace of model iteration, including unannounced updates or deprecation of experimental models, poses challenges for other researchers attempting to replicate the study. These models may not retain the same weights or configurations in the future, making it difficult to ensure consistent results. 

To mitigate this, the study documented the exact model identifier strings used during the data collection window, ensuring transparency about the specific technological generation evaluated, even though this does not guarantee future access to the same model snapshots.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)",The use of experimental endpoints poses a threat to reproducibility as these models are subject to deprecation or unannounced updates[cite: 642].,,,
What was the main finding regarding the scalability of Large Language Models vs. Fine-Tuned models?,"['CONTEXT: **Performance Analysis of Models for Security Requirements Classification**: This chunk focuses on the statistical evaluation of model performance, comparing fine-tuned models, few-shot, and zero-shot LLM approaches, highlighting significant pairwise differences, and visualizing results through a Critical Difference (CD) diagram to identify top-performing models in the domain.\n\nCONTENT: Implicit Security Requirements Classification 29\nThe analysis (Table 8) highlights the significant pairwise contrasts and\nreveals important performance distinctions:\n–Baseline vs. Advanced Models: The Naive Baseline was consistently out-\nperformed by the advanced models. The difference between the Baseline\nand models such as SecureBERT (p <0.001) and Gemini 2.0 Few-Shot\n(p <0.001) was statistically significant, confirming that the high Weighted-\nF1 scores of these models reflect genuine learning beyond simple majority-\nclass prediction.\n–Fine-Tuning vs. Zero-Shot LLMs: Fine-tuned models like SecureBERT\ndemonstrated statistically significant performance distinctions (p <0.001)\nwhen compared to general-purpose LLMs operating in a zero-shot setting,\nsuch as GPT-4o (p <0.001) and Llama 3 70B (p <0.001). This indi-\ncates that without in-context examples, domain-specific fine-tuning retains\na measurable statistical advantage.\n–Fine-Tuning vs. Few-Shot State-of-the-Art: The pairwise comparison be-\ntween the best fine-tuned model (SecureBERT) and the best LLM ap-\nproach (Gemini 2.0 Few-Shot) yielded ap-value of 0.102. This value is not\nstatistically significant at theα= 0.05 level, supporting our finding that\nfew-shot prompting with state-of-the-art LLMs can effectively match the\nperformance of specialized, fine-tuned BERT models in this domain.\nTable 8: Significant Pairwise Differences (Wilcoxon Signed-Rank Test)\nModel A Model B Statistic p-value\nNaive Baseline SecureBERT 0.0 0.00098\nNaive Baseline BERT Turkish 0.0 0.00098\nNaive Baseline Gemini 2.0 (Few-Shot) 0.0 0.00098\nNaive Baseline Gemini 2.0 Pro (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Few-Shot) 0.0 0.00098\nSecureBERT GPT-4o Mini (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Zero-Shot) 0.0 0.00098\nSecureBERT GPT-4o (Few-Shot) 0.0 0.00098\nSecureBERT Gemini 2.0 (Zero-Shot) 25.0 0.501\nSecureBERT Gemini 2.0 (Few-Shot) 14.5 0.102\nTo visualize the relative performance and statistical significance groups\nof all evaluated models, we constructed a Critical Difference (CD) diagram\n(Figure 2) using the Nemenyi post-hoc test.\nIn the CD diagram, models are arranged along the horizontal axis accord-\ning to their average rank. The best performing models, such as Gemini 2.0\nPro (Few-Shot) and BERT-Multilingual, appear on the left (lowest ranks).\nA horizontal bar connects groups of models that are not statistically signifi-\ncantly different from one another. The wide span of the CD bar (10.46) reflects\nthe high number of models compared (23) relative to the number of datasets\n(11). Despite this conservative threshold, the diagram clearly separates the\ntop-tier models (Fine-tuned BERTs and Few-Shot Gemini/GPT-4o) from the\nlower-performing group (Naive Baseline, Zero-Shot Gemma/Llama).', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**  \nThis chunk provides a detailed comparison of F1-scores across various LLMs, fine-tuned BERT models, and a baseline approach, highlighting their performance in classifying security requirements, particularly in handling class imbalance and underrepresented categories.\n\nCONTENT: Implicit Security Requirements Classification 25\nTable 7: Aggregated F1-Scores for LLM, BERT Models, and Baseline\nModel Prompting Strategy Macro-F1 Micro-F1 Weighted-F1\nLarge Language Model Results\nLlama 3 70b Zero Shot 0.813 0.941 0.941\nLlama 3 70b Few Shot 0.802 0.925 0.925\nDeepSeek R1 Zero Shot 0.812 0.921 0.916\nDeepSeek R1 Few Shot 0.820 0.927 0.921\nGemini 2.5 Zero Shot 0.8290.957 0.953\nGemini 2.5 Few Shot 0.8170.963 0.959\nGemini 2.0 Zero Shot0.8900.925 0.921\nGemini 2.0 Few Shot0.9410.938 0.938\nGemini 2.0 Pro Zero Shot 0.830 0.908 0.904\nGemini 2.0 Pro Few Shot 0.889 0.959 0.953\nGemma 3 27b Zero Shot 0.806 0.912 0.907\nGemma 3 27b Few Shot 0.802 0.917 0.912\nGemma 3 4b Zero Shot 0.605 0.738 0.742\nGemma 3 4b Few Shot 0.723 0.871 0.867\nGpt 4o Zero Shot 0.790 0.912 0.907\nGpt 4o Few Shot 0.814 0.943 0.939\nGpt 4o mini Zero Shot 0.703 0.803 0.809\nGpt 4o mini Few Shot 0.754 0.852 0.854\nBERT Fine-Tuning Results\nbert-base-multilingual-uncased Fine-Tuning0.942 0.985 0.983\nbert-base-turkish-cased Fine-Tuning 0.933 0.983 0.981\nbert-base-uncased Fine-Tuning 0.914 0.978 0.976\nSecureBERT Fine-Tuning 0.918 0.979 0.976\nBaseline\nNaive Baseline Majority Class 0.774 0.940 0.933\nrepresented categories. The bert-base-multilingual-uncased model achieved the\nhighest Weighted-F1 score at 0.983, while the lowest among the group was\n0.976 for both bert-base-uncased and SecureBERT. However, these results ob-\nscure the impact of class imbalance. Macro-F1 scores, which give equal weight\nto all categories, were lower, ranging from 0.942 to 0.914, revealing reduced\nperformance on less frequent classes.\nThis pattern is clear in the category-level results (Appendix C). Perfor-\nmance was high for common categories such as V8 (Data Protection), where\nthe bert-base-multilingual-uncased model achieved an F1-score of 0.992. In\ncontrast, results declined significantly for sparsely represented categories. For\nV6 (38 samples), F1-scores fell to 0.714 for bert-base-uncased and 0.734 for\nSecureBERT. The weakest performance was observed for V10 (27 samples),\nwith F1-scores around 0.60, indicating limited generalization due to limited\ndata.\nAn analysis of precision and recall for these difficult classes reveals specific\nfailure patterns. For class V10, the bert-base-uncased model has a low Recall of\n0.481. This indicates that while its predictions were often correct (Precision:\n0.813), it failed to identify more than half of the actual V10 requirements,\nresulting in a high number of false negatives. For class V6, the same model', 'CONTEXT: **Comparison of Fine-Tuned Models and LLMs for Security Requirements Classification**: This chunk discusses the performance comparison between fine-tuned transformer models (e.g., BERT) and few-shot prompting with LLMs (e.g., Gemini 2.0) for classifying implicit security requirements in SRS documents, emphasizing the practicality of LLMs as a resource-efficient alternative while highlighting challenges in Security Requirements Engineering (SRE).\n\nCONTENT: 2 Yusuf G¨ ur et al.\ntional fine-tuned transformer models and contemporary Large Language Mod-\nels (LLMs) employing few-shot and zero-shot prompt engineering strategies.\nThe results show that a few-shot prompting with Gemini 2.0 achieves a macro-\naverage F1 score of 0.941, directly comparable to the fine-tuned BERT model’s\n0.942. This study culminates in two primary findings: first, the validation and\npublication of the ASRD, a high-granularity, multi-label dataset for implicit\nsecurity requirements based on OWASP ASVS V2-V13; and second, the di-\nrect comparison demonstrating that few-shot Large Language Models (LLMs)\nachieve competitive multi-label classification performance (Macro-F1 0.941)\nnearly equal to resource-intensive fine-tuned transformer models (Macro-F1\n0.942). This confirms that LLMs represent a highly practical and resource-\nsaving strategy for automating the identification of embedded (implicit) secu-\nrity requirements for software security in industrial SRS documents\nKeywordsCybersecurity requirement elicitation·OWASP based security\nrequirement classification·OWASP ASVS-based Requirement Labeling·\nLLM based classification\n1 Introduction\nRequirements Engineering (RE) concerns the identification, documentation,\nand management of software requirements (Sommerville and Sawyer, 1997).\nThe increasing interconnectivity of information systems forces organizations\nto provide secure services in cyberspace. Integrating security during initial\nrequirements analysis is essential to proactively mitigate risks, reduce vulner-\nabilities, and reduce the high costs associated with downstream remediation\n(Villamizar et al., 2018). This proactive approach is central to the ”Shift-\nLeft” security paradigm, which advocates for the identification and mitigation\nof vulnerabilities as early as possible in the Software Development Life Cycle\n(SDLC).\nAlthough Security Requirements Engineering (SRE) has matured as a dis-\ncipline, its effective application in practice remains challenging. The issue is\nnot the absence of security considerations, but the difficulty of ensuring that\nsecurity requirements are properly validated and verified. An empirical investi-\ngation that combines a systematic literature review with a survey of 58 indus-\ntry professionals highlights this gap (Alam et al., 2025). While practitioners\nreported a moderate understanding of SRE practices, Security Requirements\nAssurance (SRA) was found to be poorly understood and rarely applied in\nindustrial contexts. The study concludes that validating and ensuring security\nrequirements remains a major and unresolved challenge in practice.\nThis assurance gap persists due to the documented lack of specialized se-\ncurity training for developers in early-phase RE (Andrade et al., 2023). The\ntask relies heavily on scarce specialized expertise and time-intensive manual\nanalysis. The main challenge is that critical security requirements are often not\nexplicitly stated. Instead, they are implicitly embedded within standard func-\ntional descriptions. For example, a seemingly simple functional requirement,', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.', 'CONTEXT: **Optimization and Prompting Strategies for Security Classification Models**: This chunk discusses the optimization of BERT variants through systematic hyperparameter tuning and explores the use of large language models (LLMs) for security requirement classification, focusing on zero-shot and few-shot prompting strategies to enhance task-specific performance without modifying the base model.\n\nCONTENT: 22 Yusuf G¨ ur et al.\nWe performed a systematic grid search using the Weights & Biases 12\nplatform to identify the optimal configuration for each BERT variant using\nthe validation dataset. The search space included the following parameters:\n–Maximum Sequence Length:[128, 256]tokens\n–Batch Size:[4, 8, 16]\n–Number of Epochs:[16, 24, 32]\n–Learning Rate:[1e-5, 2e-5, 3e-5]\n–Decision Threshold:[0.3, 0.4, 0.5]\nTo prevent overfitting, we monitored validation loss and implemented early\nstopping with a patience of 2–4 epochs. The checkpoint achieving the lowest\nvalidation loss for each model was selected for the final evaluation on the test\nset.\n4.3 Classification using LLM Models\nLLMs are transformer-based models trained on massive corpora for general-\npurpose natural language understanding and generation. This study adopted\nthe “pre-train, prompt, and predict” paradigm, which replaces traditional\n“pre-train, fine-tune” approaches (Liu et al., 2023a). Rather than adjusting\nthe model’s objective or architecture, prompt engineering is used to steer the\nmodel toward task-specific outputs through carefully designed textual inputs.\nPrompt engineering involves designing prompts that elicit accurate re-\nsponses for specific tasks. In zero-shot prompting, an LLM is directly used\nwithout any task-specific training. Few-shot prompting introduces a small\nnumber of labeled examples in the prompt, which allows the model to learn\nthe task pattern. This is particularly beneficial when labeled training data is\nlimited.\nFour main prompting strategies were proposed by (Liu et al., 2023a):\n–Tuning-free prompting: Requires no model changes, suitable for zero-shot\nsettings, but often demands complex prompt design.\n–Fixed-LLM prompt tuning: Involves learning soft prompts while keep-\ning the model fixed; effective for few-shot tasks but typically lacks inter-\npretability.\n–Fixed-prompt LLM tuning: Fine-tunes the model on a fixed prompt; im-\nproves performance in few-shot settings.\n–Prompt + LLM tuning: Jointly tunes both model and prompts; highly\nexpressive but prone to overfitting on small datasets.\nIn this study, we evaluated the first two of these strategies, as they do\nnot require modification of the base LLM’s weights. For our zero-shot experi-\nments, we implemented tuning-free prompting, relying on carefully engineered\nprompts to guide the models. For our few-shot analysis, our approach aligns\n12 https://wandb.ai/site', 'CONTEXT: This chunk focuses on the evaluation of various language models, including open-source and commercial models, for implicit security requirements classification, detailing their technical specifications, rationale for selection, and experimental setup involving zero-shot and few-shot prompting strategies.\n\nCONTENT: Implicit Security Requirements Classification 23\nwith fixed-LLM prompt tuning, where we provided in-context examples within\nthe prompt to guide the model’s predictions. The latter two strategies involv-\ning model fine-tuning Fixed-prompt LLM tuning and Prompt + LLM tuning)\nwere not considered due to their high computational cost. The zero shot and\nfew shot prompts can be found in Appendix A and Appendix B.\nIn these experiments, we evaluated nine language models, including open-\nsource models deployed on local infrastructure and commercial models ac-\ncessed via external application programming interfaces (APIs). The technical\nspecifications of each model and the rationale for their selection are summa-\nrized in Table 7. The requirements were processed in batches of 15 because\nproviding the full set in a single prompt exceeded the models’ context limits.\nTable 6: Details and Rationale of the LLMs Used in the Study\nModel Name Description Rationale in Study\nOpen-Source Models\ngemma-3-27b\n(Dense Trans-\nformer; 27B\nParams)\nA Google-developed lan-\nguage model trained on\na large, diverse corpus of\nweb text.13 (The Google\nGemma Team, 2025)\nTo evaluate a powerful, next-generation\nopen-source model from a major AI research\nlab, establishing a baseline for locally deploy-\nable high-parameter models.\ngemma-3-4b\n(Dense Trans-\nformer; 4B\nParams)\nA smaller, efficient model\nfrom the Gemma 3 fam-\nily, designed for resource-\nconstrained environ-\nments.13 (The Google\nGemma Team, 2025)\nTo assess the performance of a highly ef-\nficient, small-scale model to determine if\nlower-parameter models can effectively han-\ndle complex security classification tasks.\nmeta.llama3-\n3-70b-instruct-\nv1:0\n(Dense Trans-\nformer; 70B\nParams)\nAPI version of Meta’s\nLlama 3 70B Instruct.\nAn open-weight model\npre-trained on over 15T\ntokens. 14 (AI at Meta,\n2024)\nTo benchmark against a leading open-weight\nmodel known for strong reasoning and\ninstruction-following capabilities, represent-\ning the state-of-the-art in non-proprietary\nmodels.\nDeepSeek-R1\n(Mixture-of-\nExperts (MoE))\nAn API-accessible model\nfrom DeepSeek AI. As-\nsumed to be based on the\nDeepSeek-V2 architecture\n(236B total/21B active\nparams). 15 (DeepSeek AI,\n2024)\nTo include a model with a different architec-\nture (MoE) that represents an alternative,\nhighly efficient approach to scaling, specif-\nically testing its reasoning capabilities in\nsecurity contexts.\nCommercial Models (API Access)\n13 https://blog.google/technology/developers/\n14 https://ai.meta.com/blog/meta-llama-3/\n15 https://deepseek.com/', 'CONTEXT: **Analysis of Minority Class Performance and Annotation Challenges in SRE**: This chunk discusses the performance gap between majority and minority security classes in SRE, the expert-driven annotation process using the MATTER cycle, and the measures taken to mitigate subjectivity and ensure realistic, industry-relevant model evaluation.\n\nCONTENT: 32 Yusuf G¨ ur et al.\nFig. 4:Minority vs. Majority Class Performance Gap.A comparative\nanalysis revealing that while advanced LLMs and fine-tuned models achieve\nnear-parity on Majority Classes (Blue), a significant performance gap remains\non Minority Classes (Red), underscoring the “Long Tail” challenge in SRE.\nAnnotation was performed by three experienced cybersecurity experts.\nWhile their domain knowledge ensured quality, the small annotator pool may\nintroduce subjective bias and limit the range of interpretations. This was mit-\nigated through the iterative MATTER cycle which includes training, iterative\nguideline refinement, and consensus-based adjudication.\nA key threat to internal validity is subjectivity as classifications rely heavily\non the latent domain knowledge and industry experience, rather than explicit\nindicators within the requirement text itself. This expert-driven approach pro-\nvides a “gold standard” for realistic industrial needs but it may introduce in-\nconsistencies if replicated by annotators with different backgrounds or if the\nbroader system context is not explicitly documented.\nThe test set was manually selected to balance computational efficiency and\ngeneralizability assessment. While cross-validation could improve test calibra-\ntion, it was avoided due to its high computational cost.\nTo minimize researcher bias and ensure the results reflect real-world in-\ndustry needs, domain experts used for the selection of both the test set and\nthe LLM suite. Rather than selecting data or models arbitrarily, these experts\ncurated a test set containing the most complex, “implicit” security scenarios\nto challenge the models beyond simple pattern matching. For the model suite,\nthey prioritized architectures with advanced reasoning capabilities, hypothe-\nsizing that these specific technical features are essential for the multi-step de-\nduction required in security requirements engineering. Although the experts']","The main finding regarding the scalability of Large Language Models (LLMs) versus fine-tuned models is that few-shot prompting with state-of-the-art LLMs, such as Gemini 2.0, can achieve performance nearly equal to fine-tuned transformer models like BERT in terms of Macro-F1 scores (0.941 vs. 0.942). This demonstrates that LLMs represent a practical and resource-efficient alternative for automating implicit security requirements classification, especially when labeled training data is limited. However, fine-tuned models still outperform LLMs in handling minority classes and exhibit statistically significant advantages in zero-shot settings. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","LLMs represent a highly practical and resource-saving strategy as they achieve competitive performance (Macro-F1 0.941 vs 0.942) with substantially less data preparation effort[cite: 27, 660].",,,
"What is the 'pre-train, prompt, and predict' paradigm?","['CONTEXT: **Optimization and Prompting Strategies for Security Classification Models**: This chunk discusses the optimization of BERT variants through systematic hyperparameter tuning and explores the use of large language models (LLMs) for security requirement classification, focusing on zero-shot and few-shot prompting strategies to enhance task-specific performance without modifying the base model.\n\nCONTENT: 22 Yusuf G¨ ur et al.\nWe performed a systematic grid search using the Weights & Biases 12\nplatform to identify the optimal configuration for each BERT variant using\nthe validation dataset. The search space included the following parameters:\n–Maximum Sequence Length:[128, 256]tokens\n–Batch Size:[4, 8, 16]\n–Number of Epochs:[16, 24, 32]\n–Learning Rate:[1e-5, 2e-5, 3e-5]\n–Decision Threshold:[0.3, 0.4, 0.5]\nTo prevent overfitting, we monitored validation loss and implemented early\nstopping with a patience of 2–4 epochs. The checkpoint achieving the lowest\nvalidation loss for each model was selected for the final evaluation on the test\nset.\n4.3 Classification using LLM Models\nLLMs are transformer-based models trained on massive corpora for general-\npurpose natural language understanding and generation. This study adopted\nthe “pre-train, prompt, and predict” paradigm, which replaces traditional\n“pre-train, fine-tune” approaches (Liu et al., 2023a). Rather than adjusting\nthe model’s objective or architecture, prompt engineering is used to steer the\nmodel toward task-specific outputs through carefully designed textual inputs.\nPrompt engineering involves designing prompts that elicit accurate re-\nsponses for specific tasks. In zero-shot prompting, an LLM is directly used\nwithout any task-specific training. Few-shot prompting introduces a small\nnumber of labeled examples in the prompt, which allows the model to learn\nthe task pattern. This is particularly beneficial when labeled training data is\nlimited.\nFour main prompting strategies were proposed by (Liu et al., 2023a):\n–Tuning-free prompting: Requires no model changes, suitable for zero-shot\nsettings, but often demands complex prompt design.\n–Fixed-LLM prompt tuning: Involves learning soft prompts while keep-\ning the model fixed; effective for few-shot tasks but typically lacks inter-\npretability.\n–Fixed-prompt LLM tuning: Fine-tunes the model on a fixed prompt; im-\nproves performance in few-shot settings.\n–Prompt + LLM tuning: Jointly tunes both model and prompts; highly\nexpressive but prone to overfitting on small datasets.\nIn this study, we evaluated the first two of these strategies, as they do\nnot require modification of the base LLM’s weights. For our zero-shot experi-\nments, we implemented tuning-free prompting, relying on carefully engineered\nprompts to guide the models. For our few-shot analysis, our approach aligns\n12 https://wandb.ai/site', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: This chunk focuses on the evaluation of various language models, including open-source and commercial models, for implicit security requirements classification, detailing their technical specifications, rationale for selection, and experimental setup involving zero-shot and few-shot prompting strategies.\n\nCONTENT: Implicit Security Requirements Classification 23\nwith fixed-LLM prompt tuning, where we provided in-context examples within\nthe prompt to guide the model’s predictions. The latter two strategies involv-\ning model fine-tuning Fixed-prompt LLM tuning and Prompt + LLM tuning)\nwere not considered due to their high computational cost. The zero shot and\nfew shot prompts can be found in Appendix A and Appendix B.\nIn these experiments, we evaluated nine language models, including open-\nsource models deployed on local infrastructure and commercial models ac-\ncessed via external application programming interfaces (APIs). The technical\nspecifications of each model and the rationale for their selection are summa-\nrized in Table 7. The requirements were processed in batches of 15 because\nproviding the full set in a single prompt exceeded the models’ context limits.\nTable 6: Details and Rationale of the LLMs Used in the Study\nModel Name Description Rationale in Study\nOpen-Source Models\ngemma-3-27b\n(Dense Trans-\nformer; 27B\nParams)\nA Google-developed lan-\nguage model trained on\na large, diverse corpus of\nweb text.13 (The Google\nGemma Team, 2025)\nTo evaluate a powerful, next-generation\nopen-source model from a major AI research\nlab, establishing a baseline for locally deploy-\nable high-parameter models.\ngemma-3-4b\n(Dense Trans-\nformer; 4B\nParams)\nA smaller, efficient model\nfrom the Gemma 3 fam-\nily, designed for resource-\nconstrained environ-\nments.13 (The Google\nGemma Team, 2025)\nTo assess the performance of a highly ef-\nficient, small-scale model to determine if\nlower-parameter models can effectively han-\ndle complex security classification tasks.\nmeta.llama3-\n3-70b-instruct-\nv1:0\n(Dense Trans-\nformer; 70B\nParams)\nAPI version of Meta’s\nLlama 3 70B Instruct.\nAn open-weight model\npre-trained on over 15T\ntokens. 14 (AI at Meta,\n2024)\nTo benchmark against a leading open-weight\nmodel known for strong reasoning and\ninstruction-following capabilities, represent-\ning the state-of-the-art in non-proprietary\nmodels.\nDeepSeek-R1\n(Mixture-of-\nExperts (MoE))\nAn API-accessible model\nfrom DeepSeek AI. As-\nsumed to be based on the\nDeepSeek-V2 architecture\n(236B total/21B active\nparams). 15 (DeepSeek AI,\n2024)\nTo include a model with a different architec-\nture (MoE) that represents an alternative,\nhighly efficient approach to scaling, specif-\nically testing its reasoning capabilities in\nsecurity contexts.\nCommercial Models (API Access)\n13 https://blog.google/technology/developers/\n14 https://ai.meta.com/blog/meta-llama-3/\n15 https://deepseek.com/', 'CONTEXT: **Advancements in LLM-Assisted Security and Related Frameworks**: This chunk discusses the application of transformer-based models and LLMs in security requirements engineering (SRE), highlighting their capabilities, challenges, and the importance of high-quality datasets and evaluation frameworks. It also reviews the role of security frameworks in systematically identifying and classifying security requirements in automated settings.\n\nCONTENT: 6 Yusuf G¨ ur et al.\nBeyond requirements classification, security research has also turned to\ntask-specific models for narrowly defined problems. For instance, deep learning\napproaches such as BiLSTMs have been used to detect re-entrancy vulnerabil-\nities in smart contracts, where generic models are insufficient (Maturi et al.,\n2025). This work highlights the importance of explainability, as security de-\ncisions must be understandable to support assurance and auditing. Although\nthis line of research addresses a different problem, it reflects a shift toward\ndomain-aware and interpretable models.\nTransformer-based models have enabled new capabilities in automated text\nunderstanding(Zhou et al., 2025). They possess emergent abilities like in-\ncontext learning, instruction following, and step-by-step reasoning (Zhu et al.,\n2025), which allow them to perform complex tasks, including requirements\nclassification, with minimal or no labeled data (Liu et al., 2023b; Zhu et al.,\n2025). Recent trends show a growing interest in applying LLMs to RE tasks,\nincluding requirements classification, prioritization, and traceability (Rajbhoj\net al., 2024; White et al., 2024). LLMs can perform zero-shot and few-shot\nlearning, reducing the need for large annotated datasets and facilitating adap-\ntation to specialized domains like SRE (Labrak et al., 2023). Techniques such\nas prompt engineering and integration with external knowledge bases (e.g.,\nRetrieval-Augmented Generation) further improve their performance and con-\ntextual relevance (Masoudifard et al., 2024).\nLLM-assisted security solutions typically follow a three-step process: pre-\nprocessing (extracting context like documentation or target units), prompt\ngeneration (using instructions and unfilled slots for the model to complete\nwith artifacts like fuzz drivers or patches), and post-processing (validating\noutputs, e.g., checking if generated code successfully compiles) (Zhu et al.,\n2025).\nWhile these models provide powerful automation, they can also introduce\nnew risks and errors if applied without careful oversight. This underscores the\nneed for realistic, high-quality datasets and standardized evaluation frame-\nworks to reliably assess automated security requirement classification, ensuring\nboth effectiveness and safety in practice.\nThe use of automated models in security highlights both their potential and\nthe risks they can introduce. Ensuring accurate and reliable classification of\nsecurity requirements requires evaluation against high-quality, domain-specific\nbenchmarks (Jeong, 2024). This underscores the need for realistic datasets and\nstandardized evaluation frameworks tailored to SRE.\n2.2 Related Work on Security Frameworks\nAn appropriate security framework is necessary to ensure systematic and con-\nsistent identification and classification of security requirements, particularly in\nautomated settings. This section reviews widely adopted security frameworks\nand evaluates their suitability for requirement analysis.', 'CONTEXT: **Comparison of Fine-Tuned Models and LLMs for Security Requirements Classification**: This chunk discusses the performance comparison between fine-tuned transformer models (e.g., BERT) and few-shot prompting with LLMs (e.g., Gemini 2.0) for classifying implicit security requirements in SRS documents, emphasizing the practicality of LLMs as a resource-efficient alternative while highlighting challenges in Security Requirements Engineering (SRE).\n\nCONTENT: 2 Yusuf G¨ ur et al.\ntional fine-tuned transformer models and contemporary Large Language Mod-\nels (LLMs) employing few-shot and zero-shot prompt engineering strategies.\nThe results show that a few-shot prompting with Gemini 2.0 achieves a macro-\naverage F1 score of 0.941, directly comparable to the fine-tuned BERT model’s\n0.942. This study culminates in two primary findings: first, the validation and\npublication of the ASRD, a high-granularity, multi-label dataset for implicit\nsecurity requirements based on OWASP ASVS V2-V13; and second, the di-\nrect comparison demonstrating that few-shot Large Language Models (LLMs)\nachieve competitive multi-label classification performance (Macro-F1 0.941)\nnearly equal to resource-intensive fine-tuned transformer models (Macro-F1\n0.942). This confirms that LLMs represent a highly practical and resource-\nsaving strategy for automating the identification of embedded (implicit) secu-\nrity requirements for software security in industrial SRS documents\nKeywordsCybersecurity requirement elicitation·OWASP based security\nrequirement classification·OWASP ASVS-based Requirement Labeling·\nLLM based classification\n1 Introduction\nRequirements Engineering (RE) concerns the identification, documentation,\nand management of software requirements (Sommerville and Sawyer, 1997).\nThe increasing interconnectivity of information systems forces organizations\nto provide secure services in cyberspace. Integrating security during initial\nrequirements analysis is essential to proactively mitigate risks, reduce vulner-\nabilities, and reduce the high costs associated with downstream remediation\n(Villamizar et al., 2018). This proactive approach is central to the ”Shift-\nLeft” security paradigm, which advocates for the identification and mitigation\nof vulnerabilities as early as possible in the Software Development Life Cycle\n(SDLC).\nAlthough Security Requirements Engineering (SRE) has matured as a dis-\ncipline, its effective application in practice remains challenging. The issue is\nnot the absence of security considerations, but the difficulty of ensuring that\nsecurity requirements are properly validated and verified. An empirical investi-\ngation that combines a systematic literature review with a survey of 58 indus-\ntry professionals highlights this gap (Alam et al., 2025). While practitioners\nreported a moderate understanding of SRE practices, Security Requirements\nAssurance (SRA) was found to be poorly understood and rarely applied in\nindustrial contexts. The study concludes that validating and ensuring security\nrequirements remains a major and unresolved challenge in practice.\nThis assurance gap persists due to the documented lack of specialized se-\ncurity training for developers in early-phase RE (Andrade et al., 2023). The\ntask relies heavily on scarce specialized expertise and time-intensive manual\nanalysis. The main challenge is that critical security requirements are often not\nexplicitly stated. Instead, they are implicitly embedded within standard func-\ntional descriptions. For example, a seemingly simple functional requirement,', 'CONTEXT: **Evaluation of Model Challenges and Prompt Engineering Strategies**: This chunk discusses the challenges faced by models, particularly with underrepresented OWASP ASVS categories (e.g., V6 Cryptography, V12 Files/Resources), and outlines the experimental setup for prompt engineering in LLMs, including zero-shot and few-shot configurations, persona-based prompting, and strategies to ensure consistency and adherence to security standards.\n\nCONTENT: 26 Yusuf G¨ ur et al.\nshowed both low Recall (0.658) and low Precision (0.781), indicating it was\nboth missing true cases and incorrectly labeling other requirements as V6.\nModels struggle significantly with underrepresented categories, particularly\nV12 (File and Resources) and V6 (Stored Cryptography). This is evident in\nthe high number of false negatives, where the models fail to identify true\ninstances of these classes. For example, the baseline BERT model incorrectly\nclassified over half of the V12 requirements as negative (14 false negatives vs.\n13 true positives). Conversely, the matrices show that models often misclassify\nrequirements by incorrectly assigning them to other categories. The BERT\nBase model, for example, incorrectly labeled 92 different requirements as V10\n(Malicious Code) and 78 requirements as V5 (Malicious Input Handling).\n5.2 Experimental Setup for LLM Prompt Engineering\nWe adapted prompt engineering strategies from Ronanki (Ronanki et al.,\n2024), originally used for multi-class requirement classification. Two configu-\nrations were evaluated: zero-shot prompting (Appendix A), which relied solely\non task instructions and the input requirement, and few-shot prompting (Ap-\npendix B), which additionally incorporated labeled examples. The few-shot\nsetup used 30 training instances that were chosen to (i) capture multi-label\ncases where a single requirement spans multiple security categories, (ii) cover\nall 11 OWASP ASVS categories, and (iii) reflect requirements from different\nbusiness domains to preserve linguistic variation.\nPersona-based prompting was applied in both configurations by instruct-\ning the model to act as an experienced cybersecurity specialist. This alignment\nhelped reduce output variance by grounding responses in professional domain\nexpertise rather than general conversational patterns. The final prompt was\nobtained after five iterations. These iterations focused on three primary ar-\neas: (1) instruction clarity to prevent the model from defaulting to binary\nsecurity labels; (2) contextual grounding, by iteratively refining the OWASP\nASVS category definitions to ensure the model adhered to provided standards;\n(3) constraint formatting, to stabilize the PSV output structure for machine-\nreadability and ensure the inclusion of mandatory explanation fields. All ex-\nperiments were conducted with fixed parameters (Temperature = 0, Top-p =\n0.95) and repeated three times. The reported results are averaged to reduce\nthe impact of any minor, non-deterministic fluctuations in the models’ token\nselection during individual inferences.\nPrompt-based methods can be sensitive to phrasing, structure, and exam-\nple selection. To manage prompt sensitivity and contextual bias, we adopted a\nunified Persona–Context–Constraint strategy. A single prompt structure was\nused across all models, without model-specific tuning or iterative optimization\naimed at maximizing scores. The few-shot examples were chosen for representa-\ntiveness with respect to the OWASP ASVS taxonomy rather than performance\ngains.', 'CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1', 'CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the']","The ""pre-train, prompt, and predict"" paradigm is a modern approach to utilizing large language models (LLMs) for task-specific applications. Unlike the traditional ""pre-train, fine-tune"" method, this paradigm leverages prompt engineering to guide pre-trained models toward desired outputs without modifying their architecture or weights. 

In this paradigm:
1. **Pre-train**: The model is trained on massive corpora for general-purpose natural language understanding and generation.
2. **Prompt**: Carefully designed textual inputs (prompts) are used to steer the model toward task-specific outputs. Prompts can be zero-shot (no labeled examples) or few-shot (a small number of labeled examples included).
3. **Predict**: The model generates predictions based on the provided prompts.

Prompt engineering strategies include:
- **Tuning-free prompting**: No model changes, suitable for zero-shot settings but requires complex prompt design.
- **Fixed-LLM prompt tuning**: Learning soft prompts while keeping the model fixed, effective for few-shot tasks but less interpretable.

This paradigm is particularly beneficial for tasks with limited labeled data, as it avoids the computational cost of fine-tuning and allows for flexible adaptation to specialized domains. For example, in security requirement classification, zero-shot and few-shot prompting strategies have been used to classify implicit security requirements effectively.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","It is a paradigm that replaces traditional 'pre-train, fine-tune' approaches by using prompt engineering to steer a general-purpose model toward task-specific outputs without adjusting model weights[cite: 395].",,,
Why is the OWASP ASVS framework preferred over STRIDE for this specific task?,"['CONTEXT: **Comparison of Security Frameworks and Related Datasets**: This chunk contrasts various security frameworks, highlighting the suitability of OWASP ASVS for fine-grained security requirement classification, and reviews existing security-related requirement datasets, emphasizing their limitations and relevance to automated classification research.\n\nCONTENT: Implicit Security Requirements Classification 7\nSeveral established frameworks, while influential, are not designed for this\npurpose. MITRE ATT&ACK 2 framework is a threat-based model of adver-\nsary behaviors, not a taxonomy of software requirements. Microsoft’s STRIDE\noperates at a high level of abstraction (e.g., “Spoofing”, “Tampering”) which\nis useful for threat modeling but lacks the granularity needed for require-\nment classification (Khan et al., 2017). Similarly, the NIST Secure Software\nDevelopment Framework (SSDF) defines high-level secure process practices\nrather than atomic requirement categories (Souppaya et al., 2022), and the\nCommon Criteria (CC) 3 is a template-based framework designed for formal\ncertification, making it impractical for fine-grained, natural-language analysis\n(Infrastructure and Profile, 2002).\nIn contrast, the Open Web Application Security Project (OWASP)4 Appli-\ncation Security Verification Standard (ASVS)5 is well suited to the objectives\nof this study. ASVS provides a detailed, verifiable, and developer-oriented\ntaxonomy explicitly intended for requirement-level security analysis. Its orga-\nnization into distinct, actionable security categories supports direct mapping\nto functional and non-functional security controls. Previous studies have suc-\ncessfully applied ASVS in requirements and design contexts ( Lukasiewicz and\nCyga´ nska, 2019; Tan et al., 2021; Wen and Katt, 2023). Its consistency with\nstandards such as NIST 800-63B supports its use in both academic research\nand industrial settings.\n2.3 Related Work on Security Related Requirement Datasets\nHigh-quality benchmark datasets are essential for developing automated clas-\nsification models, ensuring research reproducibility, and assessing model gen-\neralizability. In response to this need, the research community has developed\na limited number of foundational datasets for security requirements analysis,\neach offering distinct advantages and limitations. The three most represen-\ntative datasets are briefly described below, and their key characteristics are\nsummarized in Table 1.\n2.3.1 PROMISEExp\nIntroduced by Lima et al. (Lima et al., 2019), to expand the well-established\ntera-PROMISE repository, this dataset resulted from a systematic curation\nof publicly available SRS documents. The curation process relied on man-\nual extraction and expert consensus to ensure high-quality annotations. Al-\nthough it offers significant project diversity compared to its predecessor, its\nprimary challenge for modern research is its “High Dimension, Low Sample\nSize” (HDLSS) nature. The high feature-to-instance ratio and inherent class\n2 https://attack.mitre.org/\n3 https://www.commoncriteriaportal.org/cc/\n4 https://owasp.org/\n5 https://owasp.org/www-project-application-security-verification-standard/', 'CONTEXT: This chunk provides detailed definitions of OWASP ASVS security requirement classes (V5–V14), which are critical for categorizing and addressing specific security concerns in software applications, as discussed in the broader context of automating security requirements classification using AI and the ASRD dataset.\n\nCONTENT: 14 Yusuf G¨ ur et al.\nTable 3 – continued from previous page\nClass Id Class Name Definition\nV5 Malicious Input Handling This class focuses on requirements\nfor validating and sanitizing all input\ndata to prevent injection attacks, such\nas SQL injection, Cross-Site Scripting\n(XSS), and others.\nV6 Stored Cryptography This class addresses the secure stor-\nage of cryptographic keys and sensi-\ntive data at rest, ensuring they are pro-\ntected from unauthorized disclosure or\nmodification.\nV7 Error Handling and Logging This class ensures that applications\nhandle errors gracefully without leak-\ning sensitive information and that\nsecurity-relevant events are logged for\nmonitoring and analysis.\nV8 Data Protection This class covers the requirements for\nprotecting sensitive data during tran-\nsit and in storage, focusing on confi-\ndentiality, integrity, and classification.\nV9 Communications Security This class focuses on securing commu-\nnication channels between system com-\nponents, such as between the client and\nserver, to prevent eavesdropping, tam-\npering, or spoofing.\nV10 Malicious Code This class deals with ensuring the ap-\nplication code is free from malicious\ncode, backdoors, or other unintended\nsecurity vulnerabilities introduced in-\ntentionally or unintentionally.\nV11 Business Logic This class addresses security con-\ncerns within the application’s business\nlogic, preventing attackers from abus-\ning workflows or functionalities for un-\nintended purposes.\nV12 File and Resources This class covers the secure handling of\nfiles and other resources, including up-\nload, download, and management, to\nprevent path traversal and other re-\nlated attacks.\nV13 API and Web Service This class provides security require-\nments specifically for APIs and web\nservices, covering aspects like authen-\ntication, authorization, and protection\nagainst common API attacks.\nV14 Configuration This class focuses on securing the con-\nfiguration of all application compo-\nnents, including the application server,\nplatform, and third-party libraries, to\nprevent security misconfigurations.', 'CONTEXT: This chunk discusses the challenges of identifying implicit security requirements in software requirements engineering (SRE), emphasizing the limitations of existing datasets and the need for AI-driven NLP methods, while highlighting the role of the OWASP ASVS framework in addressing these gaps through standardized security practices.\n\nCONTENT: Implicit Security Requirements Classification 3\n“The system will allow the user to print documents,” carries numerous implicit\nsecurity needs, including verifying user authorization, maintaining a valid ses-\nsion, and recording the action for accountability. These concerns correspond\nto common security control areas, such as access control, session management,\nand logging. This complexity requires substantial guidance. Manually iden-\ntifying and validating this network of implicit security dependencies across\nthousands of requirements is error prone, inconsistent, and not scalable (Ye\net al., 2025).\nGiven the limitations of manual SRA, automation through Artificial In-\ntelligence (AI) based Natural Language Processing (NLP) methods, offers a\npromising path forward. Although AI based approaches for RE have received\ngrowing attention (Abbasi et al., 2025; Zadenoori et al., 2025), recent evidence\nshows a gap between experimental advances and validated industrial solutions.\nFor example, an analysis of 74 primary studies found that most AI based tools\nare evaluated in controlled settings, with limited industrial adoption and weak\nintegration into real workflows (Bolanos et al., 2024). Similarly, another study\nreports a clear mismatch between expectations and practical outcomes in SRE\nin real world use (Karhu et al., 2025).\nThe main problem is the lack of suitable data, not the availability of ef-\nfective modeling approaches. The development and validation of data driven\napproaches is constrained by the scarcity and limited quality of domain spe-\ncific datasets (Wang et al., 2024; Zadenoori et al., 2025). This concern ex-\ntends beyond SRE, as leading NLP venues highlight dataset limitations that\nmake reliable evaluation difficult (Muresan et al., 2022; Goldberg et al., 2022;\nChristodoulopoulos et al., 2025).\nThis challenge is especially evident in SRE. Identifying implicit security\nrequirements relies on large collections of functional requirements annotated\nby security experts to reflect underlying security concerns. Current datasets do\nnot meet this need. For instance, PROMISE exp (Lima et al., 2019) includes\nonly a single, high-level security category; DOSSPRE (Kadebu et al., 2023)\nis based on student projects and lacks industry realism; and the Healthcare\ndataset (Riaz et al., 2014) is limited to a narrow domain and uses coarse-\ngrained labels. As a result, existing resources offer limited support for devel-\noping and evaluating methods aimed at uncovering implicit security require-\nments.\nThe OWASP Application Security Verification Standard (ASVS)1 offers a\nstandardized, systematic, and verifiable framework for defining and evaluating\napplication security controls. ASVS emphasizes the principle of “security by\ndesign” by facilitating the integration of security considerations early in the\nsoftware development lifecycle. Its comprehensive set of requirements can be\ndirectly mapped to verifiable test cases and secure coding practices, ensuring\ntraceability throughout the development process. This approach enables the\nearly identification and remediation of vulnerabilities, which is both more effi-\n1 https://owasp.org/www-project-application-security-verification-standard/', 'CONTEXT: This chunk focuses on the introduction of the **Agency Security Requirements Dataset (ASRD)**, detailing its real-world data sources, expert annotation process, and alignment with OWASP ASVS categories, as well as outlining the research questions and comparative evaluation of fine-tuned transformer models versus prompt-based approaches for security requirements classification.\n\nCONTENT: 4 Yusuf G¨ ur et al.\ncient and cost-effective compared to addressing security issues at later stages\nof development ((Khan et al., 2024).\nThis paper proposes a machine learning-based system to automatically an-\nalyze SRS documents and classify security requirements according to OWASP\nASVS. Its main contribution is the Agency Security Requirements Dataset\n(ASRD), a publicly available corpus created to support research in automated\nSRA. The ASRD comprises:\n–Real-World Data: 2,652 Software Requirements Specification (SRS) sen-\ntences extracted from six diverse, real-world industry projects,\n–Expert Annotation: Meticulously annotated by three cybersecurity experts,\neach with over 15 years of industry experience,\n–Rigorous Methodology: Developed using the iterative MATTER cycle an-\nnotation framework (Pustejovsky and Stubbs, 2012),\n–High Granularity and Multi-label Structure: Mapped to 11 distinct, action-\nable security categories from the industry-standard OWASP Application\nSecurity Verification Standard (ASVS,V2–V13), allowing each require-\nment to be associated with multiple categories.\nThe ASRD is intended as a shared research resource and benchmark. Using\nthis dataset, the study conducts an empirical analysis of automated classifica-\ntion approaches and addresses the following research questions:\n1. To what extent can fine-tuned transformer models accurately perform\nmulti-label classification of implicit security requirements into OWASP\nASVS categories using the ASRD?\n2. How does the performance of prompt-based approaches (zero-shot and few-\nshot) using modern LLMs compare to fine-tuned BERT-based models and\nnaive baselines for this task?\nThe results show that few-shot prompting with a modern language model\n(Gemini 2.0) achieves a macro-average F1 score of 0.941, closely matching the\nbest fine-tuned BERT-based model (0.942). This demonstrates that example-\nguided inference can reach performance comparable to supervised fine-tuning\nwhile requiring substantially less annotated data and model retraining. The\nevaluation compares fine-tuned transformer models (e.g., SecureBERT) with\nprompt-based methods in zero-shot and few-shot settings across multiple con-\ntemporary models, demonstrating that prompt-based approaches provide a\npractical and resource-efficient alternative for identifying implicit security re-\nquirements in industrial SRS documents.\nThe remainder of this paper is organized as follows. Section 2 reviews re-\nlated work on NLP-based requirements classification, security frameworks, and\nexisting security datasets. Section 3 describes the curation and expert anno-\ntation of the ASRD and summarizes its key characteristics. Section 4 outlines\nthe experimental setup and classification methods, including fine-tuned BERT\nmodels and prompt-based approaches. Section 5 reports the experimental re-\nsults. Section 6 discusses the findings and their implications, with a com-\nparative analysis of fine-tuning and prompting strategies. Section 7 examines', 'CONTEXT: **Overview of ASVS 4.0.3 Adoption and Security Classes**: This chunk discusses the widespread adoption of OWASP ASVS 4.0.3 as an industry-standard framework for application security verification, its use in various sectors, and the specific security classes included in the standard, highlighting the focus of the study on 11 of these classes.\n\nCONTENT: Implicit Security Requirements Classification 13\n(TRM) Guidelines. In the healthcare domain, Schmeelk and Tao (Schmeelk\nand Tao, 2022) conducted a case study on mobile health applications.\nAs of 2024–2025, commercial security platforms and verification tools con-\ntinue to offer native support for ASVS 4.0.3 compliance templates and map-\npings (Reqview, 2016; JIT.io, 2024), with requirement managers, compliance\ntracking systems, and automated security testing platforms (SAST/DAST) ex-\nplicitly designed around the 4.0.3 control structure. Multiple government and\nregulatory bodies, including the Moroccan government’s Directorate General\nfor Information Systems Security (DGSSI), have formally adopted ASVS 4.0.3\nas the basis for their national application security verification frameworks as\nof October 2024 (DGSSI, 2024).\nAt the time this study was designed and conducted (2023–2025), ASVS\n4.0.3 was the latest stable, officially released version of the standard. Version\n4.0.3, released in October 2021, had achieved widespread adoption and had\nbeen serving as the industry-standard reference for application security verifi-\ncation across finance, healthcare, technology, and government sectors for mul-\ntiple years. The ASVS 5.0 major revision was only released on 30 May 2025,\nafter the empirical work for this research had been substantially completed.\nTherefore, this research’s use of ASVS 4.0.3 represents both a temporally ap-\npropriate choice at the time of study design and a durable contribution to the\nliterature that will remain relevant and comparable with prior ASVS-based\nwork for years to come.\nThe standard includes 14 main security classes given in Table 3. For this\nstudy, only 11 classes (V2–V10, V12-V13) were used. V1, V11, and V14 were\nexcluded as they are not inferable from functional or non-functional require-\nments. Each requirement can be mapped to more than one classes.\nTable 3: OWASP ASVS 4.0.3 Classes\nClass Id Class Name Definition\nV1 Architecture, Design and\nThreat Modeling\nThis class focuses on the security of the\napplication’s architecture, component\ndesign, and the process of identifying\nand mitigating threats throughout the\ndevelopment lifecycle.\nV2 Authentication This class deals with verifying the\nidentity of users, services, or applica-\ntions, ensuring that only authorized\nentities can access specific functionali-\nties or data.\nV3 Session Management This class covers the secure manage-\nment of user sessions, from creation\nto termination, including protection of\nsession identifiers and prevention of\nsession-related attacks.\nV4 Access Control This class ensures that users can only\naccess the data and functions for which\nthey are explicitly authorized, enforc-\ning the principle of least privilege.', 'CONTEXT: This chunk provides detailed descriptions of OWASP ASVS categories (V2–V13) and their associated security requirements, along with guidelines for classifying software requirements based on specific operations (e.g., CRUD, data storage, file handling) and sensitive data handling, aligned with the ASVS 4.0.3 framework. It also outlines the expected output format for classified requirements.\n\nCONTENT: 3.0). \nV4, Erişim Kontrolleri (Access Controls) - Covers requirements related to authorization, role management, \nand preventing unauthorized access to resources (e.g., ASVS 4.0). \nV5, ""Doğrulama, Temizleme ve Şifreleme"" (Verification, Cleaning, and Encryption) - Covers requirements \nrelated to input validation, output encoding, data sanitization, and cryptographic protection of sensitive \ndata (e.g., ASVS 5.0). \nV6, Depolanmış Kriptografi (Stored Cryptography) - Covers requirements for protecting data at rest using \ncryptography, including key management and secure storage of encryption keys (e.g., ASVS 6.0). \nV7, Hata Ayıklama ve Kayıt (Debugging and Logging) - Covers requirements related to secure logging \npractices, error handling, and preventing information leakage through debug information (e.g., ASVS 7.0). \nV8, Veri Koruma (Data Protection) - Covers requirements related to data at rest and in transit protection, \nincluding encryption, backups, and data retention policies (e.g., ASVS 8.0). \nV9, İletişim (Communication) - Covers requirements related to secure communication protocols, protecting \nagainst network attacks, and ensuring data integrity during transmission (e.g., ASVS 9.0). \nV10, Zararlı Kod (Malicious Code) - Covers requirements related to preventing and mitigating the risk of \nmalicious code injection, such as cross-site scripting (XSS) and SQL injection (e.g., ASVS 10.0). \nV12, Dosya ve Kaynakları (Files and Resources) - Covers requirements related to secure file handling, \naccess control to files and resources, and preventing directory traversal attacks (e.g., ASVS 12.0). \nV13, API ve Web Servisleri (API and Web Services) - Covers requirements specific to securing web \nservices, APIs, and microservices, including authentication, authorization, input validation, and error \nhandling (e.g., ASVS 13.0). \n \n********* \n \nExtra Information for Choosing Categories (Aligned with OWASP ASVS 4.0.3-tr): \n \nAccording to given descriptions for kind of requirements, we can decide categories as in PSV: \n \nIf Requirement describes a CRUD operation and if it is Create operation|1|1|1|1|0|1|1|1|1|0|1| \nIf Requirement describes a CRUD operation and if it is Read operation|1|1|1|1|0|1|1|1|1|0|1| \nIf Requirement describes a CRUD operation and if it is Update operation|1|1|1|1|0|1|1|1|1|0|1| \nIf Requirement describes a CRUD operation and if it is Delete operation|1|1|1|0|0|1|1|1|0|0|0| \nIf Requirement describes User Types: usage of various user types as role management|1|1|1|0|0|0|0|0|0|0|0| \nIf Requirement describes Store: actions related to storage and backup of the assets at rest, e.g., backing up \nlog files|0|0|0|1|0|1|1|0|0|1|0| \nIf Requirement describes Transfer: actions related to transfer or sharing of the assets, e.g., sending data \nfrom one service to another|0|0|0|0|0|1|1|1|0|0|1| \nIf Requirement describes Upload and Download Files etc. operation|1|1|1|1|0|1|0|1|1|1|1| \nIf Requirement describes operation on sensitive data like personal, financial, health etc|1|0|1|1|1|0|1|0|0|0|0| \n \n \n********* \nOutput (PSV- The requirements that are classified): \nWe need each requirement response in given format below within new line separator: \n<Requirement Number>|<Requirement \nDescription>|<V2>|<V3>|<V4>|<V5>|<V6>|<V7>|<V8>|<V9>|<V10>|<V12>|<V13>|<Explanation> format. \nand will contain: \n   - Requirement Number (integer) \n   - Requirement Description (string)', ""CONTEXT: **Security Requirement Examples and Analysis**: This chunk provides specific examples of software system requirements mapped to OWASP ASVS categories, along with corresponding security analyses and recommendations to ensure compliance with best practices in secure software development.\n\nCONTENT: 19|Sistem, uygulama yazılımının, Spring framework ile MVC (Model-View-Controller) mimari tasarım \nşablonuna uygun geliştirilebilmesini sağlayacaktır.|0|0|0|0|0|0|0|0|0|0|0|  This is a technical requirement that \ndoesn't directly relate to ASVS categories. \n \n20|Sistem, kullanıcının veri girişi sırasında, otomatik olarak maskeleme desteği \nsağlayacaktır.|1|1|1|1|0|1|1|0|0|0|0| Identity Verification (V2), Session Management (V3), Access Controls \n(V4), Verification, Cleaning, and Encryption (V5), Debugging and Logging (V7), Data Protection (V8), \nCommunication (V9): Standard practices for data input and protection. \nAnalysis & Recommendations:  Ensure proper masking techniques are used to protect sensitive data.  \nConsider using different masking techniques for different data types. \n \n21|Sistem, tarayıcı üzerinde gösterilen filigranı, kullanıcı adı ve IP bilgisi gibi alanların şifrelenmesi ile \noluşturacaktır.|1|0|0|1|0|1|0|0|0|0|0| Identity Verification (V2): The watermark is linked to the user's \nidentity. \nVerification, Cleaning, and Encryption (V5):  Encrypting the watermark data ensures its integrity and \nconfidentiality. \nData Protection (V8):  Protecting the watermark information is important. \nAnalysis & Recommendations:  Use strong encryption algorithms for the watermark data.  Ensure the \nwatermark is securely generated and displayed to prevent tampering. \n \n22|Sistem, yöneticinin, görevli personel için kullanıcı hesabı oluşturabilmesini \nsağlayacaktır.|1|1|1|0|0|1|0|1|0|0|1| Identity Verification (V2), Session Management (V3), Access Controls \n(V4), Debugging and Logging (V7), Data Protection (V8), Communication (V9): Standard practices for data \nretrieval as well as creation or modification. \nFiles and Resources (V12):  Administering user accounts involves managing files and resources. \nAPI and Web Services (V13): Account creation may involve API calls. \nAnalysis & Recommendations:  Implement strong password policies and account lockout mechanisms.  \nEnsure proper segregation of duties for managing accounts. \n \n23|Sistem, yöneticinin, kullanıcının aktif dizinde üye olabileceği güvenlik gruplarını seçebilmesini \nsağlayacaktır.|1|1|1|0|0|1|0|1|0|0|0| Identity Verification (V2), Session Management (V3), Access Controls \n(V4), Debugging and Logging (V7), Data Protection (V8): Standard security practices apply. \nAnalysis & Recommendations:  Regularly review and update security group memberships to ensure users \nhave appropriate access.  Use a role-based access control model to manage permissions effectively. \n \n24|Sistem, güçlü şifrelerin kullanılmasını zorunlu kılacaktır.|0|0|0|0|0|0|0|0|1|0|0| Malicious Code (V10): \nEnforcing strong passwords helps prevent brute-force and dictionary attacks. \nAnalysis & Recommendations:  Define a clear password policy with requirements for length, complexity, \nand regular updates.  Consider using a password manager to help users generate and store strong passwords. \n \n25|Sistem, kullanıcıların şifrelerini yönetibilmesine olanak sağlayacaktır.|1|1|1|1|0|1|1|1|0|0|0| Identity \nVerification (V2), Session Management (V3), Access Controls (V4), Verification, Cleaning, and Encryption \n(V5), Debugging and Logging (V7), Data Protection (V8), Communication (V9): Standard security practices \napply. \nAnalysis & Recommendations:  Implement secure password reset and recovery mechanisms.  Use strong \nencryption for storing and transmitting passwords.  Consider using multi-factor authentication for added \nsecurity. \n \n26|Sistem, kullanıcının 10 dk boyunca işlem yapmaması durumunda oturumunu"", 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to']","The OWASP ASVS framework is preferred over STRIDE for this specific task because OWASP ASVS provides a detailed, verifiable, and developer-oriented taxonomy explicitly intended for requirement-level security analysis. It offers fine-grained security requirement classification, which is essential for tasks like automated classification of security requirements. In contrast, STRIDE operates at a high level of abstraction (e.g., ""Spoofing,"" ""Tampering"") and is primarily designed for threat modeling, lacking the granularity needed for detailed requirement classification. OWASP ASVS's organization into distinct, actionable security categories supports direct mapping to functional and non-functional security controls, making it more suitable for this purpose.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","STRIDE operates at a high level of abstraction useful for threat modeling but lacks the granularity needed for requirement classification, whereas ASVS provides a detailed, developer-centric taxonomy[cite: 129, 132].",,,
What loss function was used for training the BERT-based models?,"['CONTEXT: **Evaluation of BERT-Based Models for Security Requirements Classification**: This chunk details the architecture, training data, and rationale behind the BERT-based models used in the study, including SecureBERT and multilingual variants, and explains the fine-tuning process and optimization techniques employed to adapt these models for multi-label security classification tasks.\n\nCONTENT: Implicit Security Requirements Classification 21\nTable 5: Details and Rationale of the BERT-based Models Used in the Study\nModel Name\n(Architecture /\nParameters)\nDescription, Training Data,\nand Source\nRationale in Study\nBERT Base (En-\nglish)\n(12 layers, 768\nhidden, 12 heads,\n110M params.)\nStandard BERT-base archi-\ntecture. Pre-trained on the\nBookCorpus and English\nWikipedia.8(Devlin et al., 2019)\nTo serve as a strong performance\nbaseline.\nSecureBERT\n(12 layers, 768\nhidden, 12 heads,\n125M params.)\nBased on the RoBERTa architec-\nture. Pre-trained on a 12GB cor-\npus of cybersecurity texts (NVD,\nCVE, CAPEC). 9(Aghaei et al.,\n2020)\nTo test the hypothesis that\ndomain-specific vocabulary and\ncontext improve classification ac-\ncuracy.\nBERT Base\nMultilingual\n(12 layers, 768\nhidden, 12 heads,\n179M params.)\nStandard BERT-base architec-\nture. Pre-trained on the top\n104 languages with the largest\nWikipedia datasets. 10(Devlin\net al., 2019)\nTo investigate whether training\non a broader set of languages\nprovides any generalization ben-\nefit.\nBERT Base\nTurkish\n(12 layers, 768\nhidden, 12 heads,\n110M params.)\nStandard BERT-base architec-\nture. Pre-trained on a 35GB,\n4.4B token Turkish corpus from\nmultiple sources. 11(Schweter,\n2020)\nTo explore the performance of\na model pre-trained on a lan-\nguage with a different morpho-\nlogical structure than English.\nthe final hidden state of the [CLS] token to a vector corresponding to our\n11 security classes. A sigmoid activation function was applied to this layer to\nproduce independent probabilities, facilitating multi-label classification. The\nfine-tuning process was performed from end-to-end; all weights were unfrozen\nand updated to adapt the models to the specific nuances of the security re-\nquirements text.\nThe models were trained using the PyTorch Lightning framework to ensure\nreproducibility. We employed the AdamW optimizer (Loshchilov and Hutter,\n2019), an extension of the Adam optimizer with improved weight decay, uti-\nlizing a linear learning rate schedule with a warmup phase covering the first\n20% of training steps. This strategy stabilizes training in the initial epochs and\nimproves convergence. Given the multi-label nature of the task, Binary Cross-\nEntropy (BCE) Loss was used as the primary objective function. Because the\nsecurity classes are unevenly distributed, the label assignment threshold (Deci-\nsion Threshold) was tuned rather than fixed at 0.5 to better balance precision\nand recall across categories.', 'CONTEXT: **Optimization and Prompting Strategies for Security Classification Models**: This chunk discusses the optimization of BERT variants through systematic hyperparameter tuning and explores the use of large language models (LLMs) for security requirement classification, focusing on zero-shot and few-shot prompting strategies to enhance task-specific performance without modifying the base model.\n\nCONTENT: 22 Yusuf G¨ ur et al.\nWe performed a systematic grid search using the Weights & Biases 12\nplatform to identify the optimal configuration for each BERT variant using\nthe validation dataset. The search space included the following parameters:\n–Maximum Sequence Length:[128, 256]tokens\n–Batch Size:[4, 8, 16]\n–Number of Epochs:[16, 24, 32]\n–Learning Rate:[1e-5, 2e-5, 3e-5]\n–Decision Threshold:[0.3, 0.4, 0.5]\nTo prevent overfitting, we monitored validation loss and implemented early\nstopping with a patience of 2–4 epochs. The checkpoint achieving the lowest\nvalidation loss for each model was selected for the final evaluation on the test\nset.\n4.3 Classification using LLM Models\nLLMs are transformer-based models trained on massive corpora for general-\npurpose natural language understanding and generation. This study adopted\nthe “pre-train, prompt, and predict” paradigm, which replaces traditional\n“pre-train, fine-tune” approaches (Liu et al., 2023a). Rather than adjusting\nthe model’s objective or architecture, prompt engineering is used to steer the\nmodel toward task-specific outputs through carefully designed textual inputs.\nPrompt engineering involves designing prompts that elicit accurate re-\nsponses for specific tasks. In zero-shot prompting, an LLM is directly used\nwithout any task-specific training. Few-shot prompting introduces a small\nnumber of labeled examples in the prompt, which allows the model to learn\nthe task pattern. This is particularly beneficial when labeled training data is\nlimited.\nFour main prompting strategies were proposed by (Liu et al., 2023a):\n–Tuning-free prompting: Requires no model changes, suitable for zero-shot\nsettings, but often demands complex prompt design.\n–Fixed-LLM prompt tuning: Involves learning soft prompts while keep-\ning the model fixed; effective for few-shot tasks but typically lacks inter-\npretability.\n–Fixed-prompt LLM tuning: Fine-tunes the model on a fixed prompt; im-\nproves performance in few-shot settings.\n–Prompt + LLM tuning: Jointly tunes both model and prompts; highly\nexpressive but prone to overfitting on small datasets.\nIn this study, we evaluated the first two of these strategies, as they do\nnot require modification of the base LLM’s weights. For our zero-shot experi-\nments, we implemented tuning-free prompting, relying on carefully engineered\nprompts to guide the models. For our few-shot analysis, our approach aligns\n12 https://wandb.ai/site', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: This chunk provides a detailed comparison of the performance metrics (precision, recall, F1 scores, and support) for various BERT-based models, including SecureBERT, in classifying security requirements across OWASP ASVS categories, highlighting their effectiveness and challenges in handling underrepresented classes.\n\nCONTENT: bert-base-multilingual-uncased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.984 0.982 0.982 0.975 0.744 0.985 0.980 0.984 0.983 0.864 0.991RECALL 0.997 0.995 0.995 0.984 0.842 0.995 1.000 1.000 0.983 0.704 0.994F1 0.990 0.988 0.988 0.979 0.790 0.990 0.990 0.992 0.983 0.776 0.992SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nbert-base-turkish-cased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.974 0.974 0.980 0.975 0.756 0.985 0.982 0.974 0.980 0.800 0.972RECALL 0.997 0.997 1.000 0.994 0.816 0.997 1.000 1.000 0.977 0.593 0.994F1 0.985 0.985 0.990 0.984 0.785 0.991 0.991 0.987 0.978 0.681 0.983SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nbert-base-uncased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.982 0.979 0.982 0.981 0.781 0.985 0.980 0.974 0.977 0.813 0.978RECALL 0.995 0.995 0.995 0.975 0.658 0.992 0.997 0.997 0.987 0.481 0.987F1 0.988 0.987 0.988 0.978 0.714 0.988 0.988 0.985 0.982 0.604 0.982SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nSecureBERT\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.974 0.977 0.980 0.972 0.707 0.985 0.977 0.974 0.964 0.700 0.969RECALL 0.995 0.995 0.997 0.984 0.763 0.997 1.000 0.997 0.990 0.519 0.997F1 0.984 0.986 0.988 0.978 0.734 0.991 0.988 0.985 0.977 0.596 0.983SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nNaive Baseline\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: **Performance Metrics for Security Requirement Classification Models**: This chunk presents the precision, recall, F1 scores, and support metrics for various OWASP ASVS categories, highlighting the performance of BERT models and a naive baseline in classifying implicit security requirements, with a focus on challenges like class imbalance and underrepresented categories.\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.960 0.950 0.960 0.790 0.000 0.980 0.970 0.960 0.750 0.000 0.800RECALL 1.000 1.000 1.000 1.000 0.000 1.000 1.000 1.000 1.000 0.000 1.000F1 0.980 0.980 0.980 0.880 0.000 0.990 0.980 0.980 0.860 0.000 0.890SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nTest Results of the BERT models and Naïve Baseline used in the study\nImplicit Security Requirements Classification 55\nC Test Results of the Bert Models', 'CONTEXT: This chunk provides background on NLP-based techniques for software requirements classification, highlighting the evolution from traditional supervised learning methods to transformer-based models like BERT and SecureBERT, and emphasizing the challenges of classifying implicit security requirements due to ambiguity and the lack of high-quality, domain-specific datasets.\n\nCONTENT: Implicit Security Requirements Classification 5\nthreats to validity, and Section 8 concludes with a summary of contributions\nand directions for future work.\n2 Background\nThis section reviews prior work on NLP-based techniques for requirements\nclassification, followed by an overview of relevant security frameworks. It con-\ncludes with a discussion of existing datasets used in security requirements\nresearch.\n2.1 Related Work on Requirements Classification using NLP Techniques\nSoftware requirements (SR) classification supports effective project manage-\nment by enabling prioritization and risk assessment (Batool et al., 2025). The\ntask typically involves distinguishing functional requirements (FRs) from non-\nfunctional requirements (NFRs) and further categorizing NFRs into classes\nsuch as security, usability, and performance. Security requirements may ap-\npear as explicit system behaviors or as quality attributes addressing confiden-\ntiality, integrity, and availability—the security triad—which are often abstract\nand difficult to specify precisely in practice (Anwar Mohammad et al., 2019).\nThis inherent ambiguity complicates the development of clear guidelines for\nseparating security-related requirements from non-security ones.\nEarly studies applied supervised learning techniques, including Bayesian\nclassifiers(Knauss et al., 2011), decision trees (Jindal et al., 2016), and Sup-\nport Vector Machines (SVMs) (Dalpiaz et al., 2019), but these approaches\ndepended heavily on manual feature engineering and rigid linguistic patterns.\nTo address these limitations, later work adopted neural models such as convo-\nlutional neural networks (CNN) combined with Word2Vec embeddings (Dekht-\nyar and Fong, 2017). The adoption of transformer-based models such as BERT\nenabled improved classification accuracy through transfer learning and fine-\ntuning, eliminating the need for handcrafted features (Devlin et al., 2019; Sub-\nahi, 2023). More recent work explores domain-adapted transformer models,\nsuch as NoRBERT (Hey et al., 2020) and SecureBERT (Aghaei et al., 2022),\nto better capture domain-specific semantics and mitigate overfitting. These\nmodels have shown improved capability in identifying implicit non-functional\nrequirements, a particularly challenging task in security-critical settings (Nec-\nula et al., 2024). However, further progress in SRE is limited by the availability\nof large, high-quality, and domain-specific annotated datasets.\nThe subjective nature of defining security requirements further complicates\nreliable classification (Riaz and Williams, 2012). Security Requirement Elic-\nitation highly depends on domain-relevant expertise which includes various\ncostly manual steps such as creating security requirement templates, deter-\nmining security classification levels according to natural language artifacts,\nand mapping the class labels to related requirement templates by identifying\nentities.', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.']","The loss function used for training the BERT-based models in the study was **Binary Cross-Entropy (BCE) Loss**. This choice was made to accommodate the multi-label nature of the classification task, where independent probabilities were produced for each of the 11 security classes using a sigmoid activation function. Additionally, the label assignment threshold (Decision Threshold) was tuned rather than fixed at 0.5 to better balance precision and recall across categories.

**Source:** temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf",Binary Cross-Entropy (BCE) Loss was used as the primary objective function due to the multi-label nature of the task[cite: 382].,,,
What strategy was used to mitigate overfitting during BERT training?,"['CONTEXT: **Evaluation of BERT-Based Models for Security Requirements Classification**: This chunk details the architecture, training data, and rationale behind the BERT-based models used in the study, including SecureBERT and multilingual variants, and explains the fine-tuning process and optimization techniques employed to adapt these models for multi-label security classification tasks.\n\nCONTENT: Implicit Security Requirements Classification 21\nTable 5: Details and Rationale of the BERT-based Models Used in the Study\nModel Name\n(Architecture /\nParameters)\nDescription, Training Data,\nand Source\nRationale in Study\nBERT Base (En-\nglish)\n(12 layers, 768\nhidden, 12 heads,\n110M params.)\nStandard BERT-base archi-\ntecture. Pre-trained on the\nBookCorpus and English\nWikipedia.8(Devlin et al., 2019)\nTo serve as a strong performance\nbaseline.\nSecureBERT\n(12 layers, 768\nhidden, 12 heads,\n125M params.)\nBased on the RoBERTa architec-\nture. Pre-trained on a 12GB cor-\npus of cybersecurity texts (NVD,\nCVE, CAPEC). 9(Aghaei et al.,\n2020)\nTo test the hypothesis that\ndomain-specific vocabulary and\ncontext improve classification ac-\ncuracy.\nBERT Base\nMultilingual\n(12 layers, 768\nhidden, 12 heads,\n179M params.)\nStandard BERT-base architec-\nture. Pre-trained on the top\n104 languages with the largest\nWikipedia datasets. 10(Devlin\net al., 2019)\nTo investigate whether training\non a broader set of languages\nprovides any generalization ben-\nefit.\nBERT Base\nTurkish\n(12 layers, 768\nhidden, 12 heads,\n110M params.)\nStandard BERT-base architec-\nture. Pre-trained on a 35GB,\n4.4B token Turkish corpus from\nmultiple sources. 11(Schweter,\n2020)\nTo explore the performance of\na model pre-trained on a lan-\nguage with a different morpho-\nlogical structure than English.\nthe final hidden state of the [CLS] token to a vector corresponding to our\n11 security classes. A sigmoid activation function was applied to this layer to\nproduce independent probabilities, facilitating multi-label classification. The\nfine-tuning process was performed from end-to-end; all weights were unfrozen\nand updated to adapt the models to the specific nuances of the security re-\nquirements text.\nThe models were trained using the PyTorch Lightning framework to ensure\nreproducibility. We employed the AdamW optimizer (Loshchilov and Hutter,\n2019), an extension of the Adam optimizer with improved weight decay, uti-\nlizing a linear learning rate schedule with a warmup phase covering the first\n20% of training steps. This strategy stabilizes training in the initial epochs and\nimproves convergence. Given the multi-label nature of the task, Binary Cross-\nEntropy (BCE) Loss was used as the primary objective function. Because the\nsecurity classes are unevenly distributed, the label assignment threshold (Deci-\nsion Threshold) was tuned rather than fixed at 0.5 to better balance precision\nand recall across categories.', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: **Optimization and Prompting Strategies for Security Classification Models**: This chunk discusses the optimization of BERT variants through systematic hyperparameter tuning and explores the use of large language models (LLMs) for security requirement classification, focusing on zero-shot and few-shot prompting strategies to enhance task-specific performance without modifying the base model.\n\nCONTENT: 22 Yusuf G¨ ur et al.\nWe performed a systematic grid search using the Weights & Biases 12\nplatform to identify the optimal configuration for each BERT variant using\nthe validation dataset. The search space included the following parameters:\n–Maximum Sequence Length:[128, 256]tokens\n–Batch Size:[4, 8, 16]\n–Number of Epochs:[16, 24, 32]\n–Learning Rate:[1e-5, 2e-5, 3e-5]\n–Decision Threshold:[0.3, 0.4, 0.5]\nTo prevent overfitting, we monitored validation loss and implemented early\nstopping with a patience of 2–4 epochs. The checkpoint achieving the lowest\nvalidation loss for each model was selected for the final evaluation on the test\nset.\n4.3 Classification using LLM Models\nLLMs are transformer-based models trained on massive corpora for general-\npurpose natural language understanding and generation. This study adopted\nthe “pre-train, prompt, and predict” paradigm, which replaces traditional\n“pre-train, fine-tune” approaches (Liu et al., 2023a). Rather than adjusting\nthe model’s objective or architecture, prompt engineering is used to steer the\nmodel toward task-specific outputs through carefully designed textual inputs.\nPrompt engineering involves designing prompts that elicit accurate re-\nsponses for specific tasks. In zero-shot prompting, an LLM is directly used\nwithout any task-specific training. Few-shot prompting introduces a small\nnumber of labeled examples in the prompt, which allows the model to learn\nthe task pattern. This is particularly beneficial when labeled training data is\nlimited.\nFour main prompting strategies were proposed by (Liu et al., 2023a):\n–Tuning-free prompting: Requires no model changes, suitable for zero-shot\nsettings, but often demands complex prompt design.\n–Fixed-LLM prompt tuning: Involves learning soft prompts while keep-\ning the model fixed; effective for few-shot tasks but typically lacks inter-\npretability.\n–Fixed-prompt LLM tuning: Fine-tunes the model on a fixed prompt; im-\nproves performance in few-shot settings.\n–Prompt + LLM tuning: Jointly tunes both model and prompts; highly\nexpressive but prone to overfitting on small datasets.\nIn this study, we evaluated the first two of these strategies, as they do\nnot require modification of the base LLM’s weights. For our zero-shot experi-\nments, we implemented tuning-free prompting, relying on carefully engineered\nprompts to guide the models. For our few-shot analysis, our approach aligns\n12 https://wandb.ai/site', 'CONTEXT: **Comparison of Fine-Tuned Models and LLMs for Security Requirements Classification**: This chunk discusses the performance comparison between fine-tuned transformer models (e.g., BERT) and few-shot prompting with LLMs (e.g., Gemini 2.0) for classifying implicit security requirements in SRS documents, emphasizing the practicality of LLMs as a resource-efficient alternative while highlighting challenges in Security Requirements Engineering (SRE).\n\nCONTENT: 2 Yusuf G¨ ur et al.\ntional fine-tuned transformer models and contemporary Large Language Mod-\nels (LLMs) employing few-shot and zero-shot prompt engineering strategies.\nThe results show that a few-shot prompting with Gemini 2.0 achieves a macro-\naverage F1 score of 0.941, directly comparable to the fine-tuned BERT model’s\n0.942. This study culminates in two primary findings: first, the validation and\npublication of the ASRD, a high-granularity, multi-label dataset for implicit\nsecurity requirements based on OWASP ASVS V2-V13; and second, the di-\nrect comparison demonstrating that few-shot Large Language Models (LLMs)\nachieve competitive multi-label classification performance (Macro-F1 0.941)\nnearly equal to resource-intensive fine-tuned transformer models (Macro-F1\n0.942). This confirms that LLMs represent a highly practical and resource-\nsaving strategy for automating the identification of embedded (implicit) secu-\nrity requirements for software security in industrial SRS documents\nKeywordsCybersecurity requirement elicitation·OWASP based security\nrequirement classification·OWASP ASVS-based Requirement Labeling·\nLLM based classification\n1 Introduction\nRequirements Engineering (RE) concerns the identification, documentation,\nand management of software requirements (Sommerville and Sawyer, 1997).\nThe increasing interconnectivity of information systems forces organizations\nto provide secure services in cyberspace. Integrating security during initial\nrequirements analysis is essential to proactively mitigate risks, reduce vulner-\nabilities, and reduce the high costs associated with downstream remediation\n(Villamizar et al., 2018). This proactive approach is central to the ”Shift-\nLeft” security paradigm, which advocates for the identification and mitigation\nof vulnerabilities as early as possible in the Software Development Life Cycle\n(SDLC).\nAlthough Security Requirements Engineering (SRE) has matured as a dis-\ncipline, its effective application in practice remains challenging. The issue is\nnot the absence of security considerations, but the difficulty of ensuring that\nsecurity requirements are properly validated and verified. An empirical investi-\ngation that combines a systematic literature review with a survey of 58 indus-\ntry professionals highlights this gap (Alam et al., 2025). While practitioners\nreported a moderate understanding of SRE practices, Security Requirements\nAssurance (SRA) was found to be poorly understood and rarely applied in\nindustrial contexts. The study concludes that validating and ensuring security\nrequirements remains a major and unresolved challenge in practice.\nThis assurance gap persists due to the documented lack of specialized se-\ncurity training for developers in early-phase RE (Andrade et al., 2023). The\ntask relies heavily on scarce specialized expertise and time-intensive manual\nanalysis. The main challenge is that critical security requirements are often not\nexplicitly stated. Instead, they are implicitly embedded within standard func-\ntional descriptions. For example, a seemingly simple functional requirement,', 'CONTEXT: This chunk provides a detailed comparison of the performance metrics (precision, recall, F1 scores, and support) for various BERT-based models, including SecureBERT, in classifying security requirements across OWASP ASVS categories, highlighting their effectiveness and challenges in handling underrepresented classes.\n\nCONTENT: bert-base-multilingual-uncased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.984 0.982 0.982 0.975 0.744 0.985 0.980 0.984 0.983 0.864 0.991RECALL 0.997 0.995 0.995 0.984 0.842 0.995 1.000 1.000 0.983 0.704 0.994F1 0.990 0.988 0.988 0.979 0.790 0.990 0.990 0.992 0.983 0.776 0.992SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nbert-base-turkish-cased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.974 0.974 0.980 0.975 0.756 0.985 0.982 0.974 0.980 0.800 0.972RECALL 0.997 0.997 1.000 0.994 0.816 0.997 1.000 1.000 0.977 0.593 0.994F1 0.985 0.985 0.990 0.984 0.785 0.991 0.991 0.987 0.978 0.681 0.983SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nbert-base-uncased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.982 0.979 0.982 0.981 0.781 0.985 0.980 0.974 0.977 0.813 0.978RECALL 0.995 0.995 0.995 0.975 0.658 0.992 0.997 0.997 0.987 0.481 0.987F1 0.988 0.987 0.988 0.978 0.714 0.988 0.988 0.985 0.982 0.604 0.982SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nSecureBERT\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.974 0.977 0.980 0.972 0.707 0.985 0.977 0.974 0.964 0.700 0.969RECALL 0.995 0.995 0.997 0.984 0.763 0.997 1.000 0.997 0.990 0.519 0.997F1 0.984 0.986 0.988 0.978 0.734 0.991 0.988 0.985 0.977 0.596 0.983SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nNaive Baseline\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements', 'CONTEXT: **Evaluation of Model Challenges and Prompt Engineering Strategies**: This chunk discusses the challenges faced by models, particularly with underrepresented OWASP ASVS categories (e.g., V6 Cryptography, V12 Files/Resources), and outlines the experimental setup for prompt engineering in LLMs, including zero-shot and few-shot configurations, persona-based prompting, and strategies to ensure consistency and adherence to security standards.\n\nCONTENT: 26 Yusuf G¨ ur et al.\nshowed both low Recall (0.658) and low Precision (0.781), indicating it was\nboth missing true cases and incorrectly labeling other requirements as V6.\nModels struggle significantly with underrepresented categories, particularly\nV12 (File and Resources) and V6 (Stored Cryptography). This is evident in\nthe high number of false negatives, where the models fail to identify true\ninstances of these classes. For example, the baseline BERT model incorrectly\nclassified over half of the V12 requirements as negative (14 false negatives vs.\n13 true positives). Conversely, the matrices show that models often misclassify\nrequirements by incorrectly assigning them to other categories. The BERT\nBase model, for example, incorrectly labeled 92 different requirements as V10\n(Malicious Code) and 78 requirements as V5 (Malicious Input Handling).\n5.2 Experimental Setup for LLM Prompt Engineering\nWe adapted prompt engineering strategies from Ronanki (Ronanki et al.,\n2024), originally used for multi-class requirement classification. Two configu-\nrations were evaluated: zero-shot prompting (Appendix A), which relied solely\non task instructions and the input requirement, and few-shot prompting (Ap-\npendix B), which additionally incorporated labeled examples. The few-shot\nsetup used 30 training instances that were chosen to (i) capture multi-label\ncases where a single requirement spans multiple security categories, (ii) cover\nall 11 OWASP ASVS categories, and (iii) reflect requirements from different\nbusiness domains to preserve linguistic variation.\nPersona-based prompting was applied in both configurations by instruct-\ning the model to act as an experienced cybersecurity specialist. This alignment\nhelped reduce output variance by grounding responses in professional domain\nexpertise rather than general conversational patterns. The final prompt was\nobtained after five iterations. These iterations focused on three primary ar-\neas: (1) instruction clarity to prevent the model from defaulting to binary\nsecurity labels; (2) contextual grounding, by iteratively refining the OWASP\nASVS category definitions to ensure the model adhered to provided standards;\n(3) constraint formatting, to stabilize the PSV output structure for machine-\nreadability and ensure the inclusion of mandatory explanation fields. All ex-\nperiments were conducted with fixed parameters (Temperature = 0, Top-p =\n0.95) and repeated three times. The reported results are averaged to reduce\nthe impact of any minor, non-deterministic fluctuations in the models’ token\nselection during individual inferences.\nPrompt-based methods can be sensitive to phrasing, structure, and exam-\nple selection. To manage prompt sensitivity and contextual bias, we adopted a\nunified Persona–Context–Constraint strategy. A single prompt structure was\nused across all models, without model-specific tuning or iterative optimization\naimed at maximizing scores. The few-shot examples were chosen for representa-\ntiveness with respect to the OWASP ASVS taxonomy rather than performance\ngains.', 'CONTEXT: **Evaluation of Experimental and Commercial AI Models for Security Classification**: This chunk details the rationale and descriptions of experimental and commercial AI models, including Gemini and GPT-4o variants, used to benchmark their performance in nuanced security requirement classification, followed by an introduction to the results of fine-tuned BERT models.\n\nCONTENT: 24 Yusuf G¨ ur et al.\nTable 6 – continued from previous page\nModel Name Description Rationale in Study\ngemini-2.0-\nflash-thinking-\nexp-01-21\n(MoE Trans-\nformer;\nReasoning-\nOptimized)\nAn experimental API ver-\nsion of Google’s Gemini\nFlash model. This spe-\ncific version is optimized\nfor “thinking” (Chain-of-\nThought) processes while\nmaintaining the speed\nof the Flash series. 16\n(Google DeepMind, 2025a)\nTo evaluate the impact of built-in reasoning\non classification accuracy using an experi-\nmental commercial model accessed prior to\ngeneral availability.\ngemini-2.0-pro-\nexp-02-05\n(MoE Trans-\nformer; Large\nContext)\nAn experimental version of\nGoogle’s flagship Gemini\nPro model, representing\nthe state-of-the-art for\ncomplex, multimodal rea-\nsoning tasks. 16 (Google\nDeepMind, 2025a)\nTo assess frontier-level Gemini capabilities\nusing an experimental model accessed prior\nto general availability.\ngemini-2.5-\nflash-preview-\n04-17\n(MoE Trans-\nformer; Next-Gen\nArchitecture)\nA preview version of a\nnext-generation Gemini\nFlash model, likely offering\nenhancements in perfor-\nmance, context handling,\nand efficiency over the 2.0\nseries. 16 (Google Deep-\nMind, 2025b)\nTo assess whether preview architectural up-\ndates in an experimental, speed- and cost-\noptimized model improve detection of nu-\nanced security contexts (e.g., Stored Cryp-\ntography) using an experimental model ac-\ncessed prior to general availability.\ngpt-4o\n(Transformer;\nMultimodal)\nOpenAI’s flagship “omni”\nmodel, natively integrating\ntext, audio, and vision\nprocessing for faster and\nmore seamless interaction.\n17 (OpenAI, 2025)\nTo benchmark against the industry standard\nfor high-performance commercial models,\nserving as a control variable for proprietary\nmodel performance.\ngpt-4o-mini\n(Transformer;\nCost-Effective)\nA smaller, faster, and sig-\nnificantly cheaper version\nof GPT-4o, designed to\nmake near-GPT-4-level in-\ntelligence more accessible.\n17 (OpenAI, 2025)\nTo analyze the performance trade-off be-\ntween cost and quality, determining if\nsmaller proprietary models are sufficient for\nlarge-scale industrial requirements analysis.\n5 Results\nThis section presents both quantative and qualitative results.\n5.1 Results and Analysis for BERT Fine-Tuning\nTable 7 reports the overall results for the fine-tuned BERT variants. All mod-\nels achieved high Weighted-F1 scores, which show high performance on well-\n16 https://deepmind.google/technologies/gemini/\n17 https://openai.com/index/gpt-4o-mini-advancing-cost-effective-intelligence/']","The strategy used to mitigate overfitting during BERT training included the following measures:

1. **Early Stopping**: Validation loss was monitored, and early stopping was implemented with a patience of 2–4 epochs. This ensured that training was halted once the model's performance on the validation set stopped improving, preventing overfitting to the training data.

2. **Hyperparameter Tuning**: A systematic grid search was conducted to identify optimal configurations for parameters such as maximum sequence length, batch size, number of epochs, learning rate, and decision threshold. This careful tuning helped balance model complexity and generalization.

3. **Validation Loss Monitoring**: The checkpoint with the lowest validation loss was selected for final evaluation, ensuring that the model generalized well to unseen data.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)",The study monitored validation loss and implemented early stopping with a patience of 2-4 epochs[cite: 391].,,,
How did the study handle the uneven distribution of security classes during BERT training?,"['CONTEXT: **Evaluation of BERT-Based Models for Security Requirements Classification**: This chunk details the architecture, training data, and rationale behind the BERT-based models used in the study, including SecureBERT and multilingual variants, and explains the fine-tuning process and optimization techniques employed to adapt these models for multi-label security classification tasks.\n\nCONTENT: Implicit Security Requirements Classification 21\nTable 5: Details and Rationale of the BERT-based Models Used in the Study\nModel Name\n(Architecture /\nParameters)\nDescription, Training Data,\nand Source\nRationale in Study\nBERT Base (En-\nglish)\n(12 layers, 768\nhidden, 12 heads,\n110M params.)\nStandard BERT-base archi-\ntecture. Pre-trained on the\nBookCorpus and English\nWikipedia.8(Devlin et al., 2019)\nTo serve as a strong performance\nbaseline.\nSecureBERT\n(12 layers, 768\nhidden, 12 heads,\n125M params.)\nBased on the RoBERTa architec-\nture. Pre-trained on a 12GB cor-\npus of cybersecurity texts (NVD,\nCVE, CAPEC). 9(Aghaei et al.,\n2020)\nTo test the hypothesis that\ndomain-specific vocabulary and\ncontext improve classification ac-\ncuracy.\nBERT Base\nMultilingual\n(12 layers, 768\nhidden, 12 heads,\n179M params.)\nStandard BERT-base architec-\nture. Pre-trained on the top\n104 languages with the largest\nWikipedia datasets. 10(Devlin\net al., 2019)\nTo investigate whether training\non a broader set of languages\nprovides any generalization ben-\nefit.\nBERT Base\nTurkish\n(12 layers, 768\nhidden, 12 heads,\n110M params.)\nStandard BERT-base architec-\nture. Pre-trained on a 35GB,\n4.4B token Turkish corpus from\nmultiple sources. 11(Schweter,\n2020)\nTo explore the performance of\na model pre-trained on a lan-\nguage with a different morpho-\nlogical structure than English.\nthe final hidden state of the [CLS] token to a vector corresponding to our\n11 security classes. A sigmoid activation function was applied to this layer to\nproduce independent probabilities, facilitating multi-label classification. The\nfine-tuning process was performed from end-to-end; all weights were unfrozen\nand updated to adapt the models to the specific nuances of the security re-\nquirements text.\nThe models were trained using the PyTorch Lightning framework to ensure\nreproducibility. We employed the AdamW optimizer (Loshchilov and Hutter,\n2019), an extension of the Adam optimizer with improved weight decay, uti-\nlizing a linear learning rate schedule with a warmup phase covering the first\n20% of training steps. This strategy stabilizes training in the initial epochs and\nimproves convergence. Given the multi-label nature of the task, Binary Cross-\nEntropy (BCE) Loss was used as the primary objective function. Because the\nsecurity classes are unevenly distributed, the label assignment threshold (Deci-\nsion Threshold) was tuned rather than fixed at 0.5 to better balance precision\nand recall across categories.', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: This chunk provides a detailed comparison of the performance metrics (precision, recall, F1 scores, and support) for various BERT-based models, including SecureBERT, in classifying security requirements across OWASP ASVS categories, highlighting their effectiveness and challenges in handling underrepresented classes.\n\nCONTENT: bert-base-multilingual-uncased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.984 0.982 0.982 0.975 0.744 0.985 0.980 0.984 0.983 0.864 0.991RECALL 0.997 0.995 0.995 0.984 0.842 0.995 1.000 1.000 0.983 0.704 0.994F1 0.990 0.988 0.988 0.979 0.790 0.990 0.990 0.992 0.983 0.776 0.992SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nbert-base-turkish-cased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.974 0.974 0.980 0.975 0.756 0.985 0.982 0.974 0.980 0.800 0.972RECALL 0.997 0.997 1.000 0.994 0.816 0.997 1.000 1.000 0.977 0.593 0.994F1 0.985 0.985 0.990 0.984 0.785 0.991 0.991 0.987 0.978 0.681 0.983SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nbert-base-uncased\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.982 0.979 0.982 0.981 0.781 0.985 0.980 0.974 0.977 0.813 0.978RECALL 0.995 0.995 0.995 0.975 0.658 0.992 0.997 0.997 0.987 0.481 0.987F1 0.988 0.987 0.988 0.978 0.714 0.988 0.988 0.985 0.982 0.604 0.982SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nSecureBERT\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.974 0.977 0.980 0.972 0.707 0.985 0.977 0.974 0.964 0.700 0.969RECALL 0.995 0.995 0.997 0.984 0.763 0.997 1.000 0.997 0.990 0.519 0.997F1 0.984 0.986 0.988 0.978 0.734 0.991 0.988 0.985 0.977 0.596 0.983SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nNaive Baseline\nV2, Authentication Verification Requirements\nV3, Session Management Verification Requirements\nV4, Access Control Verification Requirements\nV5, Validation, Sanitization and Encoding Verification Requirements\nV6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to', 'CONTEXT: **Performance Analysis and Statistical Evaluation of Classifiers**: This chunk focuses on the performance comparison of fine-tuned BERT models and LLMs in classifying security requirements, highlighting the superior performance of fine-tuned models, particularly for minority classes, and includes a statistical evaluation using the Friedman and Wilcoxon Signed-Rank tests to confirm significant differences between classifiers.\n\nCONTENT: 28 Yusuf G¨ ur et al.\nof 0.933 and Micro-F1 of 0.940, which show that the dataset’s class imbalance\nallows a trivial classifier to achieve high accuracy by ignoring minority classes.\nThe baseline model’s Macro-F1 score of 0.774 is significantly lower than the\nfine-tuned models (≈0.94) and its F1 score is 0.00 for the minority classes V6\n(Stored Cryptography) and V12 (Files and Resources) as anticipated. Mod-\nels like SecureBERT (based on RoBERTa) achieve an F1 of 0.734 on V6,\ndemonstrating that the deep learning models are successfully learning distinct\nfeatures for rare classes rather than merely exploiting the label distribution.\nOverall, the fine-tuned BERT models outperformed the LLMs in both\nzero-shot and few-shot configurations. The best fine-tuned model, bert-base-\nmultilingual-uncased, achieved a Macro-F1 score of 0.942, which is substan-\ntially higher than any LLM model’s score.\nThe top-performing LLM was Gemini 2.0, which in its few-shot configu-\nration reached a Macro-F1 score of 0.941. This score is on par with the best\nfine-tuned BERT model, indicating that few-shot prompting with a powerful\nLLM can match the performance of a specialized, fine-tuned model. However,\nmost other LLMs did not reach this level. For example, GPT-4o’s few-shot\nMacro-F1 score was only 0.814. In zero-shot tests, where no examples were\nprovided, the best LLM (Gemini 2.0) scored a Macro-F1 of 0.890. This score\nremains below the weakest fine-tuned BERT model, with fine-tuned models\nperforming best, followed by few-shot LLMs and then zero-shot LLMs.\n5.5 Statistical Evaluation of Classifiers Performance\nWe also examined whether the observed models’ performance differences were\nstatistically significant. Following the comparison framework of (Demˇ sar, 2006),\nwe compared the distributions of classifier performance scores. The 11 OWASP\nASVS security classes were treated as independent domains (stratified subsam-\nples from the main data set). The performance of the 20 evaluated classifiers\nwas assessed using the Friedman test, followed by pairwise Wilcoxon signed-\nrank tests.\nThe null hypothesis states that all classifiers perform equivalently and their\nrank distributions are identical. In our analysis, the Friedman test yielded a\nstatistic of 188.103 with ap-value of 2.38×10 −28. This result rejects the null\nhypothesis (p <0.05), confirming that the observed performance differences\nacross the models are non-random and statistically significant.\nFollowing the rejection of the null hypothesis, we proceeded to identify the\nspecific pairs of models that differ significantly. For these pairwise compar-\nisons, we employed the Wilcoxon Signed-Rank Test. Demˇ sar recommends the\nWilcoxon test as a “safe and robust” non-parametric alternative to the paired\nt-test for comparing two classifiers. Unlike the t-test, which assumes commen-\nsurability of differences and normality, the Wilcoxon test compares the ranks\nof the differences. This ensures that outliers (such as the extreme performance\ndrops observed in minority classes like V6 and V12) do not disproportionately\nskew the results.', 'CONTEXT: **Performance Analysis of Models for Security Requirements Classification**  \nThis chunk provides a detailed comparison of F1-scores across various LLMs, fine-tuned BERT models, and a baseline approach, highlighting their performance in classifying security requirements, particularly in handling class imbalance and underrepresented categories.\n\nCONTENT: Implicit Security Requirements Classification 25\nTable 7: Aggregated F1-Scores for LLM, BERT Models, and Baseline\nModel Prompting Strategy Macro-F1 Micro-F1 Weighted-F1\nLarge Language Model Results\nLlama 3 70b Zero Shot 0.813 0.941 0.941\nLlama 3 70b Few Shot 0.802 0.925 0.925\nDeepSeek R1 Zero Shot 0.812 0.921 0.916\nDeepSeek R1 Few Shot 0.820 0.927 0.921\nGemini 2.5 Zero Shot 0.8290.957 0.953\nGemini 2.5 Few Shot 0.8170.963 0.959\nGemini 2.0 Zero Shot0.8900.925 0.921\nGemini 2.0 Few Shot0.9410.938 0.938\nGemini 2.0 Pro Zero Shot 0.830 0.908 0.904\nGemini 2.0 Pro Few Shot 0.889 0.959 0.953\nGemma 3 27b Zero Shot 0.806 0.912 0.907\nGemma 3 27b Few Shot 0.802 0.917 0.912\nGemma 3 4b Zero Shot 0.605 0.738 0.742\nGemma 3 4b Few Shot 0.723 0.871 0.867\nGpt 4o Zero Shot 0.790 0.912 0.907\nGpt 4o Few Shot 0.814 0.943 0.939\nGpt 4o mini Zero Shot 0.703 0.803 0.809\nGpt 4o mini Few Shot 0.754 0.852 0.854\nBERT Fine-Tuning Results\nbert-base-multilingual-uncased Fine-Tuning0.942 0.985 0.983\nbert-base-turkish-cased Fine-Tuning 0.933 0.983 0.981\nbert-base-uncased Fine-Tuning 0.914 0.978 0.976\nSecureBERT Fine-Tuning 0.918 0.979 0.976\nBaseline\nNaive Baseline Majority Class 0.774 0.940 0.933\nrepresented categories. The bert-base-multilingual-uncased model achieved the\nhighest Weighted-F1 score at 0.983, while the lowest among the group was\n0.976 for both bert-base-uncased and SecureBERT. However, these results ob-\nscure the impact of class imbalance. Macro-F1 scores, which give equal weight\nto all categories, were lower, ranging from 0.942 to 0.914, revealing reduced\nperformance on less frequent classes.\nThis pattern is clear in the category-level results (Appendix C). Perfor-\nmance was high for common categories such as V8 (Data Protection), where\nthe bert-base-multilingual-uncased model achieved an F1-score of 0.992. In\ncontrast, results declined significantly for sparsely represented categories. For\nV6 (38 samples), F1-scores fell to 0.714 for bert-base-uncased and 0.734 for\nSecureBERT. The weakest performance was observed for V10 (27 samples),\nwith F1-scores around 0.60, indicating limited generalization due to limited\ndata.\nAn analysis of precision and recall for these difficult classes reveals specific\nfailure patterns. For class V10, the bert-base-uncased model has a low Recall of\n0.481. This indicates that while its predictions were often correct (Precision:\n0.813), it failed to identify more than half of the actual V10 requirements,\nresulting in a high number of false negatives. For class V6, the same model', 'CONTEXT: **Optimization and Prompting Strategies for Security Classification Models**: This chunk discusses the optimization of BERT variants through systematic hyperparameter tuning and explores the use of large language models (LLMs) for security requirement classification, focusing on zero-shot and few-shot prompting strategies to enhance task-specific performance without modifying the base model.\n\nCONTENT: 22 Yusuf G¨ ur et al.\nWe performed a systematic grid search using the Weights & Biases 12\nplatform to identify the optimal configuration for each BERT variant using\nthe validation dataset. The search space included the following parameters:\n–Maximum Sequence Length:[128, 256]tokens\n–Batch Size:[4, 8, 16]\n–Number of Epochs:[16, 24, 32]\n–Learning Rate:[1e-5, 2e-5, 3e-5]\n–Decision Threshold:[0.3, 0.4, 0.5]\nTo prevent overfitting, we monitored validation loss and implemented early\nstopping with a patience of 2–4 epochs. The checkpoint achieving the lowest\nvalidation loss for each model was selected for the final evaluation on the test\nset.\n4.3 Classification using LLM Models\nLLMs are transformer-based models trained on massive corpora for general-\npurpose natural language understanding and generation. This study adopted\nthe “pre-train, prompt, and predict” paradigm, which replaces traditional\n“pre-train, fine-tune” approaches (Liu et al., 2023a). Rather than adjusting\nthe model’s objective or architecture, prompt engineering is used to steer the\nmodel toward task-specific outputs through carefully designed textual inputs.\nPrompt engineering involves designing prompts that elicit accurate re-\nsponses for specific tasks. In zero-shot prompting, an LLM is directly used\nwithout any task-specific training. Few-shot prompting introduces a small\nnumber of labeled examples in the prompt, which allows the model to learn\nthe task pattern. This is particularly beneficial when labeled training data is\nlimited.\nFour main prompting strategies were proposed by (Liu et al., 2023a):\n–Tuning-free prompting: Requires no model changes, suitable for zero-shot\nsettings, but often demands complex prompt design.\n–Fixed-LLM prompt tuning: Involves learning soft prompts while keep-\ning the model fixed; effective for few-shot tasks but typically lacks inter-\npretability.\n–Fixed-prompt LLM tuning: Fine-tunes the model on a fixed prompt; im-\nproves performance in few-shot settings.\n–Prompt + LLM tuning: Jointly tunes both model and prompts; highly\nexpressive but prone to overfitting on small datasets.\nIn this study, we evaluated the first two of these strategies, as they do\nnot require modification of the base LLM’s weights. For our zero-shot experi-\nments, we implemented tuning-free prompting, relying on carefully engineered\nprompts to guide the models. For our few-shot analysis, our approach aligns\n12 https://wandb.ai/site', 'CONTEXT: **Performance Metrics for Security Requirement Classification Models**: This chunk presents the precision, recall, F1 scores, and support metrics for various OWASP ASVS categories, highlighting the performance of BERT models and a naive baseline in classifying implicit security requirements, with a focus on challenges like class imbalance and underrepresented categories.\n\nCONTENT: V6, Stored Cryptography Verification Requirements\nV7, Error Handling and Logging Verification Requirements\nV8, Data Protection Verification Requirements\nV9, Communications Verification Requirements\nV10, Malicious Code Verification Requirements\nV12, File and Resources Verification Requirements\nV13, API and Web Service Verification Requirements\nPRECISION 0.960 0.950 0.960 0.790 0.000 0.980 0.970 0.960 0.750 0.000 0.800RECALL 1.000 1.000 1.000 1.000 0.000 1.000 1.000 1.000 1.000 0.000 1.000F1 0.980 0.980 0.980 0.880 0.000 0.990 0.980 0.980 0.860 0.000 0.890SUPPORT 382 381 385 314 38 389 384 380 299 27 317TOTAL 398 398 398 398 398 398 398 398 398 398 398\nTest Results of the BERT models and Naïve Baseline used in the study\nImplicit Security Requirements Classification 55\nC Test Results of the Bert Models']","The study addressed the uneven distribution of security classes during BERT training by tuning the label assignment threshold (Decision Threshold) instead of fixing it at 0.5. This adjustment aimed to better balance precision and recall across categories, particularly for the multi-label classification task. Additionally, stratified sampling was applied during dataset splitting to preserve label distributions across training, validation, and test sets, ensuring sufficient representation of minority classes in the test set. These strategies helped mitigate the challenges posed by class imbalance. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)",The label assignment threshold (Decision Threshold) was tuned rather than fixed at 0.5 to better balance precision and recall across categories[cite: 383].,,,
What is the key limitation of static few-shot prompting observed in the study?,"['CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to', 'CONTEXT: **Optimization and Prompting Strategies for Security Classification Models**: This chunk discusses the optimization of BERT variants through systematic hyperparameter tuning and explores the use of large language models (LLMs) for security requirement classification, focusing on zero-shot and few-shot prompting strategies to enhance task-specific performance without modifying the base model.\n\nCONTENT: 22 Yusuf G¨ ur et al.\nWe performed a systematic grid search using the Weights & Biases 12\nplatform to identify the optimal configuration for each BERT variant using\nthe validation dataset. The search space included the following parameters:\n–Maximum Sequence Length:[128, 256]tokens\n–Batch Size:[4, 8, 16]\n–Number of Epochs:[16, 24, 32]\n–Learning Rate:[1e-5, 2e-5, 3e-5]\n–Decision Threshold:[0.3, 0.4, 0.5]\nTo prevent overfitting, we monitored validation loss and implemented early\nstopping with a patience of 2–4 epochs. The checkpoint achieving the lowest\nvalidation loss for each model was selected for the final evaluation on the test\nset.\n4.3 Classification using LLM Models\nLLMs are transformer-based models trained on massive corpora for general-\npurpose natural language understanding and generation. This study adopted\nthe “pre-train, prompt, and predict” paradigm, which replaces traditional\n“pre-train, fine-tune” approaches (Liu et al., 2023a). Rather than adjusting\nthe model’s objective or architecture, prompt engineering is used to steer the\nmodel toward task-specific outputs through carefully designed textual inputs.\nPrompt engineering involves designing prompts that elicit accurate re-\nsponses for specific tasks. In zero-shot prompting, an LLM is directly used\nwithout any task-specific training. Few-shot prompting introduces a small\nnumber of labeled examples in the prompt, which allows the model to learn\nthe task pattern. This is particularly beneficial when labeled training data is\nlimited.\nFour main prompting strategies were proposed by (Liu et al., 2023a):\n–Tuning-free prompting: Requires no model changes, suitable for zero-shot\nsettings, but often demands complex prompt design.\n–Fixed-LLM prompt tuning: Involves learning soft prompts while keep-\ning the model fixed; effective for few-shot tasks but typically lacks inter-\npretability.\n–Fixed-prompt LLM tuning: Fine-tunes the model on a fixed prompt; im-\nproves performance in few-shot settings.\n–Prompt + LLM tuning: Jointly tunes both model and prompts; highly\nexpressive but prone to overfitting on small datasets.\nIn this study, we evaluated the first two of these strategies, as they do\nnot require modification of the base LLM’s weights. For our zero-shot experi-\nments, we implemented tuning-free prompting, relying on carefully engineered\nprompts to guide the models. For our few-shot analysis, our approach aligns\n12 https://wandb.ai/site', 'CONTEXT: This chunk focuses on the evaluation of various language models, including open-source and commercial models, for implicit security requirements classification, detailing their technical specifications, rationale for selection, and experimental setup involving zero-shot and few-shot prompting strategies.\n\nCONTENT: Implicit Security Requirements Classification 23\nwith fixed-LLM prompt tuning, where we provided in-context examples within\nthe prompt to guide the model’s predictions. The latter two strategies involv-\ning model fine-tuning Fixed-prompt LLM tuning and Prompt + LLM tuning)\nwere not considered due to their high computational cost. The zero shot and\nfew shot prompts can be found in Appendix A and Appendix B.\nIn these experiments, we evaluated nine language models, including open-\nsource models deployed on local infrastructure and commercial models ac-\ncessed via external application programming interfaces (APIs). The technical\nspecifications of each model and the rationale for their selection are summa-\nrized in Table 7. The requirements were processed in batches of 15 because\nproviding the full set in a single prompt exceeded the models’ context limits.\nTable 6: Details and Rationale of the LLMs Used in the Study\nModel Name Description Rationale in Study\nOpen-Source Models\ngemma-3-27b\n(Dense Trans-\nformer; 27B\nParams)\nA Google-developed lan-\nguage model trained on\na large, diverse corpus of\nweb text.13 (The Google\nGemma Team, 2025)\nTo evaluate a powerful, next-generation\nopen-source model from a major AI research\nlab, establishing a baseline for locally deploy-\nable high-parameter models.\ngemma-3-4b\n(Dense Trans-\nformer; 4B\nParams)\nA smaller, efficient model\nfrom the Gemma 3 fam-\nily, designed for resource-\nconstrained environ-\nments.13 (The Google\nGemma Team, 2025)\nTo assess the performance of a highly ef-\nficient, small-scale model to determine if\nlower-parameter models can effectively han-\ndle complex security classification tasks.\nmeta.llama3-\n3-70b-instruct-\nv1:0\n(Dense Trans-\nformer; 70B\nParams)\nAPI version of Meta’s\nLlama 3 70B Instruct.\nAn open-weight model\npre-trained on over 15T\ntokens. 14 (AI at Meta,\n2024)\nTo benchmark against a leading open-weight\nmodel known for strong reasoning and\ninstruction-following capabilities, represent-\ning the state-of-the-art in non-proprietary\nmodels.\nDeepSeek-R1\n(Mixture-of-\nExperts (MoE))\nAn API-accessible model\nfrom DeepSeek AI. As-\nsumed to be based on the\nDeepSeek-V2 architecture\n(236B total/21B active\nparams). 15 (DeepSeek AI,\n2024)\nTo include a model with a different architec-\nture (MoE) that represents an alternative,\nhighly efficient approach to scaling, specif-\nically testing its reasoning capabilities in\nsecurity contexts.\nCommercial Models (API Access)\n13 https://blog.google/technology/developers/\n14 https://ai.meta.com/blog/meta-llama-3/\n15 https://deepseek.com/', 'CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the', 'CONTEXT: **Performance Analysis of LLM Prompt Engineering and Model Comparisons**: This section evaluates the impact of zero-shot and few-shot prompting strategies on the performance of LLMs for implicit security requirements classification, highlighting inconsistencies across models and categories, particularly for underrepresented classes, and comparing their results to fine-tuned BERT models and a naive baseline.\n\nCONTENT: Implicit Security Requirements Classification 27\nFurthermore, to mitigate contextual bias, where a model might rely on\nits general training data rather than the specific task definitions, we utilized\nContextual Anchoring. We injected the explicit definitions of the 11 OWASP\nASVS classes and a set of heuristic “Extra Information” rules (e.g., map-\nping CRUD operations to specific security categories taken from guidelines)\ndirectly into the prompt’s context window. Including this information in the\nprompt directed the models to follow the specified standard, resulting in more\nconsistent classifications.\nWhile alternative prompting strategies may yield different quantitative\noutcomes, this design prioritizes experimental control and cross-model compa-\nrability. Hence, the reported results reflect conservative estimates of prompt-\nbased performance rather than optimized upper bounds.\n5.3 Results and Analysis for LLM Prompt Engineering\nTable 7 shows the overall performance of the LLM-based experiments. The\nresults compare zero-shot and few-shot prompting strategies, with detailed\nper-category scores reported in Appendix D.\nThe results show that few-shot prompting often improve performance com-\npared to zero-shot prompting, though the effect is not consistent across models\nor categories. For instance, while Gemini 2.0 Pro’s overall Macro-F1 score rose\nfrom 0.830 to 0.889 with a few-shot approach, the score for Meta Llama 3 70b\nslightly decreased from 0.795 to 0.793. On category wise GPT-4o’s F1-score\nfor class V5 rose from 0.924 to 0.948 with few-shot prompting. However, this\nimprovement was not observed across all categories. For the difficult V12 class,\nMeta Llama 3 70b’s score actually dropped from 0.271 to 0.214 when examples\nwere added.\nContrary to expectations, larger models did not consistently gain more\nfrom few-shot prompting. In fact, the smaller Gemma 4b model saw its F1-\nscore on class V5 jump from 0.709 to 0.814. By contrast, the larger Gemma\n27b model’s performance on the same task decreased from 0.946 to 0.903. This\nshows that for this task, a larger model did not guarantee a greater benefit\nfrom few-shot examples.\nAll models showed weak performance on the underrepresented categories\nV6 and V12. Few-shot prompting offered limited benefit for these classes. For\nV6, DeepSeek R1 improved only marginally, from an F1-score of 0.117 to\n0.148. For V12, Gemini 2.5 Pro achieved the highest zero-shot score (0.605),\nbut dropped sharply to 0.335 with few-shot prompting, indicating that a small\nnumber of examples is insufficient to compensate for the severe class imbalance.\n5.4 Comparative Analysis of LLMs and Fine-Tuned BERT Models\nAs a point of reference, we included a Naive Baseline that always predicts the\nmost frequent class. As shown in Table 7, the model achieves a Weighted-F1', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference', 'CONTEXT: **Evaluation of Model Challenges and Prompt Engineering Strategies**: This chunk discusses the challenges faced by models, particularly with underrepresented OWASP ASVS categories (e.g., V6 Cryptography, V12 Files/Resources), and outlines the experimental setup for prompt engineering in LLMs, including zero-shot and few-shot configurations, persona-based prompting, and strategies to ensure consistency and adherence to security standards.\n\nCONTENT: 26 Yusuf G¨ ur et al.\nshowed both low Recall (0.658) and low Precision (0.781), indicating it was\nboth missing true cases and incorrectly labeling other requirements as V6.\nModels struggle significantly with underrepresented categories, particularly\nV12 (File and Resources) and V6 (Stored Cryptography). This is evident in\nthe high number of false negatives, where the models fail to identify true\ninstances of these classes. For example, the baseline BERT model incorrectly\nclassified over half of the V12 requirements as negative (14 false negatives vs.\n13 true positives). Conversely, the matrices show that models often misclassify\nrequirements by incorrectly assigning them to other categories. The BERT\nBase model, for example, incorrectly labeled 92 different requirements as V10\n(Malicious Code) and 78 requirements as V5 (Malicious Input Handling).\n5.2 Experimental Setup for LLM Prompt Engineering\nWe adapted prompt engineering strategies from Ronanki (Ronanki et al.,\n2024), originally used for multi-class requirement classification. Two configu-\nrations were evaluated: zero-shot prompting (Appendix A), which relied solely\non task instructions and the input requirement, and few-shot prompting (Ap-\npendix B), which additionally incorporated labeled examples. The few-shot\nsetup used 30 training instances that were chosen to (i) capture multi-label\ncases where a single requirement spans multiple security categories, (ii) cover\nall 11 OWASP ASVS categories, and (iii) reflect requirements from different\nbusiness domains to preserve linguistic variation.\nPersona-based prompting was applied in both configurations by instruct-\ning the model to act as an experienced cybersecurity specialist. This alignment\nhelped reduce output variance by grounding responses in professional domain\nexpertise rather than general conversational patterns. The final prompt was\nobtained after five iterations. These iterations focused on three primary ar-\neas: (1) instruction clarity to prevent the model from defaulting to binary\nsecurity labels; (2) contextual grounding, by iteratively refining the OWASP\nASVS category definitions to ensure the model adhered to provided standards;\n(3) constraint formatting, to stabilize the PSV output structure for machine-\nreadability and ensure the inclusion of mandatory explanation fields. All ex-\nperiments were conducted with fixed parameters (Temperature = 0, Top-p =\n0.95) and repeated three times. The reported results are averaged to reduce\nthe impact of any minor, non-deterministic fluctuations in the models’ token\nselection during individual inferences.\nPrompt-based methods can be sensitive to phrasing, structure, and exam-\nple selection. To manage prompt sensitivity and contextual bias, we adopted a\nunified Persona–Context–Constraint strategy. A single prompt structure was\nused across all models, without model-specific tuning or iterative optimization\naimed at maximizing scores. The few-shot examples were chosen for representa-\ntiveness with respect to the OWASP ASVS taxonomy rather than performance\ngains.', 'CONTEXT: **Comparison of Fine-Tuned Models and LLMs for Security Requirements Classification**: This chunk discusses the performance comparison between fine-tuned transformer models (e.g., BERT) and few-shot prompting with LLMs (e.g., Gemini 2.0) for classifying implicit security requirements in SRS documents, emphasizing the practicality of LLMs as a resource-efficient alternative while highlighting challenges in Security Requirements Engineering (SRE).\n\nCONTENT: 2 Yusuf G¨ ur et al.\ntional fine-tuned transformer models and contemporary Large Language Mod-\nels (LLMs) employing few-shot and zero-shot prompt engineering strategies.\nThe results show that a few-shot prompting with Gemini 2.0 achieves a macro-\naverage F1 score of 0.941, directly comparable to the fine-tuned BERT model’s\n0.942. This study culminates in two primary findings: first, the validation and\npublication of the ASRD, a high-granularity, multi-label dataset for implicit\nsecurity requirements based on OWASP ASVS V2-V13; and second, the di-\nrect comparison demonstrating that few-shot Large Language Models (LLMs)\nachieve competitive multi-label classification performance (Macro-F1 0.941)\nnearly equal to resource-intensive fine-tuned transformer models (Macro-F1\n0.942). This confirms that LLMs represent a highly practical and resource-\nsaving strategy for automating the identification of embedded (implicit) secu-\nrity requirements for software security in industrial SRS documents\nKeywordsCybersecurity requirement elicitation·OWASP based security\nrequirement classification·OWASP ASVS-based Requirement Labeling·\nLLM based classification\n1 Introduction\nRequirements Engineering (RE) concerns the identification, documentation,\nand management of software requirements (Sommerville and Sawyer, 1997).\nThe increasing interconnectivity of information systems forces organizations\nto provide secure services in cyberspace. Integrating security during initial\nrequirements analysis is essential to proactively mitigate risks, reduce vulner-\nabilities, and reduce the high costs associated with downstream remediation\n(Villamizar et al., 2018). This proactive approach is central to the ”Shift-\nLeft” security paradigm, which advocates for the identification and mitigation\nof vulnerabilities as early as possible in the Software Development Life Cycle\n(SDLC).\nAlthough Security Requirements Engineering (SRE) has matured as a dis-\ncipline, its effective application in practice remains challenging. The issue is\nnot the absence of security considerations, but the difficulty of ensuring that\nsecurity requirements are properly validated and verified. An empirical investi-\ngation that combines a systematic literature review with a survey of 58 indus-\ntry professionals highlights this gap (Alam et al., 2025). While practitioners\nreported a moderate understanding of SRE practices, Security Requirements\nAssurance (SRA) was found to be poorly understood and rarely applied in\nindustrial contexts. The study concludes that validating and ensuring security\nrequirements remains a major and unresolved challenge in practice.\nThis assurance gap persists due to the documented lack of specialized se-\ncurity training for developers in early-phase RE (Andrade et al., 2023). The\ntask relies heavily on scarce specialized expertise and time-intensive manual\nanalysis. The main challenge is that critical security requirements are often not\nexplicitly stated. Instead, they are implicitly embedded within standard func-\ntional descriptions. For example, a seemingly simple functional requirement,']","The key limitation of static few-shot prompting observed in the study is its rigidity, which leads to inconsistent performance gains and, in some cases, degraded performance compared to zero-shot prompting. This limitation is particularly evident for underrepresented and high-variance security classes, such as OWASP ASVS categories V6 (Cryptography) and V12 (Files/Resources). Static few-shot prompting fails to generalize concepts effectively across diverse contexts, as fixed examples (e.g., related to ""file upload"") do not help the model identify requirements in different scenarios (e.g., ""directory traversal""). Consequently, the models struggle to classify rare security requirements accurately, resulting in low F1-scores for these categories.

**Source:** temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf","Static few-shot prompting is rigid; providing a fixed set of examples yielded inconsistent gains and sometimes degraded performance for minority classes because the examples did not cover the high variance of contexts[cite: 683, 684].",,,
What role did the 'senior SME' play in the annotation process?,"['CONTEXT: This chunk details the **annotation methodology** and **dataset curation process** for the ASRD, following the MATTER cycle framework. It describes annotator selection, corpus preparation, and the iterative development of annotation guidelines aligned with OWASP ASVS categories to ensure high-quality, domain-specific annotations.\n\nCONTENT: Implicit Security Requirements Classification 15\n3.3 Annotation Methodology (MATTER Cycle) & Dataset Curation\nThe annotation process followed the MATTER development cycle, an estab-\nlished iterative framework for corpus annotation (Pustejovsky and Stubbs,\n2012). Crucially, the annotation task was defined as a multi-label text classifi-\ncation problem. It consists of the phases Model, Annotate, Train, Test, Eval-\nuate, and Revise. The annotation guidelines were developed and iteratively\nrefined to ensure consistency and clarity.\nThe Model–Annotate cycle involved writing guidelines, selecting annota-\ntors, conducting trial annotations, and refining the process. Once stabilized,\nthis cycle was expanded to the full dataset to generate a Gold Standard corpus.\nThe annotation workflow included the following processes:\n–Annotator Selection: Following Bayerl and Paul’s recommendation to use\ndomain-aligned annotators (Bayerl and Paul, 2011), three cybersecurity\nsubject matter experts (SME) from the agency, each with over 15 years\nof experience in designing security architectures, analyzing threat models,\nand identifying security requirements, performed the annotations. Their\ndeep practical experience ensured accurate and context-aware interpreta-\ntion which aligned with the requirement “experts must demonstrate signif-\nicant skills, knowledge, and experience” emphasized by Hopkins (Hopkins\nand Unger, 2017). The senior manager among them also provided over-\nsight and led the adjudication process. The senior SME acted as both an\nannotator and the final adjudicator for resolving disagreements. They also\nprovided feedback to improve the quality and clarity of the annotation\nguideline.\n–Corpus Selection and Preparation: Cohen (Cohen et al., 2005) recommends\nthat during corpus design, balance and representativeness of the corpus\nis important. In line with his recommendation, of the 19 initial project\ndocuments, six were chosen for their domain diversity and potential for\neffective anonymization by the SMEs. These documents underwent a semi-\nautomated anonymization process to remove all project-specific and per-\nsonally identifiable information (PII). The process targeted entities such\nas names of individuals and organizations, project codenames, and specific\ntechnical identifiers. This was done using custom scripts with placeholder\nreplacement, followed by manual review to ensure that anonymization did\nnot alter the meaning, structure, or intent of the original requirements. The\nextracted requirements were then randomized and masked to prevent po-\ntential bias related to document origin or sequence during the annotation\nphase. Total corpus has 2,652 requirements (30 pilot + 2,622 independent\nannotations).\n–Annotation Guideline Development: The Annotation Guidelines’ develop-\nment involved an initial iterative process, refining the guidelines three times\nto resolve ambiguities before the formal assessment phase. Annotation rules\nwere based on OWASP ASVS categories V2–V13 and refined iteratively\nusing example annotations. Following best practices suggested by Cohen\n(Cohen et al., 2005), the guidelines and annotation documents ensured:', 'CONTEXT: **Annotation Process and Dataset Composition**: This chunk details the multi-stage annotation methodology used to create the ASRD dataset, addressing class distribution, challenges with imbalanced categories (e.g., V6 Cryptography, V12 Files/Resources), and the inclusion of true negatives to ensure realistic and high-quality security requirement classification.\n\nCONTENT: Implicit Security Requirements Classification 17\n0.71 to 0.79, further confirmed substantial agreement between individual\nannotator pairs.\n–Adjudication: Disagreements were resolved through structured expert dis-\ncussions led by the senior SME. When the two annotators disagreed on a\nrequirement, it was resolved through a structured process:\n–Both annotators presented their choice and their reasons.\n–The senior expert reviewed both positions against the guideline.\n–If the guideline clearly supported one choice, that one was used. If not,\nthe senior expert led a discussion to decide.\n–Final decision and the reason was written down.\nThe goal was to reach unanimous agreement for each disputed requirement.\nThis process produced final Gold Standard annotations for 135 contested\nitems, ensuring consistency and validation of the dataset.\nThis multi-stage annotation methodology produced a reliable dataset which\ncomprises 2,652 annotated security-relevant requirements. The category dis-\ntributions of the requirements can be seen in Figure 1. The class distribution\namong the classes are largely balanced (90%) except the V6(Stored Cryptog-\nraphy) and V12 (Files & Resources) as 6% each. This imbalance is considered\na reflection of the source projects, where requirements for these two categories\nare inherently less frequent than pervasive controls like access control or input\nvalidation. Stored cryptography requirements are typically captured as holis-\ntic, architectural decisions rather than numerous, distinct functional require-\nments. Similarly, explicit security controls for file handling are less ubiquitous,\nappearing only in projects with specific file processing features, which explains\ntheir low frequency in our corpus. Sample annotated requirements can be seen\nin Table 4.\nThis imbalance mirrors real-world security requirement frequency - most\nsoftware functions involve access and data; few involve file uploads or encryp-\ntion configuration - and introduces a challenge for machine learning. Partic-\nularly, the sparsity in V6 and V12 categories may hinder generalization and\ncalls for class imbalance handling techniques. Despite this, the dataset presents\na realistic and high-quality foundation for developing and evaluating security-\naware NLP and classification models.\nTwenty-six requirements (0.98% of the data) labeled as “UNASSIGNED”\nwere requirements unanimously determined by the experts to be purely func-\ntional requirements with no discernible implicit security component (e.g., “The\nsystem will enable application software to be developed with an object-oriented\nprogramming approach”,). These items were intentionally retained in the dataset\nas true negatives to ensure a realistic distribution and test the models’ ability\nto correctly reject non-security items.\n\n18 Yusuf G¨ ur et al.\nFig. 1: Distribution of Classes', 'CONTEXT: **Annotation Process and Quality Assurance in ASRD Development**: This chunk details the iterative annotation process for the ASRD dataset, including pilot and independent annotation phases, adjudication meetings, and the use of agreement metrics (e.g., Fleiss’s Kappa) to ensure high annotation quality and consistency among cybersecurity experts.\n\nCONTENT: 16 Yusuf G¨ ur et al.\n(1) original text and annotations were recoverable, (2) clear documenta-\ntion was maintained, (3) annotation quality was consistently high. The\nannotation template included fields for the software requirement text, se-\nlected OWASP labels, and annotator comments or questions. All versions\nof the guideline and annotation documents were preserved to track revi-\nsions based on annotator feedback. For the annotation process, a sample\ncorpus from the requirement set has been selected by inter agreement of\nSMEs. The first version of the Annotation Guideline based on OWASP\nASVS security classes has been developed, where each annotator has in-\ndividually classified the sample corpus by annotating it with one or more\nlabels following the instructions provided in the first Annotation Guide-\nline. After the initial annotation, the SMEs met under the guidance of the\nsenior SME, who is also the branch manager, to review and discuss the\nannotation decisions. Each of the 30 software requirements was examined\nindividually, and in cases where there were differing opinions among the\nannotators, efforts were made to persuade and convince others by provid-\ning explanations and reasons for their choices. After three iterations of\ndiscussions and deliberations, a full agreement was reached for 30 software\nrequirements.\n–Pilot Annotation: An initial batch of 30 software requirements was anno-\ntated early in the study, prompting multiple discussion rounds and three\nupdates to the guidelines. Adjudication meetings enabled the resolution\nof non-consensus requirements through SME-led discussions, during which\nthe rationale for classification was articulated. Discrepancies arising from\nquality issues, such as guideline violations, were addressed by implement-\ning corrections to ensure conformity with established criteria. Each SME\nprovided justifications for their decisions, which facilitated informed dis-\ncussions and enhanced understanding during adjudication. This iterative\nprocess resolved discrepancies across 98 requirements throughout the entire\ncorpus and was important in establishing the finalized annotation frame-\nwork.\n–Independent Annotation: Each SME classified all remaining 2622 require-\nments independently, using the finalized guideline. Annotators were re-\nquired to justify each decision. This practice proved important for facili-\ntating informed discussions and understanding annotator reasoning during\nthe subsequent adjudication phase. The process took 284 days and 267\nperson-hours of expert time.\n–Agreement Metrics: Inter-Annotator Agreement (IAA) was calculated us-\ning Fleiss’s Kappa and pairwise Cohen’s Kappa to assess consistency. IAA\nscores were instrumental in identifying instances of disagreement among\nannotators, thereby highlighting areas where the guidelines might require\nfurther clarification or where ambiguous requirement phrasings contributed\nto annotation discrepancies. Fleiss’s Kappa coefficient of 0.82 was obtained\nacross the three annotators, indicating strong agreement that significantly\nexceeded random chance. Pairwise Cohen’s Kappa values, ranging from', 'CONTEXT: **Analysis of Minority Class Performance and Annotation Challenges in SRE**: This chunk discusses the performance gap between majority and minority security classes in SRE, the expert-driven annotation process using the MATTER cycle, and the measures taken to mitigate subjectivity and ensure realistic, industry-relevant model evaluation.\n\nCONTENT: 32 Yusuf G¨ ur et al.\nFig. 4:Minority vs. Majority Class Performance Gap.A comparative\nanalysis revealing that while advanced LLMs and fine-tuned models achieve\nnear-parity on Majority Classes (Blue), a significant performance gap remains\non Minority Classes (Red), underscoring the “Long Tail” challenge in SRE.\nAnnotation was performed by three experienced cybersecurity experts.\nWhile their domain knowledge ensured quality, the small annotator pool may\nintroduce subjective bias and limit the range of interpretations. This was mit-\nigated through the iterative MATTER cycle which includes training, iterative\nguideline refinement, and consensus-based adjudication.\nA key threat to internal validity is subjectivity as classifications rely heavily\non the latent domain knowledge and industry experience, rather than explicit\nindicators within the requirement text itself. This expert-driven approach pro-\nvides a “gold standard” for realistic industrial needs but it may introduce in-\nconsistencies if replicated by annotators with different backgrounds or if the\nbroader system context is not explicitly documented.\nThe test set was manually selected to balance computational efficiency and\ngeneralizability assessment. While cross-validation could improve test calibra-\ntion, it was avoided due to its high computational cost.\nTo minimize researcher bias and ensure the results reflect real-world in-\ndustry needs, domain experts used for the selection of both the test set and\nthe LLM suite. Rather than selecting data or models arbitrarily, these experts\ncurated a test set containing the most complex, “implicit” security scenarios\nto challenge the models beyond simple pattern matching. For the model suite,\nthey prioritized architectures with advanced reasoning capabilities, hypothe-\nsizing that these specific technical features are essential for the multi-step de-\nduction required in security requirements engineering. Although the experts', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb', 'CONTEXT: **Advancements in LLM-Assisted Security and Related Frameworks**: This chunk discusses the application of transformer-based models and LLMs in security requirements engineering (SRE), highlighting their capabilities, challenges, and the importance of high-quality datasets and evaluation frameworks. It also reviews the role of security frameworks in systematically identifying and classifying security requirements in automated settings.\n\nCONTENT: 6 Yusuf G¨ ur et al.\nBeyond requirements classification, security research has also turned to\ntask-specific models for narrowly defined problems. For instance, deep learning\napproaches such as BiLSTMs have been used to detect re-entrancy vulnerabil-\nities in smart contracts, where generic models are insufficient (Maturi et al.,\n2025). This work highlights the importance of explainability, as security de-\ncisions must be understandable to support assurance and auditing. Although\nthis line of research addresses a different problem, it reflects a shift toward\ndomain-aware and interpretable models.\nTransformer-based models have enabled new capabilities in automated text\nunderstanding(Zhou et al., 2025). They possess emergent abilities like in-\ncontext learning, instruction following, and step-by-step reasoning (Zhu et al.,\n2025), which allow them to perform complex tasks, including requirements\nclassification, with minimal or no labeled data (Liu et al., 2023b; Zhu et al.,\n2025). Recent trends show a growing interest in applying LLMs to RE tasks,\nincluding requirements classification, prioritization, and traceability (Rajbhoj\net al., 2024; White et al., 2024). LLMs can perform zero-shot and few-shot\nlearning, reducing the need for large annotated datasets and facilitating adap-\ntation to specialized domains like SRE (Labrak et al., 2023). Techniques such\nas prompt engineering and integration with external knowledge bases (e.g.,\nRetrieval-Augmented Generation) further improve their performance and con-\ntextual relevance (Masoudifard et al., 2024).\nLLM-assisted security solutions typically follow a three-step process: pre-\nprocessing (extracting context like documentation or target units), prompt\ngeneration (using instructions and unfilled slots for the model to complete\nwith artifacts like fuzz drivers or patches), and post-processing (validating\noutputs, e.g., checking if generated code successfully compiles) (Zhu et al.,\n2025).\nWhile these models provide powerful automation, they can also introduce\nnew risks and errors if applied without careful oversight. This underscores the\nneed for realistic, high-quality datasets and standardized evaluation frame-\nworks to reliably assess automated security requirement classification, ensuring\nboth effectiveness and safety in practice.\nThe use of automated models in security highlights both their potential and\nthe risks they can introduce. Ensuring accurate and reliable classification of\nsecurity requirements requires evaluation against high-quality, domain-specific\nbenchmarks (Jeong, 2024). This underscores the need for realistic datasets and\nstandardized evaluation frameworks tailored to SRE.\n2.2 Related Work on Security Frameworks\nAn appropriate security framework is necessary to ensure systematic and con-\nsistent identification and classification of security requirements, particularly in\nautomated settings. This section reviews widely adopted security frameworks\nand evaluates their suitability for requirement analysis.']","The 'senior SME' played a critical role in the annotation process by providing oversight, leading adjudication meetings, and acting as the final adjudicator to resolve disagreements among annotators. Specifically, the senior SME:

1. **Oversight and Adjudication Leadership**: They led structured expert discussions to resolve disagreements when annotators had differing opinions on requirements. This involved reviewing both positions against the annotation guidelines, facilitating discussions, and making final decisions to ensure unanimous agreement.

2. **Guideline Refinement**: The senior SME provided feedback to improve the quality and clarity of the annotation guidelines, ensuring consistency and alignment with domain-specific requirements.

3. **Annotation Contribution**: In addition to their adjudication role, the senior SME also participated as an annotator, leveraging their extensive experience in cybersecurity to ensure accurate and context-aware interpretations.

These contributions were essential for producing high-quality, consistent annotations and establishing a Gold Standard corpus for the ASRD dataset.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)",The senior SME acted as both an annotator and the final adjudicator for resolving disagreements during the consensus process[cite: 244].,,,
Why did the study categorize 'Asset Handover' requirements under Authentication (V2) and Access Control (V4)?,"['CONTEXT: This chunk provides detailed descriptions of OWASP ASVS security categories (V4–V13) and their associated requirements, along with guidelines and examples for categorizing security-related operations in Software Requirements Specification (SRS) documents, supporting the classification process outlined in the broader study.\n\nCONTENT: V4, Erişim Kontrolleri (Access Controls) - Covers requirements related to authorization, role management, \nand preventing unauthorized access to resources (e.g., ASVS 4.0). \nV5, ""Doğrulama, Temizleme ve Şifreleme"" (Verification, Cleaning, and Encryption) - Covers requirements \nrelated to input validation, output encoding, data sanitization, and cryptographic protection of sensitive \ndata (e.g., ASVS 5.0). \nV6, Depolanmış Kriptografi (Stored Cryptography) - Covers requirements for protecting data at rest using \ncryptography, including key management and secure storage of encryption keys (e.g., ASVS 6.0). \nV7, Hata Ayıklama ve Kayıt (Debugging and Logging) - Covers requirements related to secure logging \npractices, error handling, and preventing information leakage through debug information (e.g., ASVS 7.0). \nV8, Veri Koruma (Data Protection) - Covers requirements related to data at rest and in transit protection, \nincluding encryption, backups, and data retention policies (e.g., ASVS 8.0). \nV9, İletişim (Communication) - Covers requirements related to secure communication protocols, protecting \nagainst network attacks, and ensuring data integrity during transmission (e.g., ASVS 9.0). \nV10, Zararlı Kod (Malicious Code) - Covers requirements related to preventing and mitigating the risk of \nmalicious code injection, such as cross-site scripting (XSS) and SQL injection (e.g., ASVS 10.0). \nV12, Dosya ve Kaynakları (Files and Resources) - Covers requirements related to secure file handling, \naccess control to files and resources, and preventing directory traversal attacks (e.g., ASVS 12.0). \nV13, API ve Web Servisleri (API and Web Services) - Covers requirements specific to securing web \nservices, APIs, and microservices, including authentication, authorization, input validation, and error \nhandling (e.g., ASVS 13.0). \n \n********* \n \nExtra Information for Choosing Categories (Aligned with OWASP ASVS 4.0.3-tr): \n \nAccording to given descriptions for kind of requirements, we can decide categories as in PSV: \n \nIf Requirement describes a CRUD operation and if it is Create operation|1|1|1|1|0|1|1|1|1|0|1| \nIf Requirement describes a CRUD operation and if it is Read operation|1|1|1|1|0|1|1|1|1|0|1| \nIf Requirement describes a CRUD operation and if it is Update operation|1|1|1|1|0|1|1|1|1|0|1| \nIf Requirement describes a CRUD operation and if it is Delete operation|1|1|1|0|0|1|1|1|0|0|0| \nIf Requirement describes User Types: usage of various user types as role management|1|1|1|0|0|0|0|0|0|0|0| \nIf Requirement describes Store: actions related to storage and backup of the assets at rest, e.g., backing up \nlog files|0|0|0|1|0|1|1|0|0|1|0| \nIf Requirement describes Transfer: actions related to transfer or sharing of the assets, e.g., sending data \nfrom one service to another|0|0|0|0|0|1|1|1|0|0|1| \nIf Requirement describes Upload and Download Files etc. operation|1|1|1|1|0|1|0|1|1|1|1| \nIf Requirement describes operation on sensitive data like personal, financial, health etc|1|0|1|1|1|0|1|0|0|0|0| \n \n********* \n \nFew-Shot Examples (PSV): \n1|Sistem, yetkili kullanıcının hukuk dosyası türü kayıt etmesini sağlayacaktır.|1|1|1|1|0|1|1|1|1|0|1| Identity \nVerification (V2): The requirement specifies ""yetkili kullanıcı,"" implying a need for authentication to verify \nthe user\'s identity and ensure they are authorized to perform this action.Session Management (V3):  \nManaging the user session after authentication is essential to maintain the user\'s authenticated status and \nprevent unauthorized acces. Access Controls (V4):  The requirement explicitly states that only ""yetkili \nkullanıcı"" (authorized user) can perform this action, indicating the need for access controls to restrict \nunauthorized users.', ""CONTEXT: **Sample Security Requirement Classifications and Dataset Insights**: This chunk provides examples of security requirement classifications from the ASRD dataset, showcasing Turkish-language requirements, their English translations, and corresponding OWASP ASVS category mappings, highlighting the dataset's structure and annotation methodology.\n\nCONTENT: 18 Yusuf G¨ ur et al.\nFig. 1: Distribution of Classes\n\nImplicit Security Requirements Classification 19\nTable 4: Sample Requirement Classifications\nNo Original Requirements in Turkish Translated Requirements\nV2, Authentication\nV3, Session Mngmt.\nV4, Access Control\nV5, Validation\nV6, Cryptography\nV7, Error Handling\nV8, Data Protection\nV9, Communication\nV10, Malicious Code\nV12, File/Resources\nV13, API/Web Service\n1 Sistem, otel devir i¸ slemi ger¸ cekle¸ stirecektir. The system shall carry out the hotel room handover\nprocess.\n1 0 1 1 0 0 1 1 1 0 1\n2 Sistem, demirba¸ s devir i¸ slemi ger¸ cekle¸ stirecektir. The system shall carry out the fixed asset handover\nprocess.\n1 1 1 1 1 0 1 1 1 1 1\n3 Sistem, i¸ sletme stokları devri ger¸ cekle¸ stirecektir. The system shall carry out the business stock han-\ndover.\n1 1 1 1 1 1 1 1 1 1 1\n4 Sistem, kullanıcının Demirba¸ s Devir ¸ cizelgesi ra-\nporunu almasını sa˘ glayacaktır.\nThe system shall allow the user to generate the\nfixed asset handover schedule report.\n1 1 1 1 1 1 1 1 1 0 1\n5 Sistem, kullanıcının El Senedi Eki raporu almasını\nsa˘ glayacaktır.\nThe system shall allow the user to generate the\nPromissory Note Attachment report.\n1 1 1 1 1 0 1 1 1 0 1\n6 Sistem, uygulama yazılımına, mevcutta bulunan\ndil deste˘ gine ilave olarak di˘ ger dillerin property\ndosyaları olarak eklenebilmesini sa˘ glayacaktır.\nThe system shall enable additional languages to be\nadded to the application software via property files,\nin addition to the existing language support.\n0 0 1 0 0 0 0 1 1 0 1\n7 Sistem, raporun ekranda g¨ or¨ unt¨ ulenerek ¨ on izlen-\nmesini, yazıcıdan alabilmesini ve dosyaya ak-\ntarılabilmesini sa˘ glayacaktır.\nThe system shall allow reports to be previewed on\nscreen, printed, and exported to files.\n1 1 1 0 0 1 1 1 1 0 1\n8 Sistem, uygulama yazılımı i¸ slevleri arası dahili\nileti¸ sim i¸ cin geli¸ stirilecek web servislerinin REST\nstandartlarını desteklemesini sa˘ glayacaktır.\nThe system shall ensure that web services devel-\noped for internal communication between applica-\ntion functions comply with REST standards.\n1 0 1 1 0 0 1 0 0 0 1\n9 Sistem, kullanıcının uygulama yazılımı ekranları ve\nsayfaları ¨ uzerinde i¸ slem yapabilece˘ gi alanlar T¨ urk¸ ce\nF ve Q klavye ile uyumlu olacaktır.\nThe system shall ensure that user input areas on\napplication screens and pages are compatible with\nTurkish F and Q keyboards.\n0 0 0 1 0 0 0 0 0 1 0\n10 Sistem, uygulamada olu¸ san hatalara ili¸ skin\nbildirimlerin T¨ urk¸ ce olmasını, hatayı a¸ cıklayacak\nteknik detay ya da hata kodunu i¸ cermesini\nsa˘ glayacaktır.\nThe system shall ensure that notifications regard-\ning errors occurring in the application are in Turk-\nish and include technical details or error codes ex-\nplaining the error.\n0 0 0 0 0 1 0 0 0 0 0\n11 Sistem, uygulama yazılımı ekranlarının, ana say-\nfaya d¨ on¨ u¸ s sa˘ glayan bir ba˘ glantı i¸ cermesini\nsa˘ glayacaktır.\nThe system shall ensure that the application soft-\nware screens contain a link that allows returning to\nthe homepage.\n0 0 1 0 0 0 0 1 0 0 0\n12 Sistem, kullanıcının, uygulamada birbiriyle ili¸ skili\nekranlar arasında bir ¨ ust sayfaya ge¸ ci¸ s yapa-\nbilmesini sa˘ glayacaktır.\nThe system shall allow users to navigate to a par-\nent (higher-level) page among related application\nscreens.\n1 1 1 1 0 0 0 1 0 0 0\n13 Sistem, uygulama ekranları i¸ cin, en az bir tane\nyardım ekranı sa˘ glayacaktır.\nThe system shall provide at least one help screen\nfor application screens.\n0 0 0 0 0 0 0 0 0 0 0\n14 Sistem, uygulamanın tasarım a¸ samasında\nbelirlenecek ekranları i¸ cin yardım videoları\nsa˘ glayacaktır.\nThe system shall provide help videos for screens\nidentified during the application design phase.\n0 0 0 0 0 0 0 0 0 0 0"", 'CONTEXT: This chunk provides detailed definitions of OWASP ASVS security requirement classes (V5–V14), which are critical for categorizing and addressing specific security concerns in software applications, as discussed in the broader context of automating security requirements classification using AI and the ASRD dataset.\n\nCONTENT: 14 Yusuf G¨ ur et al.\nTable 3 – continued from previous page\nClass Id Class Name Definition\nV5 Malicious Input Handling This class focuses on requirements\nfor validating and sanitizing all input\ndata to prevent injection attacks, such\nas SQL injection, Cross-Site Scripting\n(XSS), and others.\nV6 Stored Cryptography This class addresses the secure stor-\nage of cryptographic keys and sensi-\ntive data at rest, ensuring they are pro-\ntected from unauthorized disclosure or\nmodification.\nV7 Error Handling and Logging This class ensures that applications\nhandle errors gracefully without leak-\ning sensitive information and that\nsecurity-relevant events are logged for\nmonitoring and analysis.\nV8 Data Protection This class covers the requirements for\nprotecting sensitive data during tran-\nsit and in storage, focusing on confi-\ndentiality, integrity, and classification.\nV9 Communications Security This class focuses on securing commu-\nnication channels between system com-\nponents, such as between the client and\nserver, to prevent eavesdropping, tam-\npering, or spoofing.\nV10 Malicious Code This class deals with ensuring the ap-\nplication code is free from malicious\ncode, backdoors, or other unintended\nsecurity vulnerabilities introduced in-\ntentionally or unintentionally.\nV11 Business Logic This class addresses security con-\ncerns within the application’s business\nlogic, preventing attackers from abus-\ning workflows or functionalities for un-\nintended purposes.\nV12 File and Resources This class covers the secure handling of\nfiles and other resources, including up-\nload, download, and management, to\nprevent path traversal and other re-\nlated attacks.\nV13 API and Web Service This class provides security require-\nments specifically for APIs and web\nservices, covering aspects like authen-\ntication, authorization, and protection\nagainst common API attacks.\nV14 Configuration This class focuses on securing the con-\nfiguration of all application compo-\nnents, including the application server,\nplatform, and third-party libraries, to\nprevent security misconfigurations.', 'CONTEXT: This chunk provides detailed descriptions of OWASP ASVS categories (V2–V13) and their associated security requirements, along with guidelines for classifying software requirements based on specific operations (e.g., CRUD, data storage, file handling) and sensitive data handling, aligned with the ASVS 4.0.3 framework. It also outlines the expected output format for classified requirements.\n\nCONTENT: 3.0). \nV4, Erişim Kontrolleri (Access Controls) - Covers requirements related to authorization, role management, \nand preventing unauthorized access to resources (e.g., ASVS 4.0). \nV5, ""Doğrulama, Temizleme ve Şifreleme"" (Verification, Cleaning, and Encryption) - Covers requirements \nrelated to input validation, output encoding, data sanitization, and cryptographic protection of sensitive \ndata (e.g., ASVS 5.0). \nV6, Depolanmış Kriptografi (Stored Cryptography) - Covers requirements for protecting data at rest using \ncryptography, including key management and secure storage of encryption keys (e.g., ASVS 6.0). \nV7, Hata Ayıklama ve Kayıt (Debugging and Logging) - Covers requirements related to secure logging \npractices, error handling, and preventing information leakage through debug information (e.g., ASVS 7.0). \nV8, Veri Koruma (Data Protection) - Covers requirements related to data at rest and in transit protection, \nincluding encryption, backups, and data retention policies (e.g., ASVS 8.0). \nV9, İletişim (Communication) - Covers requirements related to secure communication protocols, protecting \nagainst network attacks, and ensuring data integrity during transmission (e.g., ASVS 9.0). \nV10, Zararlı Kod (Malicious Code) - Covers requirements related to preventing and mitigating the risk of \nmalicious code injection, such as cross-site scripting (XSS) and SQL injection (e.g., ASVS 10.0). \nV12, Dosya ve Kaynakları (Files and Resources) - Covers requirements related to secure file handling, \naccess control to files and resources, and preventing directory traversal attacks (e.g., ASVS 12.0). \nV13, API ve Web Servisleri (API and Web Services) - Covers requirements specific to securing web \nservices, APIs, and microservices, including authentication, authorization, input validation, and error \nhandling (e.g., ASVS 13.0). \n \n********* \n \nExtra Information for Choosing Categories (Aligned with OWASP ASVS 4.0.3-tr): \n \nAccording to given descriptions for kind of requirements, we can decide categories as in PSV: \n \nIf Requirement describes a CRUD operation and if it is Create operation|1|1|1|1|0|1|1|1|1|0|1| \nIf Requirement describes a CRUD operation and if it is Read operation|1|1|1|1|0|1|1|1|1|0|1| \nIf Requirement describes a CRUD operation and if it is Update operation|1|1|1|1|0|1|1|1|1|0|1| \nIf Requirement describes a CRUD operation and if it is Delete operation|1|1|1|0|0|1|1|1|0|0|0| \nIf Requirement describes User Types: usage of various user types as role management|1|1|1|0|0|0|0|0|0|0|0| \nIf Requirement describes Store: actions related to storage and backup of the assets at rest, e.g., backing up \nlog files|0|0|0|1|0|1|1|0|0|1|0| \nIf Requirement describes Transfer: actions related to transfer or sharing of the assets, e.g., sending data \nfrom one service to another|0|0|0|0|0|1|1|1|0|0|1| \nIf Requirement describes Upload and Download Files etc. operation|1|1|1|1|0|1|0|1|1|1|1| \nIf Requirement describes operation on sensitive data like personal, financial, health etc|1|0|1|1|1|0|1|0|0|0|0| \n \n \n********* \nOutput (PSV- The requirements that are classified): \nWe need each requirement response in given format below within new line separator: \n<Requirement Number>|<Requirement \nDescription>|<V2>|<V3>|<V4>|<V5>|<V6>|<V7>|<V8>|<V9>|<V10>|<V12>|<V13>|<Explanation> format. \nand will contain: \n   - Requirement Number (integer) \n   - Requirement Description (string)', 'CONTEXT: **Evaluation of LLMs and Fine-Tuned Models for Implicit Security Requirements Classification**: This chunk discusses the challenges and performance of LLMs and fine-tuned BERT models in classifying implicit security requirements, particularly for minority OWASP ASVS categories, highlighting the limitations of static few-shot prompting and the potential of automated tools to support ""Security by Design"" and ""Shift-Left"" strategies in software development.\n\nCONTENT: Implicit Security Requirements Classification 35\nexplicitly stated as a functional transaction, our domain experts classified this\nrequirement across nearly all OWASP ASVS categories. In an industrial con-\ntext, an “asset handover” implies a legally binding transfer of custody, ne-\ncessitating Authentication (V2) and Access Control (V4) to verify identity\nand authority, Data Protection (V8) for non-repudiation, and Secure Logging\n(V7) for auditability. A purely keyword-based or explicit extraction approach\nwould likely miss these dependencies, leaving the module vulnerable. Our find-\nings demonstrate that LLMs, when prompted with few-shot examples, can\neffectively mimic this expert reasoning, bridging the gap between functional\nspecifications and security compliance.\nWhile the ASRD dataset accurately reflects the natural distribution of se-\ncurity requirements in industrial projects, the performance drop on minority\nclasses reveals distinct limitations across the two model architectures eval-\nuated. For the LLMs, the limitation lies in the rigidity of Static Few-Shot\nPrompting. Our results indicate that providing a fixed set of 1–3 examples\n(Few-Shot) yielded inconsistent gains and, in cases like Llama-3 on V12, ac-\ntually degraded performance compared to Zero-Shot. This suggests that “im-\nplicit” requirements for minority classes are highly context-dependent. A fixed\nexample of V12 related to “file upload” does not help the LLM identify a V12\nrequirement related to “directory traversal.” Consequently, the models fail to\ngeneralize the concept of the minority class from static prompts, leading to\nthe low F1-scores (0.077–0.172) observed. This confirms that for rare, high-\nvariance security classes, static prompting is insufficient.\nOur study found that while fine-tuned BERT models provide strong results\n(up to 0.942 Macro-F1), few-shot prompting with a top-tier LLM like Gemini\n2.0 can achieve nearly identical performance (0.941 Macro-F1). This supports\nthe growing body of literature suggesting that in-context learning with large\nmodels can close the performance gap with task-specific fine-tuning, often\nwith significantly less labeled data. This shift from a traditional “pre-train,\nfine-tune” to a “pre-train, prompt, and predict” paradigm, as surveyed by\nLiu et al. (Liu et al., 2023a), offers a more agile and resource-efficient path\nfor deploying NLP solutions in specialized industrial contexts. Our results\nprovide a concrete example of this trend within the SRE domain and align\nwith findings given by Karlsson et.al (Karlsson et al., 2025).\nThese findings have immediate implications for the software industry, par-\nticularly in implementing “Security by Design” and “Shift-Left” strategies. In\ndiverse development environments—ranging from Agile teams to regulated sec-\ntors like healthcare or defense—developers often lack deep security expertise.\nThey focus on writing functional requirements (SRS) to meet business needs,\noften assuming security will be “added on” later. By automating the classi-\nfication of implicit security requirements using the method proposed in this\nstudy, organizations can instantly map functional specs to actionable OWASP\nASVS controls before a single line of code is written. Rather than replacing\nhuman oversight, this approach functions as a human-in-the-loop productiv-\nity multiplier. It serves as a sophisticated pre-screening tool that drastically\nspeeds up the initial analysis phase, allowing scarce cybersecurity experts to', ""CONTEXT: This chunk provides examples of system requirements from a Software Requirements Specification (SRS) document and their classification into OWASP ASVS security categories (V2–V13), along with corresponding security analyses and recommendations, demonstrating the application of the ASRD dataset and classification models discussed in the document.\n\nCONTENT: sonlandıracaktır.|0|1|0|0|0|1|0|0|0|0|0| Session Management (V3), Debugging and Logging (V7):  Session \ntimeouts enhance security and should be logged. \nAnalysis & Recommendations:  Enforce session timeouts to prevent unauthorized access from unattended \nsessions.  Log session termination events for security monitoring. \n \n27|Sistem, çerez kullanımında gerekli tüm güvenlik ayarlarının uygulanmasını zorunlu \nkılacaktır.|0|1|0|0|0|1|1|0|0|0|0| Session Management (V3), Debugging and Logging (V7), Data Protection \n(V8): Secure cookie handling is crucial for protecting user sessions. \nAnalysis & Recommendations:  Use secure cookies with the HttpOnly flag.  Encrypt sensitive data stored in \ncookies.  Implement proper cookie expiration policies. \n \n28|Sistem, kullanıcıların en az yetki prensibine göre işlem yapabilmesini sağlayacaktır.|1|1|1|0|0|1|0|0|0|0|0| \nIdentity Verification (V2), Session Management (V3), Access Controls (V4), Debugging and Logging (V7):  \nEnforcing least privilege requires proper authentication, authorization, and logging. \nAnalysis & Recommendations:  Implement role-based access control (RBAC) to manage user permissions \neffectively.  Regularly review and update user permissions. \n \n29|Sistem, kullanıcı hareketlerinin kaydını tutacaktır.|1|1|1|0|0|1|0|0|0|0|0| Identity Verification (V2), \nSession Management (V3), Access Controls (V4), Debugging and Logging (V7): User activity logging is \ncrucial for security auditing and incident response. \nAnalysis & Recommendations:  Log user actions with sufficient detail for security analysis.  Protect log files \nfrom unauthorized access and modification. \n \n30|Sistemde kullanılan eklentilerin güvenlik doğrulaması yapılacaktır.|0|0|0|0|0|1|1|0|1|0|1| Debugging and \nLogging (V7), Data Protection (V8), Malicious Code (V10), Files and Resources (V12), API and Web \nServices (V13): Plugin security is crucial to prevent vulnerabilities. \nAnalysis & Recommendations:  Validate plugins before installation and use.  Regularly update plugins to \npatch security vulnerabilities.  Restrict plugin permissions to limit potential damage. \n********* \nOutput (PSV- The requirements that are classified): \nWe need each requirement response in given format below within new line separator: \n<Requirement Number>|<Requirement \nDescription>|<V2>|<V3>|<V4>|<V5>|<V6>|<V7>|<V8>|<V9>|<V10>|<V12>|<V13>|<Explanation> format. \nand will contain: \n   - Requirement Number (integer) \n   - Requirement Description (string) \n   - <V2> through <V13>: (either 1 (if the requirement aligns with the category) or 0 (if it doesn't)) \n   - Explanation (string) \n***** \nInput (PSV - The requirements you want to classify): \n1|Sistem, kullanıcının konaklama ücret tipi bilgilerini girmesini sağlayacaktır \n3|Sistem, kullanıcının konaklama ücret tipi bilgilerini silmesini sağlayacaktır \n5|Sistem, kullanıcının oda tiplerini güncellemesini sağlayacaktır \n16|Sistem, kullanıcının otele giriş nedeni bilgisini girmesini sağlayacaktır \n22|Sistem, kullanıcının çalışma tip bilgisini girmesini sağlayacaktır \n28|Sistem, kullanıcının otel rezervasyon para yatırma süre bilgisini girmesini sağlayacaktır \n31|Sistem, kullanıcının misafir türü kaydetmesini sağlayacaktır. \n37|Sistem, kullanıcının oda tiplerini listelemesini sağlayacaktır. \n41|Sistem, kullanıcının otele giriş neden bilgilerini listelemesini sağlayacaktır.\n\n44|Sistem, kullanıcının arananlar bilgisini listelemesini sağlayacaktır. \n52|Sistem, kullanıcının yakınlık tanım bilgisini seçilen kriterlere göre sorgulayabilmesini sağlayacaktır. \n54|Sistem, kullanıcının arananlar bilgisini seçilen kriterlere göre sorgulayabilmesini sağlayacaktır. \n55|Sistem, kullanıcının otel rezervasyon iptal süre bilgisini seçilen kriterlere göre sorgulayabilmesini \nsağlayacaktır. \n65|Sistem, kullanıcının otelin katlarındaki oda doluluk oranlarını seçilen kriterlere göre sorgulayabilmesini \nsağlayacaktır. \n70|Sistem, kullanıcının otel raporlarında kullanıcı imza bilgisi girmesini sağlayacaktır."", 'CONTEXT: **Overview of ASVS 4.0.3 Adoption and Security Classes**: This chunk discusses the widespread adoption of OWASP ASVS 4.0.3 as an industry-standard framework for application security verification, its use in various sectors, and the specific security classes included in the standard, highlighting the focus of the study on 11 of these classes.\n\nCONTENT: Implicit Security Requirements Classification 13\n(TRM) Guidelines. In the healthcare domain, Schmeelk and Tao (Schmeelk\nand Tao, 2022) conducted a case study on mobile health applications.\nAs of 2024–2025, commercial security platforms and verification tools con-\ntinue to offer native support for ASVS 4.0.3 compliance templates and map-\npings (Reqview, 2016; JIT.io, 2024), with requirement managers, compliance\ntracking systems, and automated security testing platforms (SAST/DAST) ex-\nplicitly designed around the 4.0.3 control structure. Multiple government and\nregulatory bodies, including the Moroccan government’s Directorate General\nfor Information Systems Security (DGSSI), have formally adopted ASVS 4.0.3\nas the basis for their national application security verification frameworks as\nof October 2024 (DGSSI, 2024).\nAt the time this study was designed and conducted (2023–2025), ASVS\n4.0.3 was the latest stable, officially released version of the standard. Version\n4.0.3, released in October 2021, had achieved widespread adoption and had\nbeen serving as the industry-standard reference for application security verifi-\ncation across finance, healthcare, technology, and government sectors for mul-\ntiple years. The ASVS 5.0 major revision was only released on 30 May 2025,\nafter the empirical work for this research had been substantially completed.\nTherefore, this research’s use of ASVS 4.0.3 represents both a temporally ap-\npropriate choice at the time of study design and a durable contribution to the\nliterature that will remain relevant and comparable with prior ASVS-based\nwork for years to come.\nThe standard includes 14 main security classes given in Table 3. For this\nstudy, only 11 classes (V2–V10, V12-V13) were used. V1, V11, and V14 were\nexcluded as they are not inferable from functional or non-functional require-\nments. Each requirement can be mapped to more than one classes.\nTable 3: OWASP ASVS 4.0.3 Classes\nClass Id Class Name Definition\nV1 Architecture, Design and\nThreat Modeling\nThis class focuses on the security of the\napplication’s architecture, component\ndesign, and the process of identifying\nand mitigating threats throughout the\ndevelopment lifecycle.\nV2 Authentication This class deals with verifying the\nidentity of users, services, or applica-\ntions, ensuring that only authorized\nentities can access specific functionali-\nties or data.\nV3 Session Management This class covers the secure manage-\nment of user sessions, from creation\nto termination, including protection of\nsession identifiers and prevention of\nsession-related attacks.\nV4 Access Control This class ensures that users can only\naccess the data and functions for which\nthey are explicitly authorized, enforc-\ning the principle of least privilege.', 'CONTEXT: **Security Considerations for Legal File Type Management in SRS**: This chunk outlines security requirements and recommendations for managing legal file types within a system, including actions like registration, updating, deletion, and querying, mapped to OWASP ASVS categories and emphasizing best practices such as access control, input validation, secure communication, and logging.\n\nCONTENT: Verification, Cleaning, and Encryption (V5):  Recording the ""hukuk dosyası türü"" (legal file type) likely \ninvolves validation and data integrity checks to ensure the information is accurate and complete. \nDebugging and Logging (V7): Logging this action is important for auditing and security monitoring \npurposes, allowing for tracking of who registered what file type and when. \nData Protection (V8):  The stored file type data should be protected with appropriate security measures, \nsuch as encryption or access controls, to prevent unauthorized access or modification. \nCommunication (V9): Secure communication is needed if the registration action involves data transfer over \na network to protect the confidentiality and integrity of the data. \nMalicious Code (V10): Input validation should be implemented to prevent malicious code injection, \nensuring that the file type input is properly sanitized and does not contain any malicious scripts or \ncommands. \nFiles and Resources (V12): Secure file handling and storage procedures should be in place to protect the \nfiles and resources associated with the legal file type registration process. \nAPI and Web Services (V13): If an API is used for the registration process, appropriate security measures \nshould be implemented to protect the API endpoints and the data transmitted through the API. \nAnalysis & Recommendations:  The exact method for verifying user authorization needs to be defined to \nprevent privilege escalation. File type validation is crucial. Input sanitization is needed to avoid potential \ninjection attacks. \n \n2|Sistem, kullanıcının kullanılmamış hukuk dosyası türünü güncellemesini \nsağlayacaktır.|1|1|1|1|0|1|1|1|1|0|1| Similar to the previous example, this requirement involves identity \nverification (V2), session management (V3), access control (V4), verification and validation (V5), logging \n(V7), data protection (V8), secure communication (V9), protection against malicious code (V10), and file \nand resource management (V12). \nAnalysis & Recommendations: Version control or backups are necessary in case of accidental data \ncorruption during updates.  Consider implementing input validation for the new file data to ensure it meets \nrequirements and protect against injection attacks. \n \n3|Sistem, kullanıcının kullanılmamış olan hukuk dosyası türünü silmesini \nsağlayacaktır.|1|1|1|0|0|1|1|1|0|0|0| Identity verification (V2), session management (V3), and access control \n(V4) are needed to ensure only authorized users can delete file types. \nDebugging and Logging (V7): Logging deletion actions is essential for auditing and security monitoring. \nData Protection (V8):  Appropriate data protection measures, including potential backups or recovery \nmechanisms, should be in place to prevent accidental or malicious data loss. \nCommunication (V9):  Secure communication is vital if the deletion process involves transmitting data over \na network. \nAnalysis & Recommendations:  A soft delete (marking as deleted but not actually removing) is \nrecommended along with a process for permanently deleting files. Access control on who can permanently \ndelete needs careful configuration. \n \n4|Sistem, kullanıcının hukuk dosyası türlerini sorgulamasını ve listelemesini \nsağlayacaktır.|1|1|1|1|0|1|1|1|1|0|1| Identity Verification (V2), Session Management (V3), Access Controls \n(V4), Verification, Cleaning, and Encryption (V5), Debugging and Logging (V7), Data Protection (V8), \nCommunication (V9), Malicious Code (V10), Files and Resources (V12), API and Web Services (V13): \nStandard security practices apply to data retrieval as well as creation or modification. \nAnalysis & Recommendations: Protect against SQL injection and other query-based injection attacks by \nusing parameterized queries or prepared statements.  Careful definition of permissions regarding who can \nquery what is essential to prevent information leakage.']","The study categorized 'Asset Handover' requirements under Authentication (V2) and Access Control (V4) because these operations involve verifying the identity and authority of users to ensure that only authorized entities can perform the handover process. Authentication (V2) is necessary to confirm the identity of the user or entity initiating the handover, while Access Control (V4) ensures that the user has the appropriate permissions to access and transfer the asset. These categorizations align with the principles of security by design, emphasizing the need for identity verification and role-based access control to prevent unauthorized actions during legally binding transfers.

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","An asset handover implies a legally binding transfer of custody, which implicitly necessitates verifying identity (V2) and authority (V4) to ensure the action is valid[cite: 679].",,,
What is the 'Human-AI Collaborative Multi-Agent Framework' proposed for future work?,"['CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the', 'CONTEXT: Acknowledgments, Ethical Declarations, and Author Contributions: This chunk outlines the funding sources, ethical considerations, author contributions, and data availability related to the study, emphasizing transparency and the collaborative efforts behind the development of the ASRD dataset.\n\nCONTENT: 38 Yusuf G¨ ur et al.\nASRD into English. This initiative will involve a rigorous validation process by\nbilingual cybersecurity experts to ensure that the nuanced “implicit” security\ndependencies are accurately preserved across languages.\n9 Acknowledgement\nThe authors sincerely thank the subject matter experts for their valuable time\nand insight during the annotation process.\n10 Declarations\nFunding: This work has been funded by the Scientific and Technological\nResearch Council of T¨ urkiye (T¨UB˙ITAK), Scientist Support Programs Presi-\ndency (B˙IDEB), within the scope of the 2211-National Graduate Scholarship\nProgram.\nConflict of Interest/Competing Interests: The authors declare that\nthey have no known competing financial interests or personal relationships\nthat could have appeared to influence the work reported in this paper.\nEthical Approval: This study did not involve human participants, clinical\ntrials, or personal data, and therefore did not require formal approval from an\ninstitutional ethics committee. The subject matter experts contributed solely\nin their professional capacity to the annotation process.\nInformed Consent: Informed consent was not applicable as no human\nparticipants were involved. The subject matter experts participated in their\nprofessional capacity and provided voluntary contributions.\nAuthor Contributions: Yusuf G¨ ur conceptualized and designed the study,\nincluding data collection and analysis. Tu˘ gba Ta¸ skaya Temizel contributed to\nformulating research questions and supervising methodological and computa-\ntional aspects. Banu G¨ unel Kılı¸ c provided oversight on the broader scientific\nnarrative and its positioning in the field. All authors contributed to manual\nverification, manuscript drafting, and approval of the final version.\nData Availability Statement: The dataset used in this study is publicly\navailable on Figshare18 and can be accessed freely via the provided link.\nClinical Trial Number: Not applicable.\nReferences\nAbbasi MA, Ihantola P, Mikkonen T, M¨ akitalo N (2025) Towards human-ai\nsynergy in requirements engineering: A framework and preliminary study.\nIn: 2025 Sixth International Conference on Intelligent Data Science Tech-\nnologies and Applications (IDSTA), IEEE, pp 81–88\n18 https://figshare.com/s/671a40aaa1f23c33ddcb', 'CONTEXT: This chunk provides references and citations related to foundational works, recent advancements, and technical reports in security requirements engineering, AI-driven classification models, and the application of OWASP ASVS, supporting the broader discussion on automating security requirements classification using AI and LLMs.\n\nCONTENT: 40 Yusuf G¨ ur et al.\nDevlin J, Chang MW, Lee K, Toutanova K (2019) Bert: Pre-training of deep\nbidirectional transformers for language understanding. In: Proceedings of\nthe 2019 conference of the North American chapter of the association for\ncomputational linguistics: human language technologies, volume 1 (long and\nshort papers), pp 4171–4186\nDGSSI (2024) Application security verification frame-\nwork.https://www.dgssi.gov.ma/en/publications/\napplication-security-verification-framework, accessed 2025-12-\n08\nGoldberg Y, Kozareva Z, Zhang Y (2022) Proceedings of the 2022 conference\non empirical methods in natural language processing. In: Proceedings of the\n2022 Conference on Empirical Methods in Natural Language Processing\nGoogle DeepMind (2025a) Gemini 2.0: Advancements in large-scale multi-\nmodal models. Tech. rep., Google, hypothetical source for forthcoming\nmodel series.\nGoogle DeepMind (2025b) Technical report for gemini 2.5 series. Tech. rep.,\nGoogle, hypothetical source for forthcoming model series.\nHey T, Keim J, Koziolek A, Tichy WF (2020) Norbert: Transfer learning for\nrequirements classification. In: 2020 IEEE 28th international requirements\nengineering conference (RE), IEEE, pp 169–179\nHopkins P, Unger M (2017) What is a subject-matter expert? Journal of\nPipeline Engineering 16(4)\nInfrastructure PK, Profile TP (2002) Common criteria for information tech-\nnology security evaluation. National Security Agency\nJeong C (2024) Domain-specialized llm: Financial fine-tuning and utilization\nmethod using mistral 7b. Journal of Intelligence and Information Systems\n30(1):93–120, DOI 10.13088/jiis.2024.30.1.093, URLhttp://dx.doi.org/\n10.13088/jiis.2024.30.1.093\nJindal R, Malhotra R, Jain A (2016) Automated classification of security re-\nquirements. In: 2016 International Conference on Advances in Computing,\nCommunications and Informatics (ICACCI), IEEE, pp 2027–2033\nJITio (2024) How to use owasp asvs to protect web applica-\ntions.https://www.jit.io/resources/security-standards/\nowasp-asvs-to-protect-web-applications, accessed 2025-12-08\nKadebu P, Sikka S, Tyagi RK, Chiurunge P (2023) A classification approach\nfor software requirements towards maintainable security. Scientific African\n19:e01496\nKarhu K, Kasurinen J, Smolander K (2025) Expectations vs reality–\na secondary study on ai adoption in software testing. arXiv preprint\narXiv:250404921\nKarlsson F, Chatzipetrou P, Gao S, Havstorm TE (2025) How reliable are gpt-\n4o and llama3. 3-70b in classifying natural language requirements? IEEE\nSoftware\nKhan R, McLaughlin K, Laverty D, Sezer S (2017) Stride-based threat mod-\neling for cyber-physical systems. In: 2017 IEEE PES Innovative Smart Grid\nTechnologies Conference Europe (ISGT-Europe), pp 1–6, DOI 10.1109/', 'CONTEXT: ""References and Related Work on Security Requirements Engineering and AI Applications"" – This chunk provides a list of references and prior research studies that underpin the advancements discussed in the document, focusing on security requirements engineering, AI-driven classification methods, and the application of LLMs in software development and compliance tasks.\n\nCONTENT: Implicit Security Requirements Classification 41\nISGTEurope.2017.8260283\nKhan RA, Akbar MA, Rafi S, Almagrabi AO, Alzahrani M (2024) Evaluation\nof requirement engineering best practices for secure software development in\ngsd: An ism analysis. Journal of Software: Evolution and Process 36(5):e2594\nKnauss E, Houmb S, Schneider K, Islam S, J¨ urjens J (2011) Supporting re-\nquirements engineers in recognising security issues. In: International Work-\ning Conference on Requirements Engineering: Foundation for Software Qual-\nity, Springer, pp 4–18\nLabrak Y, Rouvier M, Dufour R (2023) A zero-shot and few-shot study of\ninstruction-finetuned large language models applied to clinical and biomed-\nical tasks. arXiv preprint arXiv:230712114\nLima M, Valle V, Costa E, Lira F, Gadelha B (2019) Software engineering\nrepositories: expanding the promise database. In: Proceedings of the XXXIII\nBrazilian Symposium on Software Engineering, pp 427–436\nLiu P, Yuan W, Fu J, Jiang Z, Hayashi H, Neubig G (2023a) Pre-train, prompt,\nand predict: A systematic survey of prompting methods in natural language\nprocessing. ACM computing surveys 55(9):1–35\nLiu Y, Zhang H, Chen X (2023b) Large language models for requirements\nclassification: Zero-shot and few-shot approaches. In: Proceedings of the\n2023 IEEE International Requirements Engineering Conference (RE), IEEE,\npp 45–56, DOI 10.1109/RE.2023.00012\nLiu Z, Wang H, Xu T, Wang B (2025) Rag-driven multiple assertions genera-\ntion with large language models. Empirical Software Engineering 30(3):105\nLoshchilov I, Hutter F (2019) Decoupled weight decay regularization. arXiv\npreprint arXiv:171105101 URLhttps://arxiv.org/abs/1711.05101\nMann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P, Neelakantan A, Shyam\nP, Sastry G, Askell A, Agarwal S, et al. (2020) Language models are few-shot\nlearners. arXiv preprint arXiv:200514165 1(3):3\nMasoudifard A, Sorond MM, Madadi M, Sabokrou M, Habibi E (2024) Lever-\naging graph-rag and prompt engineering to enhance llm-based automated\nrequirement traceability and compliance checks. URLhttps://arxiv.org/\nabs/2412.08593,2412.08593\nMaturi A, Alshammari R, Alqahtani F, Alqahtani M (2025) Detecting reen-\ntrancy vulnerabilities for solidity smart contracts with bidirectional lstm and\nexplainable ai. In: 2025 IEEE International Conference on Blockchain and\nCryptocurrency (ICBC), IEEE, pp 1–8, DOI 10.1109/ICBC.2025.10926491,\nURLhttps://ieeexplore.ieee.org/document/10926491\nMuresan S, Nakov P, Villavicencio A (2022) Proceedings of the 60th annual\nmeeting of the association for computational linguistics (volume 1: Long\npapers). In: Proceedings of the 60th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers)\nNecula SC, Fotache D, Rieder E (2024) Assessing the impact of artificial in-\ntelligence tools on employee productivity: insights from a comprehensive\nsurvey analysis. Electronics 13(18):3758\nOpenAI (2025) GPT-4o mini: Advancing cost-\neffective intelligence.https://openai.com/index/', 'CONTEXT: This chunk discusses the challenges of identifying implicit security requirements in software requirements engineering (SRE), emphasizing the limitations of existing datasets and the need for AI-driven NLP methods, while highlighting the role of the OWASP ASVS framework in addressing these gaps through standardized security practices.\n\nCONTENT: Implicit Security Requirements Classification 3\n“The system will allow the user to print documents,” carries numerous implicit\nsecurity needs, including verifying user authorization, maintaining a valid ses-\nsion, and recording the action for accountability. These concerns correspond\nto common security control areas, such as access control, session management,\nand logging. This complexity requires substantial guidance. Manually iden-\ntifying and validating this network of implicit security dependencies across\nthousands of requirements is error prone, inconsistent, and not scalable (Ye\net al., 2025).\nGiven the limitations of manual SRA, automation through Artificial In-\ntelligence (AI) based Natural Language Processing (NLP) methods, offers a\npromising path forward. Although AI based approaches for RE have received\ngrowing attention (Abbasi et al., 2025; Zadenoori et al., 2025), recent evidence\nshows a gap between experimental advances and validated industrial solutions.\nFor example, an analysis of 74 primary studies found that most AI based tools\nare evaluated in controlled settings, with limited industrial adoption and weak\nintegration into real workflows (Bolanos et al., 2024). Similarly, another study\nreports a clear mismatch between expectations and practical outcomes in SRE\nin real world use (Karhu et al., 2025).\nThe main problem is the lack of suitable data, not the availability of ef-\nfective modeling approaches. The development and validation of data driven\napproaches is constrained by the scarcity and limited quality of domain spe-\ncific datasets (Wang et al., 2024; Zadenoori et al., 2025). This concern ex-\ntends beyond SRE, as leading NLP venues highlight dataset limitations that\nmake reliable evaluation difficult (Muresan et al., 2022; Goldberg et al., 2022;\nChristodoulopoulos et al., 2025).\nThis challenge is especially evident in SRE. Identifying implicit security\nrequirements relies on large collections of functional requirements annotated\nby security experts to reflect underlying security concerns. Current datasets do\nnot meet this need. For instance, PROMISE exp (Lima et al., 2019) includes\nonly a single, high-level security category; DOSSPRE (Kadebu et al., 2023)\nis based on student projects and lacks industry realism; and the Healthcare\ndataset (Riaz et al., 2014) is limited to a narrow domain and uses coarse-\ngrained labels. As a result, existing resources offer limited support for devel-\noping and evaluating methods aimed at uncovering implicit security require-\nments.\nThe OWASP Application Security Verification Standard (ASVS)1 offers a\nstandardized, systematic, and verifiable framework for defining and evaluating\napplication security controls. ASVS emphasizes the principle of “security by\ndesign” by facilitating the integration of security considerations early in the\nsoftware development lifecycle. Its comprehensive set of requirements can be\ndirectly mapped to verifiable test cases and secure coding practices, ensuring\ntraceability throughout the development process. This approach enables the\nearly identification and remediation of vulnerabilities, which is both more effi-\n1 https://owasp.org/www-project-application-security-verification-standard/', ""CONTEXT: This chunk provides references and citations to prior research, tools, and frameworks relevant to Security Requirements Engineering (SRE), including studies on OWASP ASVS, generative AI applications, BERT models, and secure software development practices, supporting the document's focus on advancing AI-driven security requirement classification.\n\nCONTENT: 42 Yusuf G¨ ur et al.\ngpt-4o-mini-advancing-cost-effective-intelligence/\nPustejovsky J, Stubbs A (2012) Natural Language Annotation for Machine\nLearning: A guide to corpus-building for applications. ” O’Reilly Media,\nInc.”\nRajbhoj A, Somase A, Kulkarni P, Kulkarni V (2024) Accelerating software\ndevelopment using generative ai: Chatgpt case study. In: Proceedings of the\n17th innovations in software engineering conference, pp 1–11\nReqview (2016) Owasp application security verification standard (asvs) tem-\nplate.https://www.reqview.com/doc/asvs-template/, accessed 2025-12-\n08\nRiaz M, Williams L (2012) Security requirements patterns: understanding the\nscience behind the art of pattern writing. In: 2012 Second IEEE Interna-\ntional Workshop on Requirements Patterns (RePa), IEEE, pp 29–34\nRiaz M, King J, Slankas J, Williams L (2014) Hidden in plain sight: Automat-\nically identifying security requirements from natural language artifacts. In:\n2014 IEEE 22nd international requirements engineering conference (RE),\nIEEE, pp 183–192\nRonanki K, Cabrero-Daniel B, Horkoff J, Berger C (2024) Requirements engi-\nneering using generative ai: Prompts and prompting patterns. In: Generative\nAI for effective software development, Springer, pp 109–127\nSchmeelk S, Tao L (2022) A case study of mobile health applications: the\nowasp risk of insufficient cryptography. Journal of Computer Science Re-\nsearch 4(1):22–31\nSchweter S (2020) T¨ urkische BERT modelle. DOI 10.5281/zenodo.4158499,\nURLhttps://doi.org/10.5281/zenodo.4158499\nSommerville I, Sawyer P (1997) Requirements engineering: a good practice\nguide. John Wiley & Sons, Inc.\nSouppaya M, Scarfone K, Dodson D (2022) Secure software development\nframework (ssdf) version 1.1. NIST Special Publication 800(218):800–218\nSubahi AF (2023) Bert-based approach for greening software requirements\nengineering through non-functional requirements. IEEE Access 11:103001–\n103013\nTan V, Cheh C, Chen B (2021) From application security verification standard\n(asvs) to regulation compliance: A case study in financial services sector. In:\n2021 IEEE International Symposium on Software Reliability Engineering\nWorkshops (ISSREW), IEEE, pp 69–76, DOI 10.1109/ISSREW53611.2021.\n00046\nThe Google Gemma Team (2025) Gemma 3: Next-generation open models\nfor responsible ai. Tech. rep., Google, hypothetical source for forthcoming\nmodel series.\nVillamizar H, Kalinowski M, Viana M, Fern´ andez DM (2018) A systematic\nmapping study on security in agile requirements engineering. In: 2018 44th\nEuromicro conference on software engineering and advanced applications\n(SEAA), IEEE, pp 454–461\nWang F, Harker A, Edirisinghe M, Parhizkar M (2024) Tackling data scarcity\nchallenge through active learning in materials processing with electrospray."", 'CONTEXT: This chunk discusses the curation and preprocessing of the ASRD dataset, detailing the data collection process from real-world Software Requirements Specification (SRS) documents, the multi-stage preprocessing pipeline for sentence extraction and anonymization, and how the dataset addresses gaps in prior work by incorporating industrial complexity and linguistic diversity.\n\nCONTENT: Implicit Security Requirements Classification 9\n2.3.3 Electronic Health Domain Dataset\nThis corpus focuses on the electronic healthcare industry, a sector defined\nby stringent regulatory and high-assurance demands (Riaz et al., 2014). The\ndataset’s strength lies in its rigorous multi-stage annotation methodology,\nwhich utilized independent researchers and a mediator to ensure high inter-\nannotator agreement. While it provides a large-scale, authentic resource for\nhealthcare-specific tasks, its narrow focus may limit the generalizability of\nmodels to other industries, and its high-level security objectives may be too\ncoarse for detailed technical analysis.\n2.3.4 Summary of Datasets\nAs summarized in Table 1, these datasets vary significantly in their suitability\nfor tasks ranging from general non-functional requirement (NFR) classifica-\ntion to detailed security analysis. Our proposed Agency Security Require-\nments Dataset (ASRD) addresses gaps in prior work by adopting the OWASP\nASVS taxonomy for multi-label annotation. Furthermore, by utilizing real-\nworld projects originally written in Turkish, ASRD introduces both industrial\ncomplexity and linguistic diversity to the field.\n3 Dataset Curation, Annotation, and Evaluation\n3.1 Data Collection and Preprocessing\nThe dataset compilation began with the collection of six Software Require-\nments Specification (SRS) documents from an Agency’s Security Department.\nThese documents were selected from an initial pool of 19 projects executed\nbetween 2019 and 2023, specifically chosen for their domain diversity and\namenability to effective anonymization. The original documents were provided\nin standard document formats (e.g., PDF, DOCX) where requirements were\norganized in itemized lists. To transform these documents into a machine-\nreadable dataset, we employed a multi-stage preprocessing pipeline:\n1. Sentence Segmentation and Extraction: As the source SRS documents uti-\nlized standard itemization for requirements, we employed a rule-based ex-\ntraction method. We utilized pattern matching to identify requirement\nblocks based on hierarchical numbering schemes and line breaks. Each iden-\ntified requirement was extracted and treated as a single processing unit,\npreserving the structural integrity of the original specification.\n2. Anonymization: To protect sensitive data, a semi-automated anonymiza-\ntion process was implemented. Custom scripts replaced entities such as\nproject names, specific URLs, and IP addresses with generic placeholders.\nThis was followed by a manual review by domain experts to ensure that\nthe removal of personally identifiable information (PII) did not compromise\nthe semantic meaning or contextual integrity of the requirements.', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference']","The 'Human-AI Collaborative Multi-Agent Framework' proposed for future work is a system designed to enhance the classification of security requirements by integrating human expertise with AI-driven automation. This framework involves multiple agents working collaboratively:

1. **Retrieval-Augmented Agent**: Dynamically selects the most relevant annotated requirements using semantic similarity, replacing static few-shot examples. This ensures the AI is grounded in contextually appropriate standards, such as OWASP ASVS.

2. **Classification Confidence Agent**: Assesses the confidence and consistency of classifications, flags ambiguous or high-risk cases, and requests clarifications from human experts when necessary.

3. **Supervisor Agent**: Consolidates inputs from the retrieval and classification agents, ensuring final labels align with the OWASP ASVS taxonomy and the broader project context.

4. **Optimization Agent**: Learns from human interventions to refine retrieval strategies and prompting over time, reducing manual effort while improving accuracy on challenging security requirements.

This framework aims to address challenges like data sparsity and improve the classification of rare security requirements by combining automated processes with targeted human oversight. It is particularly suited for handling ambiguous or high-risk cases, ensuring consistency and accuracy in security requirement classification.

**Source**: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf","It is a framework combining automated classification with expert oversight, where agents retrieve relevant requirements, assess confidence, and flag unclear cases for human clarification[cite: 729, 730].",,,
What method is proposed to improve the evaluation of model generalizability in future studies?,"['CONTEXT: **Future Directions for Enhancing Security Requirements Classification**: This chunk outlines proposed advancements, including dynamic few-shot selection with retrieval-augmented generation (RAG), human-AI collaborative frameworks, and synthetic data injection, to address challenges like data sparsity and improve the classification of rare security requirements in SRE.\n\nCONTENT: Implicit Security Requirements Classification 37\ntime. This approach effectively substitutes the need for dense in-context ex-\namples with explicit external standards, ensuring accurate classification for\nrare security events where traditional fine-tuning or few-shot prompting fails.\nConsequently, this study suggests that future NLP research in SRE cannot\nrely solely on organic dataset expansion. To overcome this inherent sparsity,\nwe propose as future work three targeted algorithmic advancements:\n1. Dynamic Few-Shot Selection with Retrieval-Augmented Generation (RAG):\nSystems might dynamically retrieve the explicit definitions and verifica-\ntion criteria from standards like OWASP ASVS to ground their classifi-\ncation of rare requirements. Future work should implement RAG for Dy-\nnamic Prompting in agentic approach. Instead of fixed examples, a retriever\nshould select thekmost semantically similar valid requirements from the\ntraining set to serve as in-context examples for the specific query. This\nensures the LLM is grounded with relevant architectural patterns (e.g.,\n“encryption” vs. “hashing”) rather than generic class examples.\n2. Human-AI Collaborative Multi-Agent Framework: A promising direction\nfor future work is a Human-in-the-Loop multi-agent framework that com-\nbines automated classification with targeted expert oversight for ambigu-\nous or high-risk cases. In this setup, a retrieval-augmented agent would\ndynamically select the most relevant annotated requirements using seman-\ntic similarity, replacing static few-shot examples. A second agent would\nassess classification confidence and consistency, flagging unclear cases and\nrequesting focused clarifications from a human expert when needed. A su-\npervisor agent would then consolidate these inputs and ensure that the\nfinal labels remain consistent with the OWASP ASVS taxonomy and the\nbroader project context. In parallel, an optimization agent would learn from\nhuman interventions to refine retrieval strategies and prompting over time,\nreducing manual effort while improving accuracy on challenging security\nrequirements.\n3. Synthetic Data Injection (for Supervised Models): To address the sparsity\nhindering BERT-based fine-tuning, we recommend a Teacher-Student Data\nGeneration loop. High-reasoning LLMs (e.g., GPT-4o, Gemini 2.5 Pro)\nshould be used to generate diverse synthetic requirements that implicitly\ntrigger V6/V12 classifications. These synthetic samples can populate the\ntraining set, allowing smaller supervised models (BERT) to learn robust\ndecision boundaries without requiring expensive manual annotation.\nAdditionally, future efforts should include a more stringent evaluation of\nmodel generalizability using a leave-one-project-out cross-validation approach.\nThis method involves training a model on requirements from five of the projects\nand testing it on the single, held-out project. Repeating this process for all six\nprojects would provide a much clearer and more realistic assessment of how\nwell these models perform on entirely new, unseen SRS documents, which is\na significant measure for real-world applicability.\nFurthermore, to bridge the gap between our current findings and the global\nresearch community, we plan to undertake a professional translation of the', 'CONTEXT: **Exploration of Class Imbalance and Future Directions in SRE Automation**: This chunk discusses the challenges of class imbalance in security requirements engineering (SRE), the impact of few-shot prompting on model performance, and outlines future work, including hybrid approaches like retrieval-augmented generation (RAG) and agent-based strategies to improve classification of underrepresented security classes.\n\nCONTENT: 36 Yusuf G¨ ur et al.\nfocus their efforts on high-risk adjudication rather than manual discovery. Our\nresults suggest that commercially available LLMs can serve as always-available\nassistants, democratizing high-level security analysis for development teams.\nFurthermore, future studies could investigate the impact of this tool on prac-\ntitioners with varying levels of experience. Specifically, research is needed to\ndetermine if such automation allows junior developers to identify security con-\ncerns more accurately or if it primarily eases the cognitive load for senior\nexperts by filtering out routine classifications.\nThis study highlights class imbalance as a persistent challenge in SRE.\nThe issue is not specific to ASRD but reflects the nature of the domain itself.\nIn typical specifications, references to architectural security concerns such as\ncryptographic storage or low-level file handling, occur far less often than user-\nfacing controls like authentication (V2) or access control (V4). This creates\na “long-tail” distribution where the most important security failures often\nreside in the least represented classes. Standard supervised learning and even\nfew-shot prompting struggle to generalize from such limited examples. This is\na well-documented issue in requirements datasets, including benchmarks like\nPROMISE exp (Lima et al., 2019), which also suffers from imbalanced classes.\nThe improvement from zero-shot to few-shot prompting shows the positive\nimpact of adding in-context examples. For example, Gemma 4b’s F1 score on\nclass V5 rose from 0.709 to 0.814 with only a small number of examples. This\ngain shows how limited, well-chosen examples can steer model behavior toward\nthe intended classification task. Similar observations have been reported in\nprior work across domains, where prompt design and example selection were\nshown to play a decisive role in task performance (Mann et al., 2020; Liu et al.,\n2023a).\n8 Conclusion and Future Work\nThis work examined the feasibility of automated security requirements classi-\nfication under realistic conditions, where requirements are implicit, unevenly\ndistributed across categories, and drawn from industrial settings rather than\ncurated benchmarks. By introducing ASRD and evaluating supervised and\nprompt-based methods on a shared benchmark, this work enables direct com-\nparison across approaches. The results show that few-shot prompting is suit-\nable when labeled data is limited, while fine-tuned models are better at han-\ndling rare security requirements.\nAs a future work, we plan to explore hybrid SRE approaches that combine\nLLMs with retrieval and agent-based components. In particular, improving\nperformance on underrepresented classes remains an open problem and may\nbenefit from targeted data augmentation, retrieval-augmented methods (RAG)\nsuch as those proposed by Liu et al. (Liu et al., 2025), or agent-based strategies.\nFor instance, instead of relying on learned patterns from non-existent training\nexamples, a RAG-enabled system can dynamically retrieve the specific veri-\nfication requirements and definitions relevant to the input text at inference', 'CONTEXT: **Analysis of Minority Class Performance and Annotation Challenges in SRE**: This chunk discusses the performance gap between majority and minority security classes in SRE, the expert-driven annotation process using the MATTER cycle, and the measures taken to mitigate subjectivity and ensure realistic, industry-relevant model evaluation.\n\nCONTENT: 32 Yusuf G¨ ur et al.\nFig. 4:Minority vs. Majority Class Performance Gap.A comparative\nanalysis revealing that while advanced LLMs and fine-tuned models achieve\nnear-parity on Majority Classes (Blue), a significant performance gap remains\non Minority Classes (Red), underscoring the “Long Tail” challenge in SRE.\nAnnotation was performed by three experienced cybersecurity experts.\nWhile their domain knowledge ensured quality, the small annotator pool may\nintroduce subjective bias and limit the range of interpretations. This was mit-\nigated through the iterative MATTER cycle which includes training, iterative\nguideline refinement, and consensus-based adjudication.\nA key threat to internal validity is subjectivity as classifications rely heavily\non the latent domain knowledge and industry experience, rather than explicit\nindicators within the requirement text itself. This expert-driven approach pro-\nvides a “gold standard” for realistic industrial needs but it may introduce in-\nconsistencies if replicated by annotators with different backgrounds or if the\nbroader system context is not explicitly documented.\nThe test set was manually selected to balance computational efficiency and\ngeneralizability assessment. While cross-validation could improve test calibra-\ntion, it was avoided due to its high computational cost.\nTo minimize researcher bias and ensure the results reflect real-world in-\ndustry needs, domain experts used for the selection of both the test set and\nthe LLM suite. Rather than selecting data or models arbitrarily, these experts\ncurated a test set containing the most complex, “implicit” security scenarios\nto challenge the models beyond simple pattern matching. For the model suite,\nthey prioritized architectures with advanced reasoning capabilities, hypothe-\nsizing that these specific technical features are essential for the multi-step de-\nduction required in security requirements engineering. Although the experts', 'CONTEXT: This chunk discusses the challenges and methodologies involved in annotating the ASRD dataset, the use of experimental LLMs for implicit security requirements classification, and the trade-offs between dataset curation effort and model performance, highlighting the advantages of fine-tuned BERT models and emerging LLM reasoning capabilities.\n\nCONTENT: Implicit Security Requirements Classification 33\nlacked prior experience in Natural Language Processing (NLP) annotation,\nthis was addressed through focused training sessions to align their domain\nexpertise with the technical requirements of the MATTER cycle.\nVariations in model versions and dependencies (e.g., library updates) pose\nchallenges to reproducibility.\nA significant class imbalance, with categories like V6 and V12 severely\nunderrepresented, restricts model learning and generalization. To address this,\nextensive training, refined annotation protocols, iterative consensus-building,\nand detailed error analysis were employed.\nA significant challenge in evaluating Large Language Models (LLMs) is the\nrapid pace of model iteration. In this study, we deliberately selected several\n“experimental” and “preview” models (specifically gemini-2.0-flash-thinking-\nexp-01-21, gemini-2.0-pro-exp-02-05, and gemini-2.5-flash-preview-04-17) along-\nside stable releases. The rationale for including these unversioned, experi-\nmental models was to benchmark the absolute state-of-the-art capabilities in\n“reasoning” (Chain-of-Thought) and architectural efficiency that are not yet\npresent in General Availability (GA) versions at the time of the study. We\nhypothesized that the improved reasoning capabilities of models like Flash-\nThinking would be particularly advantageous for identifying implicit security\nrequirements, which often require multi-step deduction rather than simple pat-\ntern matching.\nHowever, we acknowledge that the use of experimental endpoints poses a\nthreat to internal validity regarding reproducibility. These models are subject\nto deprecation or unannounced updates by the provider, meaning other re-\nsearchers may not be able to query the exact same model weights in the future.\nTo mitigate this, we have documented the exact model identifier strings used\nduring our data collection window. While this does not guarantee future ac-\ncess to these specific snapshots, it ensures transparency regarding the specific\ntechnological generation evaluated. We argue that this trade-off is necessary\nto provide a forward-looking analysis of how emerging LLM capabilities (such\nas intrinsic reasoning) impact the field of Security Requirements Engineering.\n7 Discussion\nThe combined experimental results obtained from fine-tuning BERT models\nand employing various LLM prompting strategies, further refined by the com-\nparison between zero-shot and few-shot methods, yield several key insights.\nAn important dimension of our comparison is the trade-off between the ef-\nfort required to curate the dataset and the resulting classification performance.\nAs detailed in Section 3, the construction of the ASRD involved 267 person-\nhours of expert labor to annotate 2,652 requirements. This extensive effort\nwas a prerequisite for the fine-tuned BERT models, which rely on large-scale\nsupervised data.\nAs summarized in Table 9, the BERT Fine-Tuning approach achieved the\nhighest performance (Macro-F1 0.942) but at the highest cost. In contrast, the', 'CONTEXT: **Advancements in LLM-Assisted Security and Related Frameworks**: This chunk discusses the application of transformer-based models and LLMs in security requirements engineering (SRE), highlighting their capabilities, challenges, and the importance of high-quality datasets and evaluation frameworks. It also reviews the role of security frameworks in systematically identifying and classifying security requirements in automated settings.\n\nCONTENT: 6 Yusuf G¨ ur et al.\nBeyond requirements classification, security research has also turned to\ntask-specific models for narrowly defined problems. For instance, deep learning\napproaches such as BiLSTMs have been used to detect re-entrancy vulnerabil-\nities in smart contracts, where generic models are insufficient (Maturi et al.,\n2025). This work highlights the importance of explainability, as security de-\ncisions must be understandable to support assurance and auditing. Although\nthis line of research addresses a different problem, it reflects a shift toward\ndomain-aware and interpretable models.\nTransformer-based models have enabled new capabilities in automated text\nunderstanding(Zhou et al., 2025). They possess emergent abilities like in-\ncontext learning, instruction following, and step-by-step reasoning (Zhu et al.,\n2025), which allow them to perform complex tasks, including requirements\nclassification, with minimal or no labeled data (Liu et al., 2023b; Zhu et al.,\n2025). Recent trends show a growing interest in applying LLMs to RE tasks,\nincluding requirements classification, prioritization, and traceability (Rajbhoj\net al., 2024; White et al., 2024). LLMs can perform zero-shot and few-shot\nlearning, reducing the need for large annotated datasets and facilitating adap-\ntation to specialized domains like SRE (Labrak et al., 2023). Techniques such\nas prompt engineering and integration with external knowledge bases (e.g.,\nRetrieval-Augmented Generation) further improve their performance and con-\ntextual relevance (Masoudifard et al., 2024).\nLLM-assisted security solutions typically follow a three-step process: pre-\nprocessing (extracting context like documentation or target units), prompt\ngeneration (using instructions and unfilled slots for the model to complete\nwith artifacts like fuzz drivers or patches), and post-processing (validating\noutputs, e.g., checking if generated code successfully compiles) (Zhu et al.,\n2025).\nWhile these models provide powerful automation, they can also introduce\nnew risks and errors if applied without careful oversight. This underscores the\nneed for realistic, high-quality datasets and standardized evaluation frame-\nworks to reliably assess automated security requirement classification, ensuring\nboth effectiveness and safety in practice.\nThe use of automated models in security highlights both their potential and\nthe risks they can introduce. Ensuring accurate and reliable classification of\nsecurity requirements requires evaluation against high-quality, domain-specific\nbenchmarks (Jeong, 2024). This underscores the need for realistic datasets and\nstandardized evaluation frameworks tailored to SRE.\n2.2 Related Work on Security Frameworks\nAn appropriate security framework is necessary to ensure systematic and con-\nsistent identification and classification of security requirements, particularly in\nautomated settings. This section reviews widely adopted security frameworks\nand evaluates their suitability for requirement analysis.', 'CONTEXT: **Evaluation Protocol and BERT-Based Model Classification for Security Requirements**  \nThis chunk outlines the experimental methodology for evaluating fine-tuned BERT models and LLMs in classifying implicit security requirements, detailing the dataset splits, performance metrics, and transfer learning approach used to assess domain-specific and multilingual pre-training strategies.\n\nCONTENT: 20 Yusuf G¨ ur et al.\n4 Implicit Security Requirements Classification Methodology\nThis section presents the experiment protocol used to assess the two research\nquestions regarding the performance of fine-tuned BERT variant models in\nclassification of requirements statements and LLM models with zero and few-\nshot prompting.\n4.1 Evaluation Protocol and Data Usage\nThe dataset was split into training (70%, n=1,856), validation (15%, n=398),\nand test (15%, n=398) sets, with the validation set used for hyperparameter\ntuning and the test set reserved for final evaluation. Stratified sampling based\non security class labels was applied to preserve label distributions across all\nsplits. The test set was sized to include sufficient samples of minority classes\n(e.g., V6 and V12), while the training set remained large enough to support\neffective fine-tuning.\nAlthough zero-shot LLMs do not require data partitioning and few-shot\nsettings rely on only a small number of examples, the shared test set was\nretained to ensure a fair comparison between fine-tuned model variants and\nprompt-based LLM approaches.\nWe used a comprehensive suite of metrics for classification performance\nevaluation. We report Precision, which measures the accuracy of positive pre-\ndictions, and Recall, which measures the model’s ability to identify all rele-\nvant instances. The F1-score, the harmonic mean of precision and recall, is\nused to provide a single measure balancing this trade-off. To assess overall\nperformance across all 11 security classes, we calculated the micro-averaged\nF1, which reflects aggregate accuracy, the macro-averaged F1, which assesses\nperformance by treating all classes equally regardless of their frequency, and\nthe weighted-averaged F1, which accounts for class support.\n4.2 Classification using BERT based Models\nWe conducted a comparative analysis using four distinct BERT-based mod-\nels to systematically evaluate the impact of different pre-training strategies.\nThis approach allowed us to test hypotheses related to domain-specificity, lan-\nguage, and multilingualism, with the specific technical details of each model\nsummarized in Table 5.\nFor the classification task, we adopted a standard transfer learning ap-\nproach by adding a task-specific classification “head” on top of each pre-trained\nmodel. This head consists of a single fully-connected linear layer that maps\n8 https://huggingface.co/bert-base-uncased\n9 https://huggingface.co/ehsanaghaei/SecureBERT\n10 https://huggingface.co/bert-base-multilingual-cased\n11 https://huggingface.co/dbmdz/bert-base-turkish-cased', 'CONTEXT: **Evaluation of Experimental and Commercial AI Models for Security Classification**: This chunk details the rationale and descriptions of experimental and commercial AI models, including Gemini and GPT-4o variants, used to benchmark their performance in nuanced security requirement classification, followed by an introduction to the results of fine-tuned BERT models.\n\nCONTENT: 24 Yusuf G¨ ur et al.\nTable 6 – continued from previous page\nModel Name Description Rationale in Study\ngemini-2.0-\nflash-thinking-\nexp-01-21\n(MoE Trans-\nformer;\nReasoning-\nOptimized)\nAn experimental API ver-\nsion of Google’s Gemini\nFlash model. This spe-\ncific version is optimized\nfor “thinking” (Chain-of-\nThought) processes while\nmaintaining the speed\nof the Flash series. 16\n(Google DeepMind, 2025a)\nTo evaluate the impact of built-in reasoning\non classification accuracy using an experi-\nmental commercial model accessed prior to\ngeneral availability.\ngemini-2.0-pro-\nexp-02-05\n(MoE Trans-\nformer; Large\nContext)\nAn experimental version of\nGoogle’s flagship Gemini\nPro model, representing\nthe state-of-the-art for\ncomplex, multimodal rea-\nsoning tasks. 16 (Google\nDeepMind, 2025a)\nTo assess frontier-level Gemini capabilities\nusing an experimental model accessed prior\nto general availability.\ngemini-2.5-\nflash-preview-\n04-17\n(MoE Trans-\nformer; Next-Gen\nArchitecture)\nA preview version of a\nnext-generation Gemini\nFlash model, likely offering\nenhancements in perfor-\nmance, context handling,\nand efficiency over the 2.0\nseries. 16 (Google Deep-\nMind, 2025b)\nTo assess whether preview architectural up-\ndates in an experimental, speed- and cost-\noptimized model improve detection of nu-\nanced security contexts (e.g., Stored Cryp-\ntography) using an experimental model ac-\ncessed prior to general availability.\ngpt-4o\n(Transformer;\nMultimodal)\nOpenAI’s flagship “omni”\nmodel, natively integrating\ntext, audio, and vision\nprocessing for faster and\nmore seamless interaction.\n17 (OpenAI, 2025)\nTo benchmark against the industry standard\nfor high-performance commercial models,\nserving as a control variable for proprietary\nmodel performance.\ngpt-4o-mini\n(Transformer;\nCost-Effective)\nA smaller, faster, and sig-\nnificantly cheaper version\nof GPT-4o, designed to\nmake near-GPT-4-level in-\ntelligence more accessible.\n17 (OpenAI, 2025)\nTo analyze the performance trade-off be-\ntween cost and quality, determining if\nsmaller proprietary models are sufficient for\nlarge-scale industrial requirements analysis.\n5 Results\nThis section presents both quantative and qualitative results.\n5.1 Results and Analysis for BERT Fine-Tuning\nTable 7 reports the overall results for the fine-tuned BERT variants. All mod-\nels achieved high Weighted-F1 scores, which show high performance on well-\n16 https://deepmind.google/technologies/gemini/\n17 https://openai.com/index/gpt-4o-mini-advancing-cost-effective-intelligence/', 'CONTEXT: This chunk focuses on the evaluation of various language models, including open-source and commercial models, for implicit security requirements classification, detailing their technical specifications, rationale for selection, and experimental setup involving zero-shot and few-shot prompting strategies.\n\nCONTENT: Implicit Security Requirements Classification 23\nwith fixed-LLM prompt tuning, where we provided in-context examples within\nthe prompt to guide the model’s predictions. The latter two strategies involv-\ning model fine-tuning Fixed-prompt LLM tuning and Prompt + LLM tuning)\nwere not considered due to their high computational cost. The zero shot and\nfew shot prompts can be found in Appendix A and Appendix B.\nIn these experiments, we evaluated nine language models, including open-\nsource models deployed on local infrastructure and commercial models ac-\ncessed via external application programming interfaces (APIs). The technical\nspecifications of each model and the rationale for their selection are summa-\nrized in Table 7. The requirements were processed in batches of 15 because\nproviding the full set in a single prompt exceeded the models’ context limits.\nTable 6: Details and Rationale of the LLMs Used in the Study\nModel Name Description Rationale in Study\nOpen-Source Models\ngemma-3-27b\n(Dense Trans-\nformer; 27B\nParams)\nA Google-developed lan-\nguage model trained on\na large, diverse corpus of\nweb text.13 (The Google\nGemma Team, 2025)\nTo evaluate a powerful, next-generation\nopen-source model from a major AI research\nlab, establishing a baseline for locally deploy-\nable high-parameter models.\ngemma-3-4b\n(Dense Trans-\nformer; 4B\nParams)\nA smaller, efficient model\nfrom the Gemma 3 fam-\nily, designed for resource-\nconstrained environ-\nments.13 (The Google\nGemma Team, 2025)\nTo assess the performance of a highly ef-\nficient, small-scale model to determine if\nlower-parameter models can effectively han-\ndle complex security classification tasks.\nmeta.llama3-\n3-70b-instruct-\nv1:0\n(Dense Trans-\nformer; 70B\nParams)\nAPI version of Meta’s\nLlama 3 70B Instruct.\nAn open-weight model\npre-trained on over 15T\ntokens. 14 (AI at Meta,\n2024)\nTo benchmark against a leading open-weight\nmodel known for strong reasoning and\ninstruction-following capabilities, represent-\ning the state-of-the-art in non-proprietary\nmodels.\nDeepSeek-R1\n(Mixture-of-\nExperts (MoE))\nAn API-accessible model\nfrom DeepSeek AI. As-\nsumed to be based on the\nDeepSeek-V2 architecture\n(236B total/21B active\nparams). 15 (DeepSeek AI,\n2024)\nTo include a model with a different architec-\nture (MoE) that represents an alternative,\nhighly efficient approach to scaling, specif-\nically testing its reasoning capabilities in\nsecurity contexts.\nCommercial Models (API Access)\n13 https://blog.google/technology/developers/\n14 https://ai.meta.com/blog/meta-llama-3/\n15 https://deepseek.com/']","The proposed method to improve the evaluation of model generalizability in future studies is the **leave-one-project-out cross-validation approach**. This method involves training a model on requirements from five projects and testing it on the single, held-out project. Repeating this process for all six projects provides a clearer and more realistic assessment of how well the models perform on entirely new, unseen security requirements specification (SRS) documents. This approach is significant for assessing real-world applicability. 

(Source: temp/f8ae9619-5cd2-4974-a5fc-59f0583dbf66_template.pdf)","A leave-one-project-out cross-validation approach is proposed, where the model is trained on five projects and tested on the single held-out project[cite: 737, 738].",,,
